[2022-02-17 00:00:52,724] {scheduler_job.py:155} INFO - Started process (PID=46789) to work on /airflow/dags/download_data.py
[2022-02-17 00:00:52,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 00:00:52,741] {logging_mixin.py:112} INFO - [2022-02-17 00:00:52,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 00:00:53,211] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 00:00:53,271] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 00:00:53,284] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 00:00:53,288] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 00:01:06,029] {scheduler_job.py:155} INFO - Started process (PID=46815) to work on /airflow/dags/download_data.py
[2022-02-17 00:01:06,035] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 00:01:06,039] {logging_mixin.py:112} INFO - [2022-02-17 00:01:06,038] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 00:01:07,938] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 00:01:08,061] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 00:01:08,070] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 00:01:08,076] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.047 seconds
[2022-02-17 01:01:20,764] {scheduler_job.py:155} INFO - Started process (PID=46851) to work on /airflow/dags/download_data.py
[2022-02-17 01:01:20,825] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:01:20,847] {logging_mixin.py:112} INFO - [2022-02-17 01:01:20,844] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:01:26,709] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:01:26,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:01:26,833] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:01:26,848] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 6.108 seconds
[2022-02-17 01:01:34,535] {scheduler_job.py:155} INFO - Started process (PID=46877) to work on /airflow/dags/download_data.py
[2022-02-17 01:01:34,545] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:01:34,548] {logging_mixin.py:112} INFO - [2022-02-17 01:01:34,547] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:01:35,001] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:01:35,036] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:01:35,041] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:01:35,045] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 01:01:47,836] {scheduler_job.py:155} INFO - Started process (PID=46906) to work on /airflow/dags/download_data.py
[2022-02-17 01:01:47,843] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:01:47,852] {logging_mixin.py:112} INFO - [2022-02-17 01:01:47,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:01:48,439] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:01:48,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:01:48,523] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:01:48,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.699 seconds
[2022-02-17 01:02:01,137] {scheduler_job.py:155} INFO - Started process (PID=46932) to work on /airflow/dags/download_data.py
[2022-02-17 01:02:01,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:02:01,150] {logging_mixin.py:112} INFO - [2022-02-17 01:02:01,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:02:01,594] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:02:01,647] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:02:01,655] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:02:01,660] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 01:02:14,414] {scheduler_job.py:155} INFO - Started process (PID=46960) to work on /airflow/dags/download_data.py
[2022-02-17 01:02:14,419] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:02:14,421] {logging_mixin.py:112} INFO - [2022-02-17 01:02:14,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:02:14,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:02:14,913] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:02:14,919] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:02:14,922] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 01:02:27,677] {scheduler_job.py:155} INFO - Started process (PID=46986) to work on /airflow/dags/download_data.py
[2022-02-17 01:02:27,681] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:02:27,683] {logging_mixin.py:112} INFO - [2022-02-17 01:02:27,683] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:02:28,122] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:02:28,172] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:02:28,181] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:02:28,187] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 01:02:40,959] {scheduler_job.py:155} INFO - Started process (PID=47014) to work on /airflow/dags/download_data.py
[2022-02-17 01:02:40,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:02:40,972] {logging_mixin.py:112} INFO - [2022-02-17 01:02:40,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:02:41,549] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:02:41,601] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:02:41,612] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:02:41,618] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.659 seconds
[2022-02-17 01:02:54,197] {scheduler_job.py:155} INFO - Started process (PID=47040) to work on /airflow/dags/download_data.py
[2022-02-17 01:02:54,205] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:02:54,208] {logging_mixin.py:112} INFO - [2022-02-17 01:02:54,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:02:54,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:02:54,675] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:02:54,680] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:02:54,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 01:03:07,433] {scheduler_job.py:155} INFO - Started process (PID=47066) to work on /airflow/dags/download_data.py
[2022-02-17 01:03:07,438] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:03:07,440] {logging_mixin.py:112} INFO - [2022-02-17 01:03:07,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:03:07,876] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:03:07,918] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:03:07,923] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:03:07,927] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 01:03:20,741] {scheduler_job.py:155} INFO - Started process (PID=47094) to work on /airflow/dags/download_data.py
[2022-02-17 01:03:20,749] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:03:20,751] {logging_mixin.py:112} INFO - [2022-02-17 01:03:20,751] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:03:21,196] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:03:21,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:03:21,248] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:03:21,253] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 01:03:34,011] {scheduler_job.py:155} INFO - Started process (PID=47120) to work on /airflow/dags/download_data.py
[2022-02-17 01:03:34,017] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:03:34,019] {logging_mixin.py:112} INFO - [2022-02-17 01:03:34,019] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:03:34,448] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:03:34,500] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:03:34,507] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:03:34,511] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 01:03:47,263] {scheduler_job.py:155} INFO - Started process (PID=47148) to work on /airflow/dags/download_data.py
[2022-02-17 01:03:47,269] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:03:47,271] {logging_mixin.py:112} INFO - [2022-02-17 01:03:47,271] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:03:47,727] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:03:47,786] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:03:47,795] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:03:47,803] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 01:04:00,542] {scheduler_job.py:155} INFO - Started process (PID=47174) to work on /airflow/dags/download_data.py
[2022-02-17 01:04:00,549] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:04:00,551] {logging_mixin.py:112} INFO - [2022-02-17 01:04:00,551] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:04:00,978] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:04:01,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:04:01,033] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:04:01,037] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 01:04:13,857] {scheduler_job.py:155} INFO - Started process (PID=47202) to work on /airflow/dags/download_data.py
[2022-02-17 01:04:13,867] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:04:13,870] {logging_mixin.py:112} INFO - [2022-02-17 01:04:13,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:04:14,290] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:04:14,348] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:04:14,354] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:04:14,357] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 01:04:27,156] {scheduler_job.py:155} INFO - Started process (PID=47228) to work on /airflow/dags/download_data.py
[2022-02-17 01:04:27,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:04:27,165] {logging_mixin.py:112} INFO - [2022-02-17 01:04:27,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:04:27,614] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:04:27,654] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:04:27,661] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:04:27,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 01:04:40,469] {scheduler_job.py:155} INFO - Started process (PID=47254) to work on /airflow/dags/download_data.py
[2022-02-17 01:04:40,476] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:04:40,478] {logging_mixin.py:112} INFO - [2022-02-17 01:04:40,477] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:04:40,942] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:04:40,999] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:04:41,010] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:04:41,016] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 01:04:53,772] {scheduler_job.py:155} INFO - Started process (PID=47282) to work on /airflow/dags/download_data.py
[2022-02-17 01:04:53,778] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:04:53,780] {logging_mixin.py:112} INFO - [2022-02-17 01:04:53,780] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:04:54,211] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:04:54,263] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:04:54,268] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:04:54,271] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 01:05:07,060] {scheduler_job.py:155} INFO - Started process (PID=47308) to work on /airflow/dags/download_data.py
[2022-02-17 01:05:07,065] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:05:07,066] {logging_mixin.py:112} INFO - [2022-02-17 01:05:07,066] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:05:07,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:05:07,574] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:05:07,583] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:05:07,588] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 01:05:20,382] {scheduler_job.py:155} INFO - Started process (PID=47336) to work on /airflow/dags/download_data.py
[2022-02-17 01:05:20,389] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:05:20,391] {logging_mixin.py:112} INFO - [2022-02-17 01:05:20,390] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:05:20,820] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:05:20,869] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:05:20,874] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:05:20,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 01:05:33,683] {scheduler_job.py:155} INFO - Started process (PID=47362) to work on /airflow/dags/download_data.py
[2022-02-17 01:05:33,688] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:05:33,689] {logging_mixin.py:112} INFO - [2022-02-17 01:05:33,689] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:05:34,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:05:34,170] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:05:34,178] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:05:34,183] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 01:05:46,982] {scheduler_job.py:155} INFO - Started process (PID=47390) to work on /airflow/dags/download_data.py
[2022-02-17 01:05:46,990] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:05:46,992] {logging_mixin.py:112} INFO - [2022-02-17 01:05:46,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:05:47,426] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:05:47,473] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:05:47,486] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:05:47,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 01:06:00,314] {scheduler_job.py:155} INFO - Started process (PID=47416) to work on /airflow/dags/download_data.py
[2022-02-17 01:06:00,320] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:06:00,322] {logging_mixin.py:112} INFO - [2022-02-17 01:06:00,322] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:06:00,761] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:06:00,813] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:06:00,822] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:06:00,827] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 01:06:13,632] {scheduler_job.py:155} INFO - Started process (PID=47442) to work on /airflow/dags/download_data.py
[2022-02-17 01:06:13,640] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:06:13,642] {logging_mixin.py:112} INFO - [2022-02-17 01:06:13,642] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:06:14,120] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:06:14,175] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:06:14,187] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:06:14,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 01:06:26,939] {scheduler_job.py:155} INFO - Started process (PID=47470) to work on /airflow/dags/download_data.py
[2022-02-17 01:06:26,946] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:06:26,948] {logging_mixin.py:112} INFO - [2022-02-17 01:06:26,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:06:27,384] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:06:27,433] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:06:27,441] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:06:27,446] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 01:06:40,218] {scheduler_job.py:155} INFO - Started process (PID=47496) to work on /airflow/dags/download_data.py
[2022-02-17 01:06:40,228] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:06:40,230] {logging_mixin.py:112} INFO - [2022-02-17 01:06:40,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:06:40,725] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:06:40,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:06:40,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:06:40,807] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 01:06:53,504] {scheduler_job.py:155} INFO - Started process (PID=47524) to work on /airflow/dags/download_data.py
[2022-02-17 01:06:53,508] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:06:53,510] {logging_mixin.py:112} INFO - [2022-02-17 01:06:53,509] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:06:53,944] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:06:53,991] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:06:53,999] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:06:54,005] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 01:07:06,773] {scheduler_job.py:155} INFO - Started process (PID=47550) to work on /airflow/dags/download_data.py
[2022-02-17 01:07:06,778] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:07:06,781] {logging_mixin.py:112} INFO - [2022-02-17 01:07:06,780] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:07:07,226] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:07:07,276] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:07:07,287] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:07:07,290] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 01:07:20,081] {scheduler_job.py:155} INFO - Started process (PID=47578) to work on /airflow/dags/download_data.py
[2022-02-17 01:07:20,088] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:07:20,090] {logging_mixin.py:112} INFO - [2022-02-17 01:07:20,090] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:07:20,524] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:07:20,567] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:07:20,574] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:07:20,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 01:07:33,404] {scheduler_job.py:155} INFO - Started process (PID=47604) to work on /airflow/dags/download_data.py
[2022-02-17 01:07:33,411] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:07:33,413] {logging_mixin.py:112} INFO - [2022-02-17 01:07:33,413] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:07:33,842] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:07:33,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:07:33,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:07:33,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 01:07:46,687] {scheduler_job.py:155} INFO - Started process (PID=47631) to work on /airflow/dags/download_data.py
[2022-02-17 01:07:46,705] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:07:46,708] {logging_mixin.py:112} INFO - [2022-02-17 01:07:46,707] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:07:47,325] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:07:47,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:07:47,398] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:07:47,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.718 seconds
[2022-02-17 01:07:59,944] {scheduler_job.py:155} INFO - Started process (PID=47658) to work on /airflow/dags/download_data.py
[2022-02-17 01:07:59,948] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:07:59,951] {logging_mixin.py:112} INFO - [2022-02-17 01:07:59,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:08:00,402] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:08:00,454] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:08:00,460] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:08:00,466] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 01:08:13,247] {scheduler_job.py:155} INFO - Started process (PID=47684) to work on /airflow/dags/download_data.py
[2022-02-17 01:08:13,256] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:08:13,258] {logging_mixin.py:112} INFO - [2022-02-17 01:08:13,257] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:08:13,715] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:08:13,776] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:08:13,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:08:13,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 01:08:26,502] {scheduler_job.py:155} INFO - Started process (PID=47712) to work on /airflow/dags/download_data.py
[2022-02-17 01:08:26,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:08:26,513] {logging_mixin.py:112} INFO - [2022-02-17 01:08:26,512] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:08:27,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:08:27,081] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:08:27,091] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:08:27,097] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 01:08:39,771] {scheduler_job.py:155} INFO - Started process (PID=47738) to work on /airflow/dags/download_data.py
[2022-02-17 01:08:39,776] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:08:39,778] {logging_mixin.py:112} INFO - [2022-02-17 01:08:39,778] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:08:40,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:08:40,256] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:08:40,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:08:40,265] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 01:08:53,106] {scheduler_job.py:155} INFO - Started process (PID=47766) to work on /airflow/dags/download_data.py
[2022-02-17 01:08:53,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:08:53,115] {logging_mixin.py:112} INFO - [2022-02-17 01:08:53,115] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:08:53,561] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:08:53,603] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:08:53,614] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:08:53,620] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 01:09:06,389] {scheduler_job.py:155} INFO - Started process (PID=47792) to work on /airflow/dags/download_data.py
[2022-02-17 01:09:06,396] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:09:06,399] {logging_mixin.py:112} INFO - [2022-02-17 01:09:06,398] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:09:06,796] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:09:06,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:09:06,858] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:09:06,862] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.472 seconds
[2022-02-17 01:09:19,643] {scheduler_job.py:155} INFO - Started process (PID=47820) to work on /airflow/dags/download_data.py
[2022-02-17 01:09:19,658] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:09:19,661] {logging_mixin.py:112} INFO - [2022-02-17 01:09:19,660] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:09:20,126] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:09:20,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:09:20,180] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:09:20,185] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 01:09:32,917] {scheduler_job.py:155} INFO - Started process (PID=47846) to work on /airflow/dags/download_data.py
[2022-02-17 01:09:32,925] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:09:32,927] {logging_mixin.py:112} INFO - [2022-02-17 01:09:32,926] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:09:33,364] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:09:33,404] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:09:33,414] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:09:33,420] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 01:09:46,146] {scheduler_job.py:155} INFO - Started process (PID=47872) to work on /airflow/dags/download_data.py
[2022-02-17 01:09:46,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:09:46,154] {logging_mixin.py:112} INFO - [2022-02-17 01:09:46,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:09:46,611] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:09:46,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:09:46,664] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:09:46,669] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 01:09:59,465] {scheduler_job.py:155} INFO - Started process (PID=47900) to work on /airflow/dags/download_data.py
[2022-02-17 01:09:59,469] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:09:59,471] {logging_mixin.py:112} INFO - [2022-02-17 01:09:59,471] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:09:59,912] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:09:59,962] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:09:59,968] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:09:59,974] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 01:10:12,754] {scheduler_job.py:155} INFO - Started process (PID=47926) to work on /airflow/dags/download_data.py
[2022-02-17 01:10:12,759] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:10:12,761] {logging_mixin.py:112} INFO - [2022-02-17 01:10:12,761] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:10:13,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:10:13,310] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:10:13,317] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:10:13,322] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 01:10:26,079] {scheduler_job.py:155} INFO - Started process (PID=47954) to work on /airflow/dags/download_data.py
[2022-02-17 01:10:26,083] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:10:26,085] {logging_mixin.py:112} INFO - [2022-02-17 01:10:26,085] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:10:26,514] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:10:26,564] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:10:26,571] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:10:26,574] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 01:10:39,358] {scheduler_job.py:155} INFO - Started process (PID=47980) to work on /airflow/dags/download_data.py
[2022-02-17 01:10:39,363] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:10:39,364] {logging_mixin.py:112} INFO - [2022-02-17 01:10:39,364] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:10:39,813] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:10:39,859] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:10:39,866] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:10:39,871] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 01:10:52,661] {scheduler_job.py:155} INFO - Started process (PID=48008) to work on /airflow/dags/download_data.py
[2022-02-17 01:10:52,665] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:10:52,667] {logging_mixin.py:112} INFO - [2022-02-17 01:10:52,667] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:10:53,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:10:53,116] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:10:53,121] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:10:53,124] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.464 seconds
[2022-02-17 01:11:05,957] {scheduler_job.py:155} INFO - Started process (PID=48034) to work on /airflow/dags/download_data.py
[2022-02-17 01:11:05,962] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:11:05,963] {logging_mixin.py:112} INFO - [2022-02-17 01:11:05,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:11:06,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:11:06,478] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:11:06,485] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:11:06,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 01:11:19,256] {scheduler_job.py:155} INFO - Started process (PID=48060) to work on /airflow/dags/download_data.py
[2022-02-17 01:11:19,260] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:11:19,262] {logging_mixin.py:112} INFO - [2022-02-17 01:11:19,262] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:11:19,701] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:11:19,753] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:11:19,763] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:11:19,768] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 01:11:32,527] {scheduler_job.py:155} INFO - Started process (PID=48088) to work on /airflow/dags/download_data.py
[2022-02-17 01:11:32,531] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:11:32,533] {logging_mixin.py:112} INFO - [2022-02-17 01:11:32,533] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:11:32,967] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:11:33,020] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:11:33,030] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:11:33,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 01:11:45,812] {scheduler_job.py:155} INFO - Started process (PID=48114) to work on /airflow/dags/download_data.py
[2022-02-17 01:11:45,822] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:11:45,825] {logging_mixin.py:112} INFO - [2022-02-17 01:11:45,824] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:11:46,268] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:11:46,311] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:11:46,317] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:11:46,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 01:11:59,111] {scheduler_job.py:155} INFO - Started process (PID=48142) to work on /airflow/dags/download_data.py
[2022-02-17 01:11:59,122] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:11:59,124] {logging_mixin.py:112} INFO - [2022-02-17 01:11:59,123] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:11:59,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:11:59,599] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:11:59,606] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:11:59,611] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 01:12:12,364] {scheduler_job.py:155} INFO - Started process (PID=48168) to work on /airflow/dags/download_data.py
[2022-02-17 01:12:12,371] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:12:12,373] {logging_mixin.py:112} INFO - [2022-02-17 01:12:12,372] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:12:12,880] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:12:12,930] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:12:12,939] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:12:12,943] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-17 01:12:25,677] {scheduler_job.py:155} INFO - Started process (PID=48196) to work on /airflow/dags/download_data.py
[2022-02-17 01:12:25,684] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:12:25,687] {logging_mixin.py:112} INFO - [2022-02-17 01:12:25,687] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:12:26,143] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:12:26,184] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:12:26,191] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:12:26,196] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 01:12:38,936] {scheduler_job.py:155} INFO - Started process (PID=48222) to work on /airflow/dags/download_data.py
[2022-02-17 01:12:38,942] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:12:38,945] {logging_mixin.py:112} INFO - [2022-02-17 01:12:38,944] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:12:39,370] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:12:39,423] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:12:39,432] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:12:39,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 01:12:52,226] {scheduler_job.py:155} INFO - Started process (PID=48248) to work on /airflow/dags/download_data.py
[2022-02-17 01:12:52,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:12:52,236] {logging_mixin.py:112} INFO - [2022-02-17 01:12:52,236] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:12:52,698] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:12:52,744] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:12:52,753] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:12:52,759] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 01:13:05,522] {scheduler_job.py:155} INFO - Started process (PID=48276) to work on /airflow/dags/download_data.py
[2022-02-17 01:13:05,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:13:05,529] {logging_mixin.py:112} INFO - [2022-02-17 01:13:05,529] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:13:05,978] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:13:06,027] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:13:06,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:13:06,038] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 01:13:18,806] {scheduler_job.py:155} INFO - Started process (PID=48302) to work on /airflow/dags/download_data.py
[2022-02-17 01:13:18,813] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:13:18,815] {logging_mixin.py:112} INFO - [2022-02-17 01:13:18,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:13:19,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:13:19,290] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:13:19,300] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:13:19,304] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 01:13:32,093] {scheduler_job.py:155} INFO - Started process (PID=48330) to work on /airflow/dags/download_data.py
[2022-02-17 01:13:32,097] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:13:32,099] {logging_mixin.py:112} INFO - [2022-02-17 01:13:32,099] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:13:32,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:13:32,579] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:13:32,587] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:13:32,592] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 01:13:45,386] {scheduler_job.py:155} INFO - Started process (PID=48356) to work on /airflow/dags/download_data.py
[2022-02-17 01:13:45,394] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:13:45,396] {logging_mixin.py:112} INFO - [2022-02-17 01:13:45,396] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:13:45,864] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:13:45,929] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:13:45,941] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:13:45,945] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 01:13:58,680] {scheduler_job.py:155} INFO - Started process (PID=48384) to work on /airflow/dags/download_data.py
[2022-02-17 01:13:58,685] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:13:58,687] {logging_mixin.py:112} INFO - [2022-02-17 01:13:58,686] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:13:59,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:13:59,158] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:13:59,166] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:13:59,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 01:14:11,965] {scheduler_job.py:155} INFO - Started process (PID=48410) to work on /airflow/dags/download_data.py
[2022-02-17 01:14:11,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:14:11,972] {logging_mixin.py:112} INFO - [2022-02-17 01:14:11,971] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:14:12,460] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:14:12,510] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:14:12,525] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:14:12,536] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 01:14:25,299] {scheduler_job.py:155} INFO - Started process (PID=48437) to work on /airflow/dags/download_data.py
[2022-02-17 01:14:25,313] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:14:25,317] {logging_mixin.py:112} INFO - [2022-02-17 01:14:25,316] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:14:25,866] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:14:25,901] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:14:25,906] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:14:25,909] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-17 01:14:38,593] {scheduler_job.py:155} INFO - Started process (PID=48464) to work on /airflow/dags/download_data.py
[2022-02-17 01:14:38,597] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:14:38,599] {logging_mixin.py:112} INFO - [2022-02-17 01:14:38,599] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:14:39,052] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:14:39,094] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:14:39,103] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:14:39,109] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 01:14:51,894] {scheduler_job.py:155} INFO - Started process (PID=48490) to work on /airflow/dags/download_data.py
[2022-02-17 01:14:51,901] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:14:51,903] {logging_mixin.py:112} INFO - [2022-02-17 01:14:51,903] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:14:52,329] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:14:52,371] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:14:52,377] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:14:52,381] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.487 seconds
[2022-02-17 01:15:05,178] {scheduler_job.py:155} INFO - Started process (PID=48518) to work on /airflow/dags/download_data.py
[2022-02-17 01:15:05,182] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:15:05,184] {logging_mixin.py:112} INFO - [2022-02-17 01:15:05,184] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:15:05,621] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:15:05,659] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:15:05,667] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:15:05,673] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 01:15:18,440] {scheduler_job.py:155} INFO - Started process (PID=48544) to work on /airflow/dags/download_data.py
[2022-02-17 01:15:18,445] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:15:18,446] {logging_mixin.py:112} INFO - [2022-02-17 01:15:18,446] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:15:18,885] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:15:18,926] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:15:18,933] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:15:18,939] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 01:15:31,728] {scheduler_job.py:155} INFO - Started process (PID=48572) to work on /airflow/dags/download_data.py
[2022-02-17 01:15:31,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:15:31,734] {logging_mixin.py:112} INFO - [2022-02-17 01:15:31,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:15:32,185] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:15:32,236] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:15:32,245] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:15:32,249] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 01:15:44,995] {scheduler_job.py:155} INFO - Started process (PID=48598) to work on /airflow/dags/download_data.py
[2022-02-17 01:15:44,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:15:45,001] {logging_mixin.py:112} INFO - [2022-02-17 01:15:45,001] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:15:45,474] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:15:45,519] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:15:45,533] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:15:45,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 01:15:58,328] {scheduler_job.py:155} INFO - Started process (PID=48626) to work on /airflow/dags/download_data.py
[2022-02-17 01:15:58,344] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:15:58,346] {logging_mixin.py:112} INFO - [2022-02-17 01:15:58,346] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:15:58,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:15:58,840] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:15:58,846] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:15:58,850] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 01:16:11,584] {scheduler_job.py:155} INFO - Started process (PID=48652) to work on /airflow/dags/download_data.py
[2022-02-17 01:16:11,590] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:16:11,592] {logging_mixin.py:112} INFO - [2022-02-17 01:16:11,592] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:16:12,086] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:16:12,133] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:16:12,139] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:16:12,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 01:16:24,855] {scheduler_job.py:155} INFO - Started process (PID=48678) to work on /airflow/dags/download_data.py
[2022-02-17 01:16:24,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:16:24,862] {logging_mixin.py:112} INFO - [2022-02-17 01:16:24,862] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:16:25,332] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:16:25,365] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:16:25,370] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:16:25,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 01:16:38,167] {scheduler_job.py:155} INFO - Started process (PID=48706) to work on /airflow/dags/download_data.py
[2022-02-17 01:16:38,174] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:16:38,178] {logging_mixin.py:112} INFO - [2022-02-17 01:16:38,178] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:16:38,607] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:16:38,652] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:16:38,661] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:16:38,664] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 01:16:51,478] {scheduler_job.py:155} INFO - Started process (PID=48732) to work on /airflow/dags/download_data.py
[2022-02-17 01:16:51,483] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:16:51,485] {logging_mixin.py:112} INFO - [2022-02-17 01:16:51,485] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:16:51,916] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:16:51,956] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:16:51,962] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:16:51,968] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-17 01:17:04,714] {scheduler_job.py:155} INFO - Started process (PID=48760) to work on /airflow/dags/download_data.py
[2022-02-17 01:17:04,719] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:17:04,720] {logging_mixin.py:112} INFO - [2022-02-17 01:17:04,720] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:17:05,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:17:05,223] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:17:05,234] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:17:05,238] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 01:17:17,991] {scheduler_job.py:155} INFO - Started process (PID=48786) to work on /airflow/dags/download_data.py
[2022-02-17 01:17:17,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:17:18,000] {logging_mixin.py:112} INFO - [2022-02-17 01:17:18,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:17:18,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:17:18,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:17:18,512] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:17:18,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 01:17:31,274] {scheduler_job.py:155} INFO - Started process (PID=48814) to work on /airflow/dags/download_data.py
[2022-02-17 01:17:31,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:17:31,280] {logging_mixin.py:112} INFO - [2022-02-17 01:17:31,279] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:17:31,704] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:17:31,752] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:17:31,758] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:17:31,764] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 01:17:44,544] {scheduler_job.py:155} INFO - Started process (PID=48840) to work on /airflow/dags/download_data.py
[2022-02-17 01:17:44,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:17:44,558] {logging_mixin.py:112} INFO - [2022-02-17 01:17:44,558] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:17:45,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:17:45,056] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:17:45,067] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:17:45,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 01:17:57,832] {scheduler_job.py:155} INFO - Started process (PID=48866) to work on /airflow/dags/download_data.py
[2022-02-17 01:17:57,845] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:17:57,848] {logging_mixin.py:112} INFO - [2022-02-17 01:17:57,847] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:17:58,298] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:17:58,331] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:17:58,336] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:17:58,340] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 01:18:11,103] {scheduler_job.py:155} INFO - Started process (PID=48894) to work on /airflow/dags/download_data.py
[2022-02-17 01:18:11,108] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:18:11,111] {logging_mixin.py:112} INFO - [2022-02-17 01:18:11,111] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:18:11,568] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:18:11,636] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:18:11,646] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:18:11,653] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 01:18:24,406] {scheduler_job.py:155} INFO - Started process (PID=48920) to work on /airflow/dags/download_data.py
[2022-02-17 01:18:24,412] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:18:24,414] {logging_mixin.py:112} INFO - [2022-02-17 01:18:24,414] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:18:24,836] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:18:24,883] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:18:24,889] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:18:24,893] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.487 seconds
[2022-02-17 01:18:37,648] {scheduler_job.py:155} INFO - Started process (PID=48948) to work on /airflow/dags/download_data.py
[2022-02-17 01:18:37,654] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:18:37,655] {logging_mixin.py:112} INFO - [2022-02-17 01:18:37,655] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:18:38,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:18:38,162] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:18:38,170] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:18:38,176] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 01:18:50,961] {scheduler_job.py:155} INFO - Started process (PID=48974) to work on /airflow/dags/download_data.py
[2022-02-17 01:18:50,972] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:18:50,976] {logging_mixin.py:112} INFO - [2022-02-17 01:18:50,974] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:18:51,408] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:18:51,448] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:18:51,454] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:18:51,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 01:19:04,210] {scheduler_job.py:155} INFO - Started process (PID=49002) to work on /airflow/dags/download_data.py
[2022-02-17 01:19:04,220] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:19:04,222] {logging_mixin.py:112} INFO - [2022-02-17 01:19:04,222] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:19:04,658] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:19:04,695] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:19:04,700] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:19:04,704] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 01:19:17,478] {scheduler_job.py:155} INFO - Started process (PID=49028) to work on /airflow/dags/download_data.py
[2022-02-17 01:19:17,482] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:19:17,484] {logging_mixin.py:112} INFO - [2022-02-17 01:19:17,484] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:19:17,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:19:17,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:19:17,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:19:17,970] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 01:19:30,811] {scheduler_job.py:155} INFO - Started process (PID=49054) to work on /airflow/dags/download_data.py
[2022-02-17 01:19:30,817] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:19:30,819] {logging_mixin.py:112} INFO - [2022-02-17 01:19:30,818] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:19:31,249] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:19:31,294] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:19:31,301] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:19:31,304] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 01:19:44,071] {scheduler_job.py:155} INFO - Started process (PID=49082) to work on /airflow/dags/download_data.py
[2022-02-17 01:19:44,076] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:19:44,078] {logging_mixin.py:112} INFO - [2022-02-17 01:19:44,077] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:19:44,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:19:44,634] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:19:44,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:19:44,651] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-17 01:19:57,321] {scheduler_job.py:155} INFO - Started process (PID=49108) to work on /airflow/dags/download_data.py
[2022-02-17 01:19:57,326] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:19:57,328] {logging_mixin.py:112} INFO - [2022-02-17 01:19:57,328] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:19:57,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:19:57,872] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:19:57,878] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:19:57,882] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 01:20:10,576] {scheduler_job.py:155} INFO - Started process (PID=49136) to work on /airflow/dags/download_data.py
[2022-02-17 01:20:10,582] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:20:10,584] {logging_mixin.py:112} INFO - [2022-02-17 01:20:10,584] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:20:11,062] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:20:11,131] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:20:11,144] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:20:11,153] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 01:20:23,869] {scheduler_job.py:155} INFO - Started process (PID=49162) to work on /airflow/dags/download_data.py
[2022-02-17 01:20:23,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:20:23,877] {logging_mixin.py:112} INFO - [2022-02-17 01:20:23,877] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:20:24,317] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:20:24,360] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:20:24,366] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:20:24,371] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 01:20:37,117] {scheduler_job.py:155} INFO - Started process (PID=49190) to work on /airflow/dags/download_data.py
[2022-02-17 01:20:37,121] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:20:37,122] {logging_mixin.py:112} INFO - [2022-02-17 01:20:37,122] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:20:37,572] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:20:37,622] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:20:37,631] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:20:37,635] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 01:20:50,440] {scheduler_job.py:155} INFO - Started process (PID=49216) to work on /airflow/dags/download_data.py
[2022-02-17 01:20:50,449] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:20:50,453] {logging_mixin.py:112} INFO - [2022-02-17 01:20:50,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:20:50,905] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:20:50,948] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:20:50,956] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:20:50,960] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 01:21:03,769] {scheduler_job.py:155} INFO - Started process (PID=49243) to work on /airflow/dags/download_data.py
[2022-02-17 01:21:03,780] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:21:03,783] {logging_mixin.py:112} INFO - [2022-02-17 01:21:03,782] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:21:04,279] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:21:04,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:21:04,321] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:21:04,325] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 01:21:16,977] {scheduler_job.py:155} INFO - Started process (PID=49270) to work on /airflow/dags/download_data.py
[2022-02-17 01:21:16,983] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:21:16,984] {logging_mixin.py:112} INFO - [2022-02-17 01:21:16,984] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:21:17,418] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:21:17,461] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:21:17,469] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:21:17,474] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 01:21:30,270] {scheduler_job.py:155} INFO - Started process (PID=49296) to work on /airflow/dags/download_data.py
[2022-02-17 01:21:30,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:21:30,286] {logging_mixin.py:112} INFO - [2022-02-17 01:21:30,286] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:21:30,721] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:21:30,764] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:21:30,770] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:21:30,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 01:21:43,504] {scheduler_job.py:155} INFO - Started process (PID=49324) to work on /airflow/dags/download_data.py
[2022-02-17 01:21:43,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:21:43,513] {logging_mixin.py:112} INFO - [2022-02-17 01:21:43,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:21:43,983] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:21:44,037] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:21:44,049] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:21:44,056] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 01:21:56,792] {scheduler_job.py:155} INFO - Started process (PID=49350) to work on /airflow/dags/download_data.py
[2022-02-17 01:21:56,800] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:21:56,802] {logging_mixin.py:112} INFO - [2022-02-17 01:21:56,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:21:57,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:21:57,276] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:21:57,286] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:21:57,291] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 01:22:10,057] {scheduler_job.py:155} INFO - Started process (PID=49378) to work on /airflow/dags/download_data.py
[2022-02-17 01:22:10,062] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:22:10,064] {logging_mixin.py:112} INFO - [2022-02-17 01:22:10,064] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:22:10,524] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:22:10,574] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:22:10,584] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:22:10,589] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 01:22:24,416] {scheduler_job.py:155} INFO - Started process (PID=49404) to work on /airflow/dags/download_data.py
[2022-02-17 01:22:24,423] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:22:24,425] {logging_mixin.py:112} INFO - [2022-02-17 01:22:24,425] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:22:24,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:22:24,900] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:22:24,908] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:22:24,912] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 01:22:37,725] {scheduler_job.py:155} INFO - Started process (PID=49432) to work on /airflow/dags/download_data.py
[2022-02-17 01:22:37,731] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:22:37,734] {logging_mixin.py:112} INFO - [2022-02-17 01:22:37,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:22:38,159] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:22:38,212] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:22:38,221] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:22:38,229] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 01:22:51,039] {scheduler_job.py:155} INFO - Started process (PID=49458) to work on /airflow/dags/download_data.py
[2022-02-17 01:22:51,045] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:22:51,047] {logging_mixin.py:112} INFO - [2022-02-17 01:22:51,047] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:22:51,483] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:22:51,535] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:22:51,542] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:22:51,545] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 01:23:04,335] {scheduler_job.py:155} INFO - Started process (PID=49484) to work on /airflow/dags/download_data.py
[2022-02-17 01:23:04,339] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:23:04,341] {logging_mixin.py:112} INFO - [2022-02-17 01:23:04,341] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:23:04,774] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:23:04,813] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:23:04,821] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:23:04,826] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 01:23:17,619] {scheduler_job.py:155} INFO - Started process (PID=49512) to work on /airflow/dags/download_data.py
[2022-02-17 01:23:17,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:23:17,628] {logging_mixin.py:112} INFO - [2022-02-17 01:23:17,628] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:23:18,044] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:23:18,095] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:23:18,100] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:23:18,104] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-17 01:23:30,971] {scheduler_job.py:155} INFO - Started process (PID=49538) to work on /airflow/dags/download_data.py
[2022-02-17 01:23:30,978] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:23:30,980] {logging_mixin.py:112} INFO - [2022-02-17 01:23:30,979] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:23:31,424] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:23:31,466] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:23:31,473] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:23:31,479] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 01:23:44,224] {scheduler_job.py:155} INFO - Started process (PID=49566) to work on /airflow/dags/download_data.py
[2022-02-17 01:23:44,228] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:23:44,230] {logging_mixin.py:112} INFO - [2022-02-17 01:23:44,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:23:44,703] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:23:44,769] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:23:44,784] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:23:44,790] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 01:23:57,563] {scheduler_job.py:155} INFO - Started process (PID=49592) to work on /airflow/dags/download_data.py
[2022-02-17 01:23:57,567] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:23:57,569] {logging_mixin.py:112} INFO - [2022-02-17 01:23:57,568] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:23:58,018] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:23:58,075] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:23:58,083] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:23:58,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 01:24:10,834] {scheduler_job.py:155} INFO - Started process (PID=49620) to work on /airflow/dags/download_data.py
[2022-02-17 01:24:10,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:24:10,850] {logging_mixin.py:112} INFO - [2022-02-17 01:24:10,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:24:11,325] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:24:11,385] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:24:11,395] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:24:11,400] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 01:24:24,099] {scheduler_job.py:155} INFO - Started process (PID=49646) to work on /airflow/dags/download_data.py
[2022-02-17 01:24:24,107] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:24:24,109] {logging_mixin.py:112} INFO - [2022-02-17 01:24:24,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:24:24,550] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:24:24,599] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:24:24,605] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:24:24,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 01:24:37,345] {scheduler_job.py:155} INFO - Started process (PID=49672) to work on /airflow/dags/download_data.py
[2022-02-17 01:24:37,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:24:37,351] {logging_mixin.py:112} INFO - [2022-02-17 01:24:37,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:24:37,802] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:24:37,841] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:24:37,849] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:24:37,854] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 01:24:50,631] {scheduler_job.py:155} INFO - Started process (PID=49700) to work on /airflow/dags/download_data.py
[2022-02-17 01:24:50,642] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:24:50,644] {logging_mixin.py:112} INFO - [2022-02-17 01:24:50,644] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:24:51,092] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:24:51,139] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:24:51,148] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:24:51,155] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 01:25:03,926] {scheduler_job.py:155} INFO - Started process (PID=49726) to work on /airflow/dags/download_data.py
[2022-02-17 01:25:03,933] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:25:03,934] {logging_mixin.py:112} INFO - [2022-02-17 01:25:03,934] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:25:04,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:25:04,416] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:25:04,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:25:04,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 01:25:17,191] {scheduler_job.py:155} INFO - Started process (PID=49754) to work on /airflow/dags/download_data.py
[2022-02-17 01:25:17,195] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:25:17,197] {logging_mixin.py:112} INFO - [2022-02-17 01:25:17,197] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:25:17,638] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:25:17,678] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:25:17,684] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:25:17,687] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 01:25:30,510] {scheduler_job.py:155} INFO - Started process (PID=49780) to work on /airflow/dags/download_data.py
[2022-02-17 01:25:30,517] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:25:30,519] {logging_mixin.py:112} INFO - [2022-02-17 01:25:30,519] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:25:31,005] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:25:31,058] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:25:31,069] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:25:31,075] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 01:25:43,761] {scheduler_job.py:155} INFO - Started process (PID=49808) to work on /airflow/dags/download_data.py
[2022-02-17 01:25:43,771] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:25:43,773] {logging_mixin.py:112} INFO - [2022-02-17 01:25:43,773] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:25:44,218] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:25:44,275] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:25:44,284] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:25:44,289] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 01:25:57,078] {scheduler_job.py:155} INFO - Started process (PID=49834) to work on /airflow/dags/download_data.py
[2022-02-17 01:25:57,084] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:25:57,085] {logging_mixin.py:112} INFO - [2022-02-17 01:25:57,085] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:25:57,527] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:25:57,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:25:57,585] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:25:57,589] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 01:26:10,416] {scheduler_job.py:155} INFO - Started process (PID=49861) to work on /airflow/dags/download_data.py
[2022-02-17 01:26:10,433] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:26:10,435] {logging_mixin.py:112} INFO - [2022-02-17 01:26:10,435] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:26:11,126] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:26:11,186] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:26:11,197] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:26:11,204] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.788 seconds
[2022-02-17 01:26:23,692] {scheduler_job.py:155} INFO - Started process (PID=49888) to work on /airflow/dags/download_data.py
[2022-02-17 01:26:23,697] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:26:23,699] {logging_mixin.py:112} INFO - [2022-02-17 01:26:23,699] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:26:24,141] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:26:24,187] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:26:24,194] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:26:24,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 01:26:36,951] {scheduler_job.py:155} INFO - Started process (PID=49914) to work on /airflow/dags/download_data.py
[2022-02-17 01:26:36,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:26:36,960] {logging_mixin.py:112} INFO - [2022-02-17 01:26:36,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:26:37,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:26:37,447] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:26:37,457] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:26:37,464] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 01:26:50,266] {scheduler_job.py:155} INFO - Started process (PID=49942) to work on /airflow/dags/download_data.py
[2022-02-17 01:26:50,274] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:26:50,276] {logging_mixin.py:112} INFO - [2022-02-17 01:26:50,276] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:26:50,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:26:50,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:26:50,822] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:26:50,826] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 01:27:03,551] {scheduler_job.py:155} INFO - Started process (PID=49968) to work on /airflow/dags/download_data.py
[2022-02-17 01:27:03,560] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:27:03,563] {logging_mixin.py:112} INFO - [2022-02-17 01:27:03,562] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:27:03,994] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:27:04,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:27:04,044] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:27:04,050] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 01:27:16,780] {scheduler_job.py:155} INFO - Started process (PID=49996) to work on /airflow/dags/download_data.py
[2022-02-17 01:27:16,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:27:16,785] {logging_mixin.py:112} INFO - [2022-02-17 01:27:16,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:27:17,224] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:27:17,264] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:27:17,273] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:27:17,278] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 01:27:30,078] {scheduler_job.py:155} INFO - Started process (PID=50022) to work on /airflow/dags/download_data.py
[2022-02-17 01:27:30,087] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:27:30,088] {logging_mixin.py:112} INFO - [2022-02-17 01:27:30,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:27:30,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:27:30,575] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:27:30,583] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:27:30,587] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 01:27:43,382] {scheduler_job.py:155} INFO - Started process (PID=50050) to work on /airflow/dags/download_data.py
[2022-02-17 01:27:43,387] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:27:43,389] {logging_mixin.py:112} INFO - [2022-02-17 01:27:43,389] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:27:43,871] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:27:43,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:27:43,944] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:27:43,950] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 01:27:56,664] {scheduler_job.py:155} INFO - Started process (PID=50076) to work on /airflow/dags/download_data.py
[2022-02-17 01:27:56,671] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:27:56,673] {logging_mixin.py:112} INFO - [2022-02-17 01:27:56,672] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:27:57,101] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:27:57,154] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:27:57,162] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:27:57,169] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 01:28:09,954] {scheduler_job.py:155} INFO - Started process (PID=50102) to work on /airflow/dags/download_data.py
[2022-02-17 01:28:09,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:28:09,963] {logging_mixin.py:112} INFO - [2022-02-17 01:28:09,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:28:10,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:28:10,460] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:28:10,470] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:28:10,475] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 01:28:23,255] {scheduler_job.py:155} INFO - Started process (PID=50130) to work on /airflow/dags/download_data.py
[2022-02-17 01:28:23,260] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:28:23,262] {logging_mixin.py:112} INFO - [2022-02-17 01:28:23,262] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:28:23,696] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:28:23,746] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:28:23,752] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:28:23,757] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 01:28:36,519] {scheduler_job.py:155} INFO - Started process (PID=50156) to work on /airflow/dags/download_data.py
[2022-02-17 01:28:36,523] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:28:36,525] {logging_mixin.py:112} INFO - [2022-02-17 01:28:36,525] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:28:36,965] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:28:37,010] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:28:37,015] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:28:37,018] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 01:28:49,786] {scheduler_job.py:155} INFO - Started process (PID=50184) to work on /airflow/dags/download_data.py
[2022-02-17 01:28:49,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:28:49,793] {logging_mixin.py:112} INFO - [2022-02-17 01:28:49,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:28:50,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:28:50,302] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:28:50,309] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:28:50,315] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 01:29:03,077] {scheduler_job.py:155} INFO - Started process (PID=50210) to work on /airflow/dags/download_data.py
[2022-02-17 01:29:03,081] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:29:03,083] {logging_mixin.py:112} INFO - [2022-02-17 01:29:03,083] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:29:03,536] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:29:03,584] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:29:03,592] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:29:03,597] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 01:29:16,356] {scheduler_job.py:155} INFO - Started process (PID=50238) to work on /airflow/dags/download_data.py
[2022-02-17 01:29:16,362] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:29:16,364] {logging_mixin.py:112} INFO - [2022-02-17 01:29:16,364] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:29:16,780] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:29:16,820] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:29:16,826] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:29:16,831] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.475 seconds
[2022-02-17 01:29:29,623] {scheduler_job.py:155} INFO - Started process (PID=50264) to work on /airflow/dags/download_data.py
[2022-02-17 01:29:29,632] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:29:29,635] {logging_mixin.py:112} INFO - [2022-02-17 01:29:29,634] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:29:30,068] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:29:30,113] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:29:30,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:29:30,126] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 01:29:42,908] {scheduler_job.py:155} INFO - Started process (PID=50290) to work on /airflow/dags/download_data.py
[2022-02-17 01:29:42,918] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:29:42,921] {logging_mixin.py:112} INFO - [2022-02-17 01:29:42,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:29:43,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:29:43,419] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:29:43,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:29:43,436] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 01:29:56,206] {scheduler_job.py:155} INFO - Started process (PID=50318) to work on /airflow/dags/download_data.py
[2022-02-17 01:29:56,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:29:56,215] {logging_mixin.py:112} INFO - [2022-02-17 01:29:56,214] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:29:56,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:29:56,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:29:56,706] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:29:56,710] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 01:30:09,449] {scheduler_job.py:155} INFO - Started process (PID=50344) to work on /airflow/dags/download_data.py
[2022-02-17 01:30:09,453] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:30:09,454] {logging_mixin.py:112} INFO - [2022-02-17 01:30:09,454] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:30:09,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:30:09,933] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:30:09,938] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:30:09,942] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 01:30:22,748] {scheduler_job.py:155} INFO - Started process (PID=50372) to work on /airflow/dags/download_data.py
[2022-02-17 01:30:22,758] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:30:22,760] {logging_mixin.py:112} INFO - [2022-02-17 01:30:22,759] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:30:23,196] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:30:23,235] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:30:23,244] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:30:23,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 01:30:36,026] {scheduler_job.py:155} INFO - Started process (PID=50398) to work on /airflow/dags/download_data.py
[2022-02-17 01:30:36,030] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:30:36,032] {logging_mixin.py:112} INFO - [2022-02-17 01:30:36,032] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:30:36,474] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:30:36,524] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:30:36,530] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:30:36,534] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 01:30:49,339] {scheduler_job.py:155} INFO - Started process (PID=50426) to work on /airflow/dags/download_data.py
[2022-02-17 01:30:49,347] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:30:49,350] {logging_mixin.py:112} INFO - [2022-02-17 01:30:49,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:30:49,846] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:30:49,908] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:30:49,919] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:30:49,925] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 01:31:02,580] {scheduler_job.py:155} INFO - Started process (PID=50452) to work on /airflow/dags/download_data.py
[2022-02-17 01:31:02,584] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:31:02,586] {logging_mixin.py:112} INFO - [2022-02-17 01:31:02,586] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:31:03,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:31:03,199] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:31:03,209] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:31:03,214] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.634 seconds
[2022-02-17 01:31:17,003] {scheduler_job.py:155} INFO - Started process (PID=50479) to work on /airflow/dags/download_data.py
[2022-02-17 01:31:17,021] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 01:31:17,024] {logging_mixin.py:112} INFO - [2022-02-17 01:31:17,024] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 01:31:17,751] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 01:31:17,834] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 01:31:17,959] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 01:31:17,992] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.991 seconds
[2022-02-17 02:02:47,540] {scheduler_job.py:155} INFO - Started process (PID=50516) to work on /airflow/dags/download_data.py
[2022-02-17 02:02:47,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:02:47,570] {logging_mixin.py:112} INFO - [2022-02-17 02:02:47,567] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:02:48,934] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:02:49,075] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:02:49,101] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:02:49,113] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.573 seconds
[2022-02-17 02:03:00,778] {scheduler_job.py:155} INFO - Started process (PID=50541) to work on /airflow/dags/download_data.py
[2022-02-17 02:03:00,783] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:03:00,784] {logging_mixin.py:112} INFO - [2022-02-17 02:03:00,784] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:03:01,254] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:03:01,311] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:03:01,324] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:03:01,330] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 02:03:13,070] {scheduler_job.py:155} INFO - Started process (PID=50566) to work on /airflow/dags/download_data.py
[2022-02-17 02:03:13,074] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:03:13,076] {logging_mixin.py:112} INFO - [2022-02-17 02:03:13,076] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:03:13,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:03:13,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:03:13,597] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:03:13,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 02:03:26,364] {scheduler_job.py:155} INFO - Started process (PID=50594) to work on /airflow/dags/download_data.py
[2022-02-17 02:03:26,370] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:03:26,372] {logging_mixin.py:112} INFO - [2022-02-17 02:03:26,372] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:03:26,829] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:03:26,880] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:03:26,886] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:03:26,890] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 02:03:39,682] {scheduler_job.py:155} INFO - Started process (PID=50620) to work on /airflow/dags/download_data.py
[2022-02-17 02:03:39,689] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:03:39,692] {logging_mixin.py:112} INFO - [2022-02-17 02:03:39,691] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:03:40,126] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:03:40,178] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:03:40,188] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:03:40,193] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 02:03:52,980] {scheduler_job.py:155} INFO - Started process (PID=50648) to work on /airflow/dags/download_data.py
[2022-02-17 02:03:52,987] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:03:52,990] {logging_mixin.py:112} INFO - [2022-02-17 02:03:52,989] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:03:53,453] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:03:53,519] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:03:53,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:03:53,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 02:04:06,264] {scheduler_job.py:155} INFO - Started process (PID=50674) to work on /airflow/dags/download_data.py
[2022-02-17 02:04:06,272] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:04:06,274] {logging_mixin.py:112} INFO - [2022-02-17 02:04:06,274] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:04:06,711] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:04:06,762] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:04:06,769] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:04:06,775] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 02:04:19,526] {scheduler_job.py:155} INFO - Started process (PID=50702) to work on /airflow/dags/download_data.py
[2022-02-17 02:04:19,533] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:04:19,535] {logging_mixin.py:112} INFO - [2022-02-17 02:04:19,535] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:04:19,973] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:04:20,026] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:04:20,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:04:20,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 02:04:32,801] {scheduler_job.py:155} INFO - Started process (PID=50728) to work on /airflow/dags/download_data.py
[2022-02-17 02:04:32,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:04:32,810] {logging_mixin.py:112} INFO - [2022-02-17 02:04:32,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:04:33,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:04:33,337] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:04:33,345] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:04:33,350] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 02:04:46,039] {scheduler_job.py:155} INFO - Started process (PID=50754) to work on /airflow/dags/download_data.py
[2022-02-17 02:04:46,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:04:46,047] {logging_mixin.py:112} INFO - [2022-02-17 02:04:46,047] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:04:46,483] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:04:46,524] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:04:46,534] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:04:46,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 02:04:59,354] {scheduler_job.py:155} INFO - Started process (PID=50782) to work on /airflow/dags/download_data.py
[2022-02-17 02:04:59,359] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:04:59,361] {logging_mixin.py:112} INFO - [2022-02-17 02:04:59,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:04:59,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:04:59,885] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:04:59,897] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:04:59,903] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 02:05:12,659] {scheduler_job.py:155} INFO - Started process (PID=50808) to work on /airflow/dags/download_data.py
[2022-02-17 02:05:12,666] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:05:12,668] {logging_mixin.py:112} INFO - [2022-02-17 02:05:12,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:05:13,094] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:05:13,145] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:05:13,151] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:05:13,156] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 02:05:25,978] {scheduler_job.py:155} INFO - Started process (PID=50836) to work on /airflow/dags/download_data.py
[2022-02-17 02:05:25,982] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:05:25,985] {logging_mixin.py:112} INFO - [2022-02-17 02:05:25,984] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:05:26,440] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:05:26,492] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:05:26,500] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:05:26,505] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 02:05:39,292] {scheduler_job.py:155} INFO - Started process (PID=50862) to work on /airflow/dags/download_data.py
[2022-02-17 02:05:39,306] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:05:39,308] {logging_mixin.py:112} INFO - [2022-02-17 02:05:39,308] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:05:39,740] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:05:39,791] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:05:39,798] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:05:39,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 02:05:52,609] {scheduler_job.py:155} INFO - Started process (PID=50890) to work on /airflow/dags/download_data.py
[2022-02-17 02:05:52,619] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:05:52,625] {logging_mixin.py:112} INFO - [2022-02-17 02:05:52,625] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:05:53,182] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:05:53,244] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:05:53,252] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:05:53,256] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-17 02:06:05,921] {scheduler_job.py:155} INFO - Started process (PID=50916) to work on /airflow/dags/download_data.py
[2022-02-17 02:06:05,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:06:05,933] {logging_mixin.py:112} INFO - [2022-02-17 02:06:05,932] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:06:06,387] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:06:06,448] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:06:06,455] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:06:06,460] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 02:06:19,154] {scheduler_job.py:155} INFO - Started process (PID=50942) to work on /airflow/dags/download_data.py
[2022-02-17 02:06:19,159] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:06:19,161] {logging_mixin.py:112} INFO - [2022-02-17 02:06:19,161] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:06:19,599] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:06:19,649] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:06:19,655] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:06:19,658] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 02:06:32,437] {scheduler_job.py:155} INFO - Started process (PID=50970) to work on /airflow/dags/download_data.py
[2022-02-17 02:06:32,443] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:06:32,445] {logging_mixin.py:112} INFO - [2022-02-17 02:06:32,444] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:06:32,877] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:06:32,922] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:06:32,929] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:06:32,934] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 02:06:45,701] {scheduler_job.py:155} INFO - Started process (PID=50996) to work on /airflow/dags/download_data.py
[2022-02-17 02:06:45,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:06:45,709] {logging_mixin.py:112} INFO - [2022-02-17 02:06:45,708] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:06:46,153] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:06:46,211] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:06:46,220] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:06:46,226] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 02:06:59,025] {scheduler_job.py:155} INFO - Started process (PID=51024) to work on /airflow/dags/download_data.py
[2022-02-17 02:06:59,029] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:06:59,031] {logging_mixin.py:112} INFO - [2022-02-17 02:06:59,031] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:06:59,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:06:59,549] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:06:59,558] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:06:59,563] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 02:07:12,341] {scheduler_job.py:155} INFO - Started process (PID=51050) to work on /airflow/dags/download_data.py
[2022-02-17 02:07:12,346] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:07:12,347] {logging_mixin.py:112} INFO - [2022-02-17 02:07:12,347] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:07:12,780] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:07:12,825] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:07:12,832] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:07:12,837] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 02:07:25,619] {scheduler_job.py:155} INFO - Started process (PID=51078) to work on /airflow/dags/download_data.py
[2022-02-17 02:07:25,624] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:07:25,626] {logging_mixin.py:112} INFO - [2022-02-17 02:07:25,625] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:07:26,078] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:07:26,119] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:07:26,125] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:07:26,128] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 02:07:38,935] {scheduler_job.py:155} INFO - Started process (PID=51104) to work on /airflow/dags/download_data.py
[2022-02-17 02:07:38,944] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:07:38,946] {logging_mixin.py:112} INFO - [2022-02-17 02:07:38,945] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:07:39,372] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:07:39,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:07:39,432] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:07:39,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 02:07:52,293] {scheduler_job.py:155} INFO - Started process (PID=51132) to work on /airflow/dags/download_data.py
[2022-02-17 02:07:52,306] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:07:52,309] {logging_mixin.py:112} INFO - [2022-02-17 02:07:52,308] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:07:52,842] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:07:52,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:07:52,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:07:52,903] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-17 02:08:05,583] {scheduler_job.py:155} INFO - Started process (PID=51158) to work on /airflow/dags/download_data.py
[2022-02-17 02:08:05,588] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:08:05,589] {logging_mixin.py:112} INFO - [2022-02-17 02:08:05,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:08:06,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:08:06,075] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:08:06,082] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:08:06,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 02:08:18,875] {scheduler_job.py:155} INFO - Started process (PID=51184) to work on /airflow/dags/download_data.py
[2022-02-17 02:08:18,889] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:08:18,891] {logging_mixin.py:112} INFO - [2022-02-17 02:08:18,891] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:08:19,317] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:08:19,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:08:19,370] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:08:19,376] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 02:08:32,171] {scheduler_job.py:155} INFO - Started process (PID=51212) to work on /airflow/dags/download_data.py
[2022-02-17 02:08:32,175] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:08:32,177] {logging_mixin.py:112} INFO - [2022-02-17 02:08:32,176] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:08:32,613] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:08:32,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:08:32,663] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:08:32,668] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 02:08:45,459] {scheduler_job.py:155} INFO - Started process (PID=51238) to work on /airflow/dags/download_data.py
[2022-02-17 02:08:45,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:08:45,472] {logging_mixin.py:112} INFO - [2022-02-17 02:08:45,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:08:45,900] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:08:45,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:08:45,964] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:08:45,968] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 02:08:58,767] {scheduler_job.py:155} INFO - Started process (PID=51266) to work on /airflow/dags/download_data.py
[2022-02-17 02:08:58,774] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:08:58,777] {logging_mixin.py:112} INFO - [2022-02-17 02:08:58,776] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:08:59,218] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:08:59,276] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:08:59,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:08:59,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 02:09:12,079] {scheduler_job.py:155} INFO - Started process (PID=51292) to work on /airflow/dags/download_data.py
[2022-02-17 02:09:12,083] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:09:12,089] {logging_mixin.py:112} INFO - [2022-02-17 02:09:12,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:09:12,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:09:12,561] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:09:12,567] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:09:12,570] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 02:09:25,340] {scheduler_job.py:155} INFO - Started process (PID=51320) to work on /airflow/dags/download_data.py
[2022-02-17 02:09:25,345] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:09:25,347] {logging_mixin.py:112} INFO - [2022-02-17 02:09:25,347] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:09:25,799] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:09:25,851] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:09:25,861] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:09:25,865] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 02:09:38,635] {scheduler_job.py:155} INFO - Started process (PID=51346) to work on /airflow/dags/download_data.py
[2022-02-17 02:09:38,643] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:09:38,645] {logging_mixin.py:112} INFO - [2022-02-17 02:09:38,645] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:09:39,069] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:09:39,109] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:09:39,117] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:09:39,122] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.487 seconds
[2022-02-17 02:09:51,878] {scheduler_job.py:155} INFO - Started process (PID=51372) to work on /airflow/dags/download_data.py
[2022-02-17 02:09:51,890] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:09:51,893] {logging_mixin.py:112} INFO - [2022-02-17 02:09:51,893] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:09:52,352] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:09:52,411] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:09:52,424] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:09:52,431] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 02:10:05,206] {scheduler_job.py:155} INFO - Started process (PID=51400) to work on /airflow/dags/download_data.py
[2022-02-17 02:10:05,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:10:05,215] {logging_mixin.py:112} INFO - [2022-02-17 02:10:05,215] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:10:05,652] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:10:05,705] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:10:05,711] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:10:05,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 02:10:18,508] {scheduler_job.py:155} INFO - Started process (PID=51426) to work on /airflow/dags/download_data.py
[2022-02-17 02:10:18,515] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:10:18,517] {logging_mixin.py:112} INFO - [2022-02-17 02:10:18,517] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:10:18,948] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:10:19,000] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:10:19,009] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:10:19,015] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 02:10:31,813] {scheduler_job.py:155} INFO - Started process (PID=51454) to work on /airflow/dags/download_data.py
[2022-02-17 02:10:31,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:10:31,822] {logging_mixin.py:112} INFO - [2022-02-17 02:10:31,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:10:32,297] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:10:32,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:10:32,359] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:10:32,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 02:10:45,116] {scheduler_job.py:155} INFO - Started process (PID=51480) to work on /airflow/dags/download_data.py
[2022-02-17 02:10:45,123] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:10:45,125] {logging_mixin.py:112} INFO - [2022-02-17 02:10:45,124] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:10:45,519] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:10:45,566] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:10:45,574] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:10:45,578] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.462 seconds
[2022-02-17 02:10:58,380] {scheduler_job.py:155} INFO - Started process (PID=51508) to work on /airflow/dags/download_data.py
[2022-02-17 02:10:58,385] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:10:58,387] {logging_mixin.py:112} INFO - [2022-02-17 02:10:58,387] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:10:58,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:10:58,986] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:10:58,993] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:10:59,000] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.620 seconds
[2022-02-17 02:11:11,670] {scheduler_job.py:155} INFO - Started process (PID=51534) to work on /airflow/dags/download_data.py
[2022-02-17 02:11:11,674] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:11:11,676] {logging_mixin.py:112} INFO - [2022-02-17 02:11:11,676] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:11:12,135] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:11:12,190] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:11:12,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:11:12,204] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 02:11:24,986] {scheduler_job.py:155} INFO - Started process (PID=51560) to work on /airflow/dags/download_data.py
[2022-02-17 02:11:24,994] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:11:24,997] {logging_mixin.py:112} INFO - [2022-02-17 02:11:24,997] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:11:25,448] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:11:25,499] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:11:25,512] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:11:25,519] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 02:11:38,312] {scheduler_job.py:155} INFO - Started process (PID=51588) to work on /airflow/dags/download_data.py
[2022-02-17 02:11:38,317] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:11:38,319] {logging_mixin.py:112} INFO - [2022-02-17 02:11:38,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:11:38,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:11:38,812] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:11:38,820] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:11:38,825] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 02:11:51,584] {scheduler_job.py:155} INFO - Started process (PID=51614) to work on /airflow/dags/download_data.py
[2022-02-17 02:11:51,592] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:11:51,595] {logging_mixin.py:112} INFO - [2022-02-17 02:11:51,594] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:11:52,051] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:11:52,113] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:11:52,120] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:11:52,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 02:12:04,886] {scheduler_job.py:155} INFO - Started process (PID=51642) to work on /airflow/dags/download_data.py
[2022-02-17 02:12:04,890] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:12:04,891] {logging_mixin.py:112} INFO - [2022-02-17 02:12:04,891] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:12:05,332] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:12:05,376] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:12:05,385] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:12:05,391] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 02:12:18,139] {scheduler_job.py:155} INFO - Started process (PID=51668) to work on /airflow/dags/download_data.py
[2022-02-17 02:12:18,144] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:12:18,145] {logging_mixin.py:112} INFO - [2022-02-17 02:12:18,145] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:12:18,593] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:12:18,639] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:12:18,646] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:12:18,649] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 02:12:31,449] {scheduler_job.py:155} INFO - Started process (PID=51696) to work on /airflow/dags/download_data.py
[2022-02-17 02:12:31,454] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:12:31,455] {logging_mixin.py:112} INFO - [2022-02-17 02:12:31,455] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:12:31,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:12:31,954] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:12:31,960] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:12:31,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 02:12:44,754] {scheduler_job.py:155} INFO - Started process (PID=51722) to work on /airflow/dags/download_data.py
[2022-02-17 02:12:44,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:12:44,766] {logging_mixin.py:112} INFO - [2022-02-17 02:12:44,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:12:45,192] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:12:45,236] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:12:45,243] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:12:45,250] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 02:12:58,070] {scheduler_job.py:155} INFO - Started process (PID=51750) to work on /airflow/dags/download_data.py
[2022-02-17 02:12:58,096] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:12:58,098] {logging_mixin.py:112} INFO - [2022-02-17 02:12:58,098] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:12:58,654] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:12:58,706] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:12:58,716] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:12:58,728] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.658 seconds
[2022-02-17 02:13:11,377] {scheduler_job.py:155} INFO - Started process (PID=51776) to work on /airflow/dags/download_data.py
[2022-02-17 02:13:11,381] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:13:11,384] {logging_mixin.py:112} INFO - [2022-02-17 02:13:11,383] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:13:11,827] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:13:11,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:13:11,888] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:13:11,892] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 02:13:24,636] {scheduler_job.py:155} INFO - Started process (PID=51802) to work on /airflow/dags/download_data.py
[2022-02-17 02:13:24,640] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:13:24,643] {logging_mixin.py:112} INFO - [2022-02-17 02:13:24,642] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:13:25,086] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:13:25,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:13:25,162] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:13:25,167] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 02:13:37,956] {scheduler_job.py:155} INFO - Started process (PID=51830) to work on /airflow/dags/download_data.py
[2022-02-17 02:13:37,960] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:13:37,964] {logging_mixin.py:112} INFO - [2022-02-17 02:13:37,964] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:13:38,409] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:13:38,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:13:38,448] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:13:38,451] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 02:13:51,231] {scheduler_job.py:155} INFO - Started process (PID=51856) to work on /airflow/dags/download_data.py
[2022-02-17 02:13:51,240] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:13:51,243] {logging_mixin.py:112} INFO - [2022-02-17 02:13:51,242] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:13:51,709] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:13:51,767] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:13:51,773] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:13:51,778] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 02:14:04,547] {scheduler_job.py:155} INFO - Started process (PID=51884) to work on /airflow/dags/download_data.py
[2022-02-17 02:14:04,555] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:14:04,557] {logging_mixin.py:112} INFO - [2022-02-17 02:14:04,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:14:04,991] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:14:05,040] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:14:05,048] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:14:05,052] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 02:14:17,829] {scheduler_job.py:155} INFO - Started process (PID=51910) to work on /airflow/dags/download_data.py
[2022-02-17 02:14:17,836] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:14:17,838] {logging_mixin.py:112} INFO - [2022-02-17 02:14:17,838] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:14:18,259] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:14:18,297] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:14:18,304] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:14:18,307] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.479 seconds
[2022-02-17 02:14:31,094] {scheduler_job.py:155} INFO - Started process (PID=51938) to work on /airflow/dags/download_data.py
[2022-02-17 02:14:31,104] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:14:31,105] {logging_mixin.py:112} INFO - [2022-02-17 02:14:31,105] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:14:31,526] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:14:31,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:14:31,587] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:14:31,591] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 02:14:44,431] {scheduler_job.py:155} INFO - Started process (PID=51964) to work on /airflow/dags/download_data.py
[2022-02-17 02:14:44,438] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:14:44,440] {logging_mixin.py:112} INFO - [2022-02-17 02:14:44,439] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:14:44,863] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:14:44,905] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:14:44,914] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:14:44,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 02:14:57,683] {scheduler_job.py:155} INFO - Started process (PID=51990) to work on /airflow/dags/download_data.py
[2022-02-17 02:14:57,687] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:14:57,689] {logging_mixin.py:112} INFO - [2022-02-17 02:14:57,688] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:14:58,156] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:14:58,200] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:14:58,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:14:58,217] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 02:15:11,019] {scheduler_job.py:155} INFO - Started process (PID=52018) to work on /airflow/dags/download_data.py
[2022-02-17 02:15:11,025] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:15:11,028] {logging_mixin.py:112} INFO - [2022-02-17 02:15:11,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:15:11,469] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:15:11,513] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:15:11,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:15:11,526] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 02:15:24,903] {scheduler_job.py:155} INFO - Started process (PID=52044) to work on /airflow/dags/download_data.py
[2022-02-17 02:15:24,916] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:15:24,920] {logging_mixin.py:112} INFO - [2022-02-17 02:15:24,919] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:15:26,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:15:26,064] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:15:26,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:15:26,080] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.177 seconds
[2022-02-17 02:15:39,237] {scheduler_job.py:155} INFO - Started process (PID=52072) to work on /airflow/dags/download_data.py
[2022-02-17 02:15:39,250] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:15:39,252] {logging_mixin.py:112} INFO - [2022-02-17 02:15:39,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:15:40,041] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:15:40,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:15:40,123] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:15:40,129] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.892 seconds
[2022-02-17 02:15:56,180] {scheduler_job.py:155} INFO - Started process (PID=52097) to work on /airflow/dags/download_data.py
[2022-02-17 02:15:56,188] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:15:56,191] {logging_mixin.py:112} INFO - [2022-02-17 02:15:56,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:15:56,878] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:15:56,997] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:15:57,012] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:15:57,027] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.847 seconds
[2022-02-17 02:16:09,498] {scheduler_job.py:155} INFO - Started process (PID=52125) to work on /airflow/dags/download_data.py
[2022-02-17 02:16:09,502] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:16:09,518] {logging_mixin.py:112} INFO - [2022-02-17 02:16:09,517] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:16:10,017] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:16:10,070] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:16:10,082] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:16:10,085] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 02:16:22,758] {scheduler_job.py:155} INFO - Started process (PID=52151) to work on /airflow/dags/download_data.py
[2022-02-17 02:16:22,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:16:22,766] {logging_mixin.py:112} INFO - [2022-02-17 02:16:22,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:16:23,297] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:16:23,338] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:16:23,345] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:16:23,348] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 02:16:36,050] {scheduler_job.py:155} INFO - Started process (PID=52179) to work on /airflow/dags/download_data.py
[2022-02-17 02:16:36,059] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:16:36,062] {logging_mixin.py:112} INFO - [2022-02-17 02:16:36,061] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:16:36,560] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:16:36,623] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:16:36,630] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:16:36,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 02:16:49,336] {scheduler_job.py:155} INFO - Started process (PID=52205) to work on /airflow/dags/download_data.py
[2022-02-17 02:16:49,345] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:16:49,347] {logging_mixin.py:112} INFO - [2022-02-17 02:16:49,347] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:16:49,770] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:16:49,834] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:16:49,847] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:16:49,852] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 02:17:02,604] {scheduler_job.py:155} INFO - Started process (PID=52233) to work on /airflow/dags/download_data.py
[2022-02-17 02:17:02,615] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:17:02,618] {logging_mixin.py:112} INFO - [2022-02-17 02:17:02,618] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:17:03,080] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:17:03,124] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:17:03,132] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:17:03,136] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 02:17:15,886] {scheduler_job.py:155} INFO - Started process (PID=52259) to work on /airflow/dags/download_data.py
[2022-02-17 02:17:15,891] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:17:15,892] {logging_mixin.py:112} INFO - [2022-02-17 02:17:15,892] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:17:16,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:17:16,406] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:17:16,414] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:17:16,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 02:17:29,158] {scheduler_job.py:155} INFO - Started process (PID=52285) to work on /airflow/dags/download_data.py
[2022-02-17 02:17:29,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:17:29,165] {logging_mixin.py:112} INFO - [2022-02-17 02:17:29,164] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:17:29,644] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:17:29,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:17:29,710] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:17:29,719] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 02:17:42,472] {scheduler_job.py:155} INFO - Started process (PID=52313) to work on /airflow/dags/download_data.py
[2022-02-17 02:17:42,479] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:17:42,483] {logging_mixin.py:112} INFO - [2022-02-17 02:17:42,483] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:17:42,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:17:43,037] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:17:43,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:17:43,049] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 02:17:55,765] {scheduler_job.py:155} INFO - Started process (PID=52339) to work on /airflow/dags/download_data.py
[2022-02-17 02:17:55,773] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:17:55,775] {logging_mixin.py:112} INFO - [2022-02-17 02:17:55,774] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:17:56,417] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:17:56,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:17:56,474] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:17:56,479] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.714 seconds
[2022-02-17 02:18:09,067] {scheduler_job.py:155} INFO - Started process (PID=52367) to work on /airflow/dags/download_data.py
[2022-02-17 02:18:09,073] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:18:09,075] {logging_mixin.py:112} INFO - [2022-02-17 02:18:09,074] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:18:09,556] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:18:09,611] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:18:09,625] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:18:09,632] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 02:18:22,293] {scheduler_job.py:155} INFO - Started process (PID=52393) to work on /airflow/dags/download_data.py
[2022-02-17 02:18:22,298] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:18:22,300] {logging_mixin.py:112} INFO - [2022-02-17 02:18:22,300] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:18:22,810] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:18:22,883] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:18:22,892] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:18:22,897] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 02:18:35,591] {scheduler_job.py:155} INFO - Started process (PID=52421) to work on /airflow/dags/download_data.py
[2022-02-17 02:18:35,596] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:18:35,598] {logging_mixin.py:112} INFO - [2022-02-17 02:18:35,598] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:18:36,067] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:18:36,121] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:18:36,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:18:36,135] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 02:18:48,887] {scheduler_job.py:155} INFO - Started process (PID=52447) to work on /airflow/dags/download_data.py
[2022-02-17 02:18:48,895] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:18:48,900] {logging_mixin.py:112} INFO - [2022-02-17 02:18:48,900] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:18:49,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:18:49,388] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:18:49,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:18:49,397] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 02:19:02,113] {scheduler_job.py:155} INFO - Started process (PID=52473) to work on /airflow/dags/download_data.py
[2022-02-17 02:19:02,121] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:19:02,123] {logging_mixin.py:112} INFO - [2022-02-17 02:19:02,122] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:19:02,610] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:19:02,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:19:02,663] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:19:02,669] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 02:19:15,397] {scheduler_job.py:155} INFO - Started process (PID=52501) to work on /airflow/dags/download_data.py
[2022-02-17 02:19:15,401] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:19:15,403] {logging_mixin.py:112} INFO - [2022-02-17 02:19:15,403] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:19:16,134] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:19:16,187] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:19:16,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:19:16,201] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.804 seconds
[2022-02-17 02:19:28,654] {scheduler_job.py:155} INFO - Started process (PID=52527) to work on /airflow/dags/download_data.py
[2022-02-17 02:19:28,659] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:19:28,660] {logging_mixin.py:112} INFO - [2022-02-17 02:19:28,660] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:19:29,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:19:29,209] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:19:29,217] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:19:29,224] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 02:19:42,366] {scheduler_job.py:155} INFO - Started process (PID=52555) to work on /airflow/dags/download_data.py
[2022-02-17 02:19:42,372] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:19:42,373] {logging_mixin.py:112} INFO - [2022-02-17 02:19:42,373] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:19:42,826] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:19:42,866] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:19:42,872] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:19:42,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 02:19:55,586] {scheduler_job.py:155} INFO - Started process (PID=52581) to work on /airflow/dags/download_data.py
[2022-02-17 02:19:55,592] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:19:55,593] {logging_mixin.py:112} INFO - [2022-02-17 02:19:55,593] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:19:56,061] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:19:56,117] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:19:56,127] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:19:56,133] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 02:20:08,869] {scheduler_job.py:155} INFO - Started process (PID=52609) to work on /airflow/dags/download_data.py
[2022-02-17 02:20:08,873] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:20:08,875] {logging_mixin.py:112} INFO - [2022-02-17 02:20:08,875] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:20:09,320] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:20:09,364] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:20:09,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:20:09,378] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 02:20:22,147] {scheduler_job.py:155} INFO - Started process (PID=52635) to work on /airflow/dags/download_data.py
[2022-02-17 02:20:22,153] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:20:22,158] {logging_mixin.py:112} INFO - [2022-02-17 02:20:22,158] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:20:22,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:20:22,794] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:20:22,801] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:20:22,806] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.660 seconds
[2022-02-17 02:20:35,419] {scheduler_job.py:155} INFO - Started process (PID=52663) to work on /airflow/dags/download_data.py
[2022-02-17 02:20:35,433] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:20:35,448] {logging_mixin.py:112} INFO - [2022-02-17 02:20:35,448] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:20:35,997] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:20:36,054] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:20:36,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:20:36,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-17 02:20:48,730] {scheduler_job.py:155} INFO - Started process (PID=52689) to work on /airflow/dags/download_data.py
[2022-02-17 02:20:48,734] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:20:48,736] {logging_mixin.py:112} INFO - [2022-02-17 02:20:48,735] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:20:49,248] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:20:49,299] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:20:49,307] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:20:49,315] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 02:21:01,986] {scheduler_job.py:155} INFO - Started process (PID=52715) to work on /airflow/dags/download_data.py
[2022-02-17 02:21:02,003] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:21:02,007] {logging_mixin.py:112} INFO - [2022-02-17 02:21:02,006] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:21:02,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:21:02,506] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:21:02,519] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:21:02,524] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 02:21:15,296] {scheduler_job.py:155} INFO - Started process (PID=52743) to work on /airflow/dags/download_data.py
[2022-02-17 02:21:15,300] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:21:15,301] {logging_mixin.py:112} INFO - [2022-02-17 02:21:15,301] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:21:15,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:21:15,827] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:21:15,834] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:21:15,838] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 02:21:28,530] {scheduler_job.py:155} INFO - Started process (PID=52769) to work on /airflow/dags/download_data.py
[2022-02-17 02:21:28,537] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:21:28,539] {logging_mixin.py:112} INFO - [2022-02-17 02:21:28,539] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:21:29,020] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:21:29,068] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:21:29,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:21:29,076] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 02:21:41,813] {scheduler_job.py:155} INFO - Started process (PID=52797) to work on /airflow/dags/download_data.py
[2022-02-17 02:21:41,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:21:41,821] {logging_mixin.py:112} INFO - [2022-02-17 02:21:41,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:21:42,357] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:21:42,407] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:21:42,414] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:21:42,419] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 02:21:55,069] {scheduler_job.py:155} INFO - Started process (PID=52823) to work on /airflow/dags/download_data.py
[2022-02-17 02:21:55,074] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:21:55,076] {logging_mixin.py:112} INFO - [2022-02-17 02:21:55,075] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:21:55,635] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:21:55,684] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:21:55,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:21:55,695] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.627 seconds
[2022-02-17 02:22:08,398] {scheduler_job.py:155} INFO - Started process (PID=52851) to work on /airflow/dags/download_data.py
[2022-02-17 02:22:08,403] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:22:08,404] {logging_mixin.py:112} INFO - [2022-02-17 02:22:08,404] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:22:08,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:22:08,950] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:22:08,958] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:22:08,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 02:22:21,689] {scheduler_job.py:155} INFO - Started process (PID=52877) to work on /airflow/dags/download_data.py
[2022-02-17 02:22:21,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:22:21,703] {logging_mixin.py:112} INFO - [2022-02-17 02:22:21,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:22:22,168] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:22:22,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:22:22,230] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:22:22,237] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 02:22:34,980] {scheduler_job.py:155} INFO - Started process (PID=52903) to work on /airflow/dags/download_data.py
[2022-02-17 02:22:34,986] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:22:34,988] {logging_mixin.py:112} INFO - [2022-02-17 02:22:34,988] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:22:35,485] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:22:35,542] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:22:35,554] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:22:35,559] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-17 02:22:48,348] {scheduler_job.py:155} INFO - Started process (PID=52931) to work on /airflow/dags/download_data.py
[2022-02-17 02:22:48,358] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:22:48,360] {logging_mixin.py:112} INFO - [2022-02-17 02:22:48,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:22:48,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:22:48,879] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:22:48,888] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:22:48,895] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 02:23:01,619] {scheduler_job.py:155} INFO - Started process (PID=52957) to work on /airflow/dags/download_data.py
[2022-02-17 02:23:01,625] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:23:01,626] {logging_mixin.py:112} INFO - [2022-02-17 02:23:01,626] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:23:02,159] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:23:02,214] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:23:02,228] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:23:02,237] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 02:23:14,932] {scheduler_job.py:155} INFO - Started process (PID=52985) to work on /airflow/dags/download_data.py
[2022-02-17 02:23:14,942] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:23:14,944] {logging_mixin.py:112} INFO - [2022-02-17 02:23:14,943] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:23:15,397] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:23:15,449] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:23:15,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:23:15,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 02:23:28,216] {scheduler_job.py:155} INFO - Started process (PID=53011) to work on /airflow/dags/download_data.py
[2022-02-17 02:23:28,228] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:23:28,231] {logging_mixin.py:112} INFO - [2022-02-17 02:23:28,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:23:28,751] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:23:28,810] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:23:28,817] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:23:28,821] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 02:23:41,494] {scheduler_job.py:155} INFO - Started process (PID=53039) to work on /airflow/dags/download_data.py
[2022-02-17 02:23:41,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:23:41,505] {logging_mixin.py:112} INFO - [2022-02-17 02:23:41,504] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:23:42,139] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:23:42,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:23:42,183] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:23:42,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-17 02:23:54,764] {scheduler_job.py:155} INFO - Started process (PID=53065) to work on /airflow/dags/download_data.py
[2022-02-17 02:23:54,769] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:23:54,771] {logging_mixin.py:112} INFO - [2022-02-17 02:23:54,770] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:23:55,243] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:23:55,287] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:23:55,292] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:23:55,301] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 02:24:08,083] {scheduler_job.py:155} INFO - Started process (PID=53091) to work on /airflow/dags/download_data.py
[2022-02-17 02:24:08,098] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:24:08,101] {logging_mixin.py:112} INFO - [2022-02-17 02:24:08,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:24:08,593] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:24:08,636] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:24:08,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:24:08,650] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 02:24:21,344] {scheduler_job.py:155} INFO - Started process (PID=53119) to work on /airflow/dags/download_data.py
[2022-02-17 02:24:21,349] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:24:21,351] {logging_mixin.py:112} INFO - [2022-02-17 02:24:21,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:24:21,811] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:24:21,857] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:24:21,867] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:24:21,872] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 02:24:34,612] {scheduler_job.py:155} INFO - Started process (PID=53145) to work on /airflow/dags/download_data.py
[2022-02-17 02:24:34,616] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:24:34,618] {logging_mixin.py:112} INFO - [2022-02-17 02:24:34,618] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:24:35,097] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:24:35,141] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:24:35,152] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:24:35,157] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 02:24:47,968] {scheduler_job.py:155} INFO - Started process (PID=53173) to work on /airflow/dags/download_data.py
[2022-02-17 02:24:47,980] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:24:47,982] {logging_mixin.py:112} INFO - [2022-02-17 02:24:47,982] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:24:48,422] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:24:48,469] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:24:48,477] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:24:48,482] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 02:25:01,212] {scheduler_job.py:155} INFO - Started process (PID=53199) to work on /airflow/dags/download_data.py
[2022-02-17 02:25:01,218] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:25:01,220] {logging_mixin.py:112} INFO - [2022-02-17 02:25:01,219] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:25:01,696] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:25:01,740] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:25:01,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:25:01,753] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 02:25:14,497] {scheduler_job.py:155} INFO - Started process (PID=53227) to work on /airflow/dags/download_data.py
[2022-02-17 02:25:14,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:25:14,504] {logging_mixin.py:112} INFO - [2022-02-17 02:25:14,504] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:25:14,976] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:25:15,035] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:25:15,041] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:25:15,046] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 02:25:27,800] {scheduler_job.py:155} INFO - Started process (PID=53253) to work on /airflow/dags/download_data.py
[2022-02-17 02:25:27,806] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:25:27,808] {logging_mixin.py:112} INFO - [2022-02-17 02:25:27,807] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:25:28,284] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:25:28,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:25:28,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:25:28,361] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 02:25:41,097] {scheduler_job.py:155} INFO - Started process (PID=53280) to work on /airflow/dags/download_data.py
[2022-02-17 02:25:41,114] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:25:41,118] {logging_mixin.py:112} INFO - [2022-02-17 02:25:41,117] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:25:42,058] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:25:42,155] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:25:42,166] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:25:42,170] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.074 seconds
[2022-02-17 02:25:55,371] {scheduler_job.py:155} INFO - Started process (PID=53307) to work on /airflow/dags/download_data.py
[2022-02-17 02:25:55,387] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:25:55,389] {logging_mixin.py:112} INFO - [2022-02-17 02:25:55,389] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:25:55,964] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:25:56,022] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:25:56,035] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:25:56,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.668 seconds
[2022-02-17 02:26:07,651] {scheduler_job.py:155} INFO - Started process (PID=53332) to work on /airflow/dags/download_data.py
[2022-02-17 02:26:07,656] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:26:07,658] {logging_mixin.py:112} INFO - [2022-02-17 02:26:07,658] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:26:08,158] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:26:08,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:26:08,232] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:26:08,237] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 02:26:20,888] {scheduler_job.py:155} INFO - Started process (PID=53360) to work on /airflow/dags/download_data.py
[2022-02-17 02:26:20,892] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:26:20,894] {logging_mixin.py:112} INFO - [2022-02-17 02:26:20,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:26:21,402] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:26:21,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:26:21,470] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:26:21,476] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-17 02:26:34,184] {scheduler_job.py:155} INFO - Started process (PID=53386) to work on /airflow/dags/download_data.py
[2022-02-17 02:26:34,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:26:34,191] {logging_mixin.py:112} INFO - [2022-02-17 02:26:34,190] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:26:34,729] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:26:34,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:26:34,787] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:26:34,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-17 02:26:47,508] {scheduler_job.py:155} INFO - Started process (PID=53414) to work on /airflow/dags/download_data.py
[2022-02-17 02:26:47,518] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:26:47,520] {logging_mixin.py:112} INFO - [2022-02-17 02:26:47,520] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:26:48,075] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:26:48,132] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:26:48,142] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:26:48,148] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-17 02:27:00,785] {scheduler_job.py:155} INFO - Started process (PID=53440) to work on /airflow/dags/download_data.py
[2022-02-17 02:27:00,799] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:27:00,801] {logging_mixin.py:112} INFO - [2022-02-17 02:27:00,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:27:01,268] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:27:01,326] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:27:01,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:27:01,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 02:27:14,070] {scheduler_job.py:155} INFO - Started process (PID=53468) to work on /airflow/dags/download_data.py
[2022-02-17 02:27:14,075] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:27:14,077] {logging_mixin.py:112} INFO - [2022-02-17 02:27:14,077] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:27:14,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:27:14,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:27:14,577] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:27:14,580] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 02:27:27,313] {scheduler_job.py:155} INFO - Started process (PID=53494) to work on /airflow/dags/download_data.py
[2022-02-17 02:27:27,318] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:27:27,321] {logging_mixin.py:112} INFO - [2022-02-17 02:27:27,320] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:27:27,779] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:27:27,820] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:27:27,830] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:27:27,837] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 02:27:40,605] {scheduler_job.py:155} INFO - Started process (PID=53520) to work on /airflow/dags/download_data.py
[2022-02-17 02:27:40,616] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:27:40,618] {logging_mixin.py:112} INFO - [2022-02-17 02:27:40,617] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:27:41,086] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:27:41,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:27:41,134] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:27:41,138] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 02:27:53,938] {scheduler_job.py:155} INFO - Started process (PID=53548) to work on /airflow/dags/download_data.py
[2022-02-17 02:27:53,943] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:27:53,946] {logging_mixin.py:112} INFO - [2022-02-17 02:27:53,946] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:27:54,417] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:27:54,455] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:27:54,460] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:27:54,463] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 02:28:07,303] {scheduler_job.py:155} INFO - Started process (PID=53574) to work on /airflow/dags/download_data.py
[2022-02-17 02:28:07,312] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:28:07,314] {logging_mixin.py:112} INFO - [2022-02-17 02:28:07,314] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:28:07,758] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:28:07,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:28:07,812] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:28:07,819] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 02:28:20,572] {scheduler_job.py:155} INFO - Started process (PID=53602) to work on /airflow/dags/download_data.py
[2022-02-17 02:28:20,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:28:20,578] {logging_mixin.py:112} INFO - [2022-02-17 02:28:20,578] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:28:21,027] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:28:21,077] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:28:21,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:28:21,090] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 02:28:33,832] {scheduler_job.py:155} INFO - Started process (PID=53628) to work on /airflow/dags/download_data.py
[2022-02-17 02:28:33,836] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:28:33,838] {logging_mixin.py:112} INFO - [2022-02-17 02:28:33,837] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:28:34,307] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:28:34,362] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:28:34,370] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:28:34,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 02:28:47,104] {scheduler_job.py:155} INFO - Started process (PID=53656) to work on /airflow/dags/download_data.py
[2022-02-17 02:28:47,108] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:28:47,110] {logging_mixin.py:112} INFO - [2022-02-17 02:28:47,110] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:28:47,550] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:28:47,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:28:47,607] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:28:47,613] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 02:29:00,374] {scheduler_job.py:155} INFO - Started process (PID=53682) to work on /airflow/dags/download_data.py
[2022-02-17 02:29:00,382] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:29:00,384] {logging_mixin.py:112} INFO - [2022-02-17 02:29:00,383] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:29:00,856] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:29:00,915] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:29:00,927] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:29:00,937] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 02:29:13,660] {scheduler_job.py:155} INFO - Started process (PID=53708) to work on /airflow/dags/download_data.py
[2022-02-17 02:29:13,674] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:29:13,675] {logging_mixin.py:112} INFO - [2022-02-17 02:29:13,675] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:29:14,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:29:14,174] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:29:14,185] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:29:14,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 02:29:26,922] {scheduler_job.py:155} INFO - Started process (PID=53736) to work on /airflow/dags/download_data.py
[2022-02-17 02:29:26,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:29:26,929] {logging_mixin.py:112} INFO - [2022-02-17 02:29:26,929] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:29:27,387] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:29:27,435] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:29:27,447] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:29:27,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 02:29:40,194] {scheduler_job.py:155} INFO - Started process (PID=53762) to work on /airflow/dags/download_data.py
[2022-02-17 02:29:40,202] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:29:40,229] {logging_mixin.py:112} INFO - [2022-02-17 02:29:40,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:29:40,765] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:29:40,818] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:29:40,826] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:29:40,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.636 seconds
[2022-02-17 02:29:53,502] {scheduler_job.py:155} INFO - Started process (PID=53790) to work on /airflow/dags/download_data.py
[2022-02-17 02:29:53,513] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:29:53,515] {logging_mixin.py:112} INFO - [2022-02-17 02:29:53,515] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:29:53,977] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:29:54,049] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:29:54,101] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:29:54,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-17 02:30:06,771] {scheduler_job.py:155} INFO - Started process (PID=53816) to work on /airflow/dags/download_data.py
[2022-02-17 02:30:06,776] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:30:06,779] {logging_mixin.py:112} INFO - [2022-02-17 02:30:06,779] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:30:07,251] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:30:07,309] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:30:07,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:30:07,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 02:30:20,014] {scheduler_job.py:155} INFO - Started process (PID=53844) to work on /airflow/dags/download_data.py
[2022-02-17 02:30:20,024] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:30:20,025] {logging_mixin.py:112} INFO - [2022-02-17 02:30:20,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:30:20,465] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:30:20,512] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:30:20,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:30:20,527] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 02:30:33,279] {scheduler_job.py:155} INFO - Started process (PID=53870) to work on /airflow/dags/download_data.py
[2022-02-17 02:30:33,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:30:33,290] {logging_mixin.py:112} INFO - [2022-02-17 02:30:33,290] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:30:33,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:30:33,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:30:33,799] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:30:33,805] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 02:30:46,557] {scheduler_job.py:155} INFO - Started process (PID=53896) to work on /airflow/dags/download_data.py
[2022-02-17 02:30:46,564] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:30:46,566] {logging_mixin.py:112} INFO - [2022-02-17 02:30:46,566] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:30:47,084] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:30:47,209] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:30:47,216] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:30:47,232] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.675 seconds
[2022-02-17 02:30:59,833] {scheduler_job.py:155} INFO - Started process (PID=53924) to work on /airflow/dags/download_data.py
[2022-02-17 02:30:59,840] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:30:59,842] {logging_mixin.py:112} INFO - [2022-02-17 02:30:59,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:31:00,297] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:31:00,357] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:31:00,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:31:00,379] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 02:31:13,100] {scheduler_job.py:155} INFO - Started process (PID=53950) to work on /airflow/dags/download_data.py
[2022-02-17 02:31:13,108] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:31:13,110] {logging_mixin.py:112} INFO - [2022-02-17 02:31:13,110] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:31:13,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:31:13,627] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:31:13,637] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:31:13,645] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 02:31:26,393] {scheduler_job.py:155} INFO - Started process (PID=53978) to work on /airflow/dags/download_data.py
[2022-02-17 02:31:26,397] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:31:26,399] {logging_mixin.py:112} INFO - [2022-02-17 02:31:26,399] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:31:26,864] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:31:26,927] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:31:26,940] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:31:26,947] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 02:31:39,699] {scheduler_job.py:155} INFO - Started process (PID=54004) to work on /airflow/dags/download_data.py
[2022-02-17 02:31:39,706] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:31:39,708] {logging_mixin.py:112} INFO - [2022-02-17 02:31:39,708] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:31:40,134] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:31:40,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:31:40,180] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:31:40,185] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.486 seconds
[2022-02-17 02:31:52,968] {scheduler_job.py:155} INFO - Started process (PID=54032) to work on /airflow/dags/download_data.py
[2022-02-17 02:31:52,975] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:31:52,976] {logging_mixin.py:112} INFO - [2022-02-17 02:31:52,976] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:31:53,483] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:31:53,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:31:53,543] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:31:53,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-17 02:32:06,332] {scheduler_job.py:155} INFO - Started process (PID=54058) to work on /airflow/dags/download_data.py
[2022-02-17 02:32:06,342] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:32:06,345] {logging_mixin.py:112} INFO - [2022-02-17 02:32:06,344] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:32:06,996] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:32:07,032] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:32:07,039] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:32:07,043] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.711 seconds
[2022-02-17 02:32:19,570] {scheduler_job.py:155} INFO - Started process (PID=54086) to work on /airflow/dags/download_data.py
[2022-02-17 02:32:19,588] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:32:19,591] {logging_mixin.py:112} INFO - [2022-02-17 02:32:19,590] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:32:20,049] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:32:20,093] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:32:20,103] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:32:20,108] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 02:32:32,836] {scheduler_job.py:155} INFO - Started process (PID=54112) to work on /airflow/dags/download_data.py
[2022-02-17 02:32:32,841] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:32:32,842] {logging_mixin.py:112} INFO - [2022-02-17 02:32:32,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:32:33,296] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:32:33,341] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:32:33,348] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:32:33,353] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 02:32:46,122] {scheduler_job.py:155} INFO - Started process (PID=54138) to work on /airflow/dags/download_data.py
[2022-02-17 02:32:46,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:32:46,129] {logging_mixin.py:112} INFO - [2022-02-17 02:32:46,129] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:32:46,569] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:32:46,614] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:32:46,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:32:46,626] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 02:32:59,456] {scheduler_job.py:155} INFO - Started process (PID=54166) to work on /airflow/dags/download_data.py
[2022-02-17 02:32:59,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:32:59,464] {logging_mixin.py:112} INFO - [2022-02-17 02:32:59,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:32:59,922] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:32:59,984] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:32:59,993] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:33:00,000] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 02:33:12,789] {scheduler_job.py:155} INFO - Started process (PID=54192) to work on /airflow/dags/download_data.py
[2022-02-17 02:33:12,793] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:33:12,796] {logging_mixin.py:112} INFO - [2022-02-17 02:33:12,795] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:33:13,254] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:33:13,318] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:33:13,325] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:33:13,332] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 02:33:26,023] {scheduler_job.py:155} INFO - Started process (PID=54220) to work on /airflow/dags/download_data.py
[2022-02-17 02:33:26,030] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:33:26,032] {logging_mixin.py:112} INFO - [2022-02-17 02:33:26,032] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:33:26,665] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:33:26,722] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:33:26,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:33:26,740] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.717 seconds
[2022-02-17 02:33:39,303] {scheduler_job.py:155} INFO - Started process (PID=54246) to work on /airflow/dags/download_data.py
[2022-02-17 02:33:39,307] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:33:39,309] {logging_mixin.py:112} INFO - [2022-02-17 02:33:39,309] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:33:39,764] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:33:39,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:33:39,825] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:33:39,831] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 02:33:52,531] {scheduler_job.py:155} INFO - Started process (PID=54274) to work on /airflow/dags/download_data.py
[2022-02-17 02:33:52,536] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:33:52,539] {logging_mixin.py:112} INFO - [2022-02-17 02:33:52,538] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:33:53,089] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:33:53,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:33:53,145] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:33:53,153] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-17 02:34:05,858] {scheduler_job.py:155} INFO - Started process (PID=54300) to work on /airflow/dags/download_data.py
[2022-02-17 02:34:05,866] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:34:05,869] {logging_mixin.py:112} INFO - [2022-02-17 02:34:05,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:34:06,456] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:34:06,517] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:34:06,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:34:06,537] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-17 02:34:19,114] {scheduler_job.py:155} INFO - Started process (PID=54326) to work on /airflow/dags/download_data.py
[2022-02-17 02:34:19,121] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:34:19,123] {logging_mixin.py:112} INFO - [2022-02-17 02:34:19,123] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:34:19,579] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:34:19,631] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:34:19,642] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:34:19,649] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 02:34:32,427] {scheduler_job.py:155} INFO - Started process (PID=54354) to work on /airflow/dags/download_data.py
[2022-02-17 02:34:32,432] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:34:32,434] {logging_mixin.py:112} INFO - [2022-02-17 02:34:32,434] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:34:33,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:34:33,101] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:34:33,113] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:34:33,117] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.690 seconds
[2022-02-17 02:34:45,697] {scheduler_job.py:155} INFO - Started process (PID=54380) to work on /airflow/dags/download_data.py
[2022-02-17 02:34:45,706] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:34:45,711] {logging_mixin.py:112} INFO - [2022-02-17 02:34:45,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:34:46,215] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:34:46,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:34:46,275] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:34:46,279] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 02:34:58,920] {scheduler_job.py:155} INFO - Started process (PID=54408) to work on /airflow/dags/download_data.py
[2022-02-17 02:34:58,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:34:58,931] {logging_mixin.py:112} INFO - [2022-02-17 02:34:58,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:34:59,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:34:59,440] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:34:59,450] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:34:59,456] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 02:35:12,225] {scheduler_job.py:155} INFO - Started process (PID=54434) to work on /airflow/dags/download_data.py
[2022-02-17 02:35:12,229] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:35:12,231] {logging_mixin.py:112} INFO - [2022-02-17 02:35:12,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:35:12,704] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:35:12,758] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:35:12,766] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:35:12,774] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 02:35:25,460] {scheduler_job.py:155} INFO - Started process (PID=54462) to work on /airflow/dags/download_data.py
[2022-02-17 02:35:25,481] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:35:25,484] {logging_mixin.py:112} INFO - [2022-02-17 02:35:25,484] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:35:26,032] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:35:26,086] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:35:26,096] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:35:26,109] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.650 seconds
[2022-02-17 02:35:38,734] {scheduler_job.py:155} INFO - Started process (PID=54488) to work on /airflow/dags/download_data.py
[2022-02-17 02:35:38,738] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:35:38,739] {logging_mixin.py:112} INFO - [2022-02-17 02:35:38,739] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:35:39,212] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:35:39,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:35:39,272] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:35:39,278] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 02:35:52,007] {scheduler_job.py:155} INFO - Started process (PID=54514) to work on /airflow/dags/download_data.py
[2022-02-17 02:35:52,011] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:35:52,013] {logging_mixin.py:112} INFO - [2022-02-17 02:35:52,013] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:35:52,481] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:35:52,533] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:35:52,541] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:35:52,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 02:36:05,311] {scheduler_job.py:155} INFO - Started process (PID=54542) to work on /airflow/dags/download_data.py
[2022-02-17 02:36:05,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:36:05,326] {logging_mixin.py:112} INFO - [2022-02-17 02:36:05,326] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:36:05,842] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:36:05,896] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:36:05,908] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:36:05,914] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-17 02:36:18,566] {scheduler_job.py:155} INFO - Started process (PID=54568) to work on /airflow/dags/download_data.py
[2022-02-17 02:36:18,570] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:36:18,571] {logging_mixin.py:112} INFO - [2022-02-17 02:36:18,571] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:36:19,031] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:36:19,096] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:36:19,105] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:36:19,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 02:36:31,824] {scheduler_job.py:155} INFO - Started process (PID=54596) to work on /airflow/dags/download_data.py
[2022-02-17 02:36:31,835] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:36:31,839] {logging_mixin.py:112} INFO - [2022-02-17 02:36:31,838] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:36:32,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:36:32,337] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:36:32,346] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:36:32,352] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 02:36:45,145] {scheduler_job.py:155} INFO - Started process (PID=54622) to work on /airflow/dags/download_data.py
[2022-02-17 02:36:45,153] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:36:45,155] {logging_mixin.py:112} INFO - [2022-02-17 02:36:45,155] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:36:45,650] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:36:45,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:36:45,714] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:36:45,719] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 02:36:58,403] {scheduler_job.py:155} INFO - Started process (PID=54650) to work on /airflow/dags/download_data.py
[2022-02-17 02:36:58,416] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:36:58,418] {logging_mixin.py:112} INFO - [2022-02-17 02:36:58,418] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:36:59,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:36:59,102] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:36:59,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:36:59,119] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.716 seconds
[2022-02-17 02:37:11,715] {scheduler_job.py:155} INFO - Started process (PID=54676) to work on /airflow/dags/download_data.py
[2022-02-17 02:37:11,723] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:37:11,726] {logging_mixin.py:112} INFO - [2022-02-17 02:37:11,725] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:37:12,197] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:37:12,251] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:37:12,258] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:37:12,263] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 02:37:24,974] {scheduler_job.py:155} INFO - Started process (PID=54703) to work on /airflow/dags/download_data.py
[2022-02-17 02:37:24,994] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:37:24,997] {logging_mixin.py:112} INFO - [2022-02-17 02:37:24,996] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:37:25,584] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:37:25,626] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:37:25,631] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:37:25,635] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.662 seconds
[2022-02-17 02:37:38,208] {scheduler_job.py:155} INFO - Started process (PID=54730) to work on /airflow/dags/download_data.py
[2022-02-17 02:37:38,219] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:37:38,220] {logging_mixin.py:112} INFO - [2022-02-17 02:37:38,220] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:37:38,669] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:37:38,715] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:37:38,720] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:37:38,723] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 02:37:51,442] {scheduler_job.py:155} INFO - Started process (PID=54756) to work on /airflow/dags/download_data.py
[2022-02-17 02:37:51,447] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:37:51,448] {logging_mixin.py:112} INFO - [2022-02-17 02:37:51,448] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:37:51,894] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:37:51,949] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:37:51,956] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:37:51,962] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 02:38:04,776] {scheduler_job.py:155} INFO - Started process (PID=54784) to work on /airflow/dags/download_data.py
[2022-02-17 02:38:04,785] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:38:04,787] {logging_mixin.py:112} INFO - [2022-02-17 02:38:04,786] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:38:05,261] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:38:05,313] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:38:05,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:38:05,328] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 02:38:18,044] {scheduler_job.py:155} INFO - Started process (PID=54810) to work on /airflow/dags/download_data.py
[2022-02-17 02:38:18,048] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:38:18,050] {logging_mixin.py:112} INFO - [2022-02-17 02:38:18,050] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:38:18,476] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:38:18,524] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:38:18,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:38:18,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 02:38:31,274] {scheduler_job.py:155} INFO - Started process (PID=54838) to work on /airflow/dags/download_data.py
[2022-02-17 02:38:31,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:38:31,280] {logging_mixin.py:112} INFO - [2022-02-17 02:38:31,280] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:38:31,741] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:38:31,795] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:38:31,802] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:38:31,807] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 02:38:44,622] {scheduler_job.py:155} INFO - Started process (PID=54864) to work on /airflow/dags/download_data.py
[2022-02-17 02:38:44,629] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:38:44,631] {logging_mixin.py:112} INFO - [2022-02-17 02:38:44,631] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:38:45,149] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:38:45,209] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:38:45,221] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:38:45,226] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 02:38:57,790] {scheduler_job.py:155} INFO - Started process (PID=54892) to work on /airflow/dags/download_data.py
[2022-02-17 02:38:57,800] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:38:57,802] {logging_mixin.py:112} INFO - [2022-02-17 02:38:57,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:38:58,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:38:58,413] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:38:58,422] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:38:58,427] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-17 02:39:11,068] {scheduler_job.py:155} INFO - Started process (PID=54918) to work on /airflow/dags/download_data.py
[2022-02-17 02:39:11,078] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:39:11,080] {logging_mixin.py:112} INFO - [2022-02-17 02:39:11,080] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:39:11,583] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:39:11,643] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:39:11,661] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:39:11,674] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 02:39:24,313] {scheduler_job.py:155} INFO - Started process (PID=54944) to work on /airflow/dags/download_data.py
[2022-02-17 02:39:24,334] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:39:24,337] {logging_mixin.py:112} INFO - [2022-02-17 02:39:24,337] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:39:24,834] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:39:24,880] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:39:24,887] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:39:24,891] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 02:39:37,597] {scheduler_job.py:155} INFO - Started process (PID=54972) to work on /airflow/dags/download_data.py
[2022-02-17 02:39:37,608] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:39:37,610] {logging_mixin.py:112} INFO - [2022-02-17 02:39:37,610] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:39:38,065] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:39:38,117] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:39:38,127] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:39:38,132] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 02:39:50,850] {scheduler_job.py:155} INFO - Started process (PID=54998) to work on /airflow/dags/download_data.py
[2022-02-17 02:39:50,854] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:39:50,856] {logging_mixin.py:112} INFO - [2022-02-17 02:39:50,856] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:39:51,341] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:39:51,388] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:39:51,400] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:39:51,405] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 02:40:04,133] {scheduler_job.py:155} INFO - Started process (PID=55026) to work on /airflow/dags/download_data.py
[2022-02-17 02:40:04,139] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:40:04,141] {logging_mixin.py:112} INFO - [2022-02-17 02:40:04,141] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:40:04,603] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:40:04,648] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:40:04,655] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:40:04,662] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 02:40:17,430] {scheduler_job.py:155} INFO - Started process (PID=55052) to work on /airflow/dags/download_data.py
[2022-02-17 02:40:17,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:40:17,436] {logging_mixin.py:112} INFO - [2022-02-17 02:40:17,436] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:40:17,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:40:17,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:40:17,966] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:40:17,972] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 02:40:30,656] {scheduler_job.py:155} INFO - Started process (PID=55080) to work on /airflow/dags/download_data.py
[2022-02-17 02:40:30,661] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:40:30,664] {logging_mixin.py:112} INFO - [2022-02-17 02:40:30,664] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:40:31,113] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:40:31,162] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:40:31,174] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:40:31,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 02:40:43,955] {scheduler_job.py:155} INFO - Started process (PID=55106) to work on /airflow/dags/download_data.py
[2022-02-17 02:40:43,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:40:43,961] {logging_mixin.py:112} INFO - [2022-02-17 02:40:43,961] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:40:44,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:40:44,492] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:40:44,504] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:40:44,507] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 02:40:57,225] {scheduler_job.py:155} INFO - Started process (PID=55132) to work on /airflow/dags/download_data.py
[2022-02-17 02:40:57,230] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:40:57,232] {logging_mixin.py:112} INFO - [2022-02-17 02:40:57,232] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:40:57,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:40:57,752] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:40:57,764] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:40:57,770] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 02:41:10,540] {scheduler_job.py:155} INFO - Started process (PID=55160) to work on /airflow/dags/download_data.py
[2022-02-17 02:41:10,545] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:41:10,548] {logging_mixin.py:112} INFO - [2022-02-17 02:41:10,547] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:41:11,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:41:11,087] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:41:11,097] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:41:11,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 02:41:23,766] {scheduler_job.py:155} INFO - Started process (PID=55186) to work on /airflow/dags/download_data.py
[2022-02-17 02:41:23,771] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:41:23,773] {logging_mixin.py:112} INFO - [2022-02-17 02:41:23,773] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:41:24,234] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:41:24,278] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:41:24,285] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:41:24,291] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 02:41:37,035] {scheduler_job.py:155} INFO - Started process (PID=55214) to work on /airflow/dags/download_data.py
[2022-02-17 02:41:37,043] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:41:37,045] {logging_mixin.py:112} INFO - [2022-02-17 02:41:37,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:41:37,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:41:37,542] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:41:37,552] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:41:37,557] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 02:41:50,311] {scheduler_job.py:155} INFO - Started process (PID=55240) to work on /airflow/dags/download_data.py
[2022-02-17 02:41:50,320] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:41:50,322] {logging_mixin.py:112} INFO - [2022-02-17 02:41:50,321] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:41:50,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:41:50,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:41:50,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:41:50,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 02:42:03,654] {scheduler_job.py:155} INFO - Started process (PID=55268) to work on /airflow/dags/download_data.py
[2022-02-17 02:42:03,663] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:42:03,665] {logging_mixin.py:112} INFO - [2022-02-17 02:42:03,665] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:42:04,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:42:04,257] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:42:04,265] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:42:04,269] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-17 02:42:16,969] {scheduler_job.py:155} INFO - Started process (PID=55294) to work on /airflow/dags/download_data.py
[2022-02-17 02:42:16,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:42:16,982] {logging_mixin.py:112} INFO - [2022-02-17 02:42:16,982] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:42:17,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:42:17,591] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:42:17,602] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:42:17,607] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-17 02:42:30,256] {scheduler_job.py:155} INFO - Started process (PID=55320) to work on /airflow/dags/download_data.py
[2022-02-17 02:42:30,265] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:42:30,268] {logging_mixin.py:112} INFO - [2022-02-17 02:42:30,267] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:42:30,723] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:42:30,767] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:42:30,772] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:42:30,774] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 02:42:43,517] {scheduler_job.py:155} INFO - Started process (PID=55348) to work on /airflow/dags/download_data.py
[2022-02-17 02:42:43,526] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:42:43,528] {logging_mixin.py:112} INFO - [2022-02-17 02:42:43,528] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:42:43,993] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:42:44,039] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:42:44,048] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:42:44,052] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 02:42:56,797] {scheduler_job.py:155} INFO - Started process (PID=55374) to work on /airflow/dags/download_data.py
[2022-02-17 02:42:56,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:42:56,815] {logging_mixin.py:112} INFO - [2022-02-17 02:42:56,814] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:42:57,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:42:57,631] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:42:57,647] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:42:57,656] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.859 seconds
[2022-02-17 02:43:10,060] {scheduler_job.py:155} INFO - Started process (PID=55402) to work on /airflow/dags/download_data.py
[2022-02-17 02:43:10,065] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:43:10,068] {logging_mixin.py:112} INFO - [2022-02-17 02:43:10,067] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:43:10,551] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:43:10,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:43:10,623] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:43:10,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 02:43:23,293] {scheduler_job.py:155} INFO - Started process (PID=55428) to work on /airflow/dags/download_data.py
[2022-02-17 02:43:23,297] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:43:23,299] {logging_mixin.py:112} INFO - [2022-02-17 02:43:23,299] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:43:23,745] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:43:23,790] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:43:23,797] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:43:23,802] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 02:43:36,551] {scheduler_job.py:155} INFO - Started process (PID=55456) to work on /airflow/dags/download_data.py
[2022-02-17 02:43:36,558] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:43:36,560] {logging_mixin.py:112} INFO - [2022-02-17 02:43:36,560] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:43:37,020] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:43:37,069] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:43:37,078] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:43:37,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 02:43:49,830] {scheduler_job.py:155} INFO - Started process (PID=55482) to work on /airflow/dags/download_data.py
[2022-02-17 02:43:49,835] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:43:49,839] {logging_mixin.py:112} INFO - [2022-02-17 02:43:49,838] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:43:50,302] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:43:50,352] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:43:50,358] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:43:50,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 02:44:03,126] {scheduler_job.py:155} INFO - Started process (PID=55509) to work on /airflow/dags/download_data.py
[2022-02-17 02:44:03,141] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:44:03,146] {logging_mixin.py:112} INFO - [2022-02-17 02:44:03,145] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:44:03,844] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:44:03,909] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:44:03,919] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:44:03,925] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.799 seconds
[2022-02-17 02:44:16,390] {scheduler_job.py:155} INFO - Started process (PID=55536) to work on /airflow/dags/download_data.py
[2022-02-17 02:44:16,399] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:44:16,402] {logging_mixin.py:112} INFO - [2022-02-17 02:44:16,402] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:44:16,908] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:44:16,962] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:44:16,971] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:44:16,974] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 02:44:29,641] {scheduler_job.py:155} INFO - Started process (PID=55562) to work on /airflow/dags/download_data.py
[2022-02-17 02:44:29,648] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:44:29,650] {logging_mixin.py:112} INFO - [2022-02-17 02:44:29,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:44:30,098] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:44:30,149] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:44:30,155] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:44:30,162] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 02:44:42,922] {scheduler_job.py:155} INFO - Started process (PID=55590) to work on /airflow/dags/download_data.py
[2022-02-17 02:44:42,926] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:44:42,928] {logging_mixin.py:112} INFO - [2022-02-17 02:44:42,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:44:43,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:44:43,448] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:44:43,457] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:44:43,463] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 02:44:56,166] {scheduler_job.py:155} INFO - Started process (PID=55616) to work on /airflow/dags/download_data.py
[2022-02-17 02:44:56,171] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:44:56,173] {logging_mixin.py:112} INFO - [2022-02-17 02:44:56,173] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:44:56,623] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:44:56,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:44:56,701] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:44:56,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 02:45:09,451] {scheduler_job.py:155} INFO - Started process (PID=55644) to work on /airflow/dags/download_data.py
[2022-02-17 02:45:09,455] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:45:09,457] {logging_mixin.py:112} INFO - [2022-02-17 02:45:09,457] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:45:09,925] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:45:09,987] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:45:09,996] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:45:10,002] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 02:45:22,733] {scheduler_job.py:155} INFO - Started process (PID=55670) to work on /airflow/dags/download_data.py
[2022-02-17 02:45:22,737] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:45:22,740] {logging_mixin.py:112} INFO - [2022-02-17 02:45:22,739] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:45:23,192] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:45:23,244] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:45:23,254] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:45:23,259] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 02:45:36,001] {scheduler_job.py:155} INFO - Started process (PID=55698) to work on /airflow/dags/download_data.py
[2022-02-17 02:45:36,013] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:45:36,021] {logging_mixin.py:112} INFO - [2022-02-17 02:45:36,021] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:45:36,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:45:36,526] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:45:36,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:45:36,537] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 02:45:49,261] {scheduler_job.py:155} INFO - Started process (PID=55724) to work on /airflow/dags/download_data.py
[2022-02-17 02:45:49,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:45:49,269] {logging_mixin.py:112} INFO - [2022-02-17 02:45:49,269] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:45:49,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:45:49,827] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:45:49,840] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:45:49,845] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 02:46:02,521] {scheduler_job.py:155} INFO - Started process (PID=55750) to work on /airflow/dags/download_data.py
[2022-02-17 02:46:02,526] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:46:02,528] {logging_mixin.py:112} INFO - [2022-02-17 02:46:02,528] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:46:03,022] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:46:03,080] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:46:03,087] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:46:03,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 02:46:15,782] {scheduler_job.py:155} INFO - Started process (PID=55778) to work on /airflow/dags/download_data.py
[2022-02-17 02:46:15,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:46:15,788] {logging_mixin.py:112} INFO - [2022-02-17 02:46:15,787] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:46:16,237] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:46:16,277] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:46:16,283] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:46:16,287] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 02:46:29,028] {scheduler_job.py:155} INFO - Started process (PID=55804) to work on /airflow/dags/download_data.py
[2022-02-17 02:46:29,040] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:46:29,044] {logging_mixin.py:112} INFO - [2022-02-17 02:46:29,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:46:29,527] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:46:29,575] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:46:29,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:46:29,589] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 02:46:42,322] {scheduler_job.py:155} INFO - Started process (PID=55832) to work on /airflow/dags/download_data.py
[2022-02-17 02:46:42,328] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:46:42,333] {logging_mixin.py:112} INFO - [2022-02-17 02:46:42,332] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:46:42,862] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:46:42,919] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:46:42,929] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:46:42,933] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-17 02:46:55,585] {scheduler_job.py:155} INFO - Started process (PID=55858) to work on /airflow/dags/download_data.py
[2022-02-17 02:46:55,597] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:46:55,599] {logging_mixin.py:112} INFO - [2022-02-17 02:46:55,599] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:46:56,118] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:46:56,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:46:56,171] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:46:56,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 02:47:08,868] {scheduler_job.py:155} INFO - Started process (PID=55886) to work on /airflow/dags/download_data.py
[2022-02-17 02:47:08,872] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:47:08,874] {logging_mixin.py:112} INFO - [2022-02-17 02:47:08,874] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:47:09,329] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:47:09,382] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:47:09,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:47:09,397] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 02:47:22,145] {scheduler_job.py:155} INFO - Started process (PID=55912) to work on /airflow/dags/download_data.py
[2022-02-17 02:47:22,153] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:47:22,155] {logging_mixin.py:112} INFO - [2022-02-17 02:47:22,155] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:47:22,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:47:22,674] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:47:22,683] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:47:22,689] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 02:47:35,413] {scheduler_job.py:155} INFO - Started process (PID=55938) to work on /airflow/dags/download_data.py
[2022-02-17 02:47:35,429] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:47:35,452] {logging_mixin.py:112} INFO - [2022-02-17 02:47:35,452] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:47:35,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:47:35,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:47:36,005] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:47:36,010] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-17 02:47:48,680] {scheduler_job.py:155} INFO - Started process (PID=55966) to work on /airflow/dags/download_data.py
[2022-02-17 02:47:48,691] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:47:48,693] {logging_mixin.py:112} INFO - [2022-02-17 02:47:48,693] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:47:49,132] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:47:49,170] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:47:49,175] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:47:49,179] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 02:48:01,971] {scheduler_job.py:155} INFO - Started process (PID=55992) to work on /airflow/dags/download_data.py
[2022-02-17 02:48:01,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:48:01,978] {logging_mixin.py:112} INFO - [2022-02-17 02:48:01,978] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:48:02,655] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:48:02,708] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:48:02,719] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:48:02,728] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.757 seconds
[2022-02-17 02:48:15,285] {scheduler_job.py:155} INFO - Started process (PID=56020) to work on /airflow/dags/download_data.py
[2022-02-17 02:48:15,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:48:15,303] {logging_mixin.py:112} INFO - [2022-02-17 02:48:15,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:48:15,733] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:48:15,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:48:15,787] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:48:15,791] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 02:48:28,520] {scheduler_job.py:155} INFO - Started process (PID=56046) to work on /airflow/dags/download_data.py
[2022-02-17 02:48:28,526] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:48:28,528] {logging_mixin.py:112} INFO - [2022-02-17 02:48:28,528] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:48:29,003] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:48:29,060] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:48:29,071] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:48:29,076] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 02:48:41,789] {scheduler_job.py:155} INFO - Started process (PID=56074) to work on /airflow/dags/download_data.py
[2022-02-17 02:48:41,795] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:48:41,798] {logging_mixin.py:112} INFO - [2022-02-17 02:48:41,798] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:48:42,494] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:48:42,554] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:48:42,561] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:48:42,565] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.776 seconds
[2022-02-17 02:48:55,048] {scheduler_job.py:155} INFO - Started process (PID=56100) to work on /airflow/dags/download_data.py
[2022-02-17 02:48:55,052] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:48:55,055] {logging_mixin.py:112} INFO - [2022-02-17 02:48:55,054] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:48:55,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:48:55,638] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:48:55,650] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:48:55,656] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-17 02:49:08,334] {scheduler_job.py:155} INFO - Started process (PID=56126) to work on /airflow/dags/download_data.py
[2022-02-17 02:49:08,338] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:49:08,340] {logging_mixin.py:112} INFO - [2022-02-17 02:49:08,340] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:49:08,794] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:49:08,856] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:49:08,871] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:49:08,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 02:49:21,592] {scheduler_job.py:155} INFO - Started process (PID=56154) to work on /airflow/dags/download_data.py
[2022-02-17 02:49:21,599] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:49:21,601] {logging_mixin.py:112} INFO - [2022-02-17 02:49:21,601] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:49:22,027] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:49:22,066] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:49:22,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:49:22,078] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.486 seconds
[2022-02-17 02:49:34,831] {scheduler_job.py:155} INFO - Started process (PID=56180) to work on /airflow/dags/download_data.py
[2022-02-17 02:49:34,836] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:49:34,838] {logging_mixin.py:112} INFO - [2022-02-17 02:49:34,838] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:49:35,422] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:49:35,472] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:49:35,482] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:49:35,488] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-17 02:49:48,112] {scheduler_job.py:155} INFO - Started process (PID=56208) to work on /airflow/dags/download_data.py
[2022-02-17 02:49:48,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:49:48,132] {logging_mixin.py:112} INFO - [2022-02-17 02:49:48,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:49:48,596] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:49:48,661] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:49:48,671] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:49:48,678] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 02:50:01,394] {scheduler_job.py:155} INFO - Started process (PID=56234) to work on /airflow/dags/download_data.py
[2022-02-17 02:50:01,401] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:50:01,403] {logging_mixin.py:112} INFO - [2022-02-17 02:50:01,403] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:50:01,869] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:50:01,930] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:50:01,938] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:50:01,943] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 02:50:14,678] {scheduler_job.py:155} INFO - Started process (PID=56262) to work on /airflow/dags/download_data.py
[2022-02-17 02:50:14,682] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:50:14,684] {logging_mixin.py:112} INFO - [2022-02-17 02:50:14,684] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:50:15,144] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:50:15,211] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:50:15,222] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:50:15,229] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 02:50:27,924] {scheduler_job.py:155} INFO - Started process (PID=56288) to work on /airflow/dags/download_data.py
[2022-02-17 02:50:27,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:50:27,929] {logging_mixin.py:112} INFO - [2022-02-17 02:50:27,929] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:50:28,390] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:50:28,432] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:50:28,440] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:50:28,446] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 02:50:41,198] {scheduler_job.py:155} INFO - Started process (PID=56314) to work on /airflow/dags/download_data.py
[2022-02-17 02:50:41,203] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:50:41,205] {logging_mixin.py:112} INFO - [2022-02-17 02:50:41,205] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:50:41,721] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:50:41,920] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:50:41,934] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:50:41,947] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.750 seconds
[2022-02-17 02:50:54,476] {scheduler_job.py:155} INFO - Started process (PID=56342) to work on /airflow/dags/download_data.py
[2022-02-17 02:50:54,481] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:50:54,482] {logging_mixin.py:112} INFO - [2022-02-17 02:50:54,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:50:54,945] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:50:54,992] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:50:55,000] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:50:55,006] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 02:51:07,769] {scheduler_job.py:155} INFO - Started process (PID=56368) to work on /airflow/dags/download_data.py
[2022-02-17 02:51:07,774] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:51:07,776] {logging_mixin.py:112} INFO - [2022-02-17 02:51:07,776] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:51:08,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:51:08,300] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:51:08,310] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:51:08,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 02:51:21,058] {scheduler_job.py:155} INFO - Started process (PID=56396) to work on /airflow/dags/download_data.py
[2022-02-17 02:51:21,066] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:51:21,068] {logging_mixin.py:112} INFO - [2022-02-17 02:51:21,068] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:51:21,517] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:51:21,571] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:51:21,582] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:51:21,588] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 02:51:34,363] {scheduler_job.py:155} INFO - Started process (PID=56422) to work on /airflow/dags/download_data.py
[2022-02-17 02:51:34,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:51:34,377] {logging_mixin.py:112} INFO - [2022-02-17 02:51:34,377] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:51:34,851] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:51:34,923] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:51:34,933] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:51:34,937] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 02:51:47,646] {scheduler_job.py:155} INFO - Started process (PID=56450) to work on /airflow/dags/download_data.py
[2022-02-17 02:51:47,657] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:51:47,662] {logging_mixin.py:112} INFO - [2022-02-17 02:51:47,662] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:51:48,657] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:51:48,724] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:51:48,739] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:51:48,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.105 seconds
[2022-02-17 02:52:02,007] {scheduler_job.py:155} INFO - Started process (PID=56476) to work on /airflow/dags/download_data.py
[2022-02-17 02:52:02,024] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:52:02,027] {logging_mixin.py:112} INFO - [2022-02-17 02:52:02,027] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:52:02,542] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:52:02,604] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:52:02,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:52:02,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-17 02:52:14,329] {scheduler_job.py:155} INFO - Started process (PID=56503) to work on /airflow/dags/download_data.py
[2022-02-17 02:52:14,345] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:52:14,348] {logging_mixin.py:112} INFO - [2022-02-17 02:52:14,348] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:52:14,906] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:52:14,964] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:52:14,972] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:52:14,977] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-17 02:52:27,568] {scheduler_job.py:155} INFO - Started process (PID=56529) to work on /airflow/dags/download_data.py
[2022-02-17 02:52:27,573] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:52:27,575] {logging_mixin.py:112} INFO - [2022-02-17 02:52:27,575] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:52:28,061] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:52:28,116] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:52:28,124] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:52:28,129] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 02:52:40,914] {scheduler_job.py:155} INFO - Started process (PID=56555) to work on /airflow/dags/download_data.py
[2022-02-17 02:52:40,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:52:40,931] {logging_mixin.py:112} INFO - [2022-02-17 02:52:40,930] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:52:41,776] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:52:41,874] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:52:41,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:52:41,917] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.003 seconds
[2022-02-17 02:52:55,178] {scheduler_job.py:155} INFO - Started process (PID=56583) to work on /airflow/dags/download_data.py
[2022-02-17 02:52:55,190] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:52:55,191] {logging_mixin.py:112} INFO - [2022-02-17 02:52:55,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:52:55,755] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:52:55,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:52:55,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:52:55,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.655 seconds
[2022-02-17 02:53:07,430] {scheduler_job.py:155} INFO - Started process (PID=56608) to work on /airflow/dags/download_data.py
[2022-02-17 02:53:07,436] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:53:07,438] {logging_mixin.py:112} INFO - [2022-02-17 02:53:07,438] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:53:07,898] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:53:07,955] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:53:07,968] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:53:07,972] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 02:53:20,674] {scheduler_job.py:155} INFO - Started process (PID=56636) to work on /airflow/dags/download_data.py
[2022-02-17 02:53:20,678] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:53:20,680] {logging_mixin.py:112} INFO - [2022-02-17 02:53:20,680] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:53:21,141] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:53:21,195] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:53:21,206] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:53:21,213] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 02:53:33,968] {scheduler_job.py:155} INFO - Started process (PID=56662) to work on /airflow/dags/download_data.py
[2022-02-17 02:53:33,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:53:33,981] {logging_mixin.py:112} INFO - [2022-02-17 02:53:33,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:53:34,474] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:53:34,535] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:53:34,546] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:53:34,550] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 02:53:47,266] {scheduler_job.py:155} INFO - Started process (PID=56690) to work on /airflow/dags/download_data.py
[2022-02-17 02:53:47,279] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:53:47,282] {logging_mixin.py:112} INFO - [2022-02-17 02:53:47,281] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:53:47,726] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:53:47,774] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:53:47,781] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:53:47,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 02:54:00,505] {scheduler_job.py:155} INFO - Started process (PID=56716) to work on /airflow/dags/download_data.py
[2022-02-17 02:54:00,509] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:54:00,511] {logging_mixin.py:112} INFO - [2022-02-17 02:54:00,511] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:54:00,992] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:54:01,040] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:54:01,052] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:54:01,057] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 02:54:13,797] {scheduler_job.py:155} INFO - Started process (PID=56742) to work on /airflow/dags/download_data.py
[2022-02-17 02:54:13,803] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:54:13,805] {logging_mixin.py:112} INFO - [2022-02-17 02:54:13,805] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:54:14,303] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:54:14,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:54:14,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:54:14,354] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 02:54:27,032] {scheduler_job.py:155} INFO - Started process (PID=56770) to work on /airflow/dags/download_data.py
[2022-02-17 02:54:27,036] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:54:27,038] {logging_mixin.py:112} INFO - [2022-02-17 02:54:27,038] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:54:27,512] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:54:27,557] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:54:27,566] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:54:27,569] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 02:54:40,331] {scheduler_job.py:155} INFO - Started process (PID=56796) to work on /airflow/dags/download_data.py
[2022-02-17 02:54:40,337] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:54:40,339] {logging_mixin.py:112} INFO - [2022-02-17 02:54:40,339] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:54:40,910] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:54:40,955] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:54:40,963] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:54:40,969] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-17 02:54:53,565] {scheduler_job.py:155} INFO - Started process (PID=56824) to work on /airflow/dags/download_data.py
[2022-02-17 02:54:53,573] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:54:53,576] {logging_mixin.py:112} INFO - [2022-02-17 02:54:53,575] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:54:54,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:54:54,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:54:54,172] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:54:54,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-17 02:55:06,837] {scheduler_job.py:155} INFO - Started process (PID=56850) to work on /airflow/dags/download_data.py
[2022-02-17 02:55:06,843] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:55:06,845] {logging_mixin.py:112} INFO - [2022-02-17 02:55:06,845] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:55:07,311] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:55:07,370] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:55:07,379] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:55:07,384] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 02:55:20,104] {scheduler_job.py:155} INFO - Started process (PID=56878) to work on /airflow/dags/download_data.py
[2022-02-17 02:55:20,110] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:55:20,112] {logging_mixin.py:112} INFO - [2022-02-17 02:55:20,111] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:55:20,571] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:55:20,616] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:55:20,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:55:20,627] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 02:55:33,380] {scheduler_job.py:155} INFO - Started process (PID=56904) to work on /airflow/dags/download_data.py
[2022-02-17 02:55:33,385] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:55:33,386] {logging_mixin.py:112} INFO - [2022-02-17 02:55:33,386] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:55:33,835] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:55:33,882] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:55:33,891] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:55:33,897] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 02:55:46,659] {scheduler_job.py:155} INFO - Started process (PID=56930) to work on /airflow/dags/download_data.py
[2022-02-17 02:55:46,668] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:55:46,670] {logging_mixin.py:112} INFO - [2022-02-17 02:55:46,670] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:55:47,154] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:55:47,213] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:55:47,223] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:55:47,230] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 02:55:59,922] {scheduler_job.py:155} INFO - Started process (PID=56958) to work on /airflow/dags/download_data.py
[2022-02-17 02:55:59,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:55:59,932] {logging_mixin.py:112} INFO - [2022-02-17 02:55:59,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:56:00,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:56:00,439] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:56:00,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:56:00,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 02:56:13,240] {scheduler_job.py:155} INFO - Started process (PID=56984) to work on /airflow/dags/download_data.py
[2022-02-17 02:56:13,245] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:56:13,247] {logging_mixin.py:112} INFO - [2022-02-17 02:56:13,247] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:56:13,986] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:56:14,056] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:56:14,079] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:56:14,089] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.849 seconds
[2022-02-17 02:56:26,509] {scheduler_job.py:155} INFO - Started process (PID=57012) to work on /airflow/dags/download_data.py
[2022-02-17 02:56:26,521] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:56:26,523] {logging_mixin.py:112} INFO - [2022-02-17 02:56:26,522] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:56:27,017] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:56:27,071] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:56:27,079] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:56:27,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 02:56:39,779] {scheduler_job.py:155} INFO - Started process (PID=57038) to work on /airflow/dags/download_data.py
[2022-02-17 02:56:39,783] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:56:39,785] {logging_mixin.py:112} INFO - [2022-02-17 02:56:39,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:56:40,234] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:56:40,287] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:56:40,294] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:56:40,299] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 02:56:52,991] {scheduler_job.py:155} INFO - Started process (PID=57066) to work on /airflow/dags/download_data.py
[2022-02-17 02:56:52,995] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:56:52,997] {logging_mixin.py:112} INFO - [2022-02-17 02:56:52,997] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:56:53,472] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:56:53,526] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:56:53,538] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:56:53,542] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 02:57:06,285] {scheduler_job.py:155} INFO - Started process (PID=57092) to work on /airflow/dags/download_data.py
[2022-02-17 02:57:06,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:57:06,299] {logging_mixin.py:112} INFO - [2022-02-17 02:57:06,298] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:57:06,805] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:57:06,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:57:06,864] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:57:06,871] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 02:57:19,496] {scheduler_job.py:155} INFO - Started process (PID=57118) to work on /airflow/dags/download_data.py
[2022-02-17 02:57:19,505] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:57:19,507] {logging_mixin.py:112} INFO - [2022-02-17 02:57:19,507] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:57:19,973] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:57:20,030] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:57:20,042] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:57:20,058] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 02:57:32,793] {scheduler_job.py:155} INFO - Started process (PID=57146) to work on /airflow/dags/download_data.py
[2022-02-17 02:57:32,804] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:57:32,806] {logging_mixin.py:112} INFO - [2022-02-17 02:57:32,805] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:57:33,253] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:57:33,306] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:57:33,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:57:33,323] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 02:57:46,037] {scheduler_job.py:155} INFO - Started process (PID=57172) to work on /airflow/dags/download_data.py
[2022-02-17 02:57:46,042] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:57:46,044] {logging_mixin.py:112} INFO - [2022-02-17 02:57:46,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:57:46,493] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:57:46,544] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:57:46,552] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:57:46,557] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 02:57:59,327] {scheduler_job.py:155} INFO - Started process (PID=57200) to work on /airflow/dags/download_data.py
[2022-02-17 02:57:59,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:57:59,334] {logging_mixin.py:112} INFO - [2022-02-17 02:57:59,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:57:59,783] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:57:59,839] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:57:59,849] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:57:59,856] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 02:58:12,631] {scheduler_job.py:155} INFO - Started process (PID=57226) to work on /airflow/dags/download_data.py
[2022-02-17 02:58:12,638] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:58:12,641] {logging_mixin.py:112} INFO - [2022-02-17 02:58:12,640] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:58:13,119] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:58:13,174] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:58:13,183] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:58:13,188] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 02:58:25,857] {scheduler_job.py:155} INFO - Started process (PID=57254) to work on /airflow/dags/download_data.py
[2022-02-17 02:58:25,862] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:58:25,864] {logging_mixin.py:112} INFO - [2022-02-17 02:58:25,863] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:58:26,319] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:58:26,366] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:58:26,376] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:58:26,380] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 02:58:39,161] {scheduler_job.py:155} INFO - Started process (PID=57280) to work on /airflow/dags/download_data.py
[2022-02-17 02:58:39,166] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:58:39,167] {logging_mixin.py:112} INFO - [2022-02-17 02:58:39,167] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:58:39,618] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:58:39,672] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:58:39,679] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:58:39,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 02:58:52,418] {scheduler_job.py:155} INFO - Started process (PID=57308) to work on /airflow/dags/download_data.py
[2022-02-17 02:58:52,436] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:58:52,441] {logging_mixin.py:112} INFO - [2022-02-17 02:58:52,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:58:52,941] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:58:52,979] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:58:52,989] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:58:52,994] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 02:59:05,708] {scheduler_job.py:155} INFO - Started process (PID=57334) to work on /airflow/dags/download_data.py
[2022-02-17 02:59:05,717] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:59:05,719] {logging_mixin.py:112} INFO - [2022-02-17 02:59:05,719] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:59:06,170] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:59:06,215] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:59:06,227] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:59:06,233] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 02:59:18,943] {scheduler_job.py:155} INFO - Started process (PID=57360) to work on /airflow/dags/download_data.py
[2022-02-17 02:59:18,947] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:59:18,949] {logging_mixin.py:112} INFO - [2022-02-17 02:59:18,948] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:59:19,393] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:59:19,441] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:59:19,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:59:19,454] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 02:59:32,233] {scheduler_job.py:155} INFO - Started process (PID=57388) to work on /airflow/dags/download_data.py
[2022-02-17 02:59:32,244] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:59:32,245] {logging_mixin.py:112} INFO - [2022-02-17 02:59:32,245] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:59:32,687] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:59:32,731] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:59:32,740] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:59:32,748] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 02:59:45,531] {scheduler_job.py:155} INFO - Started process (PID=57414) to work on /airflow/dags/download_data.py
[2022-02-17 02:59:45,540] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:59:45,543] {logging_mixin.py:112} INFO - [2022-02-17 02:59:45,543] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:59:46,125] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:59:46,169] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:59:46,179] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:59:46,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.655 seconds
[2022-02-17 02:59:58,738] {scheduler_job.py:155} INFO - Started process (PID=57442) to work on /airflow/dags/download_data.py
[2022-02-17 02:59:58,744] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 02:59:58,745] {logging_mixin.py:112} INFO - [2022-02-17 02:59:58,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 02:59:59,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 02:59:59,266] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 02:59:59,278] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 02:59:59,285] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 03:00:12,057] {scheduler_job.py:155} INFO - Started process (PID=57468) to work on /airflow/dags/download_data.py
[2022-02-17 03:00:12,064] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:00:12,068] {logging_mixin.py:112} INFO - [2022-02-17 03:00:12,068] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:00:12,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:00:12,572] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:00:12,577] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:00:12,581] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 03:00:25,308] {scheduler_job.py:155} INFO - Started process (PID=57496) to work on /airflow/dags/download_data.py
[2022-02-17 03:00:25,312] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:00:25,314] {logging_mixin.py:112} INFO - [2022-02-17 03:00:25,313] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:00:25,735] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:00:25,784] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:00:25,796] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:00:25,802] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 03:00:38,578] {scheduler_job.py:155} INFO - Started process (PID=57522) to work on /airflow/dags/download_data.py
[2022-02-17 03:00:38,586] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:00:38,588] {logging_mixin.py:112} INFO - [2022-02-17 03:00:38,588] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:00:39,051] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:00:39,101] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:00:39,108] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:00:39,113] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 03:00:51,829] {scheduler_job.py:155} INFO - Started process (PID=57548) to work on /airflow/dags/download_data.py
[2022-02-17 03:00:51,838] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:00:51,840] {logging_mixin.py:112} INFO - [2022-02-17 03:00:51,840] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:00:52,277] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:00:52,328] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:00:52,335] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:00:52,340] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 03:01:05,114] {scheduler_job.py:155} INFO - Started process (PID=57576) to work on /airflow/dags/download_data.py
[2022-02-17 03:01:05,121] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:01:05,123] {logging_mixin.py:112} INFO - [2022-02-17 03:01:05,123] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:01:05,646] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:01:05,704] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:01:05,717] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:01:05,723] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-17 03:01:18,368] {scheduler_job.py:155} INFO - Started process (PID=57602) to work on /airflow/dags/download_data.py
[2022-02-17 03:01:18,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:01:18,378] {logging_mixin.py:112} INFO - [2022-02-17 03:01:18,377] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:01:18,834] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:01:18,890] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:01:18,899] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:01:18,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 03:01:31,658] {scheduler_job.py:155} INFO - Started process (PID=57630) to work on /airflow/dags/download_data.py
[2022-02-17 03:01:31,665] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:01:31,667] {logging_mixin.py:112} INFO - [2022-02-17 03:01:31,666] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:01:32,146] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:01:32,194] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:01:32,203] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:01:32,208] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 03:01:44,957] {scheduler_job.py:155} INFO - Started process (PID=57656) to work on /airflow/dags/download_data.py
[2022-02-17 03:01:44,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:01:44,963] {logging_mixin.py:112} INFO - [2022-02-17 03:01:44,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:01:45,420] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:01:45,470] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:01:45,477] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:01:45,483] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 03:01:58,188] {scheduler_job.py:155} INFO - Started process (PID=57684) to work on /airflow/dags/download_data.py
[2022-02-17 03:01:58,201] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:01:58,203] {logging_mixin.py:112} INFO - [2022-02-17 03:01:58,202] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:01:58,686] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:01:58,742] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:01:58,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:01:58,753] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 03:02:11,512] {scheduler_job.py:155} INFO - Started process (PID=57710) to work on /airflow/dags/download_data.py
[2022-02-17 03:02:11,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:02:11,518] {logging_mixin.py:112} INFO - [2022-02-17 03:02:11,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:02:11,965] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:02:12,004] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:02:12,009] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:02:12,013] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 03:02:24,783] {scheduler_job.py:155} INFO - Started process (PID=57736) to work on /airflow/dags/download_data.py
[2022-02-17 03:02:24,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:02:24,793] {logging_mixin.py:112} INFO - [2022-02-17 03:02:24,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:02:25,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:02:25,304] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:02:25,311] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:02:25,314] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 03:02:38,076] {scheduler_job.py:155} INFO - Started process (PID=57764) to work on /airflow/dags/download_data.py
[2022-02-17 03:02:38,080] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:02:38,097] {logging_mixin.py:112} INFO - [2022-02-17 03:02:38,097] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:02:38,543] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:02:38,594] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:02:38,600] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:02:38,604] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 03:02:51,361] {scheduler_job.py:155} INFO - Started process (PID=57790) to work on /airflow/dags/download_data.py
[2022-02-17 03:02:51,366] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:02:51,368] {logging_mixin.py:112} INFO - [2022-02-17 03:02:51,367] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:02:51,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:02:51,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:02:51,890] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:02:51,897] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 03:03:04,692] {scheduler_job.py:155} INFO - Started process (PID=57818) to work on /airflow/dags/download_data.py
[2022-02-17 03:03:04,699] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:03:04,701] {logging_mixin.py:112} INFO - [2022-02-17 03:03:04,701] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:03:05,420] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:03:05,480] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:03:05,490] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:03:05,494] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.802 seconds
[2022-02-17 03:03:17,944] {scheduler_job.py:155} INFO - Started process (PID=57844) to work on /airflow/dags/download_data.py
[2022-02-17 03:03:17,949] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:03:17,951] {logging_mixin.py:112} INFO - [2022-02-17 03:03:17,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:03:18,449] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:03:18,491] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:03:18,505] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:03:18,511] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 03:03:31,216] {scheduler_job.py:155} INFO - Started process (PID=57872) to work on /airflow/dags/download_data.py
[2022-02-17 03:03:31,221] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:03:31,223] {logging_mixin.py:112} INFO - [2022-02-17 03:03:31,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:03:31,785] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:03:31,827] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:03:31,833] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:03:31,837] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-17 03:03:44,519] {scheduler_job.py:155} INFO - Started process (PID=57898) to work on /airflow/dags/download_data.py
[2022-02-17 03:03:44,524] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:03:44,526] {logging_mixin.py:112} INFO - [2022-02-17 03:03:44,525] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:03:45,008] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:03:45,063] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:03:45,070] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:03:45,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 03:03:57,789] {scheduler_job.py:155} INFO - Started process (PID=57924) to work on /airflow/dags/download_data.py
[2022-02-17 03:03:57,794] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:03:57,797] {logging_mixin.py:112} INFO - [2022-02-17 03:03:57,797] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:03:58,451] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:03:58,498] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:03:58,509] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:03:58,519] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.730 seconds
[2022-02-17 03:04:11,075] {scheduler_job.py:155} INFO - Started process (PID=57952) to work on /airflow/dags/download_data.py
[2022-02-17 03:04:11,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:04:11,085] {logging_mixin.py:112} INFO - [2022-02-17 03:04:11,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:04:11,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:04:11,571] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:04:11,578] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:04:11,583] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 03:04:24,567] {scheduler_job.py:155} INFO - Started process (PID=57978) to work on /airflow/dags/download_data.py
[2022-02-17 03:04:24,571] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:04:24,574] {logging_mixin.py:112} INFO - [2022-02-17 03:04:24,573] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:04:25,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:04:25,050] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:04:25,058] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:04:25,061] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 03:04:37,845] {scheduler_job.py:155} INFO - Started process (PID=58006) to work on /airflow/dags/download_data.py
[2022-02-17 03:04:37,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:04:37,852] {logging_mixin.py:112} INFO - [2022-02-17 03:04:37,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:04:38,322] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:04:38,366] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:04:38,377] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:04:38,384] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 03:04:51,076] {scheduler_job.py:155} INFO - Started process (PID=58032) to work on /airflow/dags/download_data.py
[2022-02-17 03:04:51,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:04:51,083] {logging_mixin.py:112} INFO - [2022-02-17 03:04:51,083] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:04:51,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:04:51,644] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:04:51,652] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:04:51,658] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 03:05:04,327] {scheduler_job.py:155} INFO - Started process (PID=58060) to work on /airflow/dags/download_data.py
[2022-02-17 03:05:04,333] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:05:04,335] {logging_mixin.py:112} INFO - [2022-02-17 03:05:04,335] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:05:04,843] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:05:04,889] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:05:04,900] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:05:04,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 03:05:17,623] {scheduler_job.py:155} INFO - Started process (PID=58086) to work on /airflow/dags/download_data.py
[2022-02-17 03:05:17,629] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:05:17,631] {logging_mixin.py:112} INFO - [2022-02-17 03:05:17,631] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:05:18,121] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:05:18,167] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:05:18,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:05:18,177] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 03:05:30,903] {scheduler_job.py:155} INFO - Started process (PID=58114) to work on /airflow/dags/download_data.py
[2022-02-17 03:05:30,909] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:05:30,911] {logging_mixin.py:112} INFO - [2022-02-17 03:05:30,911] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:05:31,398] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:05:31,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:05:31,450] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:05:31,456] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 03:05:44,209] {scheduler_job.py:155} INFO - Started process (PID=58140) to work on /airflow/dags/download_data.py
[2022-02-17 03:05:44,215] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:05:44,217] {logging_mixin.py:112} INFO - [2022-02-17 03:05:44,217] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:05:44,703] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:05:44,748] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:05:44,757] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:05:44,761] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 03:05:57,461] {scheduler_job.py:155} INFO - Started process (PID=58166) to work on /airflow/dags/download_data.py
[2022-02-17 03:05:57,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:05:57,472] {logging_mixin.py:112} INFO - [2022-02-17 03:05:57,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:05:57,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:05:58,041] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:05:58,048] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:05:58,055] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 03:06:10,788] {scheduler_job.py:155} INFO - Started process (PID=58194) to work on /airflow/dags/download_data.py
[2022-02-17 03:06:10,796] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:06:10,798] {logging_mixin.py:112} INFO - [2022-02-17 03:06:10,798] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:06:11,298] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:06:11,347] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:06:11,359] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:06:11,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 03:06:24,025] {scheduler_job.py:155} INFO - Started process (PID=58220) to work on /airflow/dags/download_data.py
[2022-02-17 03:06:24,030] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:06:24,031] {logging_mixin.py:112} INFO - [2022-02-17 03:06:24,031] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:06:24,480] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:06:24,531] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:06:24,537] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:06:24,541] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 03:06:37,314] {scheduler_job.py:155} INFO - Started process (PID=58248) to work on /airflow/dags/download_data.py
[2022-02-17 03:06:37,322] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:06:37,324] {logging_mixin.py:112} INFO - [2022-02-17 03:06:37,324] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:06:37,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:06:37,868] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:06:37,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:06:37,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 03:06:50,587] {scheduler_job.py:155} INFO - Started process (PID=58274) to work on /airflow/dags/download_data.py
[2022-02-17 03:06:50,591] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:06:50,593] {logging_mixin.py:112} INFO - [2022-02-17 03:06:50,593] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:06:51,035] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:06:51,090] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:06:51,100] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:06:51,104] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 03:07:03,879] {scheduler_job.py:155} INFO - Started process (PID=58302) to work on /airflow/dags/download_data.py
[2022-02-17 03:07:03,886] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:07:03,887] {logging_mixin.py:112} INFO - [2022-02-17 03:07:03,887] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:07:04,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:07:04,404] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:07:04,410] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:07:04,414] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 03:07:17,158] {scheduler_job.py:155} INFO - Started process (PID=58328) to work on /airflow/dags/download_data.py
[2022-02-17 03:07:17,165] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:07:17,166] {logging_mixin.py:112} INFO - [2022-02-17 03:07:17,166] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:07:17,643] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:07:17,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:07:17,693] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:07:17,697] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 03:07:30,446] {scheduler_job.py:155} INFO - Started process (PID=58354) to work on /airflow/dags/download_data.py
[2022-02-17 03:07:30,453] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:07:30,454] {logging_mixin.py:112} INFO - [2022-02-17 03:07:30,454] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:07:30,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:07:31,012] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:07:31,020] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:07:31,027] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 03:07:43,726] {scheduler_job.py:155} INFO - Started process (PID=58382) to work on /airflow/dags/download_data.py
[2022-02-17 03:07:43,731] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:07:43,733] {logging_mixin.py:112} INFO - [2022-02-17 03:07:43,732] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:07:44,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:07:44,241] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:07:44,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:07:44,255] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 03:07:56,993] {scheduler_job.py:155} INFO - Started process (PID=58408) to work on /airflow/dags/download_data.py
[2022-02-17 03:07:57,001] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:07:57,003] {logging_mixin.py:112} INFO - [2022-02-17 03:07:57,003] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:07:57,512] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:07:57,573] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:07:57,582] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:07:57,590] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-17 03:08:10,281] {scheduler_job.py:155} INFO - Started process (PID=58436) to work on /airflow/dags/download_data.py
[2022-02-17 03:08:10,286] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:08:10,287] {logging_mixin.py:112} INFO - [2022-02-17 03:08:10,287] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:08:10,753] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:08:10,807] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:08:10,814] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:08:10,821] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 03:08:23,486] {scheduler_job.py:155} INFO - Started process (PID=58462) to work on /airflow/dags/download_data.py
[2022-02-17 03:08:23,490] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:08:23,492] {logging_mixin.py:112} INFO - [2022-02-17 03:08:23,492] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:08:23,968] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:08:24,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:08:24,028] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:08:24,036] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 03:08:36,792] {scheduler_job.py:155} INFO - Started process (PID=58490) to work on /airflow/dags/download_data.py
[2022-02-17 03:08:36,808] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:08:36,811] {logging_mixin.py:112} INFO - [2022-02-17 03:08:36,810] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:08:37,295] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:08:37,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:08:37,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:08:37,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 03:08:50,034] {scheduler_job.py:155} INFO - Started process (PID=58516) to work on /airflow/dags/download_data.py
[2022-02-17 03:08:50,038] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:08:50,040] {logging_mixin.py:112} INFO - [2022-02-17 03:08:50,040] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:08:50,510] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:08:50,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:08:50,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:08:50,567] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 03:09:03,389] {scheduler_job.py:155} INFO - Started process (PID=58542) to work on /airflow/dags/download_data.py
[2022-02-17 03:09:03,394] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:09:03,396] {logging_mixin.py:112} INFO - [2022-02-17 03:09:03,396] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:09:03,874] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:09:03,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:09:03,945] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:09:03,950] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 03:09:16,626] {scheduler_job.py:155} INFO - Started process (PID=58570) to work on /airflow/dags/download_data.py
[2022-02-17 03:09:16,635] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:09:16,637] {logging_mixin.py:112} INFO - [2022-02-17 03:09:16,636] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:09:17,104] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:09:17,147] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:09:17,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:09:17,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 03:09:29,957] {scheduler_job.py:155} INFO - Started process (PID=58596) to work on /airflow/dags/download_data.py
[2022-02-17 03:09:29,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:09:29,964] {logging_mixin.py:112} INFO - [2022-02-17 03:09:29,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:09:30,430] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:09:30,489] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:09:30,499] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:09:30,507] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 03:09:43,247] {scheduler_job.py:155} INFO - Started process (PID=58624) to work on /airflow/dags/download_data.py
[2022-02-17 03:09:43,254] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:09:43,256] {logging_mixin.py:112} INFO - [2022-02-17 03:09:43,256] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:09:43,743] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:09:43,805] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:09:43,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:09:43,822] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-17 03:09:56,491] {scheduler_job.py:155} INFO - Started process (PID=58650) to work on /airflow/dags/download_data.py
[2022-02-17 03:09:56,496] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:09:56,498] {logging_mixin.py:112} INFO - [2022-02-17 03:09:56,498] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:09:56,976] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:09:57,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:09:57,052] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:09:57,060] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 03:10:09,815] {scheduler_job.py:155} INFO - Started process (PID=58678) to work on /airflow/dags/download_data.py
[2022-02-17 03:10:09,820] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:10:09,822] {logging_mixin.py:112} INFO - [2022-02-17 03:10:09,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:10:10,297] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:10:10,353] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:10:10,362] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:10:10,367] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 03:10:23,052] {scheduler_job.py:155} INFO - Started process (PID=58704) to work on /airflow/dags/download_data.py
[2022-02-17 03:10:23,058] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:10:23,060] {logging_mixin.py:112} INFO - [2022-02-17 03:10:23,059] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:10:23,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:10:23,587] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:10:23,593] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:10:23,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 03:10:36,357] {scheduler_job.py:155} INFO - Started process (PID=58732) to work on /airflow/dags/download_data.py
[2022-02-17 03:10:36,370] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:10:36,373] {logging_mixin.py:112} INFO - [2022-02-17 03:10:36,373] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:10:36,938] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:10:36,994] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:10:37,004] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:10:37,011] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-17 03:10:49,583] {scheduler_job.py:155} INFO - Started process (PID=58758) to work on /airflow/dags/download_data.py
[2022-02-17 03:10:49,587] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:10:49,590] {logging_mixin.py:112} INFO - [2022-02-17 03:10:49,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:10:50,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:10:50,118] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:10:50,127] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:10:50,131] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 03:11:02,872] {scheduler_job.py:155} INFO - Started process (PID=58784) to work on /airflow/dags/download_data.py
[2022-02-17 03:11:02,882] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:11:02,884] {logging_mixin.py:112} INFO - [2022-02-17 03:11:02,884] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:11:03,357] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:11:03,403] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:11:03,414] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:11:03,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 03:11:16,147] {scheduler_job.py:155} INFO - Started process (PID=58812) to work on /airflow/dags/download_data.py
[2022-02-17 03:11:16,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:11:16,154] {logging_mixin.py:112} INFO - [2022-02-17 03:11:16,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:11:16,556] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:11:16,608] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:11:16,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:11:16,620] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.473 seconds
[2022-02-17 03:11:29,400] {scheduler_job.py:155} INFO - Started process (PID=58838) to work on /airflow/dags/download_data.py
[2022-02-17 03:11:29,405] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:11:29,407] {logging_mixin.py:112} INFO - [2022-02-17 03:11:29,407] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:11:29,874] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:11:29,922] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:11:29,931] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:11:29,939] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 03:11:42,657] {scheduler_job.py:155} INFO - Started process (PID=58866) to work on /airflow/dags/download_data.py
[2022-02-17 03:11:42,661] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:11:42,663] {logging_mixin.py:112} INFO - [2022-02-17 03:11:42,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:11:43,124] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:11:43,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:11:43,183] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:11:43,189] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 03:11:55,909] {scheduler_job.py:155} INFO - Started process (PID=58892) to work on /airflow/dags/download_data.py
[2022-02-17 03:11:55,927] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:11:55,931] {logging_mixin.py:112} INFO - [2022-02-17 03:11:55,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:11:56,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:11:56,460] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:11:56,472] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:11:56,481] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 03:12:09,192] {scheduler_job.py:155} INFO - Started process (PID=58920) to work on /airflow/dags/download_data.py
[2022-02-17 03:12:09,210] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:12:09,213] {logging_mixin.py:112} INFO - [2022-02-17 03:12:09,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:12:09,711] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:12:09,766] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:12:09,776] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:12:09,781] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 03:12:22,465] {scheduler_job.py:155} INFO - Started process (PID=58946) to work on /airflow/dags/download_data.py
[2022-02-17 03:12:22,473] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:12:22,476] {logging_mixin.py:112} INFO - [2022-02-17 03:12:22,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:12:22,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:12:22,992] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:12:22,999] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:12:23,002] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 03:12:35,700] {scheduler_job.py:155} INFO - Started process (PID=58972) to work on /airflow/dags/download_data.py
[2022-02-17 03:12:35,705] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:12:35,707] {logging_mixin.py:112} INFO - [2022-02-17 03:12:35,707] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:12:36,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:12:36,203] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:12:36,208] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:12:36,212] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 03:12:48,942] {scheduler_job.py:155} INFO - Started process (PID=59000) to work on /airflow/dags/download_data.py
[2022-02-17 03:12:48,950] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:12:48,953] {logging_mixin.py:112} INFO - [2022-02-17 03:12:48,952] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:12:49,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:12:49,480] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:12:49,488] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:12:49,492] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 03:13:02,225] {scheduler_job.py:155} INFO - Started process (PID=59026) to work on /airflow/dags/download_data.py
[2022-02-17 03:13:02,230] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:13:02,232] {logging_mixin.py:112} INFO - [2022-02-17 03:13:02,232] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:13:02,696] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:13:02,745] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:13:02,754] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:13:02,760] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 03:13:15,520] {scheduler_job.py:155} INFO - Started process (PID=59054) to work on /airflow/dags/download_data.py
[2022-02-17 03:13:15,524] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:13:15,526] {logging_mixin.py:112} INFO - [2022-02-17 03:13:15,525] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:13:16,013] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:13:16,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:13:16,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:13:16,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 03:13:28,806] {scheduler_job.py:155} INFO - Started process (PID=59080) to work on /airflow/dags/download_data.py
[2022-02-17 03:13:28,811] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:13:28,813] {logging_mixin.py:112} INFO - [2022-02-17 03:13:28,813] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:13:29,343] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:13:29,409] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:13:29,420] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:13:29,431] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-17 03:13:42,087] {scheduler_job.py:155} INFO - Started process (PID=59108) to work on /airflow/dags/download_data.py
[2022-02-17 03:13:42,096] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:13:42,100] {logging_mixin.py:112} INFO - [2022-02-17 03:13:42,099] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:13:42,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:13:42,652] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:13:42,658] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:13:42,664] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 03:13:55,366] {scheduler_job.py:155} INFO - Started process (PID=59134) to work on /airflow/dags/download_data.py
[2022-02-17 03:13:55,377] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:13:55,381] {logging_mixin.py:112} INFO - [2022-02-17 03:13:55,381] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:13:55,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:13:55,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:13:56,003] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:13:56,006] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-17 03:14:08,778] {scheduler_job.py:155} INFO - Started process (PID=59160) to work on /airflow/dags/download_data.py
[2022-02-17 03:14:08,782] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:14:08,784] {logging_mixin.py:112} INFO - [2022-02-17 03:14:08,784] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:14:09,268] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:14:09,334] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:14:09,346] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:14:09,352] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 03:14:22,006] {scheduler_job.py:155} INFO - Started process (PID=59188) to work on /airflow/dags/download_data.py
[2022-02-17 03:14:22,014] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:14:22,016] {logging_mixin.py:112} INFO - [2022-02-17 03:14:22,016] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:14:22,542] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:14:22,601] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:14:22,614] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:14:22,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 03:14:35,334] {scheduler_job.py:155} INFO - Started process (PID=59214) to work on /airflow/dags/download_data.py
[2022-02-17 03:14:35,351] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:14:35,358] {logging_mixin.py:112} INFO - [2022-02-17 03:14:35,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:14:36,767] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:14:36,832] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:14:36,844] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:14:36,848] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.514 seconds
[2022-02-17 03:14:49,575] {scheduler_job.py:155} INFO - Started process (PID=59242) to work on /airflow/dags/download_data.py
[2022-02-17 03:14:49,589] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:14:49,591] {logging_mixin.py:112} INFO - [2022-02-17 03:14:49,590] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:14:50,032] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:14:50,088] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:14:50,095] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:14:50,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 03:15:01,813] {scheduler_job.py:155} INFO - Started process (PID=59267) to work on /airflow/dags/download_data.py
[2022-02-17 03:15:01,827] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:15:01,830] {logging_mixin.py:112} INFO - [2022-02-17 03:15:01,829] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:15:02,319] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:15:02,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:15:02,391] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:15:02,397] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 03:15:15,075] {scheduler_job.py:155} INFO - Started process (PID=59295) to work on /airflow/dags/download_data.py
[2022-02-17 03:15:15,081] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:15:15,084] {logging_mixin.py:112} INFO - [2022-02-17 03:15:15,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:15:15,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:15:15,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:15:15,817] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:15:15,822] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.747 seconds
[2022-02-17 03:15:28,341] {scheduler_job.py:155} INFO - Started process (PID=59321) to work on /airflow/dags/download_data.py
[2022-02-17 03:15:28,345] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:15:28,347] {logging_mixin.py:112} INFO - [2022-02-17 03:15:28,347] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:15:28,882] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:15:28,926] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:15:28,936] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:15:28,940] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 03:15:41,648] {scheduler_job.py:155} INFO - Started process (PID=59347) to work on /airflow/dags/download_data.py
[2022-02-17 03:15:41,657] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:15:41,659] {logging_mixin.py:112} INFO - [2022-02-17 03:15:41,659] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:15:42,199] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:15:42,253] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:15:42,265] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:15:42,270] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-17 03:15:54,918] {scheduler_job.py:155} INFO - Started process (PID=59375) to work on /airflow/dags/download_data.py
[2022-02-17 03:15:54,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:15:54,933] {logging_mixin.py:112} INFO - [2022-02-17 03:15:54,933] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:15:55,664] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:15:55,714] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:15:55,726] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:15:55,733] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.815 seconds
[2022-02-17 03:16:08,203] {scheduler_job.py:155} INFO - Started process (PID=59401) to work on /airflow/dags/download_data.py
[2022-02-17 03:16:08,210] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:16:08,213] {logging_mixin.py:112} INFO - [2022-02-17 03:16:08,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:16:08,664] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:16:08,715] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:16:08,722] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:16:08,727] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 03:16:21,471] {scheduler_job.py:155} INFO - Started process (PID=59429) to work on /airflow/dags/download_data.py
[2022-02-17 03:16:21,481] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:16:21,483] {logging_mixin.py:112} INFO - [2022-02-17 03:16:21,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:16:21,959] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:16:22,000] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:16:22,011] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:16:22,017] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 03:16:34,723] {scheduler_job.py:155} INFO - Started process (PID=59455) to work on /airflow/dags/download_data.py
[2022-02-17 03:16:34,728] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:16:34,730] {logging_mixin.py:112} INFO - [2022-02-17 03:16:34,729] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:16:35,195] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:16:35,238] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:16:35,244] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:16:35,249] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 03:16:47,954] {scheduler_job.py:155} INFO - Started process (PID=59483) to work on /airflow/dags/download_data.py
[2022-02-17 03:16:47,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:16:47,960] {logging_mixin.py:112} INFO - [2022-02-17 03:16:47,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:16:48,437] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:16:48,489] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:16:48,498] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:16:48,502] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 03:17:01,253] {scheduler_job.py:155} INFO - Started process (PID=59509) to work on /airflow/dags/download_data.py
[2022-02-17 03:17:01,259] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:17:01,260] {logging_mixin.py:112} INFO - [2022-02-17 03:17:01,260] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:17:01,829] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:17:01,888] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:17:01,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:17:01,906] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.653 seconds
[2022-02-17 03:17:14,559] {scheduler_job.py:155} INFO - Started process (PID=59535) to work on /airflow/dags/download_data.py
[2022-02-17 03:17:14,570] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:17:14,573] {logging_mixin.py:112} INFO - [2022-02-17 03:17:14,572] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:17:15,221] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:17:15,272] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:17:15,281] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:17:15,285] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.727 seconds
[2022-02-17 03:17:27,773] {scheduler_job.py:155} INFO - Started process (PID=59563) to work on /airflow/dags/download_data.py
[2022-02-17 03:17:27,779] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:17:27,781] {logging_mixin.py:112} INFO - [2022-02-17 03:17:27,781] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:17:28,260] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:17:28,317] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:17:28,330] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:17:28,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 03:17:41,054] {scheduler_job.py:155} INFO - Started process (PID=59589) to work on /airflow/dags/download_data.py
[2022-02-17 03:17:41,061] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:17:41,062] {logging_mixin.py:112} INFO - [2022-02-17 03:17:41,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:17:41,554] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:17:41,596] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:17:41,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:17:41,605] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 03:17:54,354] {scheduler_job.py:155} INFO - Started process (PID=59617) to work on /airflow/dags/download_data.py
[2022-02-17 03:17:54,366] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:17:54,370] {logging_mixin.py:112} INFO - [2022-02-17 03:17:54,369] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:17:54,915] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:17:54,969] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:17:54,977] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:17:54,984] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-17 03:18:07,633] {scheduler_job.py:155} INFO - Started process (PID=59643) to work on /airflow/dags/download_data.py
[2022-02-17 03:18:07,643] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:18:07,645] {logging_mixin.py:112} INFO - [2022-02-17 03:18:07,645] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:18:08,130] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:18:08,181] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:18:08,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:18:08,196] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 03:18:20,869] {scheduler_job.py:155} INFO - Started process (PID=59671) to work on /airflow/dags/download_data.py
[2022-02-17 03:18:20,874] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:18:20,876] {logging_mixin.py:112} INFO - [2022-02-17 03:18:20,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:18:21,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:18:21,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:18:21,420] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:18:21,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 03:18:34,187] {scheduler_job.py:155} INFO - Started process (PID=59697) to work on /airflow/dags/download_data.py
[2022-02-17 03:18:34,197] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:18:34,199] {logging_mixin.py:112} INFO - [2022-02-17 03:18:34,199] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:18:34,691] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:18:34,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:18:34,751] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:18:34,759] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 03:18:47,451] {scheduler_job.py:155} INFO - Started process (PID=59725) to work on /airflow/dags/download_data.py
[2022-02-17 03:18:47,468] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:18:47,472] {logging_mixin.py:112} INFO - [2022-02-17 03:18:47,471] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:18:48,093] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:18:48,145] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:18:48,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:18:48,161] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.710 seconds
[2022-02-17 03:19:00,729] {scheduler_job.py:155} INFO - Started process (PID=59751) to work on /airflow/dags/download_data.py
[2022-02-17 03:19:00,738] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:19:00,741] {logging_mixin.py:112} INFO - [2022-02-17 03:19:00,740] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:19:01,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:19:01,257] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:19:01,266] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:19:01,272] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 03:19:14,010] {scheduler_job.py:155} INFO - Started process (PID=59777) to work on /airflow/dags/download_data.py
[2022-02-17 03:19:14,014] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:19:14,017] {logging_mixin.py:112} INFO - [2022-02-17 03:19:14,017] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:19:14,485] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:19:14,525] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:19:14,534] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:19:14,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 03:19:27,281] {scheduler_job.py:155} INFO - Started process (PID=59805) to work on /airflow/dags/download_data.py
[2022-02-17 03:19:27,286] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:19:27,287] {logging_mixin.py:112} INFO - [2022-02-17 03:19:27,287] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:19:27,820] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:19:27,870] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:19:27,881] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:19:27,887] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 03:19:40,580] {scheduler_job.py:155} INFO - Started process (PID=59831) to work on /airflow/dags/download_data.py
[2022-02-17 03:19:40,591] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:19:40,594] {logging_mixin.py:112} INFO - [2022-02-17 03:19:40,593] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:19:41,051] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:19:41,105] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:19:41,114] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:19:41,118] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 03:19:53,821] {scheduler_job.py:155} INFO - Started process (PID=59859) to work on /airflow/dags/download_data.py
[2022-02-17 03:19:53,831] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:19:53,832] {logging_mixin.py:112} INFO - [2022-02-17 03:19:53,832] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:19:54,294] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:19:54,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:19:54,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:19:54,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 03:20:07,127] {scheduler_job.py:155} INFO - Started process (PID=59885) to work on /airflow/dags/download_data.py
[2022-02-17 03:20:07,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:20:07,133] {logging_mixin.py:112} INFO - [2022-02-17 03:20:07,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:20:07,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:20:07,694] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:20:07,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:20:07,707] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 03:20:20,382] {scheduler_job.py:155} INFO - Started process (PID=59913) to work on /airflow/dags/download_data.py
[2022-02-17 03:20:20,390] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:20:20,392] {logging_mixin.py:112} INFO - [2022-02-17 03:20:20,391] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:20:20,861] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:20:20,901] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:20:20,910] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:20:20,915] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 03:20:33,665] {scheduler_job.py:155} INFO - Started process (PID=59939) to work on /airflow/dags/download_data.py
[2022-02-17 03:20:33,672] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:20:33,674] {logging_mixin.py:112} INFO - [2022-02-17 03:20:33,674] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:20:34,119] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:20:34,194] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:20:34,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:20:34,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 03:20:46,943] {scheduler_job.py:155} INFO - Started process (PID=59965) to work on /airflow/dags/download_data.py
[2022-02-17 03:20:46,948] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:20:46,950] {logging_mixin.py:112} INFO - [2022-02-17 03:20:46,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:20:47,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:20:47,481] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:20:47,488] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:20:47,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 03:21:00,237] {scheduler_job.py:155} INFO - Started process (PID=59993) to work on /airflow/dags/download_data.py
[2022-02-17 03:21:00,244] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:21:00,247] {logging_mixin.py:112} INFO - [2022-02-17 03:21:00,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:21:00,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:21:00,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:21:00,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:21:00,822] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 03:21:13,559] {scheduler_job.py:155} INFO - Started process (PID=60019) to work on /airflow/dags/download_data.py
[2022-02-17 03:21:13,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:21:13,570] {logging_mixin.py:112} INFO - [2022-02-17 03:21:13,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:21:14,079] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:21:14,135] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:21:14,144] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:21:14,148] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 03:21:26,812] {scheduler_job.py:155} INFO - Started process (PID=60047) to work on /airflow/dags/download_data.py
[2022-02-17 03:21:26,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:21:26,825] {logging_mixin.py:112} INFO - [2022-02-17 03:21:26,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:21:27,309] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:21:27,372] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:21:27,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:21:27,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-17 03:21:40,107] {scheduler_job.py:155} INFO - Started process (PID=60073) to work on /airflow/dags/download_data.py
[2022-02-17 03:21:40,117] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:21:40,120] {logging_mixin.py:112} INFO - [2022-02-17 03:21:40,120] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:21:40,571] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:21:40,615] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:21:40,622] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:21:40,626] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 03:21:53,325] {scheduler_job.py:155} INFO - Started process (PID=60101) to work on /airflow/dags/download_data.py
[2022-02-17 03:21:53,347] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:21:53,349] {logging_mixin.py:112} INFO - [2022-02-17 03:21:53,349] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:21:53,872] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:21:53,918] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:21:53,924] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:21:53,928] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 03:22:06,588] {scheduler_job.py:155} INFO - Started process (PID=60127) to work on /airflow/dags/download_data.py
[2022-02-17 03:22:06,602] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:22:06,605] {logging_mixin.py:112} INFO - [2022-02-17 03:22:06,604] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:22:07,101] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:22:07,149] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:22:07,155] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:22:07,162] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-17 03:22:19,824] {scheduler_job.py:155} INFO - Started process (PID=60153) to work on /airflow/dags/download_data.py
[2022-02-17 03:22:19,835] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:22:19,838] {logging_mixin.py:112} INFO - [2022-02-17 03:22:19,838] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:22:20,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:22:20,392] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:22:20,403] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:22:20,408] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 03:22:33,133] {scheduler_job.py:155} INFO - Started process (PID=60181) to work on /airflow/dags/download_data.py
[2022-02-17 03:22:33,139] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:22:33,140] {logging_mixin.py:112} INFO - [2022-02-17 03:22:33,140] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:22:33,624] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:22:33,681] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:22:33,687] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:22:33,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 03:22:46,365] {scheduler_job.py:155} INFO - Started process (PID=60207) to work on /airflow/dags/download_data.py
[2022-02-17 03:22:46,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:22:46,377] {logging_mixin.py:112} INFO - [2022-02-17 03:22:46,376] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:22:47,003] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:22:47,050] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:22:47,060] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:22:47,065] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.700 seconds
[2022-02-17 03:22:59,750] {scheduler_job.py:155} INFO - Started process (PID=60235) to work on /airflow/dags/download_data.py
[2022-02-17 03:22:59,756] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:22:59,758] {logging_mixin.py:112} INFO - [2022-02-17 03:22:59,758] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:23:00,302] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:23:00,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:23:00,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:23:00,386] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.636 seconds
[2022-02-17 03:23:13,041] {scheduler_job.py:155} INFO - Started process (PID=60261) to work on /airflow/dags/download_data.py
[2022-02-17 03:23:13,052] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:23:13,058] {logging_mixin.py:112} INFO - [2022-02-17 03:23:13,058] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:23:13,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:23:13,701] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:23:13,715] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:23:13,724] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.684 seconds
[2022-02-17 03:23:26,302] {scheduler_job.py:155} INFO - Started process (PID=60289) to work on /airflow/dags/download_data.py
[2022-02-17 03:23:26,311] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:23:26,314] {logging_mixin.py:112} INFO - [2022-02-17 03:23:26,313] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:23:26,962] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:23:27,003] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:23:27,011] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:23:27,016] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.715 seconds
[2022-02-17 03:23:39,593] {scheduler_job.py:155} INFO - Started process (PID=60315) to work on /airflow/dags/download_data.py
[2022-02-17 03:23:39,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:23:39,605] {logging_mixin.py:112} INFO - [2022-02-17 03:23:39,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:23:40,052] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:23:40,092] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:23:40,099] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:23:40,105] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 03:23:52,875] {scheduler_job.py:155} INFO - Started process (PID=60343) to work on /airflow/dags/download_data.py
[2022-02-17 03:23:52,889] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:23:52,895] {logging_mixin.py:112} INFO - [2022-02-17 03:23:52,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:23:53,414] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:23:53,457] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:23:53,462] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:23:53,468] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 03:24:06,169] {scheduler_job.py:155} INFO - Started process (PID=60369) to work on /airflow/dags/download_data.py
[2022-02-17 03:24:06,182] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:24:06,191] {logging_mixin.py:112} INFO - [2022-02-17 03:24:06,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:24:06,756] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:24:06,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:24:06,825] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:24:06,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.664 seconds
[2022-02-17 03:24:19,410] {scheduler_job.py:155} INFO - Started process (PID=60395) to work on /airflow/dags/download_data.py
[2022-02-17 03:24:19,418] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:24:19,422] {logging_mixin.py:112} INFO - [2022-02-17 03:24:19,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:24:19,957] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:24:20,011] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:24:20,022] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:24:20,027] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 03:24:32,666] {scheduler_job.py:155} INFO - Started process (PID=60423) to work on /airflow/dags/download_data.py
[2022-02-17 03:24:32,671] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:24:32,673] {logging_mixin.py:112} INFO - [2022-02-17 03:24:32,673] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:24:33,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:24:33,185] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:24:33,194] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:24:33,200] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 03:24:45,958] {scheduler_job.py:155} INFO - Started process (PID=60449) to work on /airflow/dags/download_data.py
[2022-02-17 03:24:45,968] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:24:45,971] {logging_mixin.py:112} INFO - [2022-02-17 03:24:45,970] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:24:46,482] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:24:46,534] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:24:46,543] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:24:46,548] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 03:24:59,258] {scheduler_job.py:155} INFO - Started process (PID=60477) to work on /airflow/dags/download_data.py
[2022-02-17 03:24:59,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:24:59,266] {logging_mixin.py:112} INFO - [2022-02-17 03:24:59,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:24:59,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:24:59,798] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:24:59,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:24:59,814] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 03:25:12,564] {scheduler_job.py:155} INFO - Started process (PID=60503) to work on /airflow/dags/download_data.py
[2022-02-17 03:25:12,569] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:25:12,570] {logging_mixin.py:112} INFO - [2022-02-17 03:25:12,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:25:13,074] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:25:13,132] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:25:13,144] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:25:13,163] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-17 03:25:25,798] {scheduler_job.py:155} INFO - Started process (PID=60531) to work on /airflow/dags/download_data.py
[2022-02-17 03:25:25,812] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:25:25,816] {logging_mixin.py:112} INFO - [2022-02-17 03:25:25,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:25:26,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:25:26,358] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:25:26,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:25:26,375] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 03:25:39,076] {scheduler_job.py:155} INFO - Started process (PID=60557) to work on /airflow/dags/download_data.py
[2022-02-17 03:25:39,081] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:25:39,084] {logging_mixin.py:112} INFO - [2022-02-17 03:25:39,083] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:25:39,543] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:25:39,582] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:25:39,587] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:25:39,591] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 03:25:52,334] {scheduler_job.py:155} INFO - Started process (PID=60583) to work on /airflow/dags/download_data.py
[2022-02-17 03:25:52,339] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:25:52,341] {logging_mixin.py:112} INFO - [2022-02-17 03:25:52,341] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:25:52,838] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:25:52,890] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:25:52,901] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:25:52,908] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 03:26:05,662] {scheduler_job.py:155} INFO - Started process (PID=60611) to work on /airflow/dags/download_data.py
[2022-02-17 03:26:05,679] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:26:05,681] {logging_mixin.py:112} INFO - [2022-02-17 03:26:05,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:26:06,147] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:26:06,193] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:26:06,202] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:26:06,206] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 03:26:18,966] {scheduler_job.py:155} INFO - Started process (PID=60637) to work on /airflow/dags/download_data.py
[2022-02-17 03:26:18,973] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:26:18,976] {logging_mixin.py:112} INFO - [2022-02-17 03:26:18,975] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:26:19,479] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:26:19,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:26:19,543] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:26:19,550] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 03:26:32,227] {scheduler_job.py:155} INFO - Started process (PID=60665) to work on /airflow/dags/download_data.py
[2022-02-17 03:26:32,231] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:26:32,232] {logging_mixin.py:112} INFO - [2022-02-17 03:26:32,232] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:26:32,691] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:26:32,740] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:26:32,747] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:26:32,752] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 03:26:45,491] {scheduler_job.py:155} INFO - Started process (PID=60691) to work on /airflow/dags/download_data.py
[2022-02-17 03:26:45,500] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:26:45,504] {logging_mixin.py:112} INFO - [2022-02-17 03:26:45,503] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:26:46,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:26:46,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:26:46,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:26:46,123] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-17 03:26:58,817] {scheduler_job.py:155} INFO - Started process (PID=60719) to work on /airflow/dags/download_data.py
[2022-02-17 03:26:58,837] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:26:58,842] {logging_mixin.py:112} INFO - [2022-02-17 03:26:58,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:26:59,571] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:26:59,630] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:26:59,649] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:26:59,658] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.841 seconds
[2022-02-17 03:27:12,140] {scheduler_job.py:155} INFO - Started process (PID=60745) to work on /airflow/dags/download_data.py
[2022-02-17 03:27:12,149] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:27:12,154] {logging_mixin.py:112} INFO - [2022-02-17 03:27:12,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:27:12,860] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:27:12,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:27:12,940] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:27:12,945] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.805 seconds
[2022-02-17 03:27:25,437] {scheduler_job.py:155} INFO - Started process (PID=60771) to work on /airflow/dags/download_data.py
[2022-02-17 03:27:25,445] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:27:25,447] {logging_mixin.py:112} INFO - [2022-02-17 03:27:25,447] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:27:26,786] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:27:26,832] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:27:26,844] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:27:26,850] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.413 seconds
[2022-02-17 03:27:39,720] {scheduler_job.py:155} INFO - Started process (PID=60799) to work on /airflow/dags/download_data.py
[2022-02-17 03:27:39,750] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:27:39,762] {logging_mixin.py:112} INFO - [2022-02-17 03:27:39,760] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:27:40,274] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:27:40,339] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:27:40,352] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:27:40,359] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.639 seconds
[2022-02-17 03:27:51,961] {scheduler_job.py:155} INFO - Started process (PID=60824) to work on /airflow/dags/download_data.py
[2022-02-17 03:27:51,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:27:51,972] {logging_mixin.py:112} INFO - [2022-02-17 03:27:51,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:27:52,541] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:27:52,585] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:27:52,591] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:27:52,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-17 03:28:05,307] {scheduler_job.py:155} INFO - Started process (PID=60852) to work on /airflow/dags/download_data.py
[2022-02-17 03:28:05,315] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:28:05,319] {logging_mixin.py:112} INFO - [2022-02-17 03:28:05,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:28:05,913] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:28:05,989] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:28:06,003] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:28:06,012] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.705 seconds
[2022-02-17 03:28:18,598] {scheduler_job.py:155} INFO - Started process (PID=60878) to work on /airflow/dags/download_data.py
[2022-02-17 03:28:18,605] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:28:18,607] {logging_mixin.py:112} INFO - [2022-02-17 03:28:18,607] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:28:19,883] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:28:19,946] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:28:19,957] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:28:19,962] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.364 seconds
[2022-02-17 03:28:32,881] {scheduler_job.py:155} INFO - Started process (PID=60906) to work on /airflow/dags/download_data.py
[2022-02-17 03:28:32,894] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:28:32,897] {logging_mixin.py:112} INFO - [2022-02-17 03:28:32,896] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:28:33,501] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:28:33,559] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:28:33,572] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:28:33,580] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.699 seconds
[2022-02-17 03:28:45,192] {scheduler_job.py:155} INFO - Started process (PID=60931) to work on /airflow/dags/download_data.py
[2022-02-17 03:28:45,202] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:28:45,204] {logging_mixin.py:112} INFO - [2022-02-17 03:28:45,204] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:28:45,731] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:28:45,773] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:28:45,780] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:28:45,786] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 03:28:58,417] {scheduler_job.py:155} INFO - Started process (PID=60957) to work on /airflow/dags/download_data.py
[2022-02-17 03:28:58,423] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:28:58,425] {logging_mixin.py:112} INFO - [2022-02-17 03:28:58,425] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:28:58,900] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:28:58,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:28:58,951] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:28:58,956] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 03:29:11,731] {scheduler_job.py:155} INFO - Started process (PID=60985) to work on /airflow/dags/download_data.py
[2022-02-17 03:29:11,736] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:29:11,737] {logging_mixin.py:112} INFO - [2022-02-17 03:29:11,737] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:29:12,247] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:29:12,293] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:29:12,302] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:29:12,306] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-17 03:29:24,979] {scheduler_job.py:155} INFO - Started process (PID=61011) to work on /airflow/dags/download_data.py
[2022-02-17 03:29:24,984] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:29:24,986] {logging_mixin.py:112} INFO - [2022-02-17 03:29:24,986] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:29:25,503] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:29:25,583] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:29:25,591] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:29:25,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-17 03:29:38,801] {scheduler_job.py:155} INFO - Started process (PID=61039) to work on /airflow/dags/download_data.py
[2022-02-17 03:29:38,808] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:29:38,810] {logging_mixin.py:112} INFO - [2022-02-17 03:29:38,810] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:29:39,381] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:29:39,430] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:29:39,440] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:29:39,448] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.646 seconds
[2022-02-17 03:29:52,167] {scheduler_job.py:155} INFO - Started process (PID=61065) to work on /airflow/dags/download_data.py
[2022-02-17 03:29:52,172] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:29:52,174] {logging_mixin.py:112} INFO - [2022-02-17 03:29:52,173] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:29:52,615] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:29:52,664] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:29:52,672] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:29:52,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 03:30:05,476] {scheduler_job.py:155} INFO - Started process (PID=61093) to work on /airflow/dags/download_data.py
[2022-02-17 03:30:05,490] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:30:05,492] {logging_mixin.py:112} INFO - [2022-02-17 03:30:05,492] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:30:05,963] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:30:06,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:30:06,028] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:30:06,036] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 03:30:18,727] {scheduler_job.py:155} INFO - Started process (PID=61119) to work on /airflow/dags/download_data.py
[2022-02-17 03:30:18,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:30:18,733] {logging_mixin.py:112} INFO - [2022-02-17 03:30:18,733] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:30:19,202] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:30:19,253] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:30:19,260] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:30:19,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 03:30:32,084] {scheduler_job.py:155} INFO - Started process (PID=61147) to work on /airflow/dags/download_data.py
[2022-02-17 03:30:32,095] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:30:32,097] {logging_mixin.py:112} INFO - [2022-02-17 03:30:32,097] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:30:32,590] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:30:32,632] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:30:32,639] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:30:32,644] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 03:30:45,337] {scheduler_job.py:155} INFO - Started process (PID=61173) to work on /airflow/dags/download_data.py
[2022-02-17 03:30:45,341] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:30:45,345] {logging_mixin.py:112} INFO - [2022-02-17 03:30:45,344] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:30:45,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:30:45,880] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:30:45,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:30:45,901] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 03:30:58,608] {scheduler_job.py:155} INFO - Started process (PID=61199) to work on /airflow/dags/download_data.py
[2022-02-17 03:30:58,616] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:30:58,619] {logging_mixin.py:112} INFO - [2022-02-17 03:30:58,619] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:30:59,117] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:30:59,185] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:30:59,195] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:30:59,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 03:31:11,979] {scheduler_job.py:155} INFO - Started process (PID=61227) to work on /airflow/dags/download_data.py
[2022-02-17 03:31:11,985] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:31:11,986] {logging_mixin.py:112} INFO - [2022-02-17 03:31:11,986] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:31:12,578] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:31:12,631] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:31:12,642] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:31:12,648] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.669 seconds
[2022-02-17 03:31:25,288] {scheduler_job.py:155} INFO - Started process (PID=61253) to work on /airflow/dags/download_data.py
[2022-02-17 03:31:25,294] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:31:25,297] {logging_mixin.py:112} INFO - [2022-02-17 03:31:25,297] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:31:25,860] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:31:25,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:31:25,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:31:25,956] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.668 seconds
[2022-02-17 03:31:38,631] {scheduler_job.py:155} INFO - Started process (PID=61281) to work on /airflow/dags/download_data.py
[2022-02-17 03:31:38,642] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:31:38,647] {logging_mixin.py:112} INFO - [2022-02-17 03:31:38,646] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:31:39,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:31:40,085] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:31:40,107] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:31:40,114] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.483 seconds
[2022-02-17 03:31:53,196] {scheduler_job.py:155} INFO - Started process (PID=61307) to work on /airflow/dags/download_data.py
[2022-02-17 03:31:53,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:31:53,209] {logging_mixin.py:112} INFO - [2022-02-17 03:31:53,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:31:53,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:31:54,005] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:31:54,020] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:31:54,026] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.830 seconds
[2022-02-17 03:32:05,507] {scheduler_job.py:155} INFO - Started process (PID=61334) to work on /airflow/dags/download_data.py
[2022-02-17 03:32:05,514] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:32:05,517] {logging_mixin.py:112} INFO - [2022-02-17 03:32:05,516] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:32:06,011] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:32:06,053] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:32:06,062] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:32:06,067] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 03:32:18,752] {scheduler_job.py:155} INFO - Started process (PID=61360) to work on /airflow/dags/download_data.py
[2022-02-17 03:32:18,756] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:32:18,758] {logging_mixin.py:112} INFO - [2022-02-17 03:32:18,758] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:32:19,218] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:32:19,251] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:32:19,257] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:32:19,262] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 03:32:32,029] {scheduler_job.py:155} INFO - Started process (PID=61386) to work on /airflow/dags/download_data.py
[2022-02-17 03:32:32,039] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:32:32,041] {logging_mixin.py:112} INFO - [2022-02-17 03:32:32,041] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:32:32,745] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:32:32,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:32:32,797] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:32:32,801] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.773 seconds
[2022-02-17 03:32:45,490] {scheduler_job.py:155} INFO - Started process (PID=61414) to work on /airflow/dags/download_data.py
[2022-02-17 03:32:45,501] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:32:45,503] {logging_mixin.py:112} INFO - [2022-02-17 03:32:45,503] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:32:45,999] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:32:46,049] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:32:46,058] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:32:46,063] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 03:32:58,805] {scheduler_job.py:155} INFO - Started process (PID=61440) to work on /airflow/dags/download_data.py
[2022-02-17 03:32:58,811] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:32:58,813] {logging_mixin.py:112} INFO - [2022-02-17 03:32:58,813] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:32:59,341] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:32:59,414] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:32:59,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:32:59,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-17 03:33:12,112] {scheduler_job.py:155} INFO - Started process (PID=61468) to work on /airflow/dags/download_data.py
[2022-02-17 03:33:12,123] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:33:12,126] {logging_mixin.py:112} INFO - [2022-02-17 03:33:12,125] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:33:12,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:33:12,805] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:33:12,823] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:33:12,838] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.727 seconds
[2022-02-17 03:33:25,415] {scheduler_job.py:155} INFO - Started process (PID=61494) to work on /airflow/dags/download_data.py
[2022-02-17 03:33:25,422] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:33:25,430] {logging_mixin.py:112} INFO - [2022-02-17 03:33:25,430] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:33:26,130] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:33:26,186] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:33:26,201] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:33:26,208] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.793 seconds
[2022-02-17 03:33:38,688] {scheduler_job.py:155} INFO - Started process (PID=61522) to work on /airflow/dags/download_data.py
[2022-02-17 03:33:38,701] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:33:38,706] {logging_mixin.py:112} INFO - [2022-02-17 03:33:38,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:33:39,192] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:33:39,246] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:33:39,257] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:33:39,262] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 03:33:51,967] {scheduler_job.py:155} INFO - Started process (PID=61548) to work on /airflow/dags/download_data.py
[2022-02-17 03:33:51,972] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:33:51,973] {logging_mixin.py:112} INFO - [2022-02-17 03:33:51,973] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:33:52,551] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:33:52,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:33:52,627] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:33:52,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.669 seconds
[2022-02-17 03:34:05,274] {scheduler_job.py:155} INFO - Started process (PID=61574) to work on /airflow/dags/download_data.py
[2022-02-17 03:34:05,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:34:05,279] {logging_mixin.py:112} INFO - [2022-02-17 03:34:05,279] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:34:05,833] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:34:05,913] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:34:05,924] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:34:05,929] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.656 seconds
[2022-02-17 03:34:18,585] {scheduler_job.py:155} INFO - Started process (PID=61602) to work on /airflow/dags/download_data.py
[2022-02-17 03:34:18,590] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:34:18,593] {logging_mixin.py:112} INFO - [2022-02-17 03:34:18,592] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:34:19,404] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:34:19,496] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:34:19,506] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:34:19,515] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.929 seconds
[2022-02-17 03:34:31,865] {scheduler_job.py:155} INFO - Started process (PID=61628) to work on /airflow/dags/download_data.py
[2022-02-17 03:34:31,870] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:34:31,872] {logging_mixin.py:112} INFO - [2022-02-17 03:34:31,872] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:34:32,339] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:34:32,392] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:34:32,404] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:34:32,410] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 03:34:45,148] {scheduler_job.py:155} INFO - Started process (PID=61656) to work on /airflow/dags/download_data.py
[2022-02-17 03:34:45,152] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:34:45,156] {logging_mixin.py:112} INFO - [2022-02-17 03:34:45,155] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:34:45,607] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:34:45,651] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:34:45,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:34:45,668] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 03:34:58,443] {scheduler_job.py:155} INFO - Started process (PID=61682) to work on /airflow/dags/download_data.py
[2022-02-17 03:34:58,457] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:34:58,461] {logging_mixin.py:112} INFO - [2022-02-17 03:34:58,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:34:58,971] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:34:59,021] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:34:59,033] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:34:59,037] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 03:35:11,717] {scheduler_job.py:155} INFO - Started process (PID=61710) to work on /airflow/dags/download_data.py
[2022-02-17 03:35:11,721] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:35:11,723] {logging_mixin.py:112} INFO - [2022-02-17 03:35:11,723] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:35:12,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:35:12,254] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:35:12,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:35:12,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 03:35:25,011] {scheduler_job.py:155} INFO - Started process (PID=61736) to work on /airflow/dags/download_data.py
[2022-02-17 03:35:25,016] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:35:25,017] {logging_mixin.py:112} INFO - [2022-02-17 03:35:25,017] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:35:25,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:35:25,590] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:35:25,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:35:25,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 03:35:38,334] {scheduler_job.py:155} INFO - Started process (PID=61763) to work on /airflow/dags/download_data.py
[2022-02-17 03:35:38,347] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:35:38,349] {logging_mixin.py:112} INFO - [2022-02-17 03:35:38,349] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:35:38,941] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:35:38,998] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:35:39,006] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:35:39,009] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.676 seconds
[2022-02-17 03:35:51,586] {scheduler_job.py:155} INFO - Started process (PID=61790) to work on /airflow/dags/download_data.py
[2022-02-17 03:35:51,595] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:35:51,598] {logging_mixin.py:112} INFO - [2022-02-17 03:35:51,598] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:35:52,134] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:35:52,189] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:35:52,199] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:35:52,204] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 03:36:04,877] {scheduler_job.py:155} INFO - Started process (PID=61816) to work on /airflow/dags/download_data.py
[2022-02-17 03:36:04,890] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:36:04,893] {logging_mixin.py:112} INFO - [2022-02-17 03:36:04,893] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:36:05,437] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:36:05,515] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:36:05,529] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:36:05,540] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.663 seconds
[2022-02-17 03:36:18,128] {scheduler_job.py:155} INFO - Started process (PID=61844) to work on /airflow/dags/download_data.py
[2022-02-17 03:36:18,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:36:18,134] {logging_mixin.py:112} INFO - [2022-02-17 03:36:18,134] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:36:18,576] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:36:18,626] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:36:18,637] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:36:18,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 03:36:31,425] {scheduler_job.py:155} INFO - Started process (PID=61870) to work on /airflow/dags/download_data.py
[2022-02-17 03:36:31,431] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:36:31,433] {logging_mixin.py:112} INFO - [2022-02-17 03:36:31,433] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:36:31,883] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:36:31,935] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:36:31,942] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:36:31,945] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 03:36:44,649] {scheduler_job.py:155} INFO - Started process (PID=61898) to work on /airflow/dags/download_data.py
[2022-02-17 03:36:44,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:36:44,655] {logging_mixin.py:112} INFO - [2022-02-17 03:36:44,655] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:36:45,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:36:45,115] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:36:45,121] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:36:45,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.476 seconds
[2022-02-17 03:36:57,912] {scheduler_job.py:155} INFO - Started process (PID=61924) to work on /airflow/dags/download_data.py
[2022-02-17 03:36:57,921] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:36:57,924] {logging_mixin.py:112} INFO - [2022-02-17 03:36:57,923] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:36:58,404] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:36:58,446] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:36:58,456] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:36:58,461] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 03:37:11,222] {scheduler_job.py:155} INFO - Started process (PID=61952) to work on /airflow/dags/download_data.py
[2022-02-17 03:37:11,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:37:11,239] {logging_mixin.py:112} INFO - [2022-02-17 03:37:11,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:37:11,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:37:11,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:37:11,754] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:37:11,760] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 03:37:24,455] {scheduler_job.py:155} INFO - Started process (PID=61978) to work on /airflow/dags/download_data.py
[2022-02-17 03:37:24,459] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:37:24,461] {logging_mixin.py:112} INFO - [2022-02-17 03:37:24,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:37:24,909] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:37:24,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:37:24,963] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:37:24,970] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 03:37:37,744] {scheduler_job.py:155} INFO - Started process (PID=62004) to work on /airflow/dags/download_data.py
[2022-02-17 03:37:37,754] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:37:37,756] {logging_mixin.py:112} INFO - [2022-02-17 03:37:37,756] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:37:38,196] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:37:38,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:37:38,257] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:37:38,264] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 03:37:50,962] {scheduler_job.py:155} INFO - Started process (PID=62032) to work on /airflow/dags/download_data.py
[2022-02-17 03:37:50,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:37:50,969] {logging_mixin.py:112} INFO - [2022-02-17 03:37:50,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:37:51,420] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:37:51,470] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:37:51,478] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:37:51,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 03:38:04,282] {scheduler_job.py:155} INFO - Started process (PID=62058) to work on /airflow/dags/download_data.py
[2022-02-17 03:38:04,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:38:04,288] {logging_mixin.py:112} INFO - [2022-02-17 03:38:04,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:38:04,752] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:38:04,797] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:38:04,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:38:04,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 03:38:17,508] {scheduler_job.py:155} INFO - Started process (PID=62086) to work on /airflow/dags/download_data.py
[2022-02-17 03:38:17,513] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:38:17,514] {logging_mixin.py:112} INFO - [2022-02-17 03:38:17,514] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:38:17,978] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:38:18,032] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:38:18,042] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:38:18,047] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 03:38:30,816] {scheduler_job.py:155} INFO - Started process (PID=62112) to work on /airflow/dags/download_data.py
[2022-02-17 03:38:30,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:38:30,826] {logging_mixin.py:112} INFO - [2022-02-17 03:38:30,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:38:31,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:38:31,309] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:38:31,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:38:31,322] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 03:38:44,296] {scheduler_job.py:155} INFO - Started process (PID=62140) to work on /airflow/dags/download_data.py
[2022-02-17 03:38:44,305] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:38:44,308] {logging_mixin.py:112} INFO - [2022-02-17 03:38:44,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:38:44,734] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:38:44,747] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:38:44,754] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:38:44,761] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.464 seconds
[2022-02-17 03:38:57,535] {scheduler_job.py:155} INFO - Started process (PID=62166) to work on /airflow/dags/download_data.py
[2022-02-17 03:38:57,542] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:38:57,545] {logging_mixin.py:112} INFO - [2022-02-17 03:38:57,544] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:38:57,984] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:38:58,051] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:38:58,061] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:38:58,068] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 03:39:10,819] {scheduler_job.py:155} INFO - Started process (PID=62192) to work on /airflow/dags/download_data.py
[2022-02-17 03:39:10,830] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:39:10,832] {logging_mixin.py:112} INFO - [2022-02-17 03:39:10,832] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:39:11,294] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:39:11,342] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:39:11,352] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:39:11,357] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 03:39:24,082] {scheduler_job.py:155} INFO - Started process (PID=62220) to work on /airflow/dags/download_data.py
[2022-02-17 03:39:24,086] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:39:24,088] {logging_mixin.py:112} INFO - [2022-02-17 03:39:24,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:39:24,536] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:39:24,586] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:39:24,593] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:39:24,598] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 03:39:37,359] {scheduler_job.py:155} INFO - Started process (PID=62246) to work on /airflow/dags/download_data.py
[2022-02-17 03:39:37,365] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:39:37,368] {logging_mixin.py:112} INFO - [2022-02-17 03:39:37,367] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:39:37,875] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:39:37,922] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:39:37,928] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:39:37,932] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 03:39:50,583] {scheduler_job.py:155} INFO - Started process (PID=62274) to work on /airflow/dags/download_data.py
[2022-02-17 03:39:50,589] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:39:50,591] {logging_mixin.py:112} INFO - [2022-02-17 03:39:50,591] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:39:51,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:39:51,077] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:39:51,082] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:39:51,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 03:40:03,865] {scheduler_job.py:155} INFO - Started process (PID=62300) to work on /airflow/dags/download_data.py
[2022-02-17 03:40:03,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:40:03,871] {logging_mixin.py:112} INFO - [2022-02-17 03:40:03,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:40:04,323] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:40:04,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:40:04,396] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:40:04,401] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 03:40:17,120] {scheduler_job.py:155} INFO - Started process (PID=62328) to work on /airflow/dags/download_data.py
[2022-02-17 03:40:17,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:40:17,128] {logging_mixin.py:112} INFO - [2022-02-17 03:40:17,128] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:40:17,592] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:40:17,636] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:40:17,644] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:40:17,649] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 03:40:30,395] {scheduler_job.py:155} INFO - Started process (PID=62354) to work on /airflow/dags/download_data.py
[2022-02-17 03:40:30,400] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:40:30,402] {logging_mixin.py:112} INFO - [2022-02-17 03:40:30,401] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:40:30,847] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:40:30,890] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:40:30,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:40:30,898] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 03:40:43,667] {scheduler_job.py:155} INFO - Started process (PID=62380) to work on /airflow/dags/download_data.py
[2022-02-17 03:40:43,674] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:40:43,682] {logging_mixin.py:112} INFO - [2022-02-17 03:40:43,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:40:44,158] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:40:44,208] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:40:44,218] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:40:44,222] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 03:40:56,975] {scheduler_job.py:155} INFO - Started process (PID=62408) to work on /airflow/dags/download_data.py
[2022-02-17 03:40:56,983] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:40:56,985] {logging_mixin.py:112} INFO - [2022-02-17 03:40:56,985] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:40:57,435] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:40:57,499] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:40:57,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:40:57,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 03:41:10,246] {scheduler_job.py:155} INFO - Started process (PID=62434) to work on /airflow/dags/download_data.py
[2022-02-17 03:41:10,251] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:41:10,252] {logging_mixin.py:112} INFO - [2022-02-17 03:41:10,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:41:10,751] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:41:10,817] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:41:10,825] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:41:10,831] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 03:41:23,514] {scheduler_job.py:155} INFO - Started process (PID=62462) to work on /airflow/dags/download_data.py
[2022-02-17 03:41:23,523] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:41:23,528] {logging_mixin.py:112} INFO - [2022-02-17 03:41:23,528] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:41:24,052] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:41:24,097] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:41:24,108] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:41:24,113] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 03:41:37,830] {scheduler_job.py:155} INFO - Started process (PID=62488) to work on /airflow/dags/download_data.py
[2022-02-17 03:41:37,851] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:41:37,852] {logging_mixin.py:112} INFO - [2022-02-17 03:41:37,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:41:38,456] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:41:38,502] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:41:38,512] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:41:38,517] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.688 seconds
[2022-02-17 03:41:51,158] {scheduler_job.py:155} INFO - Started process (PID=62516) to work on /airflow/dags/download_data.py
[2022-02-17 03:41:51,162] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:41:51,182] {logging_mixin.py:112} INFO - [2022-02-17 03:41:51,181] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:41:51,726] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:41:51,778] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:41:51,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:41:51,796] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.639 seconds
[2022-02-17 03:42:04,466] {scheduler_job.py:155} INFO - Started process (PID=62542) to work on /airflow/dags/download_data.py
[2022-02-17 03:42:04,477] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:42:04,480] {logging_mixin.py:112} INFO - [2022-02-17 03:42:04,479] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:42:05,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:42:05,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:42:05,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:42:05,269] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.803 seconds
[2022-02-17 03:42:17,732] {scheduler_job.py:155} INFO - Started process (PID=62570) to work on /airflow/dags/download_data.py
[2022-02-17 03:42:17,737] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:42:17,738] {logging_mixin.py:112} INFO - [2022-02-17 03:42:17,738] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:42:18,233] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:42:18,286] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:42:18,293] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:42:18,299] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 03:42:31,040] {scheduler_job.py:155} INFO - Started process (PID=62596) to work on /airflow/dags/download_data.py
[2022-02-17 03:42:31,045] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:42:31,046] {logging_mixin.py:112} INFO - [2022-02-17 03:42:31,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:42:31,668] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:42:31,733] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:42:31,740] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:42:31,744] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.704 seconds
[2022-02-17 03:42:44,313] {scheduler_job.py:155} INFO - Started process (PID=62622) to work on /airflow/dags/download_data.py
[2022-02-17 03:42:44,321] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:42:44,323] {logging_mixin.py:112} INFO - [2022-02-17 03:42:44,323] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:42:44,792] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:42:44,839] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:42:44,849] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:42:44,854] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 03:42:57,628] {scheduler_job.py:155} INFO - Started process (PID=62650) to work on /airflow/dags/download_data.py
[2022-02-17 03:42:57,637] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:42:57,639] {logging_mixin.py:112} INFO - [2022-02-17 03:42:57,639] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:42:58,168] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:42:58,221] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:42:58,237] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:42:58,247] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 03:43:10,911] {scheduler_job.py:155} INFO - Started process (PID=62676) to work on /airflow/dags/download_data.py
[2022-02-17 03:43:10,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:43:10,920] {logging_mixin.py:112} INFO - [2022-02-17 03:43:10,919] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:43:11,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:43:11,406] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:43:11,412] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:43:11,417] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 03:43:24,145] {scheduler_job.py:155} INFO - Started process (PID=62704) to work on /airflow/dags/download_data.py
[2022-02-17 03:43:24,152] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:43:24,155] {logging_mixin.py:112} INFO - [2022-02-17 03:43:24,154] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:43:24,645] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:43:24,692] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:43:24,729] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:43:24,733] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-17 03:43:37,448] {scheduler_job.py:155} INFO - Started process (PID=62730) to work on /airflow/dags/download_data.py
[2022-02-17 03:43:37,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:43:37,453] {logging_mixin.py:112} INFO - [2022-02-17 03:43:37,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:43:37,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:43:37,931] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:43:37,938] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:43:37,942] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 03:43:50,749] {scheduler_job.py:155} INFO - Started process (PID=62758) to work on /airflow/dags/download_data.py
[2022-02-17 03:43:50,767] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:43:50,772] {logging_mixin.py:112} INFO - [2022-02-17 03:43:50,770] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:43:51,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:43:51,278] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:43:51,289] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:43:51,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 03:44:04,063] {scheduler_job.py:155} INFO - Started process (PID=62784) to work on /airflow/dags/download_data.py
[2022-02-17 03:44:04,069] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:44:04,070] {logging_mixin.py:112} INFO - [2022-02-17 03:44:04,070] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:44:04,573] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:44:04,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:44:04,642] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:44:04,649] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 03:44:17,297] {scheduler_job.py:155} INFO - Started process (PID=62810) to work on /airflow/dags/download_data.py
[2022-02-17 03:44:17,301] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:44:17,303] {logging_mixin.py:112} INFO - [2022-02-17 03:44:17,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:44:17,754] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:44:17,809] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:44:17,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:44:17,820] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 03:44:30,579] {scheduler_job.py:155} INFO - Started process (PID=62838) to work on /airflow/dags/download_data.py
[2022-02-17 03:44:30,586] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:44:30,588] {logging_mixin.py:112} INFO - [2022-02-17 03:44:30,588] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:44:31,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:44:31,080] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:44:31,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:44:31,089] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 03:44:43,811] {scheduler_job.py:155} INFO - Started process (PID=62864) to work on /airflow/dags/download_data.py
[2022-02-17 03:44:43,816] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:44:43,819] {logging_mixin.py:112} INFO - [2022-02-17 03:44:43,818] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:44:44,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:44:44,327] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:44:44,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:44:44,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 03:44:57,041] {scheduler_job.py:155} INFO - Started process (PID=62892) to work on /airflow/dags/download_data.py
[2022-02-17 03:44:57,047] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:44:57,048] {logging_mixin.py:112} INFO - [2022-02-17 03:44:57,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:44:57,548] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:44:57,609] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:44:57,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:44:57,626] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 03:45:10,318] {scheduler_job.py:155} INFO - Started process (PID=62918) to work on /airflow/dags/download_data.py
[2022-02-17 03:45:10,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:45:10,325] {logging_mixin.py:112} INFO - [2022-02-17 03:45:10,324] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:45:10,793] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:45:10,849] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:45:10,857] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:45:10,861] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 03:45:23,609] {scheduler_job.py:155} INFO - Started process (PID=62946) to work on /airflow/dags/download_data.py
[2022-02-17 03:45:23,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:45:23,619] {logging_mixin.py:112} INFO - [2022-02-17 03:45:23,619] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:45:24,063] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:45:24,112] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:45:24,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:45:24,129] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 03:45:36,910] {scheduler_job.py:155} INFO - Started process (PID=62972) to work on /airflow/dags/download_data.py
[2022-02-17 03:45:36,916] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:45:36,936] {logging_mixin.py:112} INFO - [2022-02-17 03:45:36,936] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:45:37,423] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:45:37,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:45:37,484] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:45:37,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 03:45:50,145] {scheduler_job.py:155} INFO - Started process (PID=62999) to work on /airflow/dags/download_data.py
[2022-02-17 03:45:50,152] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:45:50,153] {logging_mixin.py:112} INFO - [2022-02-17 03:45:50,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:45:50,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:45:50,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:45:50,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:45:50,823] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.678 seconds
[2022-02-17 03:46:03,439] {scheduler_job.py:155} INFO - Started process (PID=63026) to work on /airflow/dags/download_data.py
[2022-02-17 03:46:03,453] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:46:03,457] {logging_mixin.py:112} INFO - [2022-02-17 03:46:03,457] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:46:03,978] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:46:04,035] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:46:04,050] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:46:04,062] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-17 03:46:16,639] {scheduler_job.py:155} INFO - Started process (PID=63052) to work on /airflow/dags/download_data.py
[2022-02-17 03:46:16,649] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:46:16,651] {logging_mixin.py:112} INFO - [2022-02-17 03:46:16,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:46:17,109] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:46:17,159] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:46:17,169] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:46:17,176] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 03:46:29,878] {scheduler_job.py:155} INFO - Started process (PID=63080) to work on /airflow/dags/download_data.py
[2022-02-17 03:46:29,883] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:46:29,884] {logging_mixin.py:112} INFO - [2022-02-17 03:46:29,884] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:46:30,357] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:46:30,404] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:46:30,411] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:46:30,416] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 03:46:43,168] {scheduler_job.py:155} INFO - Started process (PID=63106) to work on /airflow/dags/download_data.py
[2022-02-17 03:46:43,176] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:46:43,178] {logging_mixin.py:112} INFO - [2022-02-17 03:46:43,178] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:46:43,642] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:46:43,691] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:46:43,698] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:46:43,704] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 03:46:56,383] {scheduler_job.py:155} INFO - Started process (PID=63134) to work on /airflow/dags/download_data.py
[2022-02-17 03:46:56,388] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:46:56,390] {logging_mixin.py:112} INFO - [2022-02-17 03:46:56,390] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:46:56,868] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:46:56,918] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:46:56,927] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:46:56,932] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 03:47:09,704] {scheduler_job.py:155} INFO - Started process (PID=63160) to work on /airflow/dags/download_data.py
[2022-02-17 03:47:09,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:47:09,711] {logging_mixin.py:112} INFO - [2022-02-17 03:47:09,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:47:10,178] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:47:10,235] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:47:10,246] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:47:10,250] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 03:47:22,992] {scheduler_job.py:155} INFO - Started process (PID=63188) to work on /airflow/dags/download_data.py
[2022-02-17 03:47:23,002] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:47:23,004] {logging_mixin.py:112} INFO - [2022-02-17 03:47:23,004] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:47:23,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:47:23,554] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:47:23,564] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:47:23,568] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 03:47:36,288] {scheduler_job.py:155} INFO - Started process (PID=63214) to work on /airflow/dags/download_data.py
[2022-02-17 03:47:36,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:47:36,298] {logging_mixin.py:112} INFO - [2022-02-17 03:47:36,298] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:47:36,785] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:47:36,833] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:47:36,842] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:47:36,847] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 03:47:49,530] {scheduler_job.py:155} INFO - Started process (PID=63240) to work on /airflow/dags/download_data.py
[2022-02-17 03:47:49,540] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:47:49,543] {logging_mixin.py:112} INFO - [2022-02-17 03:47:49,543] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:47:50,014] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:47:50,066] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:47:50,075] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:47:50,080] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 03:48:02,874] {scheduler_job.py:155} INFO - Started process (PID=63268) to work on /airflow/dags/download_data.py
[2022-02-17 03:48:02,878] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:48:02,881] {logging_mixin.py:112} INFO - [2022-02-17 03:48:02,880] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:48:03,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:48:03,394] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:48:03,401] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:48:03,406] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 03:48:16,135] {scheduler_job.py:155} INFO - Started process (PID=63294) to work on /airflow/dags/download_data.py
[2022-02-17 03:48:16,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:48:16,149] {logging_mixin.py:112} INFO - [2022-02-17 03:48:16,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:48:16,579] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:48:16,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:48:16,634] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:48:16,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 03:48:29,380] {scheduler_job.py:155} INFO - Started process (PID=63322) to work on /airflow/dags/download_data.py
[2022-02-17 03:48:29,388] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:48:29,390] {logging_mixin.py:112} INFO - [2022-02-17 03:48:29,390] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:48:29,827] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:48:29,876] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:48:29,886] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:48:29,890] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 03:48:42,666] {scheduler_job.py:155} INFO - Started process (PID=63348) to work on /airflow/dags/download_data.py
[2022-02-17 03:48:42,675] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:48:42,677] {logging_mixin.py:112} INFO - [2022-02-17 03:48:42,677] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:48:43,121] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:48:43,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:48:43,187] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:48:43,193] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 03:48:55,962] {scheduler_job.py:155} INFO - Started process (PID=63376) to work on /airflow/dags/download_data.py
[2022-02-17 03:48:55,968] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:48:55,970] {logging_mixin.py:112} INFO - [2022-02-17 03:48:55,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:48:56,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:48:56,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:48:56,600] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:48:56,605] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.643 seconds
[2022-02-17 03:49:09,245] {scheduler_job.py:155} INFO - Started process (PID=63402) to work on /airflow/dags/download_data.py
[2022-02-17 03:49:09,252] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:49:09,255] {logging_mixin.py:112} INFO - [2022-02-17 03:49:09,255] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:49:09,816] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:49:09,875] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:49:09,882] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:49:09,888] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.643 seconds
[2022-02-17 03:49:22,517] {scheduler_job.py:155} INFO - Started process (PID=63428) to work on /airflow/dags/download_data.py
[2022-02-17 03:49:22,524] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:49:22,526] {logging_mixin.py:112} INFO - [2022-02-17 03:49:22,525] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:49:23,103] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:49:23,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:49:23,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:49:23,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-17 03:49:35,858] {scheduler_job.py:155} INFO - Started process (PID=63456) to work on /airflow/dags/download_data.py
[2022-02-17 03:49:35,866] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:49:35,868] {logging_mixin.py:112} INFO - [2022-02-17 03:49:35,868] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:49:36,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:49:36,392] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:49:36,399] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:49:36,413] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 03:49:49,123] {scheduler_job.py:155} INFO - Started process (PID=63482) to work on /airflow/dags/download_data.py
[2022-02-17 03:49:49,133] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:49:49,136] {logging_mixin.py:112} INFO - [2022-02-17 03:49:49,136] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:49:49,684] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:49:49,742] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:49:49,752] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:49:49,759] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.636 seconds
[2022-02-17 03:50:02,381] {scheduler_job.py:155} INFO - Started process (PID=63510) to work on /airflow/dags/download_data.py
[2022-02-17 03:50:02,386] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:50:02,389] {logging_mixin.py:112} INFO - [2022-02-17 03:50:02,388] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:50:02,864] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:50:02,909] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:50:02,923] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:50:02,927] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 03:50:15,676] {scheduler_job.py:155} INFO - Started process (PID=63536) to work on /airflow/dags/download_data.py
[2022-02-17 03:50:15,681] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:50:15,683] {logging_mixin.py:112} INFO - [2022-02-17 03:50:15,682] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:50:16,137] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:50:16,188] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:50:16,198] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:50:16,204] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 03:50:28,947] {scheduler_job.py:155} INFO - Started process (PID=63564) to work on /airflow/dags/download_data.py
[2022-02-17 03:50:28,951] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:50:28,952] {logging_mixin.py:112} INFO - [2022-02-17 03:50:28,952] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:50:29,392] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:50:29,432] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:50:29,438] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:50:29,442] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 03:50:42,237] {scheduler_job.py:155} INFO - Started process (PID=63590) to work on /airflow/dags/download_data.py
[2022-02-17 03:50:42,244] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:50:42,246] {logging_mixin.py:112} INFO - [2022-02-17 03:50:42,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:50:42,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:50:42,763] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:50:42,772] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:50:42,779] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 03:50:55,466] {scheduler_job.py:155} INFO - Started process (PID=63616) to work on /airflow/dags/download_data.py
[2022-02-17 03:50:55,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:50:55,473] {logging_mixin.py:112} INFO - [2022-02-17 03:50:55,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:50:56,020] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:50:56,076] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:50:56,084] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:50:56,094] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-17 03:51:08,777] {scheduler_job.py:155} INFO - Started process (PID=63644) to work on /airflow/dags/download_data.py
[2022-02-17 03:51:08,782] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:51:08,784] {logging_mixin.py:112} INFO - [2022-02-17 03:51:08,783] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:51:09,277] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:51:09,322] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:51:09,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:51:09,333] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 03:51:22,023] {scheduler_job.py:155} INFO - Started process (PID=63670) to work on /airflow/dags/download_data.py
[2022-02-17 03:51:22,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:51:22,028] {logging_mixin.py:112} INFO - [2022-02-17 03:51:22,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:51:22,477] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:51:22,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:51:22,540] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:51:22,547] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 03:51:35,324] {scheduler_job.py:155} INFO - Started process (PID=63698) to work on /airflow/dags/download_data.py
[2022-02-17 03:51:35,328] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:51:35,330] {logging_mixin.py:112} INFO - [2022-02-17 03:51:35,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:51:35,767] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:51:35,810] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:51:35,820] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:51:35,826] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 03:51:48,573] {scheduler_job.py:155} INFO - Started process (PID=63724) to work on /airflow/dags/download_data.py
[2022-02-17 03:51:48,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:51:48,580] {logging_mixin.py:112} INFO - [2022-02-17 03:51:48,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:51:49,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:51:49,072] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:51:49,079] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:51:49,084] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 03:52:01,834] {scheduler_job.py:155} INFO - Started process (PID=63752) to work on /airflow/dags/download_data.py
[2022-02-17 03:52:01,840] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:52:01,842] {logging_mixin.py:112} INFO - [2022-02-17 03:52:01,841] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:52:02,313] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:52:02,379] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:52:02,393] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:52:02,400] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 03:52:15,137] {scheduler_job.py:155} INFO - Started process (PID=63778) to work on /airflow/dags/download_data.py
[2022-02-17 03:52:15,154] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:52:15,160] {logging_mixin.py:112} INFO - [2022-02-17 03:52:15,159] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:52:15,731] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:52:15,772] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:52:15,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:52:15,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.651 seconds
[2022-02-17 03:52:28,398] {scheduler_job.py:155} INFO - Started process (PID=63806) to work on /airflow/dags/download_data.py
[2022-02-17 03:52:28,410] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:52:28,411] {logging_mixin.py:112} INFO - [2022-02-17 03:52:28,411] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:52:28,921] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:52:28,980] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:52:28,991] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:52:28,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-17 03:52:41,660] {scheduler_job.py:155} INFO - Started process (PID=63832) to work on /airflow/dags/download_data.py
[2022-02-17 03:52:41,668] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:52:41,671] {logging_mixin.py:112} INFO - [2022-02-17 03:52:41,670] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:52:42,201] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:52:42,260] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:52:42,270] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:52:42,275] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-17 03:52:54,906] {scheduler_job.py:155} INFO - Started process (PID=63858) to work on /airflow/dags/download_data.py
[2022-02-17 03:52:54,912] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:52:54,913] {logging_mixin.py:112} INFO - [2022-02-17 03:52:54,913] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:52:55,361] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:52:55,401] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:52:55,410] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:52:55,415] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 03:53:08,193] {scheduler_job.py:155} INFO - Started process (PID=63886) to work on /airflow/dags/download_data.py
[2022-02-17 03:53:08,198] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:53:08,200] {logging_mixin.py:112} INFO - [2022-02-17 03:53:08,199] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:53:08,651] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:53:08,698] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:53:08,705] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:53:08,711] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 03:53:21,447] {scheduler_job.py:155} INFO - Started process (PID=63912) to work on /airflow/dags/download_data.py
[2022-02-17 03:53:21,453] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:53:21,455] {logging_mixin.py:112} INFO - [2022-02-17 03:53:21,455] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:53:21,882] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:53:21,920] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:53:21,927] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:53:21,932] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-17 03:53:34,712] {scheduler_job.py:155} INFO - Started process (PID=63940) to work on /airflow/dags/download_data.py
[2022-02-17 03:53:34,721] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:53:34,730] {logging_mixin.py:112} INFO - [2022-02-17 03:53:34,730] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:53:35,183] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:53:35,226] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:53:35,235] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:53:35,240] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 03:53:47,969] {scheduler_job.py:155} INFO - Started process (PID=63966) to work on /airflow/dags/download_data.py
[2022-02-17 03:53:47,977] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:53:47,979] {logging_mixin.py:112} INFO - [2022-02-17 03:53:47,979] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:53:48,430] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:53:48,478] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:53:48,487] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:53:48,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 03:54:01,267] {scheduler_job.py:155} INFO - Started process (PID=63994) to work on /airflow/dags/download_data.py
[2022-02-17 03:54:01,285] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:54:01,289] {logging_mixin.py:112} INFO - [2022-02-17 03:54:01,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:54:01,757] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:54:01,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:54:01,826] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:54:01,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 03:54:14,527] {scheduler_job.py:155} INFO - Started process (PID=64020) to work on /airflow/dags/download_data.py
[2022-02-17 03:54:14,538] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:54:14,541] {logging_mixin.py:112} INFO - [2022-02-17 03:54:14,540] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:54:14,981] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:54:15,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:54:15,036] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:54:15,040] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 03:54:27,796] {scheduler_job.py:155} INFO - Started process (PID=64046) to work on /airflow/dags/download_data.py
[2022-02-17 03:54:27,806] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:54:27,807] {logging_mixin.py:112} INFO - [2022-02-17 03:54:27,807] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:54:28,249] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:54:28,295] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:54:28,305] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:54:28,311] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 03:54:41,065] {scheduler_job.py:155} INFO - Started process (PID=64074) to work on /airflow/dags/download_data.py
[2022-02-17 03:54:41,078] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:54:41,079] {logging_mixin.py:112} INFO - [2022-02-17 03:54:41,079] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:54:41,525] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:54:41,576] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:54:41,585] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:54:41,590] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 03:54:54,303] {scheduler_job.py:155} INFO - Started process (PID=64100) to work on /airflow/dags/download_data.py
[2022-02-17 03:54:54,310] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:54:54,312] {logging_mixin.py:112} INFO - [2022-02-17 03:54:54,311] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:54:54,759] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:54:54,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:54:54,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:54:54,809] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 03:55:07,576] {scheduler_job.py:155} INFO - Started process (PID=64128) to work on /airflow/dags/download_data.py
[2022-02-17 03:55:07,588] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:55:07,591] {logging_mixin.py:112} INFO - [2022-02-17 03:55:07,591] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:55:08,064] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:55:08,108] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:55:08,118] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:55:08,124] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 03:55:20,861] {scheduler_job.py:155} INFO - Started process (PID=64154) to work on /airflow/dags/download_data.py
[2022-02-17 03:55:20,867] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:55:20,869] {logging_mixin.py:112} INFO - [2022-02-17 03:55:20,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:55:21,415] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:55:21,475] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:55:21,482] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:55:21,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-17 03:55:34,206] {scheduler_job.py:155} INFO - Started process (PID=64182) to work on /airflow/dags/download_data.py
[2022-02-17 03:55:34,209] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:55:34,212] {logging_mixin.py:112} INFO - [2022-02-17 03:55:34,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:55:34,637] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:55:34,687] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:55:34,694] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:55:34,698] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 03:55:47,441] {scheduler_job.py:155} INFO - Started process (PID=64208) to work on /airflow/dags/download_data.py
[2022-02-17 03:55:47,448] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:55:47,450] {logging_mixin.py:112} INFO - [2022-02-17 03:55:47,450] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:55:47,992] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:55:48,063] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:55:48,077] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:55:48,085] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-17 03:56:00,729] {scheduler_job.py:155} INFO - Started process (PID=64234) to work on /airflow/dags/download_data.py
[2022-02-17 03:56:00,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:56:00,745] {logging_mixin.py:112} INFO - [2022-02-17 03:56:00,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:56:01,220] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:56:01,271] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:56:01,278] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:56:01,286] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 03:56:14,003] {scheduler_job.py:155} INFO - Started process (PID=64262) to work on /airflow/dags/download_data.py
[2022-02-17 03:56:14,011] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:56:14,013] {logging_mixin.py:112} INFO - [2022-02-17 03:56:14,013] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:56:14,548] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:56:14,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:56:14,620] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:56:14,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-17 03:56:27,293] {scheduler_job.py:155} INFO - Started process (PID=64288) to work on /airflow/dags/download_data.py
[2022-02-17 03:56:27,300] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:56:27,302] {logging_mixin.py:112} INFO - [2022-02-17 03:56:27,302] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:56:27,742] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:56:27,792] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:56:27,797] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:56:27,802] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 03:56:40,530] {scheduler_job.py:155} INFO - Started process (PID=64316) to work on /airflow/dags/download_data.py
[2022-02-17 03:56:40,534] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:56:40,536] {logging_mixin.py:112} INFO - [2022-02-17 03:56:40,535] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:56:40,995] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:56:41,051] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:56:41,058] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:56:41,065] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 03:56:53,801] {scheduler_job.py:155} INFO - Started process (PID=64342) to work on /airflow/dags/download_data.py
[2022-02-17 03:56:53,808] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:56:53,810] {logging_mixin.py:112} INFO - [2022-02-17 03:56:53,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:56:54,256] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:56:54,312] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:56:54,324] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:56:54,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 03:57:07,094] {scheduler_job.py:155} INFO - Started process (PID=64370) to work on /airflow/dags/download_data.py
[2022-02-17 03:57:07,100] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:57:07,102] {logging_mixin.py:112} INFO - [2022-02-17 03:57:07,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:57:07,573] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:57:07,622] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:57:07,631] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:57:07,637] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 03:57:20,374] {scheduler_job.py:155} INFO - Started process (PID=64396) to work on /airflow/dags/download_data.py
[2022-02-17 03:57:20,379] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:57:20,381] {logging_mixin.py:112} INFO - [2022-02-17 03:57:20,381] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:57:20,840] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:57:20,887] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:57:20,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:57:20,900] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 03:57:33,698] {scheduler_job.py:155} INFO - Started process (PID=64422) to work on /airflow/dags/download_data.py
[2022-02-17 03:57:33,713] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:57:33,714] {logging_mixin.py:112} INFO - [2022-02-17 03:57:33,714] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:57:34,314] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:57:34,352] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:57:34,361] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:57:34,369] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-17 03:57:47,004] {scheduler_job.py:155} INFO - Started process (PID=64450) to work on /airflow/dags/download_data.py
[2022-02-17 03:57:47,011] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:57:47,013] {logging_mixin.py:112} INFO - [2022-02-17 03:57:47,013] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:57:47,544] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:57:47,602] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:57:47,614] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:57:47,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 03:58:00,319] {scheduler_job.py:155} INFO - Started process (PID=64476) to work on /airflow/dags/download_data.py
[2022-02-17 03:58:00,326] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:58:00,328] {logging_mixin.py:112} INFO - [2022-02-17 03:58:00,328] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:58:00,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:58:00,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:58:00,888] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:58:00,895] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-17 03:58:13,612] {scheduler_job.py:155} INFO - Started process (PID=64504) to work on /airflow/dags/download_data.py
[2022-02-17 03:58:13,620] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:58:13,622] {logging_mixin.py:112} INFO - [2022-02-17 03:58:13,622] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:58:14,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:58:14,155] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:58:14,171] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:58:14,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 03:58:26,872] {scheduler_job.py:155} INFO - Started process (PID=64530) to work on /airflow/dags/download_data.py
[2022-02-17 03:58:26,877] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:58:26,879] {logging_mixin.py:112} INFO - [2022-02-17 03:58:26,878] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:58:27,335] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:58:27,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:58:27,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:58:27,385] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 03:58:40,176] {scheduler_job.py:155} INFO - Started process (PID=64558) to work on /airflow/dags/download_data.py
[2022-02-17 03:58:40,180] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:58:40,182] {logging_mixin.py:112} INFO - [2022-02-17 03:58:40,182] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:58:40,715] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:58:40,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:58:40,768] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:58:40,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-17 03:58:53,423] {scheduler_job.py:155} INFO - Started process (PID=64584) to work on /airflow/dags/download_data.py
[2022-02-17 03:58:53,427] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:58:53,429] {logging_mixin.py:112} INFO - [2022-02-17 03:58:53,429] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:58:53,875] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:58:53,923] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:58:53,930] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:58:53,936] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 03:59:06,738] {scheduler_job.py:155} INFO - Started process (PID=64612) to work on /airflow/dags/download_data.py
[2022-02-17 03:59:06,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:59:06,750] {logging_mixin.py:112} INFO - [2022-02-17 03:59:06,750] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:59:07,360] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:59:07,414] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:59:07,425] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:59:07,435] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-17 03:59:20,003] {scheduler_job.py:155} INFO - Started process (PID=64638) to work on /airflow/dags/download_data.py
[2022-02-17 03:59:20,012] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:59:20,014] {logging_mixin.py:112} INFO - [2022-02-17 03:59:20,014] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:59:20,470] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:59:20,511] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:59:20,519] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:59:20,523] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 03:59:33,271] {scheduler_job.py:155} INFO - Started process (PID=64664) to work on /airflow/dags/download_data.py
[2022-02-17 03:59:33,276] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:59:33,277] {logging_mixin.py:112} INFO - [2022-02-17 03:59:33,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:59:33,738] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:59:33,789] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:59:33,795] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:59:33,799] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 03:59:46,561] {scheduler_job.py:155} INFO - Started process (PID=64692) to work on /airflow/dags/download_data.py
[2022-02-17 03:59:46,565] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:59:46,568] {logging_mixin.py:112} INFO - [2022-02-17 03:59:46,568] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 03:59:47,078] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 03:59:47,131] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 03:59:47,141] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 03:59:47,151] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 03:59:59,853] {scheduler_job.py:155} INFO - Started process (PID=64718) to work on /airflow/dags/download_data.py
[2022-02-17 03:59:59,864] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 03:59:59,868] {logging_mixin.py:112} INFO - [2022-02-17 03:59:59,868] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:00:00,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:00:00,391] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:00:00,399] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:00:00,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 04:00:13,158] {scheduler_job.py:155} INFO - Started process (PID=64746) to work on /airflow/dags/download_data.py
[2022-02-17 04:00:13,165] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:00:13,167] {logging_mixin.py:112} INFO - [2022-02-17 04:00:13,167] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:00:13,656] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:00:13,710] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:00:13,719] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:00:13,725] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 04:00:26,409] {scheduler_job.py:155} INFO - Started process (PID=64772) to work on /airflow/dags/download_data.py
[2022-02-17 04:00:26,413] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:00:26,415] {logging_mixin.py:112} INFO - [2022-02-17 04:00:26,415] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:00:26,903] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:00:26,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:00:26,963] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:00:26,967] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 04:00:39,661] {scheduler_job.py:155} INFO - Started process (PID=64800) to work on /airflow/dags/download_data.py
[2022-02-17 04:00:39,671] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:00:39,673] {logging_mixin.py:112} INFO - [2022-02-17 04:00:39,673] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:00:40,158] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:00:40,205] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:00:40,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:00:40,215] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 04:00:52,888] {scheduler_job.py:155} INFO - Started process (PID=64826) to work on /airflow/dags/download_data.py
[2022-02-17 04:00:52,893] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:00:52,895] {logging_mixin.py:112} INFO - [2022-02-17 04:00:52,895] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:00:53,412] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:00:53,467] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:00:53,474] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:00:53,480] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 04:01:06,188] {scheduler_job.py:155} INFO - Started process (PID=64852) to work on /airflow/dags/download_data.py
[2022-02-17 04:01:06,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:01:06,201] {logging_mixin.py:112} INFO - [2022-02-17 04:01:06,201] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:01:06,681] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:01:06,732] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:01:06,740] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:01:06,746] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 04:01:19,431] {scheduler_job.py:155} INFO - Started process (PID=64880) to work on /airflow/dags/download_data.py
[2022-02-17 04:01:19,436] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:01:19,438] {logging_mixin.py:112} INFO - [2022-02-17 04:01:19,438] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:01:19,898] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:01:19,954] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:01:19,964] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:01:19,968] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 04:01:32,719] {scheduler_job.py:155} INFO - Started process (PID=64906) to work on /airflow/dags/download_data.py
[2022-02-17 04:01:32,733] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:01:32,735] {logging_mixin.py:112} INFO - [2022-02-17 04:01:32,735] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:01:33,174] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:01:33,216] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:01:33,221] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:01:33,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 04:01:45,999] {scheduler_job.py:155} INFO - Started process (PID=64934) to work on /airflow/dags/download_data.py
[2022-02-17 04:01:46,007] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:01:46,012] {logging_mixin.py:112} INFO - [2022-02-17 04:01:46,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:01:46,463] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:01:46,520] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:01:46,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:01:46,533] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 04:01:59,306] {scheduler_job.py:155} INFO - Started process (PID=64960) to work on /airflow/dags/download_data.py
[2022-02-17 04:01:59,314] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:01:59,318] {logging_mixin.py:112} INFO - [2022-02-17 04:01:59,317] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:01:59,830] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:01:59,881] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:01:59,891] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:01:59,897] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 04:02:12,588] {scheduler_job.py:155} INFO - Started process (PID=64988) to work on /airflow/dags/download_data.py
[2022-02-17 04:02:12,592] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:02:12,593] {logging_mixin.py:112} INFO - [2022-02-17 04:02:12,593] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:02:13,120] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:02:13,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:02:13,204] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:02:13,215] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.627 seconds
[2022-02-17 04:02:25,831] {scheduler_job.py:155} INFO - Started process (PID=65014) to work on /airflow/dags/download_data.py
[2022-02-17 04:02:25,836] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:02:25,838] {logging_mixin.py:112} INFO - [2022-02-17 04:02:25,837] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:02:26,307] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:02:26,351] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:02:26,358] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:02:26,362] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 04:02:39,151] {scheduler_job.py:155} INFO - Started process (PID=65040) to work on /airflow/dags/download_data.py
[2022-02-17 04:02:39,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:02:39,167] {logging_mixin.py:112} INFO - [2022-02-17 04:02:39,166] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:02:39,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:02:39,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:02:39,766] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:02:39,770] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 04:02:52,428] {scheduler_job.py:155} INFO - Started process (PID=65068) to work on /airflow/dags/download_data.py
[2022-02-17 04:02:52,440] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:02:52,443] {logging_mixin.py:112} INFO - [2022-02-17 04:02:52,442] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:02:52,913] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:02:52,967] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:02:52,976] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:02:52,982] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 04:03:05,778] {scheduler_job.py:155} INFO - Started process (PID=65094) to work on /airflow/dags/download_data.py
[2022-02-17 04:03:05,796] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:03:05,798] {logging_mixin.py:112} INFO - [2022-02-17 04:03:05,798] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:03:06,291] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:03:06,330] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:03:06,339] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:03:06,344] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 04:03:19,029] {scheduler_job.py:155} INFO - Started process (PID=65122) to work on /airflow/dags/download_data.py
[2022-02-17 04:03:19,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:03:19,047] {logging_mixin.py:112} INFO - [2022-02-17 04:03:19,047] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:03:19,493] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:03:19,550] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:03:19,557] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:03:19,562] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 04:03:32,323] {scheduler_job.py:155} INFO - Started process (PID=65148) to work on /airflow/dags/download_data.py
[2022-02-17 04:03:32,329] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:03:32,330] {logging_mixin.py:112} INFO - [2022-02-17 04:03:32,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:03:32,777] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:03:32,825] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:03:32,832] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:03:32,838] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 04:03:45,543] {scheduler_job.py:155} INFO - Started process (PID=65176) to work on /airflow/dags/download_data.py
[2022-02-17 04:03:45,549] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:03:45,551] {logging_mixin.py:112} INFO - [2022-02-17 04:03:45,550] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:03:45,991] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:03:46,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:03:46,051] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:03:46,056] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 04:03:58,806] {scheduler_job.py:155} INFO - Started process (PID=65202) to work on /airflow/dags/download_data.py
[2022-02-17 04:03:58,811] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:03:58,813] {logging_mixin.py:112} INFO - [2022-02-17 04:03:58,813] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:03:59,288] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:03:59,339] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:03:59,349] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:03:59,357] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 04:04:12,105] {scheduler_job.py:155} INFO - Started process (PID=65228) to work on /airflow/dags/download_data.py
[2022-02-17 04:04:12,128] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:04:12,134] {logging_mixin.py:112} INFO - [2022-02-17 04:04:12,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:04:12,674] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:04:12,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:04:12,730] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:04:12,736] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-17 04:04:25,353] {scheduler_job.py:155} INFO - Started process (PID=65256) to work on /airflow/dags/download_data.py
[2022-02-17 04:04:25,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:04:25,361] {logging_mixin.py:112} INFO - [2022-02-17 04:04:25,359] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:04:25,799] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:04:25,840] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:04:25,846] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:04:25,852] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 04:04:38,622] {scheduler_job.py:155} INFO - Started process (PID=65282) to work on /airflow/dags/download_data.py
[2022-02-17 04:04:38,627] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:04:38,630] {logging_mixin.py:112} INFO - [2022-02-17 04:04:38,629] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:04:39,072] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:04:39,116] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:04:39,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:04:39,126] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 04:04:51,878] {scheduler_job.py:155} INFO - Started process (PID=65310) to work on /airflow/dags/download_data.py
[2022-02-17 04:04:51,885] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:04:51,887] {logging_mixin.py:112} INFO - [2022-02-17 04:04:51,887] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:04:52,325] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:04:52,367] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:04:52,374] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:04:52,378] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 04:05:05,149] {scheduler_job.py:155} INFO - Started process (PID=65336) to work on /airflow/dags/download_data.py
[2022-02-17 04:05:05,154] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:05:05,155] {logging_mixin.py:112} INFO - [2022-02-17 04:05:05,155] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:05:05,596] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:05:05,646] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:05:05,653] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:05:05,658] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 04:05:18,395] {scheduler_job.py:155} INFO - Started process (PID=65364) to work on /airflow/dags/download_data.py
[2022-02-17 04:05:18,412] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:05:18,422] {logging_mixin.py:112} INFO - [2022-02-17 04:05:18,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:05:18,970] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:05:19,041] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:05:19,054] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:05:19,061] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-17 04:05:31,715] {scheduler_job.py:155} INFO - Started process (PID=65390) to work on /airflow/dags/download_data.py
[2022-02-17 04:05:31,721] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:05:31,723] {logging_mixin.py:112} INFO - [2022-02-17 04:05:31,723] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:05:32,560] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:05:32,621] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:05:32,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:05:32,640] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.925 seconds
[2022-02-17 04:05:45,003] {scheduler_job.py:155} INFO - Started process (PID=65418) to work on /airflow/dags/download_data.py
[2022-02-17 04:05:45,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:05:45,026] {logging_mixin.py:112} INFO - [2022-02-17 04:05:45,026] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:05:45,481] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:05:45,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:05:45,524] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:05:45,531] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 04:05:58,257] {scheduler_job.py:155} INFO - Started process (PID=65444) to work on /airflow/dags/download_data.py
[2022-02-17 04:05:58,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:05:58,266] {logging_mixin.py:112} INFO - [2022-02-17 04:05:58,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:05:58,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:05:58,803] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:05:58,813] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:05:58,818] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 04:06:11,573] {scheduler_job.py:155} INFO - Started process (PID=65470) to work on /airflow/dags/download_data.py
[2022-02-17 04:06:11,580] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:06:11,582] {logging_mixin.py:112} INFO - [2022-02-17 04:06:11,582] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:06:12,022] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:06:12,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:06:12,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:06:12,080] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 04:06:24,774] {scheduler_job.py:155} INFO - Started process (PID=65498) to work on /airflow/dags/download_data.py
[2022-02-17 04:06:24,781] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:06:24,783] {logging_mixin.py:112} INFO - [2022-02-17 04:06:24,783] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:06:25,233] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:06:25,290] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:06:25,303] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:06:25,310] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 04:06:38,048] {scheduler_job.py:155} INFO - Started process (PID=65524) to work on /airflow/dags/download_data.py
[2022-02-17 04:06:38,063] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:06:38,065] {logging_mixin.py:112} INFO - [2022-02-17 04:06:38,065] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:06:38,511] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:06:38,563] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:06:38,572] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:06:38,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 04:06:51,294] {scheduler_job.py:155} INFO - Started process (PID=65552) to work on /airflow/dags/download_data.py
[2022-02-17 04:06:51,307] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:06:51,310] {logging_mixin.py:112} INFO - [2022-02-17 04:06:51,309] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:06:51,781] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:06:51,834] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:06:51,843] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:06:51,849] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 04:07:04,573] {scheduler_job.py:155} INFO - Started process (PID=65578) to work on /airflow/dags/download_data.py
[2022-02-17 04:07:04,582] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:07:04,586] {logging_mixin.py:112} INFO - [2022-02-17 04:07:04,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:07:05,073] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:07:05,133] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:07:05,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:07:05,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 04:07:17,863] {scheduler_job.py:155} INFO - Started process (PID=65606) to work on /airflow/dags/download_data.py
[2022-02-17 04:07:17,870] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:07:17,872] {logging_mixin.py:112} INFO - [2022-02-17 04:07:17,872] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:07:18,350] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:07:18,399] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:07:18,410] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:07:18,416] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 04:07:31,149] {scheduler_job.py:155} INFO - Started process (PID=65632) to work on /airflow/dags/download_data.py
[2022-02-17 04:07:31,158] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:07:31,170] {logging_mixin.py:112} INFO - [2022-02-17 04:07:31,170] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:07:31,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:07:31,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:07:31,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:07:31,820] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.671 seconds
[2022-02-17 04:07:44,391] {scheduler_job.py:155} INFO - Started process (PID=65658) to work on /airflow/dags/download_data.py
[2022-02-17 04:07:44,404] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:07:44,406] {logging_mixin.py:112} INFO - [2022-02-17 04:07:44,406] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:07:44,981] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:07:45,033] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:07:45,044] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:07:45,052] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.661 seconds
[2022-02-17 04:07:57,869] {scheduler_job.py:155} INFO - Started process (PID=65686) to work on /airflow/dags/download_data.py
[2022-02-17 04:07:57,878] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:07:57,880] {logging_mixin.py:112} INFO - [2022-02-17 04:07:57,880] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:07:58,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:07:58,451] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:07:58,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:07:58,465] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 04:08:11,165] {scheduler_job.py:155} INFO - Started process (PID=65712) to work on /airflow/dags/download_data.py
[2022-02-17 04:08:11,171] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:08:11,175] {logging_mixin.py:112} INFO - [2022-02-17 04:08:11,174] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:08:11,638] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:08:11,684] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:08:11,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:08:11,700] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 04:08:24,422] {scheduler_job.py:155} INFO - Started process (PID=65740) to work on /airflow/dags/download_data.py
[2022-02-17 04:08:24,434] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:08:24,438] {logging_mixin.py:112} INFO - [2022-02-17 04:08:24,437] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:08:25,128] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:08:25,191] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:08:25,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:08:25,207] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.786 seconds
[2022-02-17 04:08:37,802] {scheduler_job.py:155} INFO - Started process (PID=65766) to work on /airflow/dags/download_data.py
[2022-02-17 04:08:37,820] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:08:37,823] {logging_mixin.py:112} INFO - [2022-02-17 04:08:37,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:08:38,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:08:38,448] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:08:38,455] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:08:38,460] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.658 seconds
[2022-02-17 04:08:51,024] {scheduler_job.py:155} INFO - Started process (PID=65794) to work on /airflow/dags/download_data.py
[2022-02-17 04:08:51,030] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:08:51,033] {logging_mixin.py:112} INFO - [2022-02-17 04:08:51,033] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:08:51,494] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:08:51,534] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:08:51,541] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:08:51,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 04:09:04,347] {scheduler_job.py:155} INFO - Started process (PID=65820) to work on /airflow/dags/download_data.py
[2022-02-17 04:09:04,354] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:09:04,356] {logging_mixin.py:112} INFO - [2022-02-17 04:09:04,356] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:09:04,807] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:09:04,862] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:09:04,872] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:09:04,881] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 04:09:17,640] {scheduler_job.py:155} INFO - Started process (PID=65846) to work on /airflow/dags/download_data.py
[2022-02-17 04:09:17,645] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:09:17,646] {logging_mixin.py:112} INFO - [2022-02-17 04:09:17,646] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:09:18,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:09:18,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:09:18,204] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:09:18,208] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 04:09:31,008] {scheduler_job.py:155} INFO - Started process (PID=65874) to work on /airflow/dags/download_data.py
[2022-02-17 04:09:31,019] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:09:31,026] {logging_mixin.py:112} INFO - [2022-02-17 04:09:31,026] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:09:31,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:09:31,894] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:09:31,907] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:09:31,914] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.906 seconds
[2022-02-17 04:09:44,232] {scheduler_job.py:155} INFO - Started process (PID=65900) to work on /airflow/dags/download_data.py
[2022-02-17 04:09:44,240] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:09:44,242] {logging_mixin.py:112} INFO - [2022-02-17 04:09:44,242] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:09:44,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:09:44,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:09:44,854] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:09:44,861] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-17 04:09:57,501] {scheduler_job.py:155} INFO - Started process (PID=65928) to work on /airflow/dags/download_data.py
[2022-02-17 04:09:57,504] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:09:57,508] {logging_mixin.py:112} INFO - [2022-02-17 04:09:57,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:09:58,044] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:09:58,109] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:09:58,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:09:58,124] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-17 04:10:10,800] {scheduler_job.py:155} INFO - Started process (PID=65954) to work on /airflow/dags/download_data.py
[2022-02-17 04:10:10,804] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:10:10,805] {logging_mixin.py:112} INFO - [2022-02-17 04:10:10,805] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:10:11,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:10:11,302] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:10:11,312] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:10:11,319] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 04:10:24,021] {scheduler_job.py:155} INFO - Started process (PID=65982) to work on /airflow/dags/download_data.py
[2022-02-17 04:10:24,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:10:24,029] {logging_mixin.py:112} INFO - [2022-02-17 04:10:24,029] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:10:24,474] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:10:24,523] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:10:24,530] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:10:24,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 04:10:37,291] {scheduler_job.py:155} INFO - Started process (PID=66008) to work on /airflow/dags/download_data.py
[2022-02-17 04:10:37,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:10:37,298] {logging_mixin.py:112} INFO - [2022-02-17 04:10:37,298] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:10:37,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:10:37,796] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:10:37,805] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:10:37,812] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 04:10:50,556] {scheduler_job.py:155} INFO - Started process (PID=66036) to work on /airflow/dags/download_data.py
[2022-02-17 04:10:50,571] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:10:50,575] {logging_mixin.py:112} INFO - [2022-02-17 04:10:50,574] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:10:51,097] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:10:51,140] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:10:51,146] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:10:51,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 04:11:03,859] {scheduler_job.py:155} INFO - Started process (PID=66062) to work on /airflow/dags/download_data.py
[2022-02-17 04:11:03,867] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:11:03,872] {logging_mixin.py:112} INFO - [2022-02-17 04:11:03,871] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:11:04,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:11:04,400] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:11:04,407] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:11:04,412] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 04:11:17,099] {scheduler_job.py:155} INFO - Started process (PID=66088) to work on /airflow/dags/download_data.py
[2022-02-17 04:11:17,103] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:11:17,105] {logging_mixin.py:112} INFO - [2022-02-17 04:11:17,105] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:11:17,565] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:11:17,618] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:11:17,629] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:11:17,637] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 04:11:30,431] {scheduler_job.py:155} INFO - Started process (PID=66116) to work on /airflow/dags/download_data.py
[2022-02-17 04:11:30,442] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:11:30,446] {logging_mixin.py:112} INFO - [2022-02-17 04:11:30,446] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:11:30,941] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:11:30,999] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:11:31,006] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:11:31,011] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 04:11:43,777] {scheduler_job.py:155} INFO - Started process (PID=66142) to work on /airflow/dags/download_data.py
[2022-02-17 04:11:43,806] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:11:43,809] {logging_mixin.py:112} INFO - [2022-02-17 04:11:43,808] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:11:45,018] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:11:45,072] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:11:45,080] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:11:45,085] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.309 seconds
[2022-02-17 04:11:58,122] {scheduler_job.py:155} INFO - Started process (PID=66170) to work on /airflow/dags/download_data.py
[2022-02-17 04:11:58,129] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:11:58,137] {logging_mixin.py:112} INFO - [2022-02-17 04:11:58,136] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:11:58,622] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:11:58,677] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:11:58,687] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:11:58,692] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 04:12:10,400] {scheduler_job.py:155} INFO - Started process (PID=66195) to work on /airflow/dags/download_data.py
[2022-02-17 04:12:10,416] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:12:10,421] {logging_mixin.py:112} INFO - [2022-02-17 04:12:10,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:12:10,893] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:12:10,954] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:12:10,966] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:12:10,973] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 04:12:23,640] {scheduler_job.py:155} INFO - Started process (PID=66223) to work on /airflow/dags/download_data.py
[2022-02-17 04:12:23,647] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:12:23,649] {logging_mixin.py:112} INFO - [2022-02-17 04:12:23,649] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:12:24,108] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:12:24,149] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:12:24,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:12:24,161] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 04:12:36,904] {scheduler_job.py:155} INFO - Started process (PID=66249) to work on /airflow/dags/download_data.py
[2022-02-17 04:12:36,909] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:12:36,911] {logging_mixin.py:112} INFO - [2022-02-17 04:12:36,911] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:12:37,366] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:12:37,414] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:12:37,421] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:12:37,427] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 04:12:50,158] {scheduler_job.py:155} INFO - Started process (PID=66275) to work on /airflow/dags/download_data.py
[2022-02-17 04:12:50,172] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:12:50,174] {logging_mixin.py:112} INFO - [2022-02-17 04:12:50,174] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:12:50,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:12:50,682] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:12:50,693] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:12:50,699] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 04:13:03,497] {scheduler_job.py:155} INFO - Started process (PID=66303) to work on /airflow/dags/download_data.py
[2022-02-17 04:13:03,502] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:13:03,504] {logging_mixin.py:112} INFO - [2022-02-17 04:13:03,503] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:13:03,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:13:04,015] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:13:04,027] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:13:04,031] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 04:13:16,738] {scheduler_job.py:155} INFO - Started process (PID=66329) to work on /airflow/dags/download_data.py
[2022-02-17 04:13:16,744] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:13:16,748] {logging_mixin.py:112} INFO - [2022-02-17 04:13:16,747] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:13:17,258] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:13:17,313] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:13:17,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:13:17,323] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 04:13:29,999] {scheduler_job.py:155} INFO - Started process (PID=66357) to work on /airflow/dags/download_data.py
[2022-02-17 04:13:30,008] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:13:30,010] {logging_mixin.py:112} INFO - [2022-02-17 04:13:30,009] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:13:30,481] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:13:30,534] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:13:30,545] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:13:30,550] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 04:13:43,260] {scheduler_job.py:155} INFO - Started process (PID=66383) to work on /airflow/dags/download_data.py
[2022-02-17 04:13:43,286] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:13:43,287] {logging_mixin.py:112} INFO - [2022-02-17 04:13:43,287] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:13:44,008] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:13:44,072] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:13:44,081] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:13:44,087] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.828 seconds
[2022-02-17 04:13:56,592] {scheduler_job.py:155} INFO - Started process (PID=66411) to work on /airflow/dags/download_data.py
[2022-02-17 04:13:56,602] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:13:56,606] {logging_mixin.py:112} INFO - [2022-02-17 04:13:56,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:13:57,182] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:13:57,223] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:13:57,230] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:13:57,234] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-17 04:14:09,943] {scheduler_job.py:155} INFO - Started process (PID=66437) to work on /airflow/dags/download_data.py
[2022-02-17 04:14:09,952] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:14:09,954] {logging_mixin.py:112} INFO - [2022-02-17 04:14:09,954] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:14:10,418] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:14:10,477] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:14:10,486] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:14:10,493] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 04:14:23,179] {scheduler_job.py:155} INFO - Started process (PID=66463) to work on /airflow/dags/download_data.py
[2022-02-17 04:14:23,183] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:14:23,185] {logging_mixin.py:112} INFO - [2022-02-17 04:14:23,185] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:14:23,633] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:14:23,683] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:14:23,693] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:14:23,697] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 04:14:36,501] {scheduler_job.py:155} INFO - Started process (PID=66491) to work on /airflow/dags/download_data.py
[2022-02-17 04:14:36,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:14:36,513] {logging_mixin.py:112} INFO - [2022-02-17 04:14:36,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:14:36,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:14:37,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:14:37,025] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:14:37,031] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 04:14:49,738] {scheduler_job.py:155} INFO - Started process (PID=66517) to work on /airflow/dags/download_data.py
[2022-02-17 04:14:49,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:14:49,749] {logging_mixin.py:112} INFO - [2022-02-17 04:14:49,749] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:14:50,185] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:14:50,228] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:14:50,238] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:14:50,245] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 04:15:03,003] {scheduler_job.py:155} INFO - Started process (PID=66545) to work on /airflow/dags/download_data.py
[2022-02-17 04:15:03,011] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:15:03,013] {logging_mixin.py:112} INFO - [2022-02-17 04:15:03,013] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:15:03,541] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:15:03,592] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:15:03,600] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:15:03,605] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 04:15:16,359] {scheduler_job.py:155} INFO - Started process (PID=66571) to work on /airflow/dags/download_data.py
[2022-02-17 04:15:16,370] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:15:16,380] {logging_mixin.py:112} INFO - [2022-02-17 04:15:16,379] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:15:16,998] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:15:17,049] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:15:17,060] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:15:17,072] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.713 seconds
[2022-02-17 04:15:29,724] {scheduler_job.py:155} INFO - Started process (PID=66599) to work on /airflow/dags/download_data.py
[2022-02-17 04:15:29,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:15:29,745] {logging_mixin.py:112} INFO - [2022-02-17 04:15:29,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:15:30,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:15:30,347] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:15:30,359] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:15:30,362] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.639 seconds
[2022-02-17 04:15:42,994] {scheduler_job.py:155} INFO - Started process (PID=66625) to work on /airflow/dags/download_data.py
[2022-02-17 04:15:43,003] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:15:43,005] {logging_mixin.py:112} INFO - [2022-02-17 04:15:43,005] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:15:43,477] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:15:43,521] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:15:43,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:15:43,537] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 04:15:56,271] {scheduler_job.py:155} INFO - Started process (PID=66651) to work on /airflow/dags/download_data.py
[2022-02-17 04:15:56,276] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:15:56,278] {logging_mixin.py:112} INFO - [2022-02-17 04:15:56,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:15:56,766] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:15:56,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:15:56,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:15:56,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 04:16:09,566] {scheduler_job.py:155} INFO - Started process (PID=66679) to work on /airflow/dags/download_data.py
[2022-02-17 04:16:09,573] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:16:09,575] {logging_mixin.py:112} INFO - [2022-02-17 04:16:09,574] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:16:10,109] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:16:10,165] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:16:10,175] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:16:10,180] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-17 04:16:22,845] {scheduler_job.py:155} INFO - Started process (PID=66705) to work on /airflow/dags/download_data.py
[2022-02-17 04:16:22,860] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:16:22,863] {logging_mixin.py:112} INFO - [2022-02-17 04:16:22,863] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:16:23,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:16:23,440] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:16:23,451] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:16:23,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-17 04:16:36,161] {scheduler_job.py:155} INFO - Started process (PID=66733) to work on /airflow/dags/download_data.py
[2022-02-17 04:16:36,173] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:16:36,176] {logging_mixin.py:112} INFO - [2022-02-17 04:16:36,176] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:16:36,723] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:16:36,776] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:16:36,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:16:36,793] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-17 04:16:49,478] {scheduler_job.py:155} INFO - Started process (PID=66759) to work on /airflow/dags/download_data.py
[2022-02-17 04:16:49,489] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:16:49,491] {logging_mixin.py:112} INFO - [2022-02-17 04:16:49,491] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:16:50,054] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:16:50,108] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:16:50,120] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:16:50,127] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.650 seconds
[2022-02-17 04:17:02,779] {scheduler_job.py:155} INFO - Started process (PID=66787) to work on /airflow/dags/download_data.py
[2022-02-17 04:17:02,787] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:17:02,788] {logging_mixin.py:112} INFO - [2022-02-17 04:17:02,788] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:17:03,270] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:17:03,328] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:17:03,336] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:17:03,341] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 04:17:16,076] {scheduler_job.py:155} INFO - Started process (PID=66813) to work on /airflow/dags/download_data.py
[2022-02-17 04:17:16,081] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:17:16,084] {logging_mixin.py:112} INFO - [2022-02-17 04:17:16,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:17:16,608] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:17:16,658] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:17:16,666] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:17:16,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-17 04:17:29,364] {scheduler_job.py:155} INFO - Started process (PID=66840) to work on /airflow/dags/download_data.py
[2022-02-17 04:17:29,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:17:29,375] {logging_mixin.py:112} INFO - [2022-02-17 04:17:29,375] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:17:30,049] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:17:30,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:17:30,109] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:17:30,113] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.749 seconds
[2022-02-17 04:17:42,646] {scheduler_job.py:155} INFO - Started process (PID=66867) to work on /airflow/dags/download_data.py
[2022-02-17 04:17:42,657] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:17:42,659] {logging_mixin.py:112} INFO - [2022-02-17 04:17:42,659] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:17:43,176] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:17:43,238] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:17:43,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:17:43,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 04:17:55,909] {scheduler_job.py:155} INFO - Started process (PID=66893) to work on /airflow/dags/download_data.py
[2022-02-17 04:17:55,916] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:17:55,918] {logging_mixin.py:112} INFO - [2022-02-17 04:17:55,917] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:17:56,371] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:17:56,409] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:17:56,414] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:17:56,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 04:18:09,274] {scheduler_job.py:155} INFO - Started process (PID=66921) to work on /airflow/dags/download_data.py
[2022-02-17 04:18:09,283] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:18:09,286] {logging_mixin.py:112} INFO - [2022-02-17 04:18:09,285] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:18:09,812] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:18:09,888] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:18:09,900] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:18:09,909] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.636 seconds
[2022-02-17 04:18:22,527] {scheduler_job.py:155} INFO - Started process (PID=66947) to work on /airflow/dags/download_data.py
[2022-02-17 04:18:22,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:18:22,535] {logging_mixin.py:112} INFO - [2022-02-17 04:18:22,535] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:18:23,081] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:18:23,133] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:18:23,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:18:23,151] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-17 04:18:35,832] {scheduler_job.py:155} INFO - Started process (PID=66975) to work on /airflow/dags/download_data.py
[2022-02-17 04:18:35,839] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:18:35,841] {logging_mixin.py:112} INFO - [2022-02-17 04:18:35,841] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:18:36,318] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:18:36,372] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:18:36,383] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:18:36,389] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 04:18:49,087] {scheduler_job.py:155} INFO - Started process (PID=67001) to work on /airflow/dags/download_data.py
[2022-02-17 04:18:49,093] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:18:49,094] {logging_mixin.py:112} INFO - [2022-02-17 04:18:49,094] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:18:49,611] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:18:49,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:18:49,665] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:18:49,672] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 04:19:02,404] {scheduler_job.py:155} INFO - Started process (PID=67029) to work on /airflow/dags/download_data.py
[2022-02-17 04:19:02,417] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:19:02,421] {logging_mixin.py:112} INFO - [2022-02-17 04:19:02,420] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:19:02,956] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:19:03,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:19:03,018] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:19:03,023] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-17 04:19:15,668] {scheduler_job.py:155} INFO - Started process (PID=67055) to work on /airflow/dags/download_data.py
[2022-02-17 04:19:15,674] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:19:15,677] {logging_mixin.py:112} INFO - [2022-02-17 04:19:15,677] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:19:16,309] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:19:16,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:19:16,388] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:19:16,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.728 seconds
[2022-02-17 04:19:28,979] {scheduler_job.py:155} INFO - Started process (PID=67081) to work on /airflow/dags/download_data.py
[2022-02-17 04:19:28,988] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:19:28,990] {logging_mixin.py:112} INFO - [2022-02-17 04:19:28,990] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:19:29,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:19:29,895] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:19:29,909] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:19:29,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.939 seconds
[2022-02-17 04:19:42,285] {scheduler_job.py:155} INFO - Started process (PID=67109) to work on /airflow/dags/download_data.py
[2022-02-17 04:19:42,292] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:19:42,295] {logging_mixin.py:112} INFO - [2022-02-17 04:19:42,294] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:19:42,997] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:19:43,086] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:19:43,118] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:19:43,123] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.838 seconds
[2022-02-17 04:19:55,578] {scheduler_job.py:155} INFO - Started process (PID=67135) to work on /airflow/dags/download_data.py
[2022-02-17 04:19:55,584] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:19:55,585] {logging_mixin.py:112} INFO - [2022-02-17 04:19:55,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:19:56,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:19:56,360] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:19:56,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:19:56,376] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.798 seconds
[2022-02-17 04:20:08,837] {scheduler_job.py:155} INFO - Started process (PID=67163) to work on /airflow/dags/download_data.py
[2022-02-17 04:20:08,843] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:20:08,845] {logging_mixin.py:112} INFO - [2022-02-17 04:20:08,845] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:20:09,370] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:20:09,416] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:20:09,424] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:20:09,429] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 04:20:22,164] {scheduler_job.py:155} INFO - Started process (PID=67189) to work on /airflow/dags/download_data.py
[2022-02-17 04:20:22,171] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:20:22,174] {logging_mixin.py:112} INFO - [2022-02-17 04:20:22,174] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:20:22,834] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:20:22,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:20:22,909] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:20:22,916] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.752 seconds
[2022-02-17 04:20:35,448] {scheduler_job.py:155} INFO - Started process (PID=67217) to work on /airflow/dags/download_data.py
[2022-02-17 04:20:35,457] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:20:35,460] {logging_mixin.py:112} INFO - [2022-02-17 04:20:35,459] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:20:35,964] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:20:36,015] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:20:36,027] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:20:36,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 04:20:48,718] {scheduler_job.py:155} INFO - Started process (PID=67243) to work on /airflow/dags/download_data.py
[2022-02-17 04:20:48,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:20:48,736] {logging_mixin.py:112} INFO - [2022-02-17 04:20:48,736] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:20:49,292] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:20:49,358] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:20:49,372] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:20:49,385] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-17 04:21:01,991] {scheduler_job.py:155} INFO - Started process (PID=67269) to work on /airflow/dags/download_data.py
[2022-02-17 04:21:02,003] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:21:02,005] {logging_mixin.py:112} INFO - [2022-02-17 04:21:02,005] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:21:02,490] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:21:02,535] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:21:02,541] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:21:02,547] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 04:21:15,340] {scheduler_job.py:155} INFO - Started process (PID=67297) to work on /airflow/dags/download_data.py
[2022-02-17 04:21:15,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:21:15,351] {logging_mixin.py:112} INFO - [2022-02-17 04:21:15,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:21:15,936] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:21:15,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:21:16,001] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:21:16,008] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.668 seconds
[2022-02-17 04:21:28,636] {scheduler_job.py:155} INFO - Started process (PID=67323) to work on /airflow/dags/download_data.py
[2022-02-17 04:21:28,641] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:21:28,643] {logging_mixin.py:112} INFO - [2022-02-17 04:21:28,643] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:21:29,285] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:21:29,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:21:29,356] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:21:29,361] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.725 seconds
[2022-02-17 04:21:41,961] {scheduler_job.py:155} INFO - Started process (PID=67351) to work on /airflow/dags/download_data.py
[2022-02-17 04:21:41,979] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:21:41,986] {logging_mixin.py:112} INFO - [2022-02-17 04:21:41,985] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:21:42,442] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:21:42,477] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:21:42,483] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:21:42,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 04:21:55,226] {scheduler_job.py:155} INFO - Started process (PID=67377) to work on /airflow/dags/download_data.py
[2022-02-17 04:21:55,232] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:21:55,234] {logging_mixin.py:112} INFO - [2022-02-17 04:21:55,234] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:21:55,768] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:21:55,810] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:21:55,816] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:21:55,822] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 04:22:08,503] {scheduler_job.py:155} INFO - Started process (PID=67405) to work on /airflow/dags/download_data.py
[2022-02-17 04:22:08,522] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:22:08,531] {logging_mixin.py:112} INFO - [2022-02-17 04:22:08,529] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:22:09,120] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:22:09,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:22:09,187] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:22:09,193] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.690 seconds
[2022-02-17 04:22:21,757] {scheduler_job.py:155} INFO - Started process (PID=67431) to work on /airflow/dags/download_data.py
[2022-02-17 04:22:21,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:22:21,765] {logging_mixin.py:112} INFO - [2022-02-17 04:22:21,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:22:22,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:22:22,283] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:22:22,293] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:22:22,300] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 04:22:35,027] {scheduler_job.py:155} INFO - Started process (PID=67457) to work on /airflow/dags/download_data.py
[2022-02-17 04:22:35,039] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:22:35,042] {logging_mixin.py:112} INFO - [2022-02-17 04:22:35,042] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:22:35,479] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:22:35,521] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:22:35,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:22:35,533] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 04:22:48,268] {scheduler_job.py:155} INFO - Started process (PID=67485) to work on /airflow/dags/download_data.py
[2022-02-17 04:22:48,273] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:22:48,274] {logging_mixin.py:112} INFO - [2022-02-17 04:22:48,274] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:22:48,733] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:22:48,785] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:22:48,793] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:22:48,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 04:23:01,565] {scheduler_job.py:155} INFO - Started process (PID=67511) to work on /airflow/dags/download_data.py
[2022-02-17 04:23:01,570] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:23:01,572] {logging_mixin.py:112} INFO - [2022-02-17 04:23:01,572] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:23:02,046] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:23:02,087] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:23:02,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:23:02,097] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 04:23:14,832] {scheduler_job.py:155} INFO - Started process (PID=67539) to work on /airflow/dags/download_data.py
[2022-02-17 04:23:14,843] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:23:14,846] {logging_mixin.py:112} INFO - [2022-02-17 04:23:14,845] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:23:15,320] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:23:15,373] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:23:15,380] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:23:15,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 04:23:28,120] {scheduler_job.py:155} INFO - Started process (PID=67565) to work on /airflow/dags/download_data.py
[2022-02-17 04:23:28,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:23:28,129] {logging_mixin.py:112} INFO - [2022-02-17 04:23:28,129] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:23:28,722] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:23:28,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:23:28,768] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:23:28,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.653 seconds
[2022-02-17 04:23:41,412] {scheduler_job.py:155} INFO - Started process (PID=67593) to work on /airflow/dags/download_data.py
[2022-02-17 04:23:41,425] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:23:41,432] {logging_mixin.py:112} INFO - [2022-02-17 04:23:41,427] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:23:41,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:23:41,939] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:23:41,950] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:23:41,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 04:23:54,687] {scheduler_job.py:155} INFO - Started process (PID=67619) to work on /airflow/dags/download_data.py
[2022-02-17 04:23:54,695] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:23:54,697] {logging_mixin.py:112} INFO - [2022-02-17 04:23:54,697] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:23:55,284] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:23:55,340] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:23:55,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:23:55,355] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.668 seconds
[2022-02-17 04:24:07,981] {scheduler_job.py:155} INFO - Started process (PID=67646) to work on /airflow/dags/download_data.py
[2022-02-17 04:24:07,996] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:24:08,001] {logging_mixin.py:112} INFO - [2022-02-17 04:24:08,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:24:08,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:24:08,812] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:24:08,833] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:24:08,843] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.863 seconds
[2022-02-17 04:24:21,242] {scheduler_job.py:155} INFO - Started process (PID=67673) to work on /airflow/dags/download_data.py
[2022-02-17 04:24:21,252] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:24:21,254] {logging_mixin.py:112} INFO - [2022-02-17 04:24:21,253] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:24:21,777] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:24:21,821] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:24:21,826] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:24:21,831] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-17 04:24:34,478] {scheduler_job.py:155} INFO - Started process (PID=67699) to work on /airflow/dags/download_data.py
[2022-02-17 04:24:34,492] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:24:34,494] {logging_mixin.py:112} INFO - [2022-02-17 04:24:34,493] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:24:35,020] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:24:35,069] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:24:35,077] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:24:35,083] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 04:24:47,893] {scheduler_job.py:155} INFO - Started process (PID=67727) to work on /airflow/dags/download_data.py
[2022-02-17 04:24:47,901] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:24:47,907] {logging_mixin.py:112} INFO - [2022-02-17 04:24:47,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:24:48,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:24:48,548] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:24:48,558] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:24:48,566] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.678 seconds
[2022-02-17 04:25:01,214] {scheduler_job.py:155} INFO - Started process (PID=67753) to work on /airflow/dags/download_data.py
[2022-02-17 04:25:01,231] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:25:01,233] {logging_mixin.py:112} INFO - [2022-02-17 04:25:01,233] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:25:01,893] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:25:01,970] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:25:01,977] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:25:01,984] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.770 seconds
[2022-02-17 04:25:14,494] {scheduler_job.py:155} INFO - Started process (PID=67781) to work on /airflow/dags/download_data.py
[2022-02-17 04:25:14,500] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:25:14,502] {logging_mixin.py:112} INFO - [2022-02-17 04:25:14,501] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:25:15,103] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:25:15,150] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:25:15,159] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:25:15,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.671 seconds
[2022-02-17 04:25:27,787] {scheduler_job.py:155} INFO - Started process (PID=67807) to work on /airflow/dags/download_data.py
[2022-02-17 04:25:27,794] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:25:27,795] {logging_mixin.py:112} INFO - [2022-02-17 04:25:27,795] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:25:28,328] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:25:28,376] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:25:28,390] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:25:28,395] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-17 04:25:41,149] {scheduler_job.py:155} INFO - Started process (PID=67835) to work on /airflow/dags/download_data.py
[2022-02-17 04:25:41,159] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:25:41,166] {logging_mixin.py:112} INFO - [2022-02-17 04:25:41,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:25:42,142] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:25:42,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:25:42,264] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:25:42,283] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.134 seconds
[2022-02-17 04:25:55,393] {scheduler_job.py:155} INFO - Started process (PID=67861) to work on /airflow/dags/download_data.py
[2022-02-17 04:25:55,408] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:25:55,413] {logging_mixin.py:112} INFO - [2022-02-17 04:25:55,412] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:25:56,099] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:25:56,163] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:25:56,176] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:25:56,182] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.789 seconds
[2022-02-17 04:26:07,688] {scheduler_job.py:155} INFO - Started process (PID=67886) to work on /airflow/dags/download_data.py
[2022-02-17 04:26:07,699] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:26:07,702] {logging_mixin.py:112} INFO - [2022-02-17 04:26:07,701] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:26:08,539] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:26:08,596] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:26:08,607] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:26:08,612] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.924 seconds
[2022-02-17 04:26:20,940] {scheduler_job.py:155} INFO - Started process (PID=67914) to work on /airflow/dags/download_data.py
[2022-02-17 04:26:20,948] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:26:20,950] {logging_mixin.py:112} INFO - [2022-02-17 04:26:20,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:26:21,620] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:26:21,669] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:26:21,680] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:26:21,687] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.747 seconds
[2022-02-17 04:26:34,241] {scheduler_job.py:155} INFO - Started process (PID=67940) to work on /airflow/dags/download_data.py
[2022-02-17 04:26:34,248] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:26:34,251] {logging_mixin.py:112} INFO - [2022-02-17 04:26:34,250] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:26:35,061] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:26:35,116] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:26:35,124] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:26:35,129] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.888 seconds
[2022-02-17 04:26:47,479] {scheduler_job.py:155} INFO - Started process (PID=67968) to work on /airflow/dags/download_data.py
[2022-02-17 04:26:47,486] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:26:47,487] {logging_mixin.py:112} INFO - [2022-02-17 04:26:47,487] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:26:48,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:26:48,097] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:26:48,108] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:26:48,115] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-17 04:27:00,802] {scheduler_job.py:155} INFO - Started process (PID=67994) to work on /airflow/dags/download_data.py
[2022-02-17 04:27:00,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:27:00,826] {logging_mixin.py:112} INFO - [2022-02-17 04:27:00,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:27:01,405] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:27:01,457] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:27:01,468] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:27:01,473] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-17 04:27:14,061] {scheduler_job.py:155} INFO - Started process (PID=68022) to work on /airflow/dags/download_data.py
[2022-02-17 04:27:14,067] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:27:14,069] {logging_mixin.py:112} INFO - [2022-02-17 04:27:14,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:27:14,613] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:27:14,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:27:14,675] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:27:14,682] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-17 04:27:27,360] {scheduler_job.py:155} INFO - Started process (PID=68048) to work on /airflow/dags/download_data.py
[2022-02-17 04:27:27,372] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:27:27,374] {logging_mixin.py:112} INFO - [2022-02-17 04:27:27,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:27:27,936] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:27:27,993] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:27:28,000] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:27:28,005] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-17 04:27:40,639] {scheduler_job.py:155} INFO - Started process (PID=68074) to work on /airflow/dags/download_data.py
[2022-02-17 04:27:40,654] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:27:40,656] {logging_mixin.py:112} INFO - [2022-02-17 04:27:40,656] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:27:41,213] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:27:41,273] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:27:41,287] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:27:41,297] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.659 seconds
[2022-02-17 04:27:53,917] {scheduler_job.py:155} INFO - Started process (PID=68102) to work on /airflow/dags/download_data.py
[2022-02-17 04:27:53,929] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:27:53,932] {logging_mixin.py:112} INFO - [2022-02-17 04:27:53,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:27:54,430] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:27:54,473] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:27:54,483] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:27:54,488] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 04:28:07,268] {scheduler_job.py:155} INFO - Started process (PID=68128) to work on /airflow/dags/download_data.py
[2022-02-17 04:28:07,284] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:28:07,289] {logging_mixin.py:112} INFO - [2022-02-17 04:28:07,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:28:07,835] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:28:07,885] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:28:07,894] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:28:07,901] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-17 04:28:20,540] {scheduler_job.py:155} INFO - Started process (PID=68156) to work on /airflow/dags/download_data.py
[2022-02-17 04:28:20,547] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:28:20,550] {logging_mixin.py:112} INFO - [2022-02-17 04:28:20,550] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:28:21,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:28:21,066] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:28:21,077] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:28:21,082] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 04:28:33,837] {scheduler_job.py:155} INFO - Started process (PID=68182) to work on /airflow/dags/download_data.py
[2022-02-17 04:28:33,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:28:33,861] {logging_mixin.py:112} INFO - [2022-02-17 04:28:33,861] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:28:34,371] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:28:34,415] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:28:34,421] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:28:34,427] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 04:28:47,103] {scheduler_job.py:155} INFO - Started process (PID=68210) to work on /airflow/dags/download_data.py
[2022-02-17 04:28:47,118] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:28:47,123] {logging_mixin.py:112} INFO - [2022-02-17 04:28:47,119] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:28:47,802] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:28:47,847] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:28:47,856] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:28:47,861] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.761 seconds
[2022-02-17 04:29:00,384] {scheduler_job.py:155} INFO - Started process (PID=68236) to work on /airflow/dags/download_data.py
[2022-02-17 04:29:00,390] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:29:00,397] {logging_mixin.py:112} INFO - [2022-02-17 04:29:00,397] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:29:00,971] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:29:01,039] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:29:01,050] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:29:01,060] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.676 seconds
[2022-02-17 04:29:13,686] {scheduler_job.py:155} INFO - Started process (PID=68262) to work on /airflow/dags/download_data.py
[2022-02-17 04:29:13,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:29:13,693] {logging_mixin.py:112} INFO - [2022-02-17 04:29:13,693] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:29:14,336] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:29:14,396] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:29:14,406] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:29:14,409] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.724 seconds
[2022-02-17 04:29:27,044] {scheduler_job.py:155} INFO - Started process (PID=68290) to work on /airflow/dags/download_data.py
[2022-02-17 04:29:27,057] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:29:27,062] {logging_mixin.py:112} INFO - [2022-02-17 04:29:27,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:29:27,882] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:29:27,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:29:27,960] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:29:27,973] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.929 seconds
[2022-02-17 04:29:40,318] {scheduler_job.py:155} INFO - Started process (PID=68316) to work on /airflow/dags/download_data.py
[2022-02-17 04:29:40,322] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:29:40,324] {logging_mixin.py:112} INFO - [2022-02-17 04:29:40,324] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:29:40,845] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:29:40,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:29:40,910] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:29:40,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 04:29:53,569] {scheduler_job.py:155} INFO - Started process (PID=68344) to work on /airflow/dags/download_data.py
[2022-02-17 04:29:53,580] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:29:53,585] {logging_mixin.py:112} INFO - [2022-02-17 04:29:53,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:29:54,135] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:29:54,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:29:54,193] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:29:54,197] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-17 04:30:06,868] {scheduler_job.py:155} INFO - Started process (PID=68370) to work on /airflow/dags/download_data.py
[2022-02-17 04:30:06,876] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:30:06,878] {logging_mixin.py:112} INFO - [2022-02-17 04:30:06,878] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:30:07,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:30:07,518] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:30:07,529] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:30:07,534] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-17 04:30:20,136] {scheduler_job.py:155} INFO - Started process (PID=68398) to work on /airflow/dags/download_data.py
[2022-02-17 04:30:20,141] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:30:20,144] {logging_mixin.py:112} INFO - [2022-02-17 04:30:20,143] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:30:20,739] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:30:20,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:30:20,817] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:30:20,824] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.688 seconds
[2022-02-17 04:30:33,434] {scheduler_job.py:155} INFO - Started process (PID=68424) to work on /airflow/dags/download_data.py
[2022-02-17 04:30:33,441] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:30:33,445] {logging_mixin.py:112} INFO - [2022-02-17 04:30:33,444] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:30:33,996] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:30:34,053] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:30:34,065] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:30:34,072] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-17 04:30:46,653] {scheduler_job.py:155} INFO - Started process (PID=68450) to work on /airflow/dags/download_data.py
[2022-02-17 04:30:46,659] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:30:46,661] {logging_mixin.py:112} INFO - [2022-02-17 04:30:46,661] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:30:47,217] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:30:47,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:30:47,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:30:47,328] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.675 seconds
[2022-02-17 04:31:00,077] {scheduler_job.py:155} INFO - Started process (PID=68478) to work on /airflow/dags/download_data.py
[2022-02-17 04:31:00,085] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:31:00,087] {logging_mixin.py:112} INFO - [2022-02-17 04:31:00,087] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:31:01,182] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:31:01,232] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:31:01,240] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:31:01,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.169 seconds
[2022-02-17 04:31:14,303] {scheduler_job.py:155} INFO - Started process (PID=68504) to work on /airflow/dags/download_data.py
[2022-02-17 04:31:14,311] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:31:14,314] {logging_mixin.py:112} INFO - [2022-02-17 04:31:14,313] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:31:14,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:31:14,849] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:31:14,860] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:31:14,864] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 04:31:26,633] {scheduler_job.py:155} INFO - Started process (PID=68531) to work on /airflow/dags/download_data.py
[2022-02-17 04:31:26,642] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:31:26,649] {logging_mixin.py:112} INFO - [2022-02-17 04:31:26,646] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:31:27,450] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:31:27,486] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:31:27,499] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:31:27,504] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.871 seconds
[2022-02-17 04:31:39,961] {scheduler_job.py:155} INFO - Started process (PID=68557) to work on /airflow/dags/download_data.py
[2022-02-17 04:31:39,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:31:39,969] {logging_mixin.py:112} INFO - [2022-02-17 04:31:39,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:31:40,453] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:31:40,497] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:31:40,507] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:31:40,512] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 04:31:53,283] {scheduler_job.py:155} INFO - Started process (PID=68585) to work on /airflow/dags/download_data.py
[2022-02-17 04:31:53,291] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:31:53,294] {logging_mixin.py:112} INFO - [2022-02-17 04:31:53,294] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:31:53,867] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:31:53,905] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:31:53,911] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:31:53,917] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.634 seconds
[2022-02-17 04:32:06,659] {scheduler_job.py:155} INFO - Started process (PID=68611) to work on /airflow/dags/download_data.py
[2022-02-17 04:32:06,665] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:32:06,673] {logging_mixin.py:112} INFO - [2022-02-17 04:32:06,673] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:32:07,200] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:32:07,291] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:32:07,301] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:32:07,311] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.652 seconds
[2022-02-17 04:32:19,901] {scheduler_job.py:155} INFO - Started process (PID=68637) to work on /airflow/dags/download_data.py
[2022-02-17 04:32:19,907] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:32:19,909] {logging_mixin.py:112} INFO - [2022-02-17 04:32:19,909] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:32:21,141] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:32:21,334] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:32:21,348] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:32:21,352] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.451 seconds
[2022-02-17 04:32:34,215] {scheduler_job.py:155} INFO - Started process (PID=68665) to work on /airflow/dags/download_data.py
[2022-02-17 04:32:34,223] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:32:34,229] {logging_mixin.py:112} INFO - [2022-02-17 04:32:34,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:32:34,865] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:32:34,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:32:34,954] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:32:34,961] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.747 seconds
[2022-02-17 04:32:46,467] {scheduler_job.py:155} INFO - Started process (PID=68690) to work on /airflow/dags/download_data.py
[2022-02-17 04:32:46,477] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:32:46,483] {logging_mixin.py:112} INFO - [2022-02-17 04:32:46,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:32:46,990] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:32:47,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:32:47,048] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:32:47,054] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 04:32:59,819] {scheduler_job.py:155} INFO - Started process (PID=68718) to work on /airflow/dags/download_data.py
[2022-02-17 04:32:59,833] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:32:59,842] {logging_mixin.py:112} INFO - [2022-02-17 04:32:59,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:33:00,343] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:33:00,389] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:33:00,395] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:33:00,399] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-17 04:33:13,094] {scheduler_job.py:155} INFO - Started process (PID=68744) to work on /airflow/dags/download_data.py
[2022-02-17 04:33:13,120] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:33:13,121] {logging_mixin.py:112} INFO - [2022-02-17 04:33:13,121] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:33:14,060] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:33:14,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:33:14,199] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:33:14,212] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.118 seconds
[2022-02-17 04:33:27,442] {scheduler_job.py:155} INFO - Started process (PID=68772) to work on /airflow/dags/download_data.py
[2022-02-17 04:33:27,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:33:27,453] {logging_mixin.py:112} INFO - [2022-02-17 04:33:27,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:33:27,959] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:33:28,021] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:33:28,031] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:33:28,038] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 04:33:39,736] {scheduler_job.py:155} INFO - Started process (PID=68797) to work on /airflow/dags/download_data.py
[2022-02-17 04:33:39,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:33:39,746] {logging_mixin.py:112} INFO - [2022-02-17 04:33:39,746] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:33:40,283] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:33:40,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:33:40,360] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:33:40,366] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-17 04:33:53,012] {scheduler_job.py:155} INFO - Started process (PID=68825) to work on /airflow/dags/download_data.py
[2022-02-17 04:33:53,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:33:53,029] {logging_mixin.py:112} INFO - [2022-02-17 04:33:53,029] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:33:53,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:33:53,620] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:33:53,626] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:33:53,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 04:34:06,324] {scheduler_job.py:155} INFO - Started process (PID=68851) to work on /airflow/dags/download_data.py
[2022-02-17 04:34:06,330] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:34:06,331] {logging_mixin.py:112} INFO - [2022-02-17 04:34:06,331] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:34:06,796] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:34:06,844] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:34:06,850] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:34:06,855] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 04:34:19,570] {scheduler_job.py:155} INFO - Started process (PID=68877) to work on /airflow/dags/download_data.py
[2022-02-17 04:34:19,575] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:34:19,577] {logging_mixin.py:112} INFO - [2022-02-17 04:34:19,577] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:34:20,078] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:34:20,135] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:34:20,147] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:34:20,151] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 04:34:32,908] {scheduler_job.py:155} INFO - Started process (PID=68905) to work on /airflow/dags/download_data.py
[2022-02-17 04:34:32,915] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:34:32,918] {logging_mixin.py:112} INFO - [2022-02-17 04:34:32,918] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:34:33,364] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:34:33,415] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:34:33,425] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:34:33,430] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 04:34:46,279] {scheduler_job.py:155} INFO - Started process (PID=68931) to work on /airflow/dags/download_data.py
[2022-02-17 04:34:46,285] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:34:46,289] {logging_mixin.py:112} INFO - [2022-02-17 04:34:46,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:34:47,135] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:34:47,225] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:34:47,238] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:34:47,252] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.973 seconds
[2022-02-17 04:34:59,631] {scheduler_job.py:155} INFO - Started process (PID=68959) to work on /airflow/dags/download_data.py
[2022-02-17 04:34:59,641] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:34:59,644] {logging_mixin.py:112} INFO - [2022-02-17 04:34:59,644] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:35:00,276] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:35:00,345] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:35:00,352] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:35:00,359] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.728 seconds
[2022-02-17 04:35:13,315] {scheduler_job.py:155} INFO - Started process (PID=68985) to work on /airflow/dags/download_data.py
[2022-02-17 04:35:13,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:35:13,326] {logging_mixin.py:112} INFO - [2022-02-17 04:35:13,326] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:35:13,826] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:35:13,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:35:13,885] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:35:13,894] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-17 04:35:26,627] {scheduler_job.py:155} INFO - Started process (PID=69013) to work on /airflow/dags/download_data.py
[2022-02-17 04:35:26,637] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:35:26,642] {logging_mixin.py:112} INFO - [2022-02-17 04:35:26,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:35:27,159] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:35:27,208] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:35:27,221] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:35:27,229] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 04:35:39,953] {scheduler_job.py:155} INFO - Started process (PID=69039) to work on /airflow/dags/download_data.py
[2022-02-17 04:35:39,960] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:35:39,962] {logging_mixin.py:112} INFO - [2022-02-17 04:35:39,962] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:35:40,783] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:35:40,865] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:35:40,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:35:40,907] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.954 seconds
[2022-02-17 04:35:53,208] {scheduler_job.py:155} INFO - Started process (PID=69065) to work on /airflow/dags/download_data.py
[2022-02-17 04:35:53,216] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:35:53,219] {logging_mixin.py:112} INFO - [2022-02-17 04:35:53,218] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:35:53,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:35:53,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:35:53,853] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:35:53,858] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.651 seconds
[2022-02-17 04:36:06,662] {scheduler_job.py:155} INFO - Started process (PID=69093) to work on /airflow/dags/download_data.py
[2022-02-17 04:36:06,673] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:36:06,675] {logging_mixin.py:112} INFO - [2022-02-17 04:36:06,675] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:36:07,171] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:36:07,209] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:36:07,222] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:36:07,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 04:36:19,946] {scheduler_job.py:155} INFO - Started process (PID=69119) to work on /airflow/dags/download_data.py
[2022-02-17 04:36:19,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:36:19,962] {logging_mixin.py:112} INFO - [2022-02-17 04:36:19,962] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:36:20,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:36:20,450] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:36:20,457] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:36:20,463] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 04:36:33,233] {scheduler_job.py:155} INFO - Started process (PID=69147) to work on /airflow/dags/download_data.py
[2022-02-17 04:36:33,243] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:36:33,248] {logging_mixin.py:112} INFO - [2022-02-17 04:36:33,248] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:36:33,730] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:36:33,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:36:33,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:36:33,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 04:36:46,977] {scheduler_job.py:155} INFO - Started process (PID=69173) to work on /airflow/dags/download_data.py
[2022-02-17 04:36:46,985] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:36:46,987] {logging_mixin.py:112} INFO - [2022-02-17 04:36:46,986] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:36:47,491] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:36:47,533] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:36:47,541] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:36:47,545] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 04:37:00,283] {scheduler_job.py:155} INFO - Started process (PID=69201) to work on /airflow/dags/download_data.py
[2022-02-17 04:37:00,293] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:37:00,295] {logging_mixin.py:112} INFO - [2022-02-17 04:37:00,295] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:37:01,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:37:01,083] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:37:01,091] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:37:01,099] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.819 seconds
[2022-02-17 04:37:13,558] {scheduler_job.py:155} INFO - Started process (PID=69227) to work on /airflow/dags/download_data.py
[2022-02-17 04:37:13,563] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:37:13,565] {logging_mixin.py:112} INFO - [2022-02-17 04:37:13,565] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:37:14,164] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:37:14,228] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:37:14,245] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:37:14,250] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.692 seconds
[2022-02-17 04:37:26,830] {scheduler_job.py:155} INFO - Started process (PID=69253) to work on /airflow/dags/download_data.py
[2022-02-17 04:37:26,834] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:37:26,837] {logging_mixin.py:112} INFO - [2022-02-17 04:37:26,837] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:37:27,436] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:37:27,510] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:37:27,520] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:37:27,526] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.696 seconds
[2022-02-17 04:37:40,167] {scheduler_job.py:155} INFO - Started process (PID=69281) to work on /airflow/dags/download_data.py
[2022-02-17 04:37:40,173] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:37:40,175] {logging_mixin.py:112} INFO - [2022-02-17 04:37:40,174] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:37:40,646] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:37:40,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:37:40,707] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:37:40,712] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 04:37:53,416] {scheduler_job.py:155} INFO - Started process (PID=69307) to work on /airflow/dags/download_data.py
[2022-02-17 04:37:53,421] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:37:53,423] {logging_mixin.py:112} INFO - [2022-02-17 04:37:53,423] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:37:53,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:37:53,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:37:53,943] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:37:53,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 04:38:06,753] {scheduler_job.py:155} INFO - Started process (PID=69335) to work on /airflow/dags/download_data.py
[2022-02-17 04:38:06,758] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:38:06,760] {logging_mixin.py:112} INFO - [2022-02-17 04:38:06,760] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:38:07,242] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:38:07,309] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:38:07,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:38:07,322] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 04:38:20,008] {scheduler_job.py:155} INFO - Started process (PID=69361) to work on /airflow/dags/download_data.py
[2022-02-17 04:38:20,013] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:38:20,017] {logging_mixin.py:112} INFO - [2022-02-17 04:38:20,017] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:38:20,470] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:38:20,524] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:38:20,534] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:38:20,540] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 04:38:33,349] {scheduler_job.py:155} INFO - Started process (PID=69389) to work on /airflow/dags/download_data.py
[2022-02-17 04:38:33,355] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:38:33,357] {logging_mixin.py:112} INFO - [2022-02-17 04:38:33,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:38:33,878] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:38:33,968] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:38:33,978] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:38:33,986] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-17 04:38:46,623] {scheduler_job.py:155} INFO - Started process (PID=69415) to work on /airflow/dags/download_data.py
[2022-02-17 04:38:46,627] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:38:46,630] {logging_mixin.py:112} INFO - [2022-02-17 04:38:46,630] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:38:47,117] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:38:47,169] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:38:47,180] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:38:47,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 04:38:59,954] {scheduler_job.py:155} INFO - Started process (PID=69443) to work on /airflow/dags/download_data.py
[2022-02-17 04:38:59,971] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:38:59,973] {logging_mixin.py:112} INFO - [2022-02-17 04:38:59,973] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:39:00,563] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:39:00,634] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:39:00,643] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:39:00,653] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.701 seconds
[2022-02-17 04:39:13,228] {scheduler_job.py:155} INFO - Started process (PID=69469) to work on /airflow/dags/download_data.py
[2022-02-17 04:39:13,240] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:39:13,243] {logging_mixin.py:112} INFO - [2022-02-17 04:39:13,242] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:39:13,756] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:39:13,810] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:39:13,821] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:39:13,827] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-17 04:39:26,506] {scheduler_job.py:155} INFO - Started process (PID=69495) to work on /airflow/dags/download_data.py
[2022-02-17 04:39:26,513] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:39:26,515] {logging_mixin.py:112} INFO - [2022-02-17 04:39:26,515] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:39:26,997] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:39:27,056] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:39:27,069] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:39:27,074] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 04:39:39,820] {scheduler_job.py:155} INFO - Started process (PID=69523) to work on /airflow/dags/download_data.py
[2022-02-17 04:39:39,827] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:39:39,830] {logging_mixin.py:112} INFO - [2022-02-17 04:39:39,829] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:39:40,301] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:39:40,357] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:39:40,366] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:39:40,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 04:39:53,187] {scheduler_job.py:155} INFO - Started process (PID=69549) to work on /airflow/dags/download_data.py
[2022-02-17 04:39:53,193] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:39:53,195] {logging_mixin.py:112} INFO - [2022-02-17 04:39:53,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:39:53,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:39:53,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:39:53,860] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:39:53,865] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.678 seconds
[2022-02-17 04:40:06,547] {scheduler_job.py:155} INFO - Started process (PID=69577) to work on /airflow/dags/download_data.py
[2022-02-17 04:40:06,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:40:06,556] {logging_mixin.py:112} INFO - [2022-02-17 04:40:06,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:40:07,125] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:40:07,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:40:07,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:40:07,220] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.673 seconds
[2022-02-17 04:40:19,813] {scheduler_job.py:155} INFO - Started process (PID=69603) to work on /airflow/dags/download_data.py
[2022-02-17 04:40:19,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:40:19,821] {logging_mixin.py:112} INFO - [2022-02-17 04:40:19,820] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:40:20,355] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:40:20,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:40:20,415] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:40:20,422] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-17 04:40:33,147] {scheduler_job.py:155} INFO - Started process (PID=69631) to work on /airflow/dags/download_data.py
[2022-02-17 04:40:33,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:40:33,153] {logging_mixin.py:112} INFO - [2022-02-17 04:40:33,152] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:40:33,607] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:40:33,647] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:40:33,654] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:40:33,659] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 04:40:46,394] {scheduler_job.py:155} INFO - Started process (PID=69657) to work on /airflow/dags/download_data.py
[2022-02-17 04:40:46,401] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:40:46,404] {logging_mixin.py:112} INFO - [2022-02-17 04:40:46,403] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:40:47,071] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:40:47,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:40:47,137] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:40:47,143] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.749 seconds
[2022-02-17 04:40:59,668] {scheduler_job.py:155} INFO - Started process (PID=69683) to work on /airflow/dags/download_data.py
[2022-02-17 04:40:59,673] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:40:59,674] {logging_mixin.py:112} INFO - [2022-02-17 04:40:59,674] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:41:00,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:41:00,231] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:41:00,242] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:41:00,248] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 04:41:12,936] {scheduler_job.py:155} INFO - Started process (PID=69711) to work on /airflow/dags/download_data.py
[2022-02-17 04:41:12,940] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:41:12,942] {logging_mixin.py:112} INFO - [2022-02-17 04:41:12,941] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:41:13,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:41:13,512] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:41:13,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:41:13,527] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 04:41:26,228] {scheduler_job.py:155} INFO - Started process (PID=69737) to work on /airflow/dags/download_data.py
[2022-02-17 04:41:26,234] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:41:26,237] {logging_mixin.py:112} INFO - [2022-02-17 04:41:26,237] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:41:27,064] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:41:27,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:41:27,139] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:41:27,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.916 seconds
[2022-02-17 04:41:39,679] {scheduler_job.py:155} INFO - Started process (PID=69765) to work on /airflow/dags/download_data.py
[2022-02-17 04:41:39,687] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:41:39,690] {logging_mixin.py:112} INFO - [2022-02-17 04:41:39,689] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:41:40,388] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:41:40,447] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:41:40,457] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:41:40,463] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.785 seconds
[2022-02-17 04:41:52,945] {scheduler_job.py:155} INFO - Started process (PID=69791) to work on /airflow/dags/download_data.py
[2022-02-17 04:41:52,951] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:41:52,952] {logging_mixin.py:112} INFO - [2022-02-17 04:41:52,952] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:41:53,447] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:41:53,495] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:41:53,502] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:41:53,508] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 04:42:06,271] {scheduler_job.py:155} INFO - Started process (PID=69819) to work on /airflow/dags/download_data.py
[2022-02-17 04:42:06,280] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:42:06,285] {logging_mixin.py:112} INFO - [2022-02-17 04:42:06,285] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:42:06,835] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:42:06,884] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:42:06,892] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:42:06,897] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-17 04:42:19,544] {scheduler_job.py:155} INFO - Started process (PID=69845) to work on /airflow/dags/download_data.py
[2022-02-17 04:42:19,548] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:42:19,549] {logging_mixin.py:112} INFO - [2022-02-17 04:42:19,549] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:42:20,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:42:20,220] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:42:20,231] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:42:20,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.702 seconds
[2022-02-17 04:42:32,821] {scheduler_job.py:155} INFO - Started process (PID=69871) to work on /airflow/dags/download_data.py
[2022-02-17 04:42:32,826] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:42:32,827] {logging_mixin.py:112} INFO - [2022-02-17 04:42:32,827] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:42:33,268] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:42:33,312] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:42:33,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:42:33,322] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 04:42:46,094] {scheduler_job.py:155} INFO - Started process (PID=69899) to work on /airflow/dags/download_data.py
[2022-02-17 04:42:46,102] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:42:46,105] {logging_mixin.py:112} INFO - [2022-02-17 04:42:46,105] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:42:46,608] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:42:46,664] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:42:46,677] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:42:46,683] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 04:42:59,517] {scheduler_job.py:155} INFO - Started process (PID=69925) to work on /airflow/dags/download_data.py
[2022-02-17 04:42:59,528] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:42:59,530] {logging_mixin.py:112} INFO - [2022-02-17 04:42:59,530] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:43:00,572] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:43:00,693] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:43:00,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:43:00,719] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.202 seconds
[2022-02-17 04:43:13,893] {scheduler_job.py:155} INFO - Started process (PID=69953) to work on /airflow/dags/download_data.py
[2022-02-17 04:43:13,898] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:43:13,899] {logging_mixin.py:112} INFO - [2022-02-17 04:43:13,899] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:43:14,415] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:43:14,459] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:43:14,469] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:43:14,473] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-17 04:43:26,212] {scheduler_job.py:155} INFO - Started process (PID=69978) to work on /airflow/dags/download_data.py
[2022-02-17 04:43:26,217] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:43:26,223] {logging_mixin.py:112} INFO - [2022-02-17 04:43:26,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:43:26,814] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:43:26,870] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:43:26,881] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:43:26,889] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.678 seconds
[2022-02-17 04:43:39,518] {scheduler_job.py:155} INFO - Started process (PID=70006) to work on /airflow/dags/download_data.py
[2022-02-17 04:43:39,524] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:43:39,526] {logging_mixin.py:112} INFO - [2022-02-17 04:43:39,526] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:43:40,005] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:43:40,067] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:43:40,077] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:43:40,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 04:43:52,803] {scheduler_job.py:155} INFO - Started process (PID=70032) to work on /airflow/dags/download_data.py
[2022-02-17 04:43:52,812] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:43:52,816] {logging_mixin.py:112} INFO - [2022-02-17 04:43:52,816] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:43:53,288] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:43:53,341] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:43:53,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:43:53,358] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 04:44:06,126] {scheduler_job.py:155} INFO - Started process (PID=70060) to work on /airflow/dags/download_data.py
[2022-02-17 04:44:06,135] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:44:06,138] {logging_mixin.py:112} INFO - [2022-02-17 04:44:06,137] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:44:06,671] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:44:06,727] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:44:06,743] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:44:06,749] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-17 04:44:19,346] {scheduler_job.py:155} INFO - Started process (PID=70086) to work on /airflow/dags/download_data.py
[2022-02-17 04:44:19,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:44:19,351] {logging_mixin.py:112} INFO - [2022-02-17 04:44:19,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:44:19,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:44:19,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:44:19,854] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:44:19,858] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 04:44:32,698] {scheduler_job.py:155} INFO - Started process (PID=70112) to work on /airflow/dags/download_data.py
[2022-02-17 04:44:32,708] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:44:32,710] {logging_mixin.py:112} INFO - [2022-02-17 04:44:32,710] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:44:33,190] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:44:33,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:44:33,252] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:44:33,260] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 04:44:45,932] {scheduler_job.py:155} INFO - Started process (PID=70140) to work on /airflow/dags/download_data.py
[2022-02-17 04:44:45,937] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:44:45,939] {logging_mixin.py:112} INFO - [2022-02-17 04:44:45,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:44:46,422] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:44:46,470] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:44:46,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:44:46,488] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 04:44:59,202] {scheduler_job.py:155} INFO - Started process (PID=70166) to work on /airflow/dags/download_data.py
[2022-02-17 04:44:59,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:44:59,208] {logging_mixin.py:112} INFO - [2022-02-17 04:44:59,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:44:59,680] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:44:59,731] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:44:59,740] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:44:59,747] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 04:45:12,424] {scheduler_job.py:155} INFO - Started process (PID=70194) to work on /airflow/dags/download_data.py
[2022-02-17 04:45:12,429] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:45:12,431] {logging_mixin.py:112} INFO - [2022-02-17 04:45:12,430] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:45:12,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:45:12,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:45:12,964] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:45:12,969] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 04:45:25,713] {scheduler_job.py:155} INFO - Started process (PID=70220) to work on /airflow/dags/download_data.py
[2022-02-17 04:45:25,719] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:45:25,720] {logging_mixin.py:112} INFO - [2022-02-17 04:45:25,720] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:45:26,222] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:45:26,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:45:26,282] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:45:26,287] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 04:45:38,971] {scheduler_job.py:155} INFO - Started process (PID=70248) to work on /airflow/dags/download_data.py
[2022-02-17 04:45:38,978] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:45:38,980] {logging_mixin.py:112} INFO - [2022-02-17 04:45:38,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:45:39,425] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:45:39,473] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:45:39,483] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:45:39,488] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 04:45:52,241] {scheduler_job.py:155} INFO - Started process (PID=70274) to work on /airflow/dags/download_data.py
[2022-02-17 04:45:52,247] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:45:52,252] {logging_mixin.py:112} INFO - [2022-02-17 04:45:52,251] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:45:53,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:45:53,110] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:45:53,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:45:53,126] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.885 seconds
[2022-02-17 04:46:05,546] {scheduler_job.py:155} INFO - Started process (PID=70300) to work on /airflow/dags/download_data.py
[2022-02-17 04:46:05,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:46:05,559] {logging_mixin.py:112} INFO - [2022-02-17 04:46:05,558] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:46:06,048] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:46:06,107] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:46:06,116] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:46:06,122] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-17 04:46:18,894] {scheduler_job.py:155} INFO - Started process (PID=70328) to work on /airflow/dags/download_data.py
[2022-02-17 04:46:18,899] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:46:18,901] {logging_mixin.py:112} INFO - [2022-02-17 04:46:18,901] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:46:19,635] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:46:19,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:46:19,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:46:19,702] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.808 seconds
[2022-02-17 04:46:32,192] {scheduler_job.py:155} INFO - Started process (PID=70354) to work on /airflow/dags/download_data.py
[2022-02-17 04:46:32,196] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:46:32,198] {logging_mixin.py:112} INFO - [2022-02-17 04:46:32,198] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:46:32,658] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:46:32,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:46:32,710] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:46:32,717] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 04:46:45,457] {scheduler_job.py:155} INFO - Started process (PID=70382) to work on /airflow/dags/download_data.py
[2022-02-17 04:46:45,464] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:46:45,466] {logging_mixin.py:112} INFO - [2022-02-17 04:46:45,466] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:46:45,915] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:46:45,967] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:46:45,974] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:46:45,979] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 04:46:58,733] {scheduler_job.py:155} INFO - Started process (PID=70408) to work on /airflow/dags/download_data.py
[2022-02-17 04:46:58,740] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:46:58,742] {logging_mixin.py:112} INFO - [2022-02-17 04:46:58,742] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:46:59,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:46:59,258] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:46:59,265] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:46:59,269] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 04:47:12,030] {scheduler_job.py:155} INFO - Started process (PID=70436) to work on /airflow/dags/download_data.py
[2022-02-17 04:47:12,040] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:47:12,046] {logging_mixin.py:112} INFO - [2022-02-17 04:47:12,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:47:12,714] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:47:12,776] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:47:12,787] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:47:12,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.762 seconds
[2022-02-17 04:47:25,378] {scheduler_job.py:155} INFO - Started process (PID=70462) to work on /airflow/dags/download_data.py
[2022-02-17 04:47:25,386] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:47:25,388] {logging_mixin.py:112} INFO - [2022-02-17 04:47:25,388] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:47:25,888] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:47:25,939] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:47:25,947] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:47:25,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-17 04:47:38,650] {scheduler_job.py:155} INFO - Started process (PID=70488) to work on /airflow/dags/download_data.py
[2022-02-17 04:47:38,658] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:47:38,662] {logging_mixin.py:112} INFO - [2022-02-17 04:47:38,662] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:47:39,172] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:47:39,225] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:47:39,245] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:47:39,253] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 04:47:51,915] {scheduler_job.py:155} INFO - Started process (PID=70516) to work on /airflow/dags/download_data.py
[2022-02-17 04:47:51,921] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:47:51,923] {logging_mixin.py:112} INFO - [2022-02-17 04:47:51,923] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:47:52,450] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:47:52,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:47:52,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:47:52,517] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 04:48:05,234] {scheduler_job.py:155} INFO - Started process (PID=70542) to work on /airflow/dags/download_data.py
[2022-02-17 04:48:05,247] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:48:05,249] {logging_mixin.py:112} INFO - [2022-02-17 04:48:05,249] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:48:05,713] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:48:05,764] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:48:05,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:48:05,780] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 04:48:18,442] {scheduler_job.py:155} INFO - Started process (PID=70570) to work on /airflow/dags/download_data.py
[2022-02-17 04:48:18,448] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:48:18,449] {logging_mixin.py:112} INFO - [2022-02-17 04:48:18,449] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:48:18,944] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:48:18,994] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:48:19,004] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:48:19,013] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 04:48:31,716] {scheduler_job.py:155} INFO - Started process (PID=70596) to work on /airflow/dags/download_data.py
[2022-02-17 04:48:31,724] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:48:31,731] {logging_mixin.py:112} INFO - [2022-02-17 04:48:31,731] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:48:32,216] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:48:32,270] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:48:32,278] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:48:32,287] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 04:48:44,946] {scheduler_job.py:155} INFO - Started process (PID=70624) to work on /airflow/dags/download_data.py
[2022-02-17 04:48:44,952] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:48:44,957] {logging_mixin.py:112} INFO - [2022-02-17 04:48:44,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:48:45,486] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:48:45,544] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:48:45,555] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:48:45,559] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-17 04:48:58,248] {scheduler_job.py:155} INFO - Started process (PID=70650) to work on /airflow/dags/download_data.py
[2022-02-17 04:48:58,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:48:58,257] {logging_mixin.py:112} INFO - [2022-02-17 04:48:58,257] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:48:58,812] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:48:58,882] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:48:58,891] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:48:58,900] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.653 seconds
[2022-02-17 04:49:11,573] {scheduler_job.py:155} INFO - Started process (PID=70677) to work on /airflow/dags/download_data.py
[2022-02-17 04:49:11,581] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:49:11,583] {logging_mixin.py:112} INFO - [2022-02-17 04:49:11,583] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:49:12,276] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:49:12,335] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:49:12,347] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:49:12,351] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.778 seconds
[2022-02-17 04:49:24,947] {scheduler_job.py:155} INFO - Started process (PID=70704) to work on /airflow/dags/download_data.py
[2022-02-17 04:49:24,956] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:49:24,958] {logging_mixin.py:112} INFO - [2022-02-17 04:49:24,958] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:49:25,638] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:49:25,702] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:49:25,717] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:49:25,725] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.778 seconds
[2022-02-17 04:49:38,400] {scheduler_job.py:155} INFO - Started process (PID=70730) to work on /airflow/dags/download_data.py
[2022-02-17 04:49:38,415] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:49:38,417] {logging_mixin.py:112} INFO - [2022-02-17 04:49:38,417] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:49:39,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:49:39,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:49:39,419] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:49:39,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.024 seconds
[2022-02-17 04:49:52,612] {scheduler_job.py:155} INFO - Started process (PID=70758) to work on /airflow/dags/download_data.py
[2022-02-17 04:49:52,621] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:49:52,625] {logging_mixin.py:112} INFO - [2022-02-17 04:49:52,624] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:49:53,134] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:49:53,181] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:49:53,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:49:53,197] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 04:50:04,905] {scheduler_job.py:155} INFO - Started process (PID=70783) to work on /airflow/dags/download_data.py
[2022-02-17 04:50:04,911] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:50:04,913] {logging_mixin.py:112} INFO - [2022-02-17 04:50:04,912] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:50:05,451] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:50:05,508] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:50:05,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:50:05,520] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-17 04:50:18,318] {scheduler_job.py:155} INFO - Started process (PID=70811) to work on /airflow/dags/download_data.py
[2022-02-17 04:50:18,324] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:50:18,325] {logging_mixin.py:112} INFO - [2022-02-17 04:50:18,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:50:18,822] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:50:18,859] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:50:18,864] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:50:18,868] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 04:50:31,726] {scheduler_job.py:155} INFO - Started process (PID=70837) to work on /airflow/dags/download_data.py
[2022-02-17 04:50:31,738] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:50:31,741] {logging_mixin.py:112} INFO - [2022-02-17 04:50:31,740] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:50:32,279] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:50:32,328] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:50:32,338] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:50:32,341] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-17 04:50:44,963] {scheduler_job.py:155} INFO - Started process (PID=70865) to work on /airflow/dags/download_data.py
[2022-02-17 04:50:44,973] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:50:44,980] {logging_mixin.py:112} INFO - [2022-02-17 04:50:44,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:50:45,511] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:50:45,570] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:50:45,580] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:50:45,585] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-17 04:50:58,252] {scheduler_job.py:155} INFO - Started process (PID=70891) to work on /airflow/dags/download_data.py
[2022-02-17 04:50:58,256] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:50:58,258] {logging_mixin.py:112} INFO - [2022-02-17 04:50:58,258] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:50:58,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:50:58,834] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:50:58,846] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:50:58,852] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 04:51:11,550] {scheduler_job.py:155} INFO - Started process (PID=70917) to work on /airflow/dags/download_data.py
[2022-02-17 04:51:11,560] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:51:11,563] {logging_mixin.py:112} INFO - [2022-02-17 04:51:11,562] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:51:12,088] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:51:12,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:51:12,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:51:12,168] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 04:51:24,854] {scheduler_job.py:155} INFO - Started process (PID=70945) to work on /airflow/dags/download_data.py
[2022-02-17 04:51:24,858] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:51:24,860] {logging_mixin.py:112} INFO - [2022-02-17 04:51:24,859] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:51:25,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:51:25,395] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:51:25,403] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:51:25,406] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 04:51:38,157] {scheduler_job.py:155} INFO - Started process (PID=70971) to work on /airflow/dags/download_data.py
[2022-02-17 04:51:38,165] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:51:38,167] {logging_mixin.py:112} INFO - [2022-02-17 04:51:38,167] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:51:38,664] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:51:38,718] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:51:38,730] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:51:38,735] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-17 04:51:51,397] {scheduler_job.py:155} INFO - Started process (PID=70999) to work on /airflow/dags/download_data.py
[2022-02-17 04:51:51,401] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:51:51,404] {logging_mixin.py:112} INFO - [2022-02-17 04:51:51,403] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:51:51,872] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:51:51,919] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:51:51,926] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:51:51,930] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 04:52:04,729] {scheduler_job.py:155} INFO - Started process (PID=71025) to work on /airflow/dags/download_data.py
[2022-02-17 04:52:04,739] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:52:04,759] {logging_mixin.py:112} INFO - [2022-02-17 04:52:04,759] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:52:05,502] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:52:05,559] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:52:05,568] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:52:05,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.850 seconds
[2022-02-17 04:52:17,958] {scheduler_job.py:155} INFO - Started process (PID=71053) to work on /airflow/dags/download_data.py
[2022-02-17 04:52:17,962] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:52:17,964] {logging_mixin.py:112} INFO - [2022-02-17 04:52:17,964] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:52:18,435] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:52:18,486] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:52:18,493] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:52:18,500] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 04:52:31,247] {scheduler_job.py:155} INFO - Started process (PID=71079) to work on /airflow/dags/download_data.py
[2022-02-17 04:52:31,254] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:52:31,258] {logging_mixin.py:112} INFO - [2022-02-17 04:52:31,258] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:52:31,814] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:52:31,880] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:52:31,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:52:31,902] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.655 seconds
[2022-02-17 04:52:44,474] {scheduler_job.py:155} INFO - Started process (PID=71105) to work on /airflow/dags/download_data.py
[2022-02-17 04:52:44,484] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:52:44,486] {logging_mixin.py:112} INFO - [2022-02-17 04:52:44,486] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:52:45,045] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:52:45,099] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:52:45,112] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:52:45,117] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-17 04:52:57,783] {scheduler_job.py:155} INFO - Started process (PID=71133) to work on /airflow/dags/download_data.py
[2022-02-17 04:52:57,790] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:52:57,792] {logging_mixin.py:112} INFO - [2022-02-17 04:52:57,792] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:52:58,529] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:52:58,581] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:52:58,594] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:52:58,598] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.815 seconds
[2022-02-17 04:53:11,079] {scheduler_job.py:155} INFO - Started process (PID=71159) to work on /airflow/dags/download_data.py
[2022-02-17 04:53:11,087] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:53:11,089] {logging_mixin.py:112} INFO - [2022-02-17 04:53:11,089] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:53:11,583] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:53:11,640] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:53:11,652] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:53:11,660] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 04:53:24,362] {scheduler_job.py:155} INFO - Started process (PID=71187) to work on /airflow/dags/download_data.py
[2022-02-17 04:53:24,368] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:53:24,371] {logging_mixin.py:112} INFO - [2022-02-17 04:53:24,370] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:53:24,983] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:53:25,037] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:53:25,047] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:53:25,053] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.691 seconds
[2022-02-17 04:53:37,654] {scheduler_job.py:155} INFO - Started process (PID=71213) to work on /airflow/dags/download_data.py
[2022-02-17 04:53:37,658] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:53:37,660] {logging_mixin.py:112} INFO - [2022-02-17 04:53:37,659] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:53:38,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:53:38,242] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:53:38,253] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:53:38,260] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 04:53:51,018] {scheduler_job.py:155} INFO - Started process (PID=71241) to work on /airflow/dags/download_data.py
[2022-02-17 04:53:51,028] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:53:51,030] {logging_mixin.py:112} INFO - [2022-02-17 04:53:51,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:53:51,637] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:53:51,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:53:51,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:53:51,705] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.687 seconds
[2022-02-17 04:54:04,320] {scheduler_job.py:155} INFO - Started process (PID=71267) to work on /airflow/dags/download_data.py
[2022-02-17 04:54:04,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:54:04,328] {logging_mixin.py:112} INFO - [2022-02-17 04:54:04,328] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:54:04,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:54:04,871] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:54:04,881] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:54:04,885] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 04:54:17,589] {scheduler_job.py:155} INFO - Started process (PID=71293) to work on /airflow/dags/download_data.py
[2022-02-17 04:54:17,596] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:54:17,600] {logging_mixin.py:112} INFO - [2022-02-17 04:54:17,599] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:54:18,172] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:54:18,223] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:54:18,233] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:54:18,238] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.649 seconds
[2022-02-17 04:54:30,973] {scheduler_job.py:155} INFO - Started process (PID=71321) to work on /airflow/dags/download_data.py
[2022-02-17 04:54:30,982] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:54:30,988] {logging_mixin.py:112} INFO - [2022-02-17 04:54:30,988] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:54:31,595] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:54:31,661] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:54:31,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:54:31,689] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.716 seconds
[2022-02-17 04:54:44,241] {scheduler_job.py:155} INFO - Started process (PID=71347) to work on /airflow/dags/download_data.py
[2022-02-17 04:54:44,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:54:44,262] {logging_mixin.py:112} INFO - [2022-02-17 04:54:44,260] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:54:45,022] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:54:45,126] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:54:45,135] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:54:45,140] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.899 seconds
[2022-02-17 04:54:57,989] {scheduler_job.py:155} INFO - Started process (PID=71375) to work on /airflow/dags/download_data.py
[2022-02-17 04:54:58,007] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:54:58,049] {logging_mixin.py:112} INFO - [2022-02-17 04:54:58,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:54:58,896] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:54:58,999] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:54:59,010] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:54:59,015] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.027 seconds
[2022-02-17 04:55:12,163] {scheduler_job.py:155} INFO - Started process (PID=71401) to work on /airflow/dags/download_data.py
[2022-02-17 04:55:12,170] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:55:12,173] {logging_mixin.py:112} INFO - [2022-02-17 04:55:12,173] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:55:12,742] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:55:12,796] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:55:12,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:55:12,813] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.649 seconds
[2022-02-17 04:55:24,417] {scheduler_job.py:155} INFO - Started process (PID=71428) to work on /airflow/dags/download_data.py
[2022-02-17 04:55:24,422] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:55:24,424] {logging_mixin.py:112} INFO - [2022-02-17 04:55:24,424] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:55:24,976] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:55:25,115] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:55:25,135] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:55:25,142] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.725 seconds
[2022-02-17 04:55:37,741] {scheduler_job.py:155} INFO - Started process (PID=71454) to work on /airflow/dags/download_data.py
[2022-02-17 04:55:37,752] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:55:37,757] {logging_mixin.py:112} INFO - [2022-02-17 04:55:37,756] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:55:38,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:55:38,687] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:55:38,708] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:55:38,715] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.974 seconds
[2022-02-17 04:55:51,042] {scheduler_job.py:155} INFO - Started process (PID=71482) to work on /airflow/dags/download_data.py
[2022-02-17 04:55:51,053] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:55:51,055] {logging_mixin.py:112} INFO - [2022-02-17 04:55:51,054] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:55:51,614] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:55:51,678] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:55:51,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:55:51,700] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.659 seconds
[2022-02-17 04:56:04,330] {scheduler_job.py:155} INFO - Started process (PID=71508) to work on /airflow/dags/download_data.py
[2022-02-17 04:56:04,345] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:56:04,350] {logging_mixin.py:112} INFO - [2022-02-17 04:56:04,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:56:04,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:56:04,868] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:56:04,878] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:56:04,883] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 04:56:17,582] {scheduler_job.py:155} INFO - Started process (PID=71534) to work on /airflow/dags/download_data.py
[2022-02-17 04:56:17,591] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:56:17,599] {logging_mixin.py:112} INFO - [2022-02-17 04:56:17,599] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:56:18,150] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:56:18,210] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:56:18,219] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:56:18,226] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-17 04:56:30,862] {scheduler_job.py:155} INFO - Started process (PID=71562) to work on /airflow/dags/download_data.py
[2022-02-17 04:56:30,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:56:30,870] {logging_mixin.py:112} INFO - [2022-02-17 04:56:30,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:56:31,521] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:56:31,580] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:56:31,600] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:56:31,605] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.743 seconds
[2022-02-17 04:56:44,149] {scheduler_job.py:155} INFO - Started process (PID=71588) to work on /airflow/dags/download_data.py
[2022-02-17 04:56:44,162] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:56:44,166] {logging_mixin.py:112} INFO - [2022-02-17 04:56:44,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:56:44,671] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:56:44,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:56:44,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:56:44,731] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 04:56:57,467] {scheduler_job.py:155} INFO - Started process (PID=71616) to work on /airflow/dags/download_data.py
[2022-02-17 04:56:57,492] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:56:57,507] {logging_mixin.py:112} INFO - [2022-02-17 04:56:57,507] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:56:58,313] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:56:58,360] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:56:58,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:56:58,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.907 seconds
[2022-02-17 04:57:10,702] {scheduler_job.py:155} INFO - Started process (PID=71642) to work on /airflow/dags/download_data.py
[2022-02-17 04:57:10,711] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:57:10,713] {logging_mixin.py:112} INFO - [2022-02-17 04:57:10,713] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:57:11,221] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:57:11,279] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:57:11,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:57:11,296] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 04:57:24,047] {scheduler_job.py:155} INFO - Started process (PID=71670) to work on /airflow/dags/download_data.py
[2022-02-17 04:57:24,063] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:57:24,065] {logging_mixin.py:112} INFO - [2022-02-17 04:57:24,065] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:57:24,619] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:57:24,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:57:24,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:57:24,689] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-17 04:57:37,338] {scheduler_job.py:155} INFO - Started process (PID=71696) to work on /airflow/dags/download_data.py
[2022-02-17 04:57:37,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:57:37,361] {logging_mixin.py:112} INFO - [2022-02-17 04:57:37,361] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:57:37,888] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:57:37,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:57:37,952] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:57:37,960] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-17 04:57:50,601] {scheduler_job.py:155} INFO - Started process (PID=71722) to work on /airflow/dags/download_data.py
[2022-02-17 04:57:50,606] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:57:50,607] {logging_mixin.py:112} INFO - [2022-02-17 04:57:50,607] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:57:51,090] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:57:51,148] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:57:51,157] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:57:51,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 04:58:03,923] {scheduler_job.py:155} INFO - Started process (PID=71750) to work on /airflow/dags/download_data.py
[2022-02-17 04:58:03,931] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:58:03,932] {logging_mixin.py:112} INFO - [2022-02-17 04:58:03,932] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:58:04,444] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:58:04,501] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:58:04,512] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:58:04,517] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 04:58:17,215] {scheduler_job.py:155} INFO - Started process (PID=71776) to work on /airflow/dags/download_data.py
[2022-02-17 04:58:17,224] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:58:17,226] {logging_mixin.py:112} INFO - [2022-02-17 04:58:17,226] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:58:17,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:58:17,798] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:58:17,809] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:58:17,816] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-17 04:58:30,508] {scheduler_job.py:155} INFO - Started process (PID=71804) to work on /airflow/dags/download_data.py
[2022-02-17 04:58:30,512] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:58:30,514] {logging_mixin.py:112} INFO - [2022-02-17 04:58:30,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:58:30,985] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:58:31,039] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:58:31,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:58:31,050] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 04:58:43,768] {scheduler_job.py:155} INFO - Started process (PID=71830) to work on /airflow/dags/download_data.py
[2022-02-17 04:58:43,777] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:58:43,779] {logging_mixin.py:112} INFO - [2022-02-17 04:58:43,779] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:58:44,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:58:44,328] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:58:44,342] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:58:44,350] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 04:58:57,163] {scheduler_job.py:155} INFO - Started process (PID=71858) to work on /airflow/dags/download_data.py
[2022-02-17 04:58:57,172] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:58:57,175] {logging_mixin.py:112} INFO - [2022-02-17 04:58:57,173] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:58:57,853] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:58:57,901] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:58:57,908] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:58:57,912] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.749 seconds
[2022-02-17 04:59:10,512] {scheduler_job.py:155} INFO - Started process (PID=71884) to work on /airflow/dags/download_data.py
[2022-02-17 04:59:10,523] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:59:10,526] {logging_mixin.py:112} INFO - [2022-02-17 04:59:10,526] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:59:11,093] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:59:11,158] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:59:11,165] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:59:11,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.659 seconds
[2022-02-17 04:59:23,807] {scheduler_job.py:155} INFO - Started process (PID=71910) to work on /airflow/dags/download_data.py
[2022-02-17 04:59:23,817] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:59:23,819] {logging_mixin.py:112} INFO - [2022-02-17 04:59:23,818] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:59:24,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:59:24,333] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:59:24,345] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:59:24,351] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 04:59:37,130] {scheduler_job.py:155} INFO - Started process (PID=71938) to work on /airflow/dags/download_data.py
[2022-02-17 04:59:37,138] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:59:37,140] {logging_mixin.py:112} INFO - [2022-02-17 04:59:37,140] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:59:37,604] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:59:37,659] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:59:37,669] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:59:37,674] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 04:59:50,428] {scheduler_job.py:155} INFO - Started process (PID=71964) to work on /airflow/dags/download_data.py
[2022-02-17 04:59:50,437] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 04:59:50,440] {logging_mixin.py:112} INFO - [2022-02-17 04:59:50,439] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 04:59:50,995] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 04:59:51,041] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 04:59:51,053] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 04:59:51,059] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.631 seconds
[2022-02-17 05:00:03,713] {scheduler_job.py:155} INFO - Started process (PID=71992) to work on /airflow/dags/download_data.py
[2022-02-17 05:00:03,720] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:00:03,723] {logging_mixin.py:112} INFO - [2022-02-17 05:00:03,722] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:00:04,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:00:04,337] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:00:04,346] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:00:04,353] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-17 05:00:16,995] {scheduler_job.py:155} INFO - Started process (PID=72018) to work on /airflow/dags/download_data.py
[2022-02-17 05:00:17,004] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:00:17,007] {logging_mixin.py:112} INFO - [2022-02-17 05:00:17,007] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:00:17,525] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:00:17,586] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:00:17,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:00:17,603] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-17 05:00:30,303] {scheduler_job.py:155} INFO - Started process (PID=72046) to work on /airflow/dags/download_data.py
[2022-02-17 05:00:30,314] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:00:30,317] {logging_mixin.py:112} INFO - [2022-02-17 05:00:30,317] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:00:30,949] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:00:31,005] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:00:31,021] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:00:31,028] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.725 seconds
[2022-02-17 05:00:43,610] {scheduler_job.py:155} INFO - Started process (PID=72072) to work on /airflow/dags/download_data.py
[2022-02-17 05:00:43,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:00:43,617] {logging_mixin.py:112} INFO - [2022-02-17 05:00:43,616] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:00:44,373] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:00:44,428] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:00:44,439] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:00:44,446] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.837 seconds
[2022-02-17 05:00:56,921] {scheduler_job.py:155} INFO - Started process (PID=72098) to work on /airflow/dags/download_data.py
[2022-02-17 05:00:56,926] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:00:56,927] {logging_mixin.py:112} INFO - [2022-02-17 05:00:56,927] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:00:57,422] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:00:57,484] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:00:57,496] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:00:57,503] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 05:01:10,249] {scheduler_job.py:155} INFO - Started process (PID=72126) to work on /airflow/dags/download_data.py
[2022-02-17 05:01:10,263] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:01:10,270] {logging_mixin.py:112} INFO - [2022-02-17 05:01:10,270] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:01:11,061] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:01:11,147] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:01:11,168] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:01:11,177] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.928 seconds
[2022-02-17 05:01:23,576] {scheduler_job.py:155} INFO - Started process (PID=72152) to work on /airflow/dags/download_data.py
[2022-02-17 05:01:23,585] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:01:23,587] {logging_mixin.py:112} INFO - [2022-02-17 05:01:23,587] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:01:24,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:01:24,235] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:01:24,244] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:01:24,252] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-17 05:01:36,851] {scheduler_job.py:155} INFO - Started process (PID=72180) to work on /airflow/dags/download_data.py
[2022-02-17 05:01:36,858] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:01:36,861] {logging_mixin.py:112} INFO - [2022-02-17 05:01:36,861] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:01:37,317] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:01:37,362] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:01:37,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:01:37,375] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 05:01:50,155] {scheduler_job.py:155} INFO - Started process (PID=72206) to work on /airflow/dags/download_data.py
[2022-02-17 05:01:50,161] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:01:50,169] {logging_mixin.py:112} INFO - [2022-02-17 05:01:50,168] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:01:50,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:01:50,692] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:01:50,702] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:01:50,707] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 05:02:03,648] {scheduler_job.py:155} INFO - Started process (PID=72234) to work on /airflow/dags/download_data.py
[2022-02-17 05:02:03,661] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:02:03,664] {logging_mixin.py:112} INFO - [2022-02-17 05:02:03,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:02:04,227] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:02:04,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:02:04,291] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:02:04,298] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.651 seconds
[2022-02-17 05:02:16,904] {scheduler_job.py:155} INFO - Started process (PID=72260) to work on /airflow/dags/download_data.py
[2022-02-17 05:02:16,915] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:02:16,917] {logging_mixin.py:112} INFO - [2022-02-17 05:02:16,917] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:02:17,416] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:02:17,475] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:02:17,482] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:02:17,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 05:02:30,198] {scheduler_job.py:155} INFO - Started process (PID=72288) to work on /airflow/dags/download_data.py
[2022-02-17 05:02:30,204] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:02:30,207] {logging_mixin.py:112} INFO - [2022-02-17 05:02:30,206] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:02:30,840] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:02:30,908] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:02:30,919] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:02:30,927] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.729 seconds
[2022-02-17 05:02:43,500] {scheduler_job.py:155} INFO - Started process (PID=72314) to work on /airflow/dags/download_data.py
[2022-02-17 05:02:43,509] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:02:43,511] {logging_mixin.py:112} INFO - [2022-02-17 05:02:43,510] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:02:44,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:02:44,086] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:02:44,095] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:02:44,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-17 05:02:56,798] {scheduler_job.py:155} INFO - Started process (PID=72340) to work on /airflow/dags/download_data.py
[2022-02-17 05:02:56,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:02:56,821] {logging_mixin.py:112} INFO - [2022-02-17 05:02:56,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:02:57,340] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:02:57,388] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:02:57,396] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:02:57,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 05:03:10,110] {scheduler_job.py:155} INFO - Started process (PID=72368) to work on /airflow/dags/download_data.py
[2022-02-17 05:03:10,118] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:03:10,121] {logging_mixin.py:112} INFO - [2022-02-17 05:03:10,119] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:03:10,584] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:03:10,640] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:03:10,648] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:03:10,652] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 05:03:23,520] {scheduler_job.py:155} INFO - Started process (PID=72394) to work on /airflow/dags/download_data.py
[2022-02-17 05:03:23,531] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:03:23,537] {logging_mixin.py:112} INFO - [2022-02-17 05:03:23,536] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:03:24,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:03:24,110] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:03:24,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:03:24,126] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 05:03:36,794] {scheduler_job.py:155} INFO - Started process (PID=72422) to work on /airflow/dags/download_data.py
[2022-02-17 05:03:36,800] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:03:36,802] {logging_mixin.py:112} INFO - [2022-02-17 05:03:36,802] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:03:37,256] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:03:37,308] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:03:37,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:03:37,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 05:03:50,049] {scheduler_job.py:155} INFO - Started process (PID=72448) to work on /airflow/dags/download_data.py
[2022-02-17 05:03:50,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:03:50,063] {logging_mixin.py:112} INFO - [2022-02-17 05:03:50,061] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:03:50,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:03:50,586] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:03:50,599] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:03:50,605] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 05:04:03,337] {scheduler_job.py:155} INFO - Started process (PID=72476) to work on /airflow/dags/download_data.py
[2022-02-17 05:04:03,342] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:04:03,343] {logging_mixin.py:112} INFO - [2022-02-17 05:04:03,343] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:04:04,015] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:04:04,136] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:04:04,169] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:04:04,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.841 seconds
[2022-02-17 05:04:16,668] {scheduler_job.py:155} INFO - Started process (PID=72502) to work on /airflow/dags/download_data.py
[2022-02-17 05:04:16,678] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:04:16,692] {logging_mixin.py:112} INFO - [2022-02-17 05:04:16,691] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:04:17,162] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:04:17,215] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:04:17,227] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:04:17,233] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 05:04:29,941] {scheduler_job.py:155} INFO - Started process (PID=72528) to work on /airflow/dags/download_data.py
[2022-02-17 05:04:29,945] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:04:29,947] {logging_mixin.py:112} INFO - [2022-02-17 05:04:29,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:04:30,615] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:04:30,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:04:30,686] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:04:30,692] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.751 seconds
[2022-02-17 05:04:43,237] {scheduler_job.py:155} INFO - Started process (PID=72556) to work on /airflow/dags/download_data.py
[2022-02-17 05:04:43,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:04:43,257] {logging_mixin.py:112} INFO - [2022-02-17 05:04:43,256] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:04:43,790] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:04:43,846] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:04:43,857] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:04:43,861] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-17 05:04:56,511] {scheduler_job.py:155} INFO - Started process (PID=72582) to work on /airflow/dags/download_data.py
[2022-02-17 05:04:56,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:04:56,520] {logging_mixin.py:112} INFO - [2022-02-17 05:04:56,520] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:04:57,060] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:04:57,110] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:04:57,127] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:04:57,134] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-17 05:05:09,762] {scheduler_job.py:155} INFO - Started process (PID=72610) to work on /airflow/dags/download_data.py
[2022-02-17 05:05:09,776] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:05:09,779] {logging_mixin.py:112} INFO - [2022-02-17 05:05:09,779] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:05:10,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:05:10,458] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:05:10,466] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:05:10,471] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.709 seconds
[2022-02-17 05:05:23,123] {scheduler_job.py:155} INFO - Started process (PID=72636) to work on /airflow/dags/download_data.py
[2022-02-17 05:05:23,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:05:23,128] {logging_mixin.py:112} INFO - [2022-02-17 05:05:23,128] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:05:23,804] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:05:23,854] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:05:23,865] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:05:23,871] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.748 seconds
[2022-02-17 05:05:36,454] {scheduler_job.py:155} INFO - Started process (PID=72664) to work on /airflow/dags/download_data.py
[2022-02-17 05:05:36,463] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:05:36,466] {logging_mixin.py:112} INFO - [2022-02-17 05:05:36,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:05:37,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:05:37,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:05:37,121] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:05:37,133] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-17 05:05:49,746] {scheduler_job.py:155} INFO - Started process (PID=72690) to work on /airflow/dags/download_data.py
[2022-02-17 05:05:49,752] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:05:49,756] {logging_mixin.py:112} INFO - [2022-02-17 05:05:49,756] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:05:50,267] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:05:50,324] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:05:50,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:05:50,341] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 05:06:03,035] {scheduler_job.py:155} INFO - Started process (PID=72716) to work on /airflow/dags/download_data.py
[2022-02-17 05:06:03,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:06:03,046] {logging_mixin.py:112} INFO - [2022-02-17 05:06:03,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:06:03,567] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:06:03,615] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:06:03,628] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:06:03,632] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-17 05:06:16,353] {scheduler_job.py:155} INFO - Started process (PID=72744) to work on /airflow/dags/download_data.py
[2022-02-17 05:06:16,367] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:06:16,369] {logging_mixin.py:112} INFO - [2022-02-17 05:06:16,369] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:06:16,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:06:17,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:06:17,019] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:06:17,024] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.671 seconds
[2022-02-17 05:06:29,663] {scheduler_job.py:155} INFO - Started process (PID=72770) to work on /airflow/dags/download_data.py
[2022-02-17 05:06:29,678] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:06:29,684] {logging_mixin.py:112} INFO - [2022-02-17 05:06:29,683] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:06:30,186] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:06:30,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:06:30,255] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:06:30,268] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 05:06:42,931] {scheduler_job.py:155} INFO - Started process (PID=72798) to work on /airflow/dags/download_data.py
[2022-02-17 05:06:42,938] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:06:42,939] {logging_mixin.py:112} INFO - [2022-02-17 05:06:42,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:06:43,539] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:06:43,602] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:06:43,613] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:06:43,617] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.686 seconds
[2022-02-17 05:06:56,225] {scheduler_job.py:155} INFO - Started process (PID=72824) to work on /airflow/dags/download_data.py
[2022-02-17 05:06:56,230] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:06:56,231] {logging_mixin.py:112} INFO - [2022-02-17 05:06:56,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:06:56,805] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:06:56,861] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:06:56,872] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:06:56,879] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-17 05:07:09,536] {scheduler_job.py:155} INFO - Started process (PID=72852) to work on /airflow/dags/download_data.py
[2022-02-17 05:07:09,546] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:07:09,549] {logging_mixin.py:112} INFO - [2022-02-17 05:07:09,548] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:07:10,068] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:07:10,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:07:10,166] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:07:10,176] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-17 05:07:22,796] {scheduler_job.py:155} INFO - Started process (PID=72878) to work on /airflow/dags/download_data.py
[2022-02-17 05:07:22,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:07:22,811] {logging_mixin.py:112} INFO - [2022-02-17 05:07:22,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:07:23,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:07:23,300] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:07:23,312] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:07:23,316] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 05:07:36,067] {scheduler_job.py:155} INFO - Started process (PID=72904) to work on /airflow/dags/download_data.py
[2022-02-17 05:07:36,072] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:07:36,075] {logging_mixin.py:112} INFO - [2022-02-17 05:07:36,075] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:07:36,541] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:07:36,593] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:07:36,604] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:07:36,609] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 05:07:49,345] {scheduler_job.py:155} INFO - Started process (PID=72932) to work on /airflow/dags/download_data.py
[2022-02-17 05:07:49,355] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:07:49,357] {logging_mixin.py:112} INFO - [2022-02-17 05:07:49,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:07:50,066] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:07:50,115] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:07:50,128] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:07:50,134] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.789 seconds
[2022-02-17 05:08:02,632] {scheduler_job.py:155} INFO - Started process (PID=72958) to work on /airflow/dags/download_data.py
[2022-02-17 05:08:02,641] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:08:02,643] {logging_mixin.py:112} INFO - [2022-02-17 05:08:02,642] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:08:03,074] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:08:03,119] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:08:03,125] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:08:03,129] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 05:08:15,941] {scheduler_job.py:155} INFO - Started process (PID=72986) to work on /airflow/dags/download_data.py
[2022-02-17 05:08:15,952] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:08:15,955] {logging_mixin.py:112} INFO - [2022-02-17 05:08:15,954] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:08:16,434] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:08:16,489] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:08:16,497] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:08:16,503] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 05:08:29,240] {scheduler_job.py:155} INFO - Started process (PID=73012) to work on /airflow/dags/download_data.py
[2022-02-17 05:08:29,246] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:08:29,248] {logging_mixin.py:112} INFO - [2022-02-17 05:08:29,248] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:08:29,696] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:08:29,756] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:08:29,765] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:08:29,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 05:08:42,474] {scheduler_job.py:155} INFO - Started process (PID=73040) to work on /airflow/dags/download_data.py
[2022-02-17 05:08:42,480] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:08:42,482] {logging_mixin.py:112} INFO - [2022-02-17 05:08:42,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:08:42,952] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:08:42,993] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:08:43,000] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:08:43,003] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 05:08:55,782] {scheduler_job.py:155} INFO - Started process (PID=73066) to work on /airflow/dags/download_data.py
[2022-02-17 05:08:55,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:08:55,788] {logging_mixin.py:112} INFO - [2022-02-17 05:08:55,788] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:08:56,322] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:08:56,374] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:08:56,383] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:08:56,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 05:09:09,106] {scheduler_job.py:155} INFO - Started process (PID=73094) to work on /airflow/dags/download_data.py
[2022-02-17 05:09:09,130] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:09:09,134] {logging_mixin.py:112} INFO - [2022-02-17 05:09:09,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:09:09,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:09:09,862] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:09:09,871] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:09:09,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.773 seconds
[2022-02-17 05:09:22,413] {scheduler_job.py:155} INFO - Started process (PID=73120) to work on /airflow/dags/download_data.py
[2022-02-17 05:09:22,440] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:09:22,455] {logging_mixin.py:112} INFO - [2022-02-17 05:09:22,455] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:09:23,198] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:09:23,257] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:09:23,267] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:09:23,274] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.876 seconds
[2022-02-17 05:09:35,662] {scheduler_job.py:155} INFO - Started process (PID=73146) to work on /airflow/dags/download_data.py
[2022-02-17 05:09:35,668] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:09:35,671] {logging_mixin.py:112} INFO - [2022-02-17 05:09:35,671] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:09:36,180] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:09:36,237] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:09:36,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:09:36,254] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 05:09:48,928] {scheduler_job.py:155} INFO - Started process (PID=73174) to work on /airflow/dags/download_data.py
[2022-02-17 05:09:48,934] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:09:48,936] {logging_mixin.py:112} INFO - [2022-02-17 05:09:48,936] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:09:49,510] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:09:49,562] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:09:49,573] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:09:49,578] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.650 seconds
[2022-02-17 05:10:02,247] {scheduler_job.py:155} INFO - Started process (PID=73200) to work on /airflow/dags/download_data.py
[2022-02-17 05:10:02,251] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:10:02,252] {logging_mixin.py:112} INFO - [2022-02-17 05:10:02,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:10:02,766] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:10:02,825] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:10:02,835] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:10:02,841] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 05:10:15,483] {scheduler_job.py:155} INFO - Started process (PID=73228) to work on /airflow/dags/download_data.py
[2022-02-17 05:10:15,493] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:10:15,495] {logging_mixin.py:112} INFO - [2022-02-17 05:10:15,494] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:10:17,336] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:10:17,407] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:10:17,422] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:10:17,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.945 seconds
[2022-02-17 05:10:29,770] {scheduler_job.py:155} INFO - Started process (PID=73254) to work on /airflow/dags/download_data.py
[2022-02-17 05:10:29,781] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:10:29,784] {logging_mixin.py:112} INFO - [2022-02-17 05:10:29,783] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:10:30,307] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:10:30,363] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:10:30,370] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:10:30,377] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-17 05:10:42,013] {scheduler_job.py:155} INFO - Started process (PID=73281) to work on /airflow/dags/download_data.py
[2022-02-17 05:10:42,021] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:10:42,023] {logging_mixin.py:112} INFO - [2022-02-17 05:10:42,023] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:10:42,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:10:42,577] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:10:42,585] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:10:42,592] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-17 05:10:55,314] {scheduler_job.py:155} INFO - Started process (PID=73307) to work on /airflow/dags/download_data.py
[2022-02-17 05:10:55,319] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:10:55,321] {logging_mixin.py:112} INFO - [2022-02-17 05:10:55,321] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:10:55,800] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:10:55,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:10:55,857] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:10:55,861] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 05:11:08,627] {scheduler_job.py:155} INFO - Started process (PID=73333) to work on /airflow/dags/download_data.py
[2022-02-17 05:11:08,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:11:08,635] {logging_mixin.py:112} INFO - [2022-02-17 05:11:08,634] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:11:09,096] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:11:09,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:11:09,153] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:11:09,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 05:11:21,900] {scheduler_job.py:155} INFO - Started process (PID=73361) to work on /airflow/dags/download_data.py
[2022-02-17 05:11:21,906] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:11:21,908] {logging_mixin.py:112} INFO - [2022-02-17 05:11:21,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:11:22,408] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:11:22,470] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:11:22,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:11:22,485] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 05:11:35,195] {scheduler_job.py:155} INFO - Started process (PID=73387) to work on /airflow/dags/download_data.py
[2022-02-17 05:11:35,203] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:11:35,208] {logging_mixin.py:112} INFO - [2022-02-17 05:11:35,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:11:35,683] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:11:35,748] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:11:35,757] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:11:35,762] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 05:11:48,429] {scheduler_job.py:155} INFO - Started process (PID=73415) to work on /airflow/dags/download_data.py
[2022-02-17 05:11:48,440] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:11:48,442] {logging_mixin.py:112} INFO - [2022-02-17 05:11:48,442] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:11:48,948] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:11:49,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:11:49,014] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:11:49,021] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 05:12:01,726] {scheduler_job.py:155} INFO - Started process (PID=73441) to work on /airflow/dags/download_data.py
[2022-02-17 05:12:01,734] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:12:01,736] {logging_mixin.py:112} INFO - [2022-02-17 05:12:01,736] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:12:02,284] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:12:02,354] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:12:02,372] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:12:02,378] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.652 seconds
[2022-02-17 05:12:15,000] {scheduler_job.py:155} INFO - Started process (PID=73469) to work on /airflow/dags/download_data.py
[2022-02-17 05:12:15,009] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:12:15,011] {logging_mixin.py:112} INFO - [2022-02-17 05:12:15,010] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:12:15,529] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:12:15,582] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:12:15,587] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:12:15,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 05:12:28,375] {scheduler_job.py:155} INFO - Started process (PID=73495) to work on /airflow/dags/download_data.py
[2022-02-17 05:12:28,383] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:12:28,386] {logging_mixin.py:112} INFO - [2022-02-17 05:12:28,385] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:12:28,868] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:12:28,986] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:12:29,004] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:12:29,020] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-17 05:12:41,637] {scheduler_job.py:155} INFO - Started process (PID=73521) to work on /airflow/dags/download_data.py
[2022-02-17 05:12:41,648] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:12:41,650] {logging_mixin.py:112} INFO - [2022-02-17 05:12:41,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:12:42,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:12:42,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:12:42,171] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:12:42,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 05:12:54,970] {scheduler_job.py:155} INFO - Started process (PID=73549) to work on /airflow/dags/download_data.py
[2022-02-17 05:12:54,980] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:12:54,982] {logging_mixin.py:112} INFO - [2022-02-17 05:12:54,982] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:12:55,796] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:12:55,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:12:55,860] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:12:55,867] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.897 seconds
[2022-02-17 05:13:08,300] {scheduler_job.py:155} INFO - Started process (PID=73575) to work on /airflow/dags/download_data.py
[2022-02-17 05:13:08,304] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:13:08,305] {logging_mixin.py:112} INFO - [2022-02-17 05:13:08,305] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:13:08,780] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:13:08,867] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:13:08,882] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:13:08,893] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 05:13:21,566] {scheduler_job.py:155} INFO - Started process (PID=73603) to work on /airflow/dags/download_data.py
[2022-02-17 05:13:21,575] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:13:21,577] {logging_mixin.py:112} INFO - [2022-02-17 05:13:21,577] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:13:22,021] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:13:22,070] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:13:22,081] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:13:22,088] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 05:13:34,910] {scheduler_job.py:155} INFO - Started process (PID=73629) to work on /airflow/dags/download_data.py
[2022-02-17 05:13:34,926] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:13:34,930] {logging_mixin.py:112} INFO - [2022-02-17 05:13:34,929] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:13:35,581] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:13:35,643] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:13:35,652] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:13:35,658] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.748 seconds
[2022-02-17 05:13:48,128] {scheduler_job.py:155} INFO - Started process (PID=73657) to work on /airflow/dags/download_data.py
[2022-02-17 05:13:48,133] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:13:48,134] {logging_mixin.py:112} INFO - [2022-02-17 05:13:48,134] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:13:48,615] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:13:48,678] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:13:48,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:13:48,692] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 05:14:01,438] {scheduler_job.py:155} INFO - Started process (PID=73683) to work on /airflow/dags/download_data.py
[2022-02-17 05:14:01,443] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:14:01,444] {logging_mixin.py:112} INFO - [2022-02-17 05:14:01,444] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:14:01,922] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:14:01,975] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:14:01,985] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:14:01,990] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 05:14:14,709] {scheduler_job.py:155} INFO - Started process (PID=73710) to work on /airflow/dags/download_data.py
[2022-02-17 05:14:14,727] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:14:14,731] {logging_mixin.py:112} INFO - [2022-02-17 05:14:14,730] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:14:15,447] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:14:15,493] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:14:15,506] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:14:15,513] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.804 seconds
[2022-02-17 05:14:27,970] {scheduler_job.py:155} INFO - Started process (PID=73737) to work on /airflow/dags/download_data.py
[2022-02-17 05:14:27,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:14:27,979] {logging_mixin.py:112} INFO - [2022-02-17 05:14:27,979] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:14:28,514] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:14:28,575] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:14:28,589] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:14:28,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-17 05:14:41,225] {scheduler_job.py:155} INFO - Started process (PID=73763) to work on /airflow/dags/download_data.py
[2022-02-17 05:14:41,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:14:41,238] {logging_mixin.py:112} INFO - [2022-02-17 05:14:41,237] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:14:41,774] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:14:41,851] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:14:41,871] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:14:41,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.652 seconds
[2022-02-17 05:14:54,655] {scheduler_job.py:155} INFO - Started process (PID=73791) to work on /airflow/dags/download_data.py
[2022-02-17 05:14:54,665] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:14:54,667] {logging_mixin.py:112} INFO - [2022-02-17 05:14:54,667] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:14:55,143] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:14:55,200] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:14:55,208] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:14:55,214] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 05:15:07,909] {scheduler_job.py:155} INFO - Started process (PID=73817) to work on /airflow/dags/download_data.py
[2022-02-17 05:15:08,090] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:15:08,093] {logging_mixin.py:112} INFO - [2022-02-17 05:15:08,092] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:15:08,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:15:08,659] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:15:08,669] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:15:08,674] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.766 seconds
[2022-02-17 05:15:21,197] {scheduler_job.py:155} INFO - Started process (PID=73845) to work on /airflow/dags/download_data.py
[2022-02-17 05:15:21,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:15:21,209] {logging_mixin.py:112} INFO - [2022-02-17 05:15:21,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:15:21,691] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:15:21,752] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:15:21,765] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:15:21,770] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 05:15:34,526] {scheduler_job.py:155} INFO - Started process (PID=73871) to work on /airflow/dags/download_data.py
[2022-02-17 05:15:34,537] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:15:34,539] {logging_mixin.py:112} INFO - [2022-02-17 05:15:34,539] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:15:34,998] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:15:35,041] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:15:35,048] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:15:35,052] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 05:15:47,776] {scheduler_job.py:155} INFO - Started process (PID=73899) to work on /airflow/dags/download_data.py
[2022-02-17 05:15:47,789] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:15:47,790] {logging_mixin.py:112} INFO - [2022-02-17 05:15:47,790] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:15:48,223] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:15:48,266] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:15:48,277] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:15:48,283] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 05:16:01,045] {scheduler_job.py:155} INFO - Started process (PID=73925) to work on /airflow/dags/download_data.py
[2022-02-17 05:16:01,049] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:16:01,051] {logging_mixin.py:112} INFO - [2022-02-17 05:16:01,051] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:16:01,507] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:16:01,552] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:16:01,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:16:01,567] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 05:16:14,292] {scheduler_job.py:155} INFO - Started process (PID=73951) to work on /airflow/dags/download_data.py
[2022-02-17 05:16:14,302] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:16:14,304] {logging_mixin.py:112} INFO - [2022-02-17 05:16:14,304] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:16:14,759] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:16:14,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:16:14,819] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:16:14,824] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 05:16:27,631] {scheduler_job.py:155} INFO - Started process (PID=73979) to work on /airflow/dags/download_data.py
[2022-02-17 05:16:27,638] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:16:27,640] {logging_mixin.py:112} INFO - [2022-02-17 05:16:27,640] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:16:28,088] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:16:28,135] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:16:28,150] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:16:28,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 05:16:40,897] {scheduler_job.py:155} INFO - Started process (PID=74005) to work on /airflow/dags/download_data.py
[2022-02-17 05:16:40,906] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:16:40,909] {logging_mixin.py:112} INFO - [2022-02-17 05:16:40,908] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:16:41,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:16:41,420] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:16:41,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:16:41,433] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 05:16:54,185] {scheduler_job.py:155} INFO - Started process (PID=74033) to work on /airflow/dags/download_data.py
[2022-02-17 05:16:54,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:16:54,191] {logging_mixin.py:112} INFO - [2022-02-17 05:16:54,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:16:54,721] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:16:54,783] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:16:54,792] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:16:54,798] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-17 05:17:07,457] {scheduler_job.py:155} INFO - Started process (PID=74059) to work on /airflow/dags/download_data.py
[2022-02-17 05:17:07,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:17:07,466] {logging_mixin.py:112} INFO - [2022-02-17 05:17:07,463] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:17:07,941] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:17:07,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:17:08,003] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:17:08,010] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 05:17:20,716] {scheduler_job.py:155} INFO - Started process (PID=74087) to work on /airflow/dags/download_data.py
[2022-02-17 05:17:20,723] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:17:20,724] {logging_mixin.py:112} INFO - [2022-02-17 05:17:20,724] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:17:21,155] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:17:21,205] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:17:21,214] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:17:21,223] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 05:17:33,992] {scheduler_job.py:155} INFO - Started process (PID=74113) to work on /airflow/dags/download_data.py
[2022-02-17 05:17:34,008] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:17:34,010] {logging_mixin.py:112} INFO - [2022-02-17 05:17:34,010] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:17:34,503] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:17:34,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:17:34,576] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:17:34,584] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 05:17:47,268] {scheduler_job.py:155} INFO - Started process (PID=74139) to work on /airflow/dags/download_data.py
[2022-02-17 05:17:47,279] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:17:47,281] {logging_mixin.py:112} INFO - [2022-02-17 05:17:47,280] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:17:47,765] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:17:47,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:17:47,825] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:17:47,831] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 05:18:00,576] {scheduler_job.py:155} INFO - Started process (PID=74167) to work on /airflow/dags/download_data.py
[2022-02-17 05:18:00,583] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:18:00,584] {logging_mixin.py:112} INFO - [2022-02-17 05:18:00,584] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:18:01,073] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:18:01,124] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:18:01,132] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:18:01,138] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 05:18:13,856] {scheduler_job.py:155} INFO - Started process (PID=74193) to work on /airflow/dags/download_data.py
[2022-02-17 05:18:13,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:18:13,862] {logging_mixin.py:112} INFO - [2022-02-17 05:18:13,862] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:18:14,319] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:18:14,383] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:18:14,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:18:14,400] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 05:18:27,150] {scheduler_job.py:155} INFO - Started process (PID=74221) to work on /airflow/dags/download_data.py
[2022-02-17 05:18:27,155] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:18:27,157] {logging_mixin.py:112} INFO - [2022-02-17 05:18:27,157] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:18:27,621] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:18:27,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:18:27,665] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:18:27,670] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 05:18:40,429] {scheduler_job.py:155} INFO - Started process (PID=74247) to work on /airflow/dags/download_data.py
[2022-02-17 05:18:40,443] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:18:40,445] {logging_mixin.py:112} INFO - [2022-02-17 05:18:40,445] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:18:40,894] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:18:40,941] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:18:40,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:18:40,959] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 05:18:53,728] {scheduler_job.py:155} INFO - Started process (PID=74275) to work on /airflow/dags/download_data.py
[2022-02-17 05:18:53,744] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:18:53,748] {logging_mixin.py:112} INFO - [2022-02-17 05:18:53,747] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:18:54,276] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:18:54,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:18:54,330] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:18:54,335] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-17 05:19:06,998] {scheduler_job.py:155} INFO - Started process (PID=74301) to work on /airflow/dags/download_data.py
[2022-02-17 05:19:07,003] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:19:07,005] {logging_mixin.py:112} INFO - [2022-02-17 05:19:07,004] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:19:07,474] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:19:07,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:19:07,546] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:19:07,550] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 05:19:20,260] {scheduler_job.py:155} INFO - Started process (PID=74327) to work on /airflow/dags/download_data.py
[2022-02-17 05:19:20,270] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:19:20,274] {logging_mixin.py:112} INFO - [2022-02-17 05:19:20,273] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:19:20,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:19:20,781] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:19:20,789] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:19:20,794] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 05:19:33,532] {scheduler_job.py:155} INFO - Started process (PID=74355) to work on /airflow/dags/download_data.py
[2022-02-17 05:19:33,543] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:19:33,545] {logging_mixin.py:112} INFO - [2022-02-17 05:19:33,545] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:19:34,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:19:34,052] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:19:34,059] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:19:34,064] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 05:19:46,800] {scheduler_job.py:155} INFO - Started process (PID=74381) to work on /airflow/dags/download_data.py
[2022-02-17 05:19:46,806] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:19:46,808] {logging_mixin.py:112} INFO - [2022-02-17 05:19:46,808] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:19:47,274] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:19:47,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:19:47,323] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:19:47,328] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 05:20:00,052] {scheduler_job.py:155} INFO - Started process (PID=74409) to work on /airflow/dags/download_data.py
[2022-02-17 05:20:00,058] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:20:00,060] {logging_mixin.py:112} INFO - [2022-02-17 05:20:00,059] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:20:00,526] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:20:00,581] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:20:00,593] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:20:00,597] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 05:20:13,347] {scheduler_job.py:155} INFO - Started process (PID=74435) to work on /airflow/dags/download_data.py
[2022-02-17 05:20:13,359] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:20:13,361] {logging_mixin.py:112} INFO - [2022-02-17 05:20:13,361] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:20:13,869] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:20:13,910] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:20:13,918] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:20:13,922] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-17 05:20:26,613] {scheduler_job.py:155} INFO - Started process (PID=74463) to work on /airflow/dags/download_data.py
[2022-02-17 05:20:26,620] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:20:26,623] {logging_mixin.py:112} INFO - [2022-02-17 05:20:26,623] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:20:27,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:20:27,332] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:20:27,340] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:20:27,348] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.734 seconds
[2022-02-17 05:20:39,895] {scheduler_job.py:155} INFO - Started process (PID=74489) to work on /airflow/dags/download_data.py
[2022-02-17 05:20:39,904] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:20:39,907] {logging_mixin.py:112} INFO - [2022-02-17 05:20:39,906] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:20:40,374] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:20:40,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:20:40,434] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:20:40,442] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 05:20:53,173] {scheduler_job.py:155} INFO - Started process (PID=74515) to work on /airflow/dags/download_data.py
[2022-02-17 05:20:53,181] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:20:53,185] {logging_mixin.py:112} INFO - [2022-02-17 05:20:53,184] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:20:53,698] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:20:53,756] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:20:53,766] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:20:53,772] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-17 05:21:06,488] {scheduler_job.py:155} INFO - Started process (PID=74543) to work on /airflow/dags/download_data.py
[2022-02-17 05:21:06,497] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:21:06,499] {logging_mixin.py:112} INFO - [2022-02-17 05:21:06,499] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:21:06,950] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:21:07,008] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:21:07,014] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:21:07,019] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 05:21:19,736] {scheduler_job.py:155} INFO - Started process (PID=74569) to work on /airflow/dags/download_data.py
[2022-02-17 05:21:19,749] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:21:19,751] {logging_mixin.py:112} INFO - [2022-02-17 05:21:19,751] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:21:20,214] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:21:20,268] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:21:20,276] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:21:20,281] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 05:21:33,023] {scheduler_job.py:155} INFO - Started process (PID=74597) to work on /airflow/dags/download_data.py
[2022-02-17 05:21:33,028] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:21:33,030] {logging_mixin.py:112} INFO - [2022-02-17 05:21:33,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:21:33,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:21:33,552] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:21:33,559] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:21:33,566] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 05:21:46,280] {scheduler_job.py:155} INFO - Started process (PID=74623) to work on /airflow/dags/download_data.py
[2022-02-17 05:21:46,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:21:46,289] {logging_mixin.py:112} INFO - [2022-02-17 05:21:46,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:21:46,737] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:21:46,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:21:46,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:21:46,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 05:21:59,544] {scheduler_job.py:155} INFO - Started process (PID=74651) to work on /airflow/dags/download_data.py
[2022-02-17 05:21:59,548] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:21:59,551] {logging_mixin.py:112} INFO - [2022-02-17 05:21:59,550] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:22:00,022] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:22:00,074] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:22:00,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:22:00,090] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 05:22:12,799] {scheduler_job.py:155} INFO - Started process (PID=74677) to work on /airflow/dags/download_data.py
[2022-02-17 05:22:12,803] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:22:12,805] {logging_mixin.py:112} INFO - [2022-02-17 05:22:12,805] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:22:13,275] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:22:13,324] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:22:13,331] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:22:13,336] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 05:22:26,063] {scheduler_job.py:155} INFO - Started process (PID=74705) to work on /airflow/dags/download_data.py
[2022-02-17 05:22:26,079] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:22:26,083] {logging_mixin.py:112} INFO - [2022-02-17 05:22:26,081] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:22:26,542] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:22:26,590] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:22:26,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:22:26,606] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 05:22:39,281] {scheduler_job.py:155} INFO - Started process (PID=74731) to work on /airflow/dags/download_data.py
[2022-02-17 05:22:39,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:22:39,289] {logging_mixin.py:112} INFO - [2022-02-17 05:22:39,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:22:39,758] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:22:39,795] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:22:39,805] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:22:39,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 05:22:52,530] {scheduler_job.py:155} INFO - Started process (PID=74757) to work on /airflow/dags/download_data.py
[2022-02-17 05:22:52,536] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:22:52,537] {logging_mixin.py:112} INFO - [2022-02-17 05:22:52,537] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:22:52,984] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:22:53,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:22:53,053] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:22:53,058] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 05:23:05,866] {scheduler_job.py:155} INFO - Started process (PID=74785) to work on /airflow/dags/download_data.py
[2022-02-17 05:23:05,872] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:23:05,873] {logging_mixin.py:112} INFO - [2022-02-17 05:23:05,873] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:23:06,355] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:23:06,416] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:23:06,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:23:06,435] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 05:23:19,141] {scheduler_job.py:155} INFO - Started process (PID=74811) to work on /airflow/dags/download_data.py
[2022-02-17 05:23:19,146] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:23:19,147] {logging_mixin.py:112} INFO - [2022-02-17 05:23:19,147] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:23:19,628] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:23:19,682] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:23:19,690] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:23:19,694] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 05:23:32,445] {scheduler_job.py:155} INFO - Started process (PID=74839) to work on /airflow/dags/download_data.py
[2022-02-17 05:23:32,458] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:23:32,460] {logging_mixin.py:112} INFO - [2022-02-17 05:23:32,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:23:32,982] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:23:33,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:23:33,052] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:23:33,058] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-17 05:23:45,690] {scheduler_job.py:155} INFO - Started process (PID=74865) to work on /airflow/dags/download_data.py
[2022-02-17 05:23:45,696] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:23:45,698] {logging_mixin.py:112} INFO - [2022-02-17 05:23:45,698] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:23:46,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:23:46,223] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:23:46,238] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:23:46,242] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 05:23:58,982] {scheduler_job.py:155} INFO - Started process (PID=74893) to work on /airflow/dags/download_data.py
[2022-02-17 05:23:58,996] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:23:58,998] {logging_mixin.py:112} INFO - [2022-02-17 05:23:58,998] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:23:59,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:23:59,535] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:23:59,545] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:23:59,551] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 05:24:12,284] {scheduler_job.py:155} INFO - Started process (PID=74919) to work on /airflow/dags/download_data.py
[2022-02-17 05:24:12,290] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:24:12,292] {logging_mixin.py:112} INFO - [2022-02-17 05:24:12,292] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:24:12,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:24:12,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:24:12,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:24:12,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 05:24:25,559] {scheduler_job.py:155} INFO - Started process (PID=74945) to work on /airflow/dags/download_data.py
[2022-02-17 05:24:25,564] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:24:25,566] {logging_mixin.py:112} INFO - [2022-02-17 05:24:25,566] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:24:26,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:24:26,052] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:24:26,064] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:24:26,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 05:24:38,792] {scheduler_job.py:155} INFO - Started process (PID=74973) to work on /airflow/dags/download_data.py
[2022-02-17 05:24:38,799] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:24:38,801] {logging_mixin.py:112} INFO - [2022-02-17 05:24:38,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:24:39,299] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:24:39,351] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:24:39,359] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:24:39,364] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 05:24:52,128] {scheduler_job.py:155} INFO - Started process (PID=74999) to work on /airflow/dags/download_data.py
[2022-02-17 05:24:52,134] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:24:52,136] {logging_mixin.py:112} INFO - [2022-02-17 05:24:52,136] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:24:53,007] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:24:53,082] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:24:53,098] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:24:53,109] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.982 seconds
[2022-02-17 05:25:05,450] {scheduler_job.py:155} INFO - Started process (PID=75027) to work on /airflow/dags/download_data.py
[2022-02-17 05:25:05,456] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:25:05,459] {logging_mixin.py:112} INFO - [2022-02-17 05:25:05,459] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:25:06,172] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:25:06,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:25:06,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:25:06,259] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.809 seconds
[2022-02-17 05:25:18,765] {scheduler_job.py:155} INFO - Started process (PID=75053) to work on /airflow/dags/download_data.py
[2022-02-17 05:25:18,776] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:25:18,779] {logging_mixin.py:112} INFO - [2022-02-17 05:25:18,778] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:25:19,255] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:25:19,308] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:25:19,315] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:25:19,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 05:25:32,033] {scheduler_job.py:155} INFO - Started process (PID=75081) to work on /airflow/dags/download_data.py
[2022-02-17 05:25:32,054] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:25:32,063] {logging_mixin.py:112} INFO - [2022-02-17 05:25:32,063] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:25:32,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:25:32,892] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:25:32,907] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:25:32,915] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.882 seconds
[2022-02-17 05:25:45,302] {scheduler_job.py:155} INFO - Started process (PID=75107) to work on /airflow/dags/download_data.py
[2022-02-17 05:25:45,311] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:25:45,313] {logging_mixin.py:112} INFO - [2022-02-17 05:25:45,312] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:25:45,762] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:25:45,813] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:25:45,823] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:25:45,827] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 05:25:58,591] {scheduler_job.py:155} INFO - Started process (PID=75133) to work on /airflow/dags/download_data.py
[2022-02-17 05:25:58,597] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:25:58,599] {logging_mixin.py:112} INFO - [2022-02-17 05:25:58,598] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:25:59,204] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:25:59,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:25:59,276] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:25:59,282] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.690 seconds
[2022-02-17 05:26:11,876] {scheduler_job.py:155} INFO - Started process (PID=75161) to work on /airflow/dags/download_data.py
[2022-02-17 05:26:11,886] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:26:11,889] {logging_mixin.py:112} INFO - [2022-02-17 05:26:11,889] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:26:12,388] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:26:12,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:26:12,452] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:26:12,456] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-17 05:26:25,168] {scheduler_job.py:155} INFO - Started process (PID=75187) to work on /airflow/dags/download_data.py
[2022-02-17 05:26:25,175] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:26:25,177] {logging_mixin.py:112} INFO - [2022-02-17 05:26:25,176] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:26:25,612] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:26:25,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:26:25,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:26:25,676] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 05:26:38,437] {scheduler_job.py:155} INFO - Started process (PID=75215) to work on /airflow/dags/download_data.py
[2022-02-17 05:26:38,444] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:26:38,446] {logging_mixin.py:112} INFO - [2022-02-17 05:26:38,446] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:26:38,871] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:26:38,923] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:26:38,933] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:26:38,938] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 05:26:51,731] {scheduler_job.py:155} INFO - Started process (PID=75241) to work on /airflow/dags/download_data.py
[2022-02-17 05:26:51,737] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:26:51,739] {logging_mixin.py:112} INFO - [2022-02-17 05:26:51,738] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:26:52,167] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:26:52,206] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:26:52,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:26:52,215] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.483 seconds
[2022-02-17 05:27:04,999] {scheduler_job.py:155} INFO - Started process (PID=75269) to work on /airflow/dags/download_data.py
[2022-02-17 05:27:05,003] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:27:05,005] {logging_mixin.py:112} INFO - [2022-02-17 05:27:05,005] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:27:05,471] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:27:05,520] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:27:05,533] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:27:05,537] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 05:27:18,270] {scheduler_job.py:155} INFO - Started process (PID=75295) to work on /airflow/dags/download_data.py
[2022-02-17 05:27:18,275] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:27:18,277] {logging_mixin.py:112} INFO - [2022-02-17 05:27:18,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:27:18,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:27:18,770] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:27:18,780] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:27:18,784] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 05:27:31,573] {scheduler_job.py:155} INFO - Started process (PID=75322) to work on /airflow/dags/download_data.py
[2022-02-17 05:27:31,583] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:27:31,585] {logging_mixin.py:112} INFO - [2022-02-17 05:27:31,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:27:32,221] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:27:32,260] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:27:32,267] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:27:32,271] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-17 05:27:44,815] {scheduler_job.py:155} INFO - Started process (PID=75349) to work on /airflow/dags/download_data.py
[2022-02-17 05:27:44,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:27:44,824] {logging_mixin.py:112} INFO - [2022-02-17 05:27:44,824] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:27:45,272] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:27:45,324] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:27:45,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:27:45,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 05:27:58,093] {scheduler_job.py:155} INFO - Started process (PID=75375) to work on /airflow/dags/download_data.py
[2022-02-17 05:27:58,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:27:58,101] {logging_mixin.py:112} INFO - [2022-02-17 05:27:58,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:27:58,559] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:27:58,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:27:58,605] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:27:58,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 05:28:11,374] {scheduler_job.py:155} INFO - Started process (PID=75403) to work on /airflow/dags/download_data.py
[2022-02-17 05:28:11,383] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:28:11,385] {logging_mixin.py:112} INFO - [2022-02-17 05:28:11,385] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:28:11,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:28:11,863] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:28:11,868] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:28:11,872] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 05:28:24,687] {scheduler_job.py:155} INFO - Started process (PID=75429) to work on /airflow/dags/download_data.py
[2022-02-17 05:28:24,694] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:28:24,697] {logging_mixin.py:112} INFO - [2022-02-17 05:28:24,696] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:28:25,129] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:28:25,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:28:25,190] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:28:25,194] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 05:28:37,953] {scheduler_job.py:155} INFO - Started process (PID=75457) to work on /airflow/dags/download_data.py
[2022-02-17 05:28:37,960] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:28:37,963] {logging_mixin.py:112} INFO - [2022-02-17 05:28:37,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:28:38,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:28:38,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:28:38,450] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:28:38,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 05:28:51,171] {scheduler_job.py:155} INFO - Started process (PID=75483) to work on /airflow/dags/download_data.py
[2022-02-17 05:28:51,176] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:28:51,178] {logging_mixin.py:112} INFO - [2022-02-17 05:28:51,178] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:28:51,622] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:28:51,674] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:28:51,681] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:28:51,685] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 05:29:04,460] {scheduler_job.py:155} INFO - Started process (PID=75511) to work on /airflow/dags/download_data.py
[2022-02-17 05:29:04,473] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:29:04,475] {logging_mixin.py:112} INFO - [2022-02-17 05:29:04,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:29:04,941] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:29:04,993] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:29:04,999] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:29:05,004] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 05:29:17,738] {scheduler_job.py:155} INFO - Started process (PID=75537) to work on /airflow/dags/download_data.py
[2022-02-17 05:29:17,746] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:29:17,751] {logging_mixin.py:112} INFO - [2022-02-17 05:29:17,750] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:29:18,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:29:18,258] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:29:18,269] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:29:18,276] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 05:29:31,058] {scheduler_job.py:155} INFO - Started process (PID=75563) to work on /airflow/dags/download_data.py
[2022-02-17 05:29:31,062] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:29:31,064] {logging_mixin.py:112} INFO - [2022-02-17 05:29:31,064] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:29:31,560] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:29:31,621] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:29:31,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:29:31,642] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 05:29:44,389] {scheduler_job.py:155} INFO - Started process (PID=75591) to work on /airflow/dags/download_data.py
[2022-02-17 05:29:44,394] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:29:44,400] {logging_mixin.py:112} INFO - [2022-02-17 05:29:44,400] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:29:44,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:29:44,945] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:29:44,952] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:29:44,959] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 05:29:57,659] {scheduler_job.py:155} INFO - Started process (PID=75617) to work on /airflow/dags/download_data.py
[2022-02-17 05:29:57,664] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:29:57,666] {logging_mixin.py:112} INFO - [2022-02-17 05:29:57,666] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:29:58,165] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:29:58,217] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:29:58,227] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:29:58,232] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 05:30:10,903] {scheduler_job.py:155} INFO - Started process (PID=75645) to work on /airflow/dags/download_data.py
[2022-02-17 05:30:10,911] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:30:10,912] {logging_mixin.py:112} INFO - [2022-02-17 05:30:10,912] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:30:11,401] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:30:11,450] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:30:11,459] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:30:11,467] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 05:30:24,196] {scheduler_job.py:155} INFO - Started process (PID=75671) to work on /airflow/dags/download_data.py
[2022-02-17 05:30:24,203] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:30:24,206] {logging_mixin.py:112} INFO - [2022-02-17 05:30:24,205] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:30:24,711] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:30:24,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:30:24,790] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:30:24,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-17 05:30:37,475] {scheduler_job.py:155} INFO - Started process (PID=75699) to work on /airflow/dags/download_data.py
[2022-02-17 05:30:37,480] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:30:37,481] {logging_mixin.py:112} INFO - [2022-02-17 05:30:37,481] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:30:37,940] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:30:37,988] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:30:37,999] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:30:38,005] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 05:30:50,746] {scheduler_job.py:155} INFO - Started process (PID=75725) to work on /airflow/dags/download_data.py
[2022-02-17 05:30:50,758] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:30:50,760] {logging_mixin.py:112} INFO - [2022-02-17 05:30:50,760] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:30:51,260] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:30:51,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:30:51,330] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:30:51,336] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 05:31:04,036] {scheduler_job.py:155} INFO - Started process (PID=75751) to work on /airflow/dags/download_data.py
[2022-02-17 05:31:04,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:31:04,049] {logging_mixin.py:112} INFO - [2022-02-17 05:31:04,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:31:04,530] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:31:04,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:31:04,603] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:31:04,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 05:31:17,283] {scheduler_job.py:155} INFO - Started process (PID=75779) to work on /airflow/dags/download_data.py
[2022-02-17 05:31:17,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:31:17,288] {logging_mixin.py:112} INFO - [2022-02-17 05:31:17,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:31:17,734] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:31:17,783] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:31:17,791] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:31:17,794] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 05:31:30,591] {scheduler_job.py:155} INFO - Started process (PID=75805) to work on /airflow/dags/download_data.py
[2022-02-17 05:31:30,596] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:31:30,597] {logging_mixin.py:112} INFO - [2022-02-17 05:31:30,597] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:31:31,121] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:31:31,191] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:31:31,203] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:31:31,210] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 05:31:43,864] {scheduler_job.py:155} INFO - Started process (PID=75833) to work on /airflow/dags/download_data.py
[2022-02-17 05:31:43,870] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:31:43,872] {logging_mixin.py:112} INFO - [2022-02-17 05:31:43,872] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:31:44,356] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:31:44,412] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:31:44,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:31:44,427] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 05:31:57,232] {scheduler_job.py:155} INFO - Started process (PID=75859) to work on /airflow/dags/download_data.py
[2022-02-17 05:31:57,240] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:31:57,244] {logging_mixin.py:112} INFO - [2022-02-17 05:31:57,244] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:31:57,839] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:31:57,937] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:31:57,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:31:57,956] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.725 seconds
[2022-02-17 05:32:10,495] {scheduler_job.py:155} INFO - Started process (PID=75887) to work on /airflow/dags/download_data.py
[2022-02-17 05:32:10,499] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:32:10,504] {logging_mixin.py:112} INFO - [2022-02-17 05:32:10,504] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:32:11,006] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:32:11,057] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:32:11,063] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:32:11,069] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 05:32:23,804] {scheduler_job.py:155} INFO - Started process (PID=75913) to work on /airflow/dags/download_data.py
[2022-02-17 05:32:23,810] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:32:23,811] {logging_mixin.py:112} INFO - [2022-02-17 05:32:23,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:32:24,275] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:32:24,327] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:32:24,332] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:32:24,336] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 05:32:37,074] {scheduler_job.py:155} INFO - Started process (PID=75939) to work on /airflow/dags/download_data.py
[2022-02-17 05:32:37,079] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:32:37,081] {logging_mixin.py:112} INFO - [2022-02-17 05:32:37,081] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:32:37,608] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:32:37,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:32:37,671] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:32:37,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-17 05:32:50,349] {scheduler_job.py:155} INFO - Started process (PID=75967) to work on /airflow/dags/download_data.py
[2022-02-17 05:32:50,360] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:32:50,362] {logging_mixin.py:112} INFO - [2022-02-17 05:32:50,361] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:32:50,818] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:32:50,883] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:32:50,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:32:50,900] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 05:33:03,660] {scheduler_job.py:155} INFO - Started process (PID=75993) to work on /airflow/dags/download_data.py
[2022-02-17 05:33:03,670] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:33:03,671] {logging_mixin.py:112} INFO - [2022-02-17 05:33:03,671] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:33:04,197] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:33:04,259] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:33:04,270] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:33:04,274] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-17 05:33:17,025] {scheduler_job.py:155} INFO - Started process (PID=76021) to work on /airflow/dags/download_data.py
[2022-02-17 05:33:17,034] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:33:17,038] {logging_mixin.py:112} INFO - [2022-02-17 05:33:17,038] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:33:17,607] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:33:17,658] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:33:17,666] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:33:17,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.650 seconds
[2022-02-17 05:33:30,303] {scheduler_job.py:155} INFO - Started process (PID=76047) to work on /airflow/dags/download_data.py
[2022-02-17 05:33:30,310] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:33:30,311] {logging_mixin.py:112} INFO - [2022-02-17 05:33:30,311] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:33:30,801] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:33:30,866] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:33:30,874] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:33:30,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 05:33:43,565] {scheduler_job.py:155} INFO - Started process (PID=76075) to work on /airflow/dags/download_data.py
[2022-02-17 05:33:43,570] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:33:43,571] {logging_mixin.py:112} INFO - [2022-02-17 05:33:43,571] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:33:44,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:33:44,083] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:33:44,090] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:33:44,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 05:33:56,890] {scheduler_job.py:155} INFO - Started process (PID=76101) to work on /airflow/dags/download_data.py
[2022-02-17 05:33:56,898] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:33:56,901] {logging_mixin.py:112} INFO - [2022-02-17 05:33:56,901] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:33:57,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:33:57,423] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:33:57,434] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:33:57,440] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 05:34:10,145] {scheduler_job.py:155} INFO - Started process (PID=76129) to work on /airflow/dags/download_data.py
[2022-02-17 05:34:10,154] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:34:10,156] {logging_mixin.py:112} INFO - [2022-02-17 05:34:10,156] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:34:10,843] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:34:10,892] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:34:10,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:34:10,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.759 seconds
[2022-02-17 05:34:23,424] {scheduler_job.py:155} INFO - Started process (PID=76155) to work on /airflow/dags/download_data.py
[2022-02-17 05:34:23,431] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:34:23,432] {logging_mixin.py:112} INFO - [2022-02-17 05:34:23,432] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:34:23,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:34:23,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:34:23,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:34:23,953] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 05:34:36,687] {scheduler_job.py:155} INFO - Started process (PID=76181) to work on /airflow/dags/download_data.py
[2022-02-17 05:34:36,694] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:34:36,696] {logging_mixin.py:112} INFO - [2022-02-17 05:34:36,696] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:34:37,134] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:34:37,189] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:34:37,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:34:37,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 05:34:49,954] {scheduler_job.py:155} INFO - Started process (PID=76209) to work on /airflow/dags/download_data.py
[2022-02-17 05:34:49,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:34:49,963] {logging_mixin.py:112} INFO - [2022-02-17 05:34:49,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:34:50,416] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:34:50,466] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:34:50,477] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:34:50,483] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 05:35:03,221] {scheduler_job.py:155} INFO - Started process (PID=76235) to work on /airflow/dags/download_data.py
[2022-02-17 05:35:03,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:35:03,229] {logging_mixin.py:112} INFO - [2022-02-17 05:35:03,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:35:03,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:35:03,977] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:35:03,990] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:35:03,997] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.776 seconds
[2022-02-17 05:35:16,509] {scheduler_job.py:155} INFO - Started process (PID=76263) to work on /airflow/dags/download_data.py
[2022-02-17 05:35:16,514] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:35:16,516] {logging_mixin.py:112} INFO - [2022-02-17 05:35:16,516] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:35:17,021] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:35:17,063] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:35:17,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:35:17,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 05:35:29,855] {scheduler_job.py:155} INFO - Started process (PID=76289) to work on /airflow/dags/download_data.py
[2022-02-17 05:35:29,860] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:35:29,862] {logging_mixin.py:112} INFO - [2022-02-17 05:35:29,862] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:35:30,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:35:30,407] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:35:30,420] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:35:30,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 05:35:43,089] {scheduler_job.py:155} INFO - Started process (PID=76317) to work on /airflow/dags/download_data.py
[2022-02-17 05:35:43,094] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:35:43,096] {logging_mixin.py:112} INFO - [2022-02-17 05:35:43,095] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:35:43,582] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:35:43,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:35:43,660] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:35:43,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 05:35:56,485] {scheduler_job.py:155} INFO - Started process (PID=76343) to work on /airflow/dags/download_data.py
[2022-02-17 05:35:56,490] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:35:56,493] {logging_mixin.py:112} INFO - [2022-02-17 05:35:56,493] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:35:57,119] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:35:57,179] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:35:57,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:35:57,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.720 seconds
[2022-02-17 05:36:09,729] {scheduler_job.py:155} INFO - Started process (PID=76369) to work on /airflow/dags/download_data.py
[2022-02-17 05:36:09,736] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:36:09,739] {logging_mixin.py:112} INFO - [2022-02-17 05:36:09,738] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:36:10,242] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:36:10,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:36:10,349] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:36:10,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.627 seconds
[2022-02-17 05:36:23,025] {scheduler_job.py:155} INFO - Started process (PID=76397) to work on /airflow/dags/download_data.py
[2022-02-17 05:36:23,037] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:36:23,038] {logging_mixin.py:112} INFO - [2022-02-17 05:36:23,038] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:36:23,549] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:36:23,608] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:36:23,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:36:23,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-17 05:36:36,309] {scheduler_job.py:155} INFO - Started process (PID=76423) to work on /airflow/dags/download_data.py
[2022-02-17 05:36:36,316] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:36:36,318] {logging_mixin.py:112} INFO - [2022-02-17 05:36:36,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:36:36,763] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:36:36,813] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:36:36,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:36:36,831] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 05:36:49,606] {scheduler_job.py:155} INFO - Started process (PID=76451) to work on /airflow/dags/download_data.py
[2022-02-17 05:36:49,618] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:36:49,621] {logging_mixin.py:112} INFO - [2022-02-17 05:36:49,620] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:36:50,048] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:36:50,097] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:36:50,109] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:36:50,115] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 05:37:02,939] {scheduler_job.py:155} INFO - Started process (PID=76477) to work on /airflow/dags/download_data.py
[2022-02-17 05:37:02,945] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:37:02,948] {logging_mixin.py:112} INFO - [2022-02-17 05:37:02,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:37:03,463] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:37:03,513] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:37:03,523] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:37:03,528] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 05:37:16,189] {scheduler_job.py:155} INFO - Started process (PID=76505) to work on /airflow/dags/download_data.py
[2022-02-17 05:37:16,194] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:37:16,196] {logging_mixin.py:112} INFO - [2022-02-17 05:37:16,195] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:37:16,790] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:37:16,855] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:37:16,866] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:37:16,869] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.680 seconds
[2022-02-17 05:37:29,565] {scheduler_job.py:155} INFO - Started process (PID=76531) to work on /airflow/dags/download_data.py
[2022-02-17 05:37:29,576] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:37:29,579] {logging_mixin.py:112} INFO - [2022-02-17 05:37:29,578] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:37:30,375] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:37:30,438] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:37:30,450] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:37:30,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.905 seconds
[2022-02-17 05:37:42,839] {scheduler_job.py:155} INFO - Started process (PID=76557) to work on /airflow/dags/download_data.py
[2022-02-17 05:37:42,844] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:37:42,847] {logging_mixin.py:112} INFO - [2022-02-17 05:37:42,846] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:37:43,321] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:37:43,370] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:37:43,377] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:37:43,381] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 05:37:56,139] {scheduler_job.py:155} INFO - Started process (PID=76585) to work on /airflow/dags/download_data.py
[2022-02-17 05:37:56,149] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:37:56,151] {logging_mixin.py:112} INFO - [2022-02-17 05:37:56,151] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:37:56,665] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:37:56,723] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:37:56,730] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:37:56,734] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 05:38:09,449] {scheduler_job.py:155} INFO - Started process (PID=76611) to work on /airflow/dags/download_data.py
[2022-02-17 05:38:09,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:38:09,464] {logging_mixin.py:112} INFO - [2022-02-17 05:38:09,463] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:38:09,924] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:38:09,967] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:38:09,973] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:38:09,979] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 05:38:22,703] {scheduler_job.py:155} INFO - Started process (PID=76639) to work on /airflow/dags/download_data.py
[2022-02-17 05:38:22,713] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:38:22,715] {logging_mixin.py:112} INFO - [2022-02-17 05:38:22,714] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:38:23,200] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:38:23,260] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:38:23,270] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:38:23,278] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-17 05:38:35,983] {scheduler_job.py:155} INFO - Started process (PID=76665) to work on /airflow/dags/download_data.py
[2022-02-17 05:38:35,987] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:38:35,989] {logging_mixin.py:112} INFO - [2022-02-17 05:38:35,988] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:38:36,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:38:36,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:38:36,547] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:38:36,552] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 05:38:49,209] {scheduler_job.py:155} INFO - Started process (PID=76693) to work on /airflow/dags/download_data.py
[2022-02-17 05:38:49,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:38:49,215] {logging_mixin.py:112} INFO - [2022-02-17 05:38:49,215] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:38:49,673] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:38:49,727] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:38:49,740] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:38:49,745] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 05:39:02,507] {scheduler_job.py:155} INFO - Started process (PID=76719) to work on /airflow/dags/download_data.py
[2022-02-17 05:39:02,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:39:02,513] {logging_mixin.py:112} INFO - [2022-02-17 05:39:02,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:39:03,001] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:39:03,064] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:39:03,072] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:39:03,079] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 05:39:15,797] {scheduler_job.py:155} INFO - Started process (PID=76745) to work on /airflow/dags/download_data.py
[2022-02-17 05:39:15,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:39:15,807] {logging_mixin.py:112} INFO - [2022-02-17 05:39:15,806] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:39:16,508] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:39:16,562] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:39:16,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:39:16,593] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.796 seconds
[2022-02-17 05:39:29,114] {scheduler_job.py:155} INFO - Started process (PID=76773) to work on /airflow/dags/download_data.py
[2022-02-17 05:39:29,118] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:39:29,121] {logging_mixin.py:112} INFO - [2022-02-17 05:39:29,120] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:39:29,621] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:39:29,688] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:39:29,701] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:39:29,706] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 05:39:42,426] {scheduler_job.py:155} INFO - Started process (PID=76799) to work on /airflow/dags/download_data.py
[2022-02-17 05:39:42,431] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:39:42,433] {logging_mixin.py:112} INFO - [2022-02-17 05:39:42,433] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:39:43,591] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:39:43,637] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:39:43,646] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:39:43,656] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.230 seconds
[2022-02-17 05:39:56,760] {scheduler_job.py:155} INFO - Started process (PID=76827) to work on /airflow/dags/download_data.py
[2022-02-17 05:39:56,771] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:39:56,773] {logging_mixin.py:112} INFO - [2022-02-17 05:39:56,772] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:39:57,251] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:39:57,303] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:39:57,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:39:57,324] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 05:40:09,131] {scheduler_job.py:155} INFO - Started process (PID=76852) to work on /airflow/dags/download_data.py
[2022-02-17 05:40:09,138] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:40:09,142] {logging_mixin.py:112} INFO - [2022-02-17 05:40:09,141] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:40:11,496] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:40:11,607] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:40:11,619] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:40:11,628] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.497 seconds
[2022-02-17 05:40:23,481] {scheduler_job.py:155} INFO - Started process (PID=76880) to work on /airflow/dags/download_data.py
[2022-02-17 05:40:23,488] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:40:23,490] {logging_mixin.py:112} INFO - [2022-02-17 05:40:23,490] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:40:23,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:40:24,015] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:40:24,023] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:40:24,028] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 05:40:36,773] {scheduler_job.py:155} INFO - Started process (PID=76906) to work on /airflow/dags/download_data.py
[2022-02-17 05:40:36,778] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:40:36,779] {logging_mixin.py:112} INFO - [2022-02-17 05:40:36,779] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:40:37,247] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:40:37,303] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:40:37,315] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:40:37,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 05:40:50,013] {scheduler_job.py:155} INFO - Started process (PID=76934) to work on /airflow/dags/download_data.py
[2022-02-17 05:40:50,017] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:40:50,020] {logging_mixin.py:112} INFO - [2022-02-17 05:40:50,019] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:40:50,476] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:40:50,527] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:40:50,536] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:40:50,541] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 05:41:03,337] {scheduler_job.py:155} INFO - Started process (PID=76960) to work on /airflow/dags/download_data.py
[2022-02-17 05:41:03,342] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:41:03,344] {logging_mixin.py:112} INFO - [2022-02-17 05:41:03,344] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:41:03,831] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:41:03,886] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:41:03,897] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:41:03,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 05:41:16,584] {scheduler_job.py:155} INFO - Started process (PID=76986) to work on /airflow/dags/download_data.py
[2022-02-17 05:41:16,594] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:41:16,597] {logging_mixin.py:112} INFO - [2022-02-17 05:41:16,596] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:41:17,089] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:41:17,155] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:41:17,164] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:41:17,170] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 05:41:29,888] {scheduler_job.py:155} INFO - Started process (PID=77014) to work on /airflow/dags/download_data.py
[2022-02-17 05:41:29,894] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:41:29,895] {logging_mixin.py:112} INFO - [2022-02-17 05:41:29,895] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:41:30,404] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:41:30,471] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:41:30,484] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:41:30,498] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-17 05:41:43,143] {scheduler_job.py:155} INFO - Started process (PID=77040) to work on /airflow/dags/download_data.py
[2022-02-17 05:41:43,149] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:41:43,170] {logging_mixin.py:112} INFO - [2022-02-17 05:41:43,170] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:41:43,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:41:43,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:41:43,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:41:43,793] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.650 seconds
[2022-02-17 05:41:56,433] {scheduler_job.py:155} INFO - Started process (PID=77068) to work on /airflow/dags/download_data.py
[2022-02-17 05:41:56,437] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:41:56,439] {logging_mixin.py:112} INFO - [2022-02-17 05:41:56,439] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:41:56,933] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:41:56,981] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:41:56,990] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:41:56,997] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 05:42:09,697] {scheduler_job.py:155} INFO - Started process (PID=77094) to work on /airflow/dags/download_data.py
[2022-02-17 05:42:09,702] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:42:09,703] {logging_mixin.py:112} INFO - [2022-02-17 05:42:09,703] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:42:10,376] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:42:10,441] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:42:10,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:42:10,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.760 seconds
[2022-02-17 05:42:22,999] {scheduler_job.py:155} INFO - Started process (PID=77122) to work on /airflow/dags/download_data.py
[2022-02-17 05:42:23,019] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:42:23,022] {logging_mixin.py:112} INFO - [2022-02-17 05:42:23,021] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:42:23,476] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:42:23,528] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:42:23,534] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:42:23,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 05:42:36,299] {scheduler_job.py:155} INFO - Started process (PID=77148) to work on /airflow/dags/download_data.py
[2022-02-17 05:42:36,308] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:42:36,310] {logging_mixin.py:112} INFO - [2022-02-17 05:42:36,310] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:42:36,837] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:42:36,886] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:42:36,901] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:42:36,913] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-17 05:42:49,520] {scheduler_job.py:155} INFO - Started process (PID=77174) to work on /airflow/dags/download_data.py
[2022-02-17 05:42:49,526] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:42:49,528] {logging_mixin.py:112} INFO - [2022-02-17 05:42:49,527] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:42:50,035] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:42:50,085] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:42:50,095] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:42:50,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 05:43:02,806] {scheduler_job.py:155} INFO - Started process (PID=77202) to work on /airflow/dags/download_data.py
[2022-02-17 05:43:02,812] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:43:02,815] {logging_mixin.py:112} INFO - [2022-02-17 05:43:02,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:43:03,295] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:43:03,358] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:43:03,370] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:43:03,375] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 05:43:16,129] {scheduler_job.py:155} INFO - Started process (PID=77228) to work on /airflow/dags/download_data.py
[2022-02-17 05:43:16,139] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:43:16,141] {logging_mixin.py:112} INFO - [2022-02-17 05:43:16,141] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:43:16,637] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:43:16,687] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:43:16,695] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:43:16,700] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 05:43:29,412] {scheduler_job.py:155} INFO - Started process (PID=77256) to work on /airflow/dags/download_data.py
[2022-02-17 05:43:29,423] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:43:29,428] {logging_mixin.py:112} INFO - [2022-02-17 05:43:29,428] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:43:30,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:43:30,088] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:43:30,103] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:43:30,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-17 05:43:42,668] {scheduler_job.py:155} INFO - Started process (PID=77282) to work on /airflow/dags/download_data.py
[2022-02-17 05:43:42,683] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:43:42,710] {logging_mixin.py:112} INFO - [2022-02-17 05:43:42,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:43:43,226] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:43:43,280] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:43:43,301] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:43:43,306] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-17 05:43:56,013] {scheduler_job.py:155} INFO - Started process (PID=77310) to work on /airflow/dags/download_data.py
[2022-02-17 05:43:56,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:43:56,034] {logging_mixin.py:112} INFO - [2022-02-17 05:43:56,034] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:43:56,581] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:43:56,646] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:43:56,653] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:43:56,660] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-17 05:44:09,261] {scheduler_job.py:155} INFO - Started process (PID=77336) to work on /airflow/dags/download_data.py
[2022-02-17 05:44:09,271] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:44:09,272] {logging_mixin.py:112} INFO - [2022-02-17 05:44:09,272] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:44:09,753] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:44:09,805] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:44:09,814] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:44:09,820] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 05:44:22,556] {scheduler_job.py:155} INFO - Started process (PID=77364) to work on /airflow/dags/download_data.py
[2022-02-17 05:44:22,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:44:22,571] {logging_mixin.py:112} INFO - [2022-02-17 05:44:22,571] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:44:23,200] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:44:23,247] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:44:23,264] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:44:23,285] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.730 seconds
[2022-02-17 05:44:35,853] {scheduler_job.py:155} INFO - Started process (PID=77390) to work on /airflow/dags/download_data.py
[2022-02-17 05:44:35,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:44:35,862] {logging_mixin.py:112} INFO - [2022-02-17 05:44:35,862] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:44:36,397] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:44:36,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:44:36,464] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:44:36,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-17 05:44:49,182] {scheduler_job.py:155} INFO - Started process (PID=77416) to work on /airflow/dags/download_data.py
[2022-02-17 05:44:49,197] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:44:49,200] {logging_mixin.py:112} INFO - [2022-02-17 05:44:49,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:44:49,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:44:49,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:44:49,950] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:44:49,956] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.774 seconds
[2022-02-17 05:45:02,471] {scheduler_job.py:155} INFO - Started process (PID=77444) to work on /airflow/dags/download_data.py
[2022-02-17 05:45:02,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:45:02,499] {logging_mixin.py:112} INFO - [2022-02-17 05:45:02,499] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:45:03,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:45:03,520] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:45:03,551] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:45:03,556] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.085 seconds
[2022-02-17 05:45:16,792] {scheduler_job.py:155} INFO - Started process (PID=77470) to work on /airflow/dags/download_data.py
[2022-02-17 05:45:16,804] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:45:16,806] {logging_mixin.py:112} INFO - [2022-02-17 05:45:16,805] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:45:17,410] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:45:17,447] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:45:17,455] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:45:17,459] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.668 seconds
[2022-02-17 05:45:29,094] {scheduler_job.py:155} INFO - Started process (PID=77497) to work on /airflow/dags/download_data.py
[2022-02-17 05:45:29,104] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:45:29,108] {logging_mixin.py:112} INFO - [2022-02-17 05:45:29,107] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:45:29,699] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:45:29,756] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:45:29,769] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:45:29,776] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.682 seconds
[2022-02-17 05:45:42,437] {scheduler_job.py:155} INFO - Started process (PID=77523) to work on /airflow/dags/download_data.py
[2022-02-17 05:45:42,450] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:45:42,452] {logging_mixin.py:112} INFO - [2022-02-17 05:45:42,452] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:45:43,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:45:43,074] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:45:43,083] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:45:43,090] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-17 05:45:55,758] {scheduler_job.py:155} INFO - Started process (PID=77551) to work on /airflow/dags/download_data.py
[2022-02-17 05:45:55,766] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:45:55,768] {logging_mixin.py:112} INFO - [2022-02-17 05:45:55,768] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:45:56,297] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:45:56,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:45:56,363] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:45:56,369] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-17 05:46:09,076] {scheduler_job.py:155} INFO - Started process (PID=77577) to work on /airflow/dags/download_data.py
[2022-02-17 05:46:09,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:46:09,085] {logging_mixin.py:112} INFO - [2022-02-17 05:46:09,085] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:46:09,578] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:46:09,634] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:46:09,643] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:46:09,652] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-17 05:46:22,360] {scheduler_job.py:155} INFO - Started process (PID=77603) to work on /airflow/dags/download_data.py
[2022-02-17 05:46:22,371] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:46:22,375] {logging_mixin.py:112} INFO - [2022-02-17 05:46:22,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:46:22,940] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:46:23,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:46:23,025] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:46:23,033] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.673 seconds
[2022-02-17 05:46:35,663] {scheduler_job.py:155} INFO - Started process (PID=77631) to work on /airflow/dags/download_data.py
[2022-02-17 05:46:35,672] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:46:35,675] {logging_mixin.py:112} INFO - [2022-02-17 05:46:35,674] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:46:36,151] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:46:36,203] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:46:36,217] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:46:36,222] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 05:46:48,925] {scheduler_job.py:155} INFO - Started process (PID=77657) to work on /airflow/dags/download_data.py
[2022-02-17 05:46:48,932] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:46:48,935] {logging_mixin.py:112} INFO - [2022-02-17 05:46:48,934] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:46:49,424] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:46:49,478] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:46:49,488] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:46:49,494] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 05:47:02,229] {scheduler_job.py:155} INFO - Started process (PID=77685) to work on /airflow/dags/download_data.py
[2022-02-17 05:47:02,237] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:47:02,242] {logging_mixin.py:112} INFO - [2022-02-17 05:47:02,241] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:47:02,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:47:02,845] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:47:02,853] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:47:02,859] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-17 05:47:15,507] {scheduler_job.py:155} INFO - Started process (PID=77711) to work on /airflow/dags/download_data.py
[2022-02-17 05:47:15,522] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:47:15,526] {logging_mixin.py:112} INFO - [2022-02-17 05:47:15,525] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:47:16,401] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:47:16,450] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:47:16,464] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:47:16,473] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.966 seconds
[2022-02-17 05:47:28,844] {scheduler_job.py:155} INFO - Started process (PID=77739) to work on /airflow/dags/download_data.py
[2022-02-17 05:47:28,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:47:28,851] {logging_mixin.py:112} INFO - [2022-02-17 05:47:28,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:47:29,355] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:47:29,400] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:47:29,412] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:47:29,423] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-17 05:47:42,126] {scheduler_job.py:155} INFO - Started process (PID=77765) to work on /airflow/dags/download_data.py
[2022-02-17 05:47:42,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:47:42,135] {logging_mixin.py:112} INFO - [2022-02-17 05:47:42,135] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:47:42,752] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:47:42,798] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:47:42,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:47:42,813] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.687 seconds
[2022-02-17 05:47:55,431] {scheduler_job.py:155} INFO - Started process (PID=77791) to work on /airflow/dags/download_data.py
[2022-02-17 05:47:55,439] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:47:55,441] {logging_mixin.py:112} INFO - [2022-02-17 05:47:55,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:47:56,041] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:47:56,101] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:47:56,116] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:47:56,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.695 seconds
[2022-02-17 05:48:08,750] {scheduler_job.py:155} INFO - Started process (PID=77819) to work on /airflow/dags/download_data.py
[2022-02-17 05:48:08,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:48:08,766] {logging_mixin.py:112} INFO - [2022-02-17 05:48:08,766] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:48:09,314] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:48:09,367] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:48:09,372] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:48:09,377] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.627 seconds
[2022-02-17 05:48:22,070] {scheduler_job.py:155} INFO - Started process (PID=77845) to work on /airflow/dags/download_data.py
[2022-02-17 05:48:22,077] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:48:22,083] {logging_mixin.py:112} INFO - [2022-02-17 05:48:22,083] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:48:22,612] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:48:22,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:48:22,663] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:48:22,670] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 05:48:35,361] {scheduler_job.py:155} INFO - Started process (PID=77873) to work on /airflow/dags/download_data.py
[2022-02-17 05:48:35,367] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:48:35,368] {logging_mixin.py:112} INFO - [2022-02-17 05:48:35,368] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:48:35,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:48:35,982] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:48:35,995] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:48:36,001] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-17 05:48:48,667] {scheduler_job.py:155} INFO - Started process (PID=77899) to work on /airflow/dags/download_data.py
[2022-02-17 05:48:48,674] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:48:48,677] {logging_mixin.py:112} INFO - [2022-02-17 05:48:48,676] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:48:49,164] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:48:49,215] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:48:49,224] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:48:49,232] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 05:49:01,988] {scheduler_job.py:155} INFO - Started process (PID=77927) to work on /airflow/dags/download_data.py
[2022-02-17 05:49:02,001] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:49:02,003] {logging_mixin.py:112} INFO - [2022-02-17 05:49:02,003] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:49:02,591] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:49:02,634] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:49:02,644] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:49:02,651] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.663 seconds
[2022-02-17 05:49:15,285] {scheduler_job.py:155} INFO - Started process (PID=77953) to work on /airflow/dags/download_data.py
[2022-02-17 05:49:15,294] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:49:15,297] {logging_mixin.py:112} INFO - [2022-02-17 05:49:15,296] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:49:15,888] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:49:15,941] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:49:15,950] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:49:15,959] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.674 seconds
[2022-02-17 05:49:28,582] {scheduler_job.py:155} INFO - Started process (PID=77979) to work on /airflow/dags/download_data.py
[2022-02-17 05:49:28,587] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:49:28,589] {logging_mixin.py:112} INFO - [2022-02-17 05:49:28,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:49:29,158] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:49:29,223] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:49:29,234] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:49:29,240] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.658 seconds
[2022-02-17 05:49:41,922] {scheduler_job.py:155} INFO - Started process (PID=78007) to work on /airflow/dags/download_data.py
[2022-02-17 05:49:41,929] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:49:41,932] {logging_mixin.py:112} INFO - [2022-02-17 05:49:41,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:49:42,397] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:49:42,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:49:42,479] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:49:42,485] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 05:49:55,243] {scheduler_job.py:155} INFO - Started process (PID=78033) to work on /airflow/dags/download_data.py
[2022-02-17 05:49:55,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:49:55,257] {logging_mixin.py:112} INFO - [2022-02-17 05:49:55,257] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:49:55,803] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:49:55,859] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:49:55,871] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:49:55,876] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-17 05:50:08,544] {scheduler_job.py:155} INFO - Started process (PID=78061) to work on /airflow/dags/download_data.py
[2022-02-17 05:50:08,552] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:50:08,554] {logging_mixin.py:112} INFO - [2022-02-17 05:50:08,554] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:50:09,092] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:50:09,134] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:50:09,145] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:50:09,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 05:50:21,845] {scheduler_job.py:155} INFO - Started process (PID=78087) to work on /airflow/dags/download_data.py
[2022-02-17 05:50:21,858] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:50:21,866] {logging_mixin.py:112} INFO - [2022-02-17 05:50:21,864] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:50:22,960] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:50:23,223] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:50:23,251] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:50:23,273] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.428 seconds
[2022-02-17 05:50:36,227] {scheduler_job.py:155} INFO - Started process (PID=78115) to work on /airflow/dags/download_data.py
[2022-02-17 05:50:36,236] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:50:36,239] {logging_mixin.py:112} INFO - [2022-02-17 05:50:36,239] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:50:36,776] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:50:36,825] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:50:36,836] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:50:36,844] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 05:50:48,525] {scheduler_job.py:155} INFO - Started process (PID=78140) to work on /airflow/dags/download_data.py
[2022-02-17 05:50:48,539] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:50:48,541] {logging_mixin.py:112} INFO - [2022-02-17 05:50:48,541] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:50:49,036] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:50:49,096] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:50:49,105] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:50:49,115] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 05:51:01,839] {scheduler_job.py:155} INFO - Started process (PID=78168) to work on /airflow/dags/download_data.py
[2022-02-17 05:51:01,852] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:51:01,859] {logging_mixin.py:112} INFO - [2022-02-17 05:51:01,859] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:51:02,497] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:51:02,550] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:51:02,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:51:02,569] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.730 seconds
[2022-02-17 05:51:15,115] {scheduler_job.py:155} INFO - Started process (PID=78194) to work on /airflow/dags/download_data.py
[2022-02-17 05:51:15,119] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:51:15,120] {logging_mixin.py:112} INFO - [2022-02-17 05:51:15,120] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:51:15,615] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:51:15,660] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:51:15,668] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:51:15,674] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 05:51:28,420] {scheduler_job.py:155} INFO - Started process (PID=78220) to work on /airflow/dags/download_data.py
[2022-02-17 05:51:28,425] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:51:28,427] {logging_mixin.py:112} INFO - [2022-02-17 05:51:28,427] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:51:28,932] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:51:28,985] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:51:28,994] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:51:29,000] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-17 05:51:41,672] {scheduler_job.py:155} INFO - Started process (PID=78248) to work on /airflow/dags/download_data.py
[2022-02-17 05:51:41,676] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:51:41,678] {logging_mixin.py:112} INFO - [2022-02-17 05:51:41,678] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:51:42,192] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:51:42,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:51:42,259] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:51:42,269] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-17 05:51:54,972] {scheduler_job.py:155} INFO - Started process (PID=78274) to work on /airflow/dags/download_data.py
[2022-02-17 05:51:54,977] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:51:54,979] {logging_mixin.py:112} INFO - [2022-02-17 05:51:54,979] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:51:55,480] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:51:55,537] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:51:55,548] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:51:55,552] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-17 05:52:08,229] {scheduler_job.py:155} INFO - Started process (PID=78302) to work on /airflow/dags/download_data.py
[2022-02-17 05:52:08,237] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:52:08,239] {logging_mixin.py:112} INFO - [2022-02-17 05:52:08,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:52:08,713] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:52:08,768] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:52:08,774] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:52:08,781] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 05:52:21,532] {scheduler_job.py:155} INFO - Started process (PID=78328) to work on /airflow/dags/download_data.py
[2022-02-17 05:52:21,548] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:52:21,554] {logging_mixin.py:112} INFO - [2022-02-17 05:52:21,553] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:52:22,132] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:52:22,189] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:52:22,199] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:52:22,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.674 seconds
[2022-02-17 05:52:34,831] {scheduler_job.py:155} INFO - Started process (PID=78356) to work on /airflow/dags/download_data.py
[2022-02-17 05:52:34,839] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:52:34,842] {logging_mixin.py:112} INFO - [2022-02-17 05:52:34,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:52:35,377] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:52:35,429] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:52:35,437] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:52:35,448] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 05:52:48,104] {scheduler_job.py:155} INFO - Started process (PID=78382) to work on /airflow/dags/download_data.py
[2022-02-17 05:52:48,118] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:52:48,120] {logging_mixin.py:112} INFO - [2022-02-17 05:52:48,120] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:52:48,619] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:52:48,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:52:48,676] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:52:48,681] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 05:53:01,369] {scheduler_job.py:155} INFO - Started process (PID=78408) to work on /airflow/dags/download_data.py
[2022-02-17 05:53:01,376] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:53:01,377] {logging_mixin.py:112} INFO - [2022-02-17 05:53:01,377] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:53:01,973] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:53:02,027] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:53:02,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:53:02,041] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-17 05:53:14,632] {scheduler_job.py:155} INFO - Started process (PID=78436) to work on /airflow/dags/download_data.py
[2022-02-17 05:53:14,636] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:53:14,639] {logging_mixin.py:112} INFO - [2022-02-17 05:53:14,639] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:53:15,107] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:53:15,163] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:53:15,170] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:53:15,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 05:53:27,920] {scheduler_job.py:155} INFO - Started process (PID=78462) to work on /airflow/dags/download_data.py
[2022-02-17 05:53:27,925] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:53:27,927] {logging_mixin.py:112} INFO - [2022-02-17 05:53:27,926] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:53:28,411] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:53:28,460] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:53:28,469] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:53:28,476] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 05:53:41,194] {scheduler_job.py:155} INFO - Started process (PID=78490) to work on /airflow/dags/download_data.py
[2022-02-17 05:53:41,208] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:53:41,212] {logging_mixin.py:112} INFO - [2022-02-17 05:53:41,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:53:41,796] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:53:41,849] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:53:41,862] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:53:41,870] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.676 seconds
[2022-02-17 05:53:54,473] {scheduler_job.py:155} INFO - Started process (PID=78516) to work on /airflow/dags/download_data.py
[2022-02-17 05:53:54,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:53:54,479] {logging_mixin.py:112} INFO - [2022-02-17 05:53:54,479] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:53:54,950] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:53:54,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:53:55,002] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:53:55,006] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 05:54:07,724] {scheduler_job.py:155} INFO - Started process (PID=78544) to work on /airflow/dags/download_data.py
[2022-02-17 05:54:07,730] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:54:07,732] {logging_mixin.py:112} INFO - [2022-02-17 05:54:07,732] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:54:08,287] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:54:08,343] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:54:08,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:54:08,354] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-17 05:54:21,098] {scheduler_job.py:155} INFO - Started process (PID=78570) to work on /airflow/dags/download_data.py
[2022-02-17 05:54:21,115] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:54:21,117] {logging_mixin.py:112} INFO - [2022-02-17 05:54:21,117] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:54:21,799] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:54:21,869] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:54:21,885] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:54:21,897] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.799 seconds
[2022-02-17 05:54:34,393] {scheduler_job.py:155} INFO - Started process (PID=78596) to work on /airflow/dags/download_data.py
[2022-02-17 05:54:34,400] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:54:34,403] {logging_mixin.py:112} INFO - [2022-02-17 05:54:34,402] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:54:34,844] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:54:34,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:54:34,905] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:54:34,910] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 05:54:47,621] {scheduler_job.py:155} INFO - Started process (PID=78624) to work on /airflow/dags/download_data.py
[2022-02-17 05:54:47,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:54:47,629] {logging_mixin.py:112} INFO - [2022-02-17 05:54:47,628] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:54:48,086] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:54:48,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:54:48,144] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:54:48,148] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 05:55:00,958] {scheduler_job.py:155} INFO - Started process (PID=78650) to work on /airflow/dags/download_data.py
[2022-02-17 05:55:00,965] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:55:00,968] {logging_mixin.py:112} INFO - [2022-02-17 05:55:00,967] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:55:01,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:55:01,564] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:55:01,576] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:55:01,580] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-17 05:55:14,166] {scheduler_job.py:155} INFO - Started process (PID=78678) to work on /airflow/dags/download_data.py
[2022-02-17 05:55:14,171] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:55:14,173] {logging_mixin.py:112} INFO - [2022-02-17 05:55:14,173] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:55:14,753] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:55:14,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:55:14,811] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:55:14,820] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.655 seconds
[2022-02-17 05:55:27,465] {scheduler_job.py:155} INFO - Started process (PID=78704) to work on /airflow/dags/download_data.py
[2022-02-17 05:55:27,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:55:27,472] {logging_mixin.py:112} INFO - [2022-02-17 05:55:27,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:55:27,924] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:55:27,982] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:55:27,995] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:55:27,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 05:55:40,712] {scheduler_job.py:155} INFO - Started process (PID=78732) to work on /airflow/dags/download_data.py
[2022-02-17 05:55:40,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:55:40,718] {logging_mixin.py:112} INFO - [2022-02-17 05:55:40,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:55:41,204] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:55:41,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:55:41,260] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:55:41,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 05:55:54,075] {scheduler_job.py:155} INFO - Started process (PID=78758) to work on /airflow/dags/download_data.py
[2022-02-17 05:55:54,083] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:55:54,085] {logging_mixin.py:112} INFO - [2022-02-17 05:55:54,085] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:55:54,549] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:55:54,608] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:55:54,634] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:55:54,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 05:56:07,339] {scheduler_job.py:155} INFO - Started process (PID=78784) to work on /airflow/dags/download_data.py
[2022-02-17 05:56:07,343] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:56:07,345] {logging_mixin.py:112} INFO - [2022-02-17 05:56:07,345] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:56:07,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:56:07,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:56:07,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:56:07,952] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-17 05:56:20,668] {scheduler_job.py:155} INFO - Started process (PID=78812) to work on /airflow/dags/download_data.py
[2022-02-17 05:56:20,677] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:56:20,679] {logging_mixin.py:112} INFO - [2022-02-17 05:56:20,679] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:56:21,151] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:56:21,211] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:56:21,223] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:56:21,230] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 05:56:34,004] {scheduler_job.py:155} INFO - Started process (PID=78838) to work on /airflow/dags/download_data.py
[2022-02-17 05:56:34,011] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:56:34,013] {logging_mixin.py:112} INFO - [2022-02-17 05:56:34,013] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:56:34,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:56:34,681] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:56:34,689] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:56:34,695] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.691 seconds
[2022-02-17 05:56:47,284] {scheduler_job.py:155} INFO - Started process (PID=78866) to work on /airflow/dags/download_data.py
[2022-02-17 05:56:47,290] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:56:47,293] {logging_mixin.py:112} INFO - [2022-02-17 05:56:47,292] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:56:47,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:56:47,812] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:56:47,823] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:56:47,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 05:57:00,559] {scheduler_job.py:155} INFO - Started process (PID=78892) to work on /airflow/dags/download_data.py
[2022-02-17 05:57:00,563] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:57:00,566] {logging_mixin.py:112} INFO - [2022-02-17 05:57:00,565] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:57:01,046] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:57:01,098] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:57:01,106] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:57:01,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 05:57:13,797] {scheduler_job.py:155} INFO - Started process (PID=78920) to work on /airflow/dags/download_data.py
[2022-02-17 05:57:13,802] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:57:13,804] {logging_mixin.py:112} INFO - [2022-02-17 05:57:13,804] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:57:14,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:57:14,412] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:57:14,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:57:14,435] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-17 05:57:27,143] {scheduler_job.py:155} INFO - Started process (PID=78946) to work on /airflow/dags/download_data.py
[2022-02-17 05:57:27,148] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:57:27,150] {logging_mixin.py:112} INFO - [2022-02-17 05:57:27,150] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:57:27,681] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:57:27,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:57:27,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:57:27,754] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-17 05:57:40,396] {scheduler_job.py:155} INFO - Started process (PID=78974) to work on /airflow/dags/download_data.py
[2022-02-17 05:57:40,401] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:57:40,409] {logging_mixin.py:112} INFO - [2022-02-17 05:57:40,409] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:57:40,880] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:57:40,931] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:57:40,938] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:57:40,945] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 05:57:53,675] {scheduler_job.py:155} INFO - Started process (PID=79000) to work on /airflow/dags/download_data.py
[2022-02-17 05:57:53,680] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:57:53,681] {logging_mixin.py:112} INFO - [2022-02-17 05:57:53,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:57:54,156] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:57:54,216] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:57:54,224] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:57:54,234] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 05:58:06,953] {scheduler_job.py:155} INFO - Started process (PID=79026) to work on /airflow/dags/download_data.py
[2022-02-17 05:58:06,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:58:06,972] {logging_mixin.py:112} INFO - [2022-02-17 05:58:06,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:58:07,414] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:58:07,457] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:58:07,466] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:58:07,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 05:58:20,310] {scheduler_job.py:155} INFO - Started process (PID=79054) to work on /airflow/dags/download_data.py
[2022-02-17 05:58:20,319] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:58:20,324] {logging_mixin.py:112} INFO - [2022-02-17 05:58:20,323] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:58:21,060] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:58:21,119] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:58:21,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:58:21,140] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.830 seconds
[2022-02-17 05:58:33,660] {scheduler_job.py:155} INFO - Started process (PID=79080) to work on /airflow/dags/download_data.py
[2022-02-17 05:58:33,665] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:58:33,666] {logging_mixin.py:112} INFO - [2022-02-17 05:58:33,666] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:58:34,135] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:58:34,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:58:34,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:58:34,200] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 05:58:47,005] {scheduler_job.py:155} INFO - Started process (PID=79108) to work on /airflow/dags/download_data.py
[2022-02-17 05:58:47,016] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:58:47,018] {logging_mixin.py:112} INFO - [2022-02-17 05:58:47,018] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:58:47,551] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:58:47,603] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:58:47,612] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:58:47,619] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-17 05:59:00,345] {scheduler_job.py:155} INFO - Started process (PID=79134) to work on /airflow/dags/download_data.py
[2022-02-17 05:59:00,354] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:59:00,356] {logging_mixin.py:112} INFO - [2022-02-17 05:59:00,355] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:59:00,873] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:59:00,936] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:59:00,945] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:59:00,952] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-17 05:59:13,587] {scheduler_job.py:155} INFO - Started process (PID=79162) to work on /airflow/dags/download_data.py
[2022-02-17 05:59:13,591] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:59:13,593] {logging_mixin.py:112} INFO - [2022-02-17 05:59:13,592] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:59:14,058] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:59:14,105] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:59:14,113] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:59:14,122] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 05:59:26,922] {scheduler_job.py:155} INFO - Started process (PID=79188) to work on /airflow/dags/download_data.py
[2022-02-17 05:59:26,933] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:59:26,935] {logging_mixin.py:112} INFO - [2022-02-17 05:59:26,935] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:59:27,431] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:59:27,482] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:59:27,491] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:59:27,495] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 05:59:40,220] {scheduler_job.py:155} INFO - Started process (PID=79214) to work on /airflow/dags/download_data.py
[2022-02-17 05:59:40,228] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:59:40,230] {logging_mixin.py:112} INFO - [2022-02-17 05:59:40,230] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:59:40,857] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:59:40,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:59:40,955] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:59:40,961] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.742 seconds
[2022-02-17 05:59:53,542] {scheduler_job.py:155} INFO - Started process (PID=79242) to work on /airflow/dags/download_data.py
[2022-02-17 05:59:53,546] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 05:59:53,548] {logging_mixin.py:112} INFO - [2022-02-17 05:59:53,548] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 05:59:54,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 05:59:54,087] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 05:59:54,101] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 05:59:54,111] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 06:00:06,856] {scheduler_job.py:155} INFO - Started process (PID=79268) to work on /airflow/dags/download_data.py
[2022-02-17 06:00:06,862] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:00:06,864] {logging_mixin.py:112} INFO - [2022-02-17 06:00:06,864] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:00:07,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:00:07,412] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:00:07,421] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:00:07,427] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 06:00:20,227] {scheduler_job.py:155} INFO - Started process (PID=79296) to work on /airflow/dags/download_data.py
[2022-02-17 06:00:20,238] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:00:20,240] {logging_mixin.py:112} INFO - [2022-02-17 06:00:20,240] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:00:20,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:00:20,759] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:00:20,770] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:00:20,776] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 06:00:33,810] {scheduler_job.py:155} INFO - Started process (PID=79322) to work on /airflow/dags/download_data.py
[2022-02-17 06:00:33,817] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:00:33,819] {logging_mixin.py:112} INFO - [2022-02-17 06:00:33,819] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:00:34,866] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:00:34,950] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:00:34,965] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:00:34,976] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.166 seconds
[2022-02-17 06:00:48,230] {scheduler_job.py:155} INFO - Started process (PID=79350) to work on /airflow/dags/download_data.py
[2022-02-17 06:00:48,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:00:48,237] {logging_mixin.py:112} INFO - [2022-02-17 06:00:48,237] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:00:48,740] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:00:48,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:00:48,796] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:00:48,803] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 06:01:00,553] {scheduler_job.py:155} INFO - Started process (PID=79375) to work on /airflow/dags/download_data.py
[2022-02-17 06:01:00,557] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:01:00,559] {logging_mixin.py:112} INFO - [2022-02-17 06:01:00,559] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:01:01,038] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:01:01,083] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:01:01,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:01:01,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 06:01:13,823] {scheduler_job.py:155} INFO - Started process (PID=79401) to work on /airflow/dags/download_data.py
[2022-02-17 06:01:13,829] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:01:13,840] {logging_mixin.py:112} INFO - [2022-02-17 06:01:13,839] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:01:14,409] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:01:14,461] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:01:14,473] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:01:14,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.662 seconds
[2022-02-17 06:01:27,133] {scheduler_job.py:155} INFO - Started process (PID=79429) to work on /airflow/dags/download_data.py
[2022-02-17 06:01:27,138] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:01:27,140] {logging_mixin.py:112} INFO - [2022-02-17 06:01:27,140] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:01:27,628] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:01:27,673] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:01:27,681] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:01:27,689] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 06:01:40,420] {scheduler_job.py:155} INFO - Started process (PID=79455) to work on /airflow/dags/download_data.py
[2022-02-17 06:01:40,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:01:40,433] {logging_mixin.py:112} INFO - [2022-02-17 06:01:40,432] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:01:40,911] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:01:40,995] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:01:41,007] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:01:41,013] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 06:01:53,839] {scheduler_job.py:155} INFO - Started process (PID=79483) to work on /airflow/dags/download_data.py
[2022-02-17 06:01:53,845] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:01:53,856] {logging_mixin.py:112} INFO - [2022-02-17 06:01:53,856] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:01:54,349] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:01:54,387] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:01:54,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:01:54,398] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 06:02:07,313] {scheduler_job.py:155} INFO - Started process (PID=79509) to work on /airflow/dags/download_data.py
[2022-02-17 06:02:07,320] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:02:07,323] {logging_mixin.py:112} INFO - [2022-02-17 06:02:07,322] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:02:08,029] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:02:08,083] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:02:08,090] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:02:08,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.783 seconds
[2022-02-17 06:02:20,620] {scheduler_job.py:155} INFO - Started process (PID=79537) to work on /airflow/dags/download_data.py
[2022-02-17 06:02:20,627] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:02:20,629] {logging_mixin.py:112} INFO - [2022-02-17 06:02:20,629] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:02:21,140] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:02:21,192] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:02:21,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:02:21,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 06:02:33,947] {scheduler_job.py:155} INFO - Started process (PID=79563) to work on /airflow/dags/download_data.py
[2022-02-17 06:02:33,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:02:33,959] {logging_mixin.py:112} INFO - [2022-02-17 06:02:33,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:02:34,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:02:34,923] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:02:34,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:02:34,975] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.028 seconds
[2022-02-17 06:02:48,402] {scheduler_job.py:155} INFO - Started process (PID=79590) to work on /airflow/dags/download_data.py
[2022-02-17 06:02:48,410] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:02:48,413] {logging_mixin.py:112} INFO - [2022-02-17 06:02:48,412] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:02:51,685] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:02:51,770] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:02:51,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:02:51,801] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 3.400 seconds
[2022-02-17 06:03:02,836] {scheduler_job.py:155} INFO - Started process (PID=79616) to work on /airflow/dags/download_data.py
[2022-02-17 06:03:02,842] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:03:02,844] {logging_mixin.py:112} INFO - [2022-02-17 06:03:02,844] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:03:03,330] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:03:03,376] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:03:03,384] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:03:03,391] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 06:03:16,225] {scheduler_job.py:155} INFO - Started process (PID=79642) to work on /airflow/dags/download_data.py
[2022-02-17 06:03:16,229] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:03:16,231] {logging_mixin.py:112} INFO - [2022-02-17 06:03:16,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:03:16,724] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:03:16,769] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:03:16,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:03:16,782] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 06:03:29,493] {scheduler_job.py:155} INFO - Started process (PID=79670) to work on /airflow/dags/download_data.py
[2022-02-17 06:03:29,498] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:03:29,500] {logging_mixin.py:112} INFO - [2022-02-17 06:03:29,500] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:03:29,967] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:03:30,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:03:30,033] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:03:30,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 06:03:42,776] {scheduler_job.py:155} INFO - Started process (PID=79696) to work on /airflow/dags/download_data.py
[2022-02-17 06:03:42,781] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:03:42,784] {logging_mixin.py:112} INFO - [2022-02-17 06:03:42,783] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:03:43,335] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:03:43,390] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:03:43,398] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:03:43,406] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-17 06:03:56,037] {scheduler_job.py:155} INFO - Started process (PID=79724) to work on /airflow/dags/download_data.py
[2022-02-17 06:03:56,041] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:03:56,043] {logging_mixin.py:112} INFO - [2022-02-17 06:03:56,042] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:03:56,491] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:03:56,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:03:56,537] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:03:56,541] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 06:04:09,271] {scheduler_job.py:155} INFO - Started process (PID=79750) to work on /airflow/dags/download_data.py
[2022-02-17 06:04:09,275] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:04:09,277] {logging_mixin.py:112} INFO - [2022-02-17 06:04:09,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:04:09,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:04:09,767] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:04:09,775] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:04:09,780] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 06:04:22,563] {scheduler_job.py:155} INFO - Started process (PID=79778) to work on /airflow/dags/download_data.py
[2022-02-17 06:04:22,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:04:22,582] {logging_mixin.py:112} INFO - [2022-02-17 06:04:22,581] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:04:23,127] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:04:23,181] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:04:23,194] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:04:23,202] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-17 06:04:35,877] {scheduler_job.py:155} INFO - Started process (PID=79804) to work on /airflow/dags/download_data.py
[2022-02-17 06:04:35,884] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:04:35,886] {logging_mixin.py:112} INFO - [2022-02-17 06:04:35,886] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:04:36,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:04:36,387] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:04:36,397] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:04:36,402] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 06:04:49,107] {scheduler_job.py:155} INFO - Started process (PID=79830) to work on /airflow/dags/download_data.py
[2022-02-17 06:04:49,111] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:04:49,113] {logging_mixin.py:112} INFO - [2022-02-17 06:04:49,113] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:04:49,718] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:04:49,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:04:49,795] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:04:49,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.697 seconds
[2022-02-17 06:05:02,405] {scheduler_job.py:155} INFO - Started process (PID=79858) to work on /airflow/dags/download_data.py
[2022-02-17 06:05:02,409] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:05:02,410] {logging_mixin.py:112} INFO - [2022-02-17 06:05:02,410] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:05:02,894] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:05:02,930] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:05:02,937] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:05:02,942] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 06:05:15,698] {scheduler_job.py:155} INFO - Started process (PID=79884) to work on /airflow/dags/download_data.py
[2022-02-17 06:05:15,702] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:05:15,706] {logging_mixin.py:112} INFO - [2022-02-17 06:05:15,705] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:05:16,166] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:05:16,214] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:05:16,221] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:05:16,226] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 06:05:28,968] {scheduler_job.py:155} INFO - Started process (PID=79912) to work on /airflow/dags/download_data.py
[2022-02-17 06:05:28,980] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:05:28,983] {logging_mixin.py:112} INFO - [2022-02-17 06:05:28,983] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:05:29,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:05:29,514] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:05:29,524] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:05:29,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 06:05:42,248] {scheduler_job.py:155} INFO - Started process (PID=79938) to work on /airflow/dags/download_data.py
[2022-02-17 06:05:42,255] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:05:42,257] {logging_mixin.py:112} INFO - [2022-02-17 06:05:42,257] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:05:42,770] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:05:42,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:05:42,823] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:05:42,829] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 06:05:55,599] {scheduler_job.py:155} INFO - Started process (PID=79966) to work on /airflow/dags/download_data.py
[2022-02-17 06:05:55,606] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:05:55,607] {logging_mixin.py:112} INFO - [2022-02-17 06:05:55,607] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:05:56,181] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:05:56,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:05:56,260] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:05:56,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-17 06:06:08,874] {scheduler_job.py:155} INFO - Started process (PID=79992) to work on /airflow/dags/download_data.py
[2022-02-17 06:06:08,879] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:06:08,880] {logging_mixin.py:112} INFO - [2022-02-17 06:06:08,880] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:06:09,403] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:06:09,448] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:06:09,456] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:06:09,461] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 06:06:22,187] {scheduler_job.py:155} INFO - Started process (PID=80019) to work on /airflow/dags/download_data.py
[2022-02-17 06:06:22,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:06:22,201] {logging_mixin.py:112} INFO - [2022-02-17 06:06:22,201] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:06:22,841] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:06:22,892] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:06:22,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:06:22,905] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.718 seconds
[2022-02-17 06:06:35,535] {scheduler_job.py:155} INFO - Started process (PID=80046) to work on /airflow/dags/download_data.py
[2022-02-17 06:06:35,544] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:06:35,546] {logging_mixin.py:112} INFO - [2022-02-17 06:06:35,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:06:36,027] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:06:36,074] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:06:36,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:06:36,089] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 06:06:48,805] {scheduler_job.py:155} INFO - Started process (PID=80072) to work on /airflow/dags/download_data.py
[2022-02-17 06:06:48,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:06:48,816] {logging_mixin.py:112} INFO - [2022-02-17 06:06:48,816] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:06:49,328] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:06:49,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:06:49,392] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:06:49,397] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 06:07:02,107] {scheduler_job.py:155} INFO - Started process (PID=80100) to work on /airflow/dags/download_data.py
[2022-02-17 06:07:02,114] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:07:02,116] {logging_mixin.py:112} INFO - [2022-02-17 06:07:02,116] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:07:02,566] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:07:02,609] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:07:02,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:07:02,620] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 06:07:15,388] {scheduler_job.py:155} INFO - Started process (PID=80126) to work on /airflow/dags/download_data.py
[2022-02-17 06:07:15,395] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:07:15,398] {logging_mixin.py:112} INFO - [2022-02-17 06:07:15,397] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:07:15,858] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:07:15,909] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:07:15,916] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:07:15,920] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 06:07:28,656] {scheduler_job.py:155} INFO - Started process (PID=80154) to work on /airflow/dags/download_data.py
[2022-02-17 06:07:28,660] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:07:28,662] {logging_mixin.py:112} INFO - [2022-02-17 06:07:28,662] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:07:29,116] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:07:29,169] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:07:29,176] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:07:29,180] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 06:07:41,950] {scheduler_job.py:155} INFO - Started process (PID=80180) to work on /airflow/dags/download_data.py
[2022-02-17 06:07:41,957] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:07:41,960] {logging_mixin.py:112} INFO - [2022-02-17 06:07:41,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:07:42,425] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:07:42,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:07:42,485] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:07:42,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 06:07:55,223] {scheduler_job.py:155} INFO - Started process (PID=80208) to work on /airflow/dags/download_data.py
[2022-02-17 06:07:55,234] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:07:55,237] {logging_mixin.py:112} INFO - [2022-02-17 06:07:55,236] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:07:55,696] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:07:55,743] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:07:55,765] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:07:55,771] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 06:08:08,543] {scheduler_job.py:155} INFO - Started process (PID=80234) to work on /airflow/dags/download_data.py
[2022-02-17 06:08:08,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:08:08,556] {logging_mixin.py:112} INFO - [2022-02-17 06:08:08,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:08:09,064] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:08:09,114] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:08:09,124] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:08:09,133] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 06:08:21,896] {scheduler_job.py:155} INFO - Started process (PID=80260) to work on /airflow/dags/download_data.py
[2022-02-17 06:08:21,902] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:08:21,905] {logging_mixin.py:112} INFO - [2022-02-17 06:08:21,904] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:08:22,361] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:08:22,414] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:08:22,422] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:08:22,427] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 06:08:35,199] {scheduler_job.py:155} INFO - Started process (PID=80288) to work on /airflow/dags/download_data.py
[2022-02-17 06:08:35,210] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:08:35,220] {logging_mixin.py:112} INFO - [2022-02-17 06:08:35,216] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:08:35,679] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:08:35,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:08:35,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:08:35,752] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 06:08:48,446] {scheduler_job.py:155} INFO - Started process (PID=80314) to work on /airflow/dags/download_data.py
[2022-02-17 06:08:48,450] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:08:48,452] {logging_mixin.py:112} INFO - [2022-02-17 06:08:48,452] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:08:48,897] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:08:48,936] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:08:48,945] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:08:48,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 06:09:01,734] {scheduler_job.py:155} INFO - Started process (PID=80342) to work on /airflow/dags/download_data.py
[2022-02-17 06:09:01,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:09:01,744] {logging_mixin.py:112} INFO - [2022-02-17 06:09:01,744] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:09:02,218] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:09:02,251] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:09:02,256] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:09:02,262] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 06:09:15,002] {scheduler_job.py:155} INFO - Started process (PID=80368) to work on /airflow/dags/download_data.py
[2022-02-17 06:09:15,006] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:09:15,007] {logging_mixin.py:112} INFO - [2022-02-17 06:09:15,007] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:09:15,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:09:15,495] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:09:15,502] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:09:15,506] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 06:09:28,299] {scheduler_job.py:155} INFO - Started process (PID=80396) to work on /airflow/dags/download_data.py
[2022-02-17 06:09:28,307] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:09:28,309] {logging_mixin.py:112} INFO - [2022-02-17 06:09:28,309] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:09:28,758] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:09:28,813] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:09:28,822] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:09:28,828] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 06:09:41,585] {scheduler_job.py:155} INFO - Started process (PID=80422) to work on /airflow/dags/download_data.py
[2022-02-17 06:09:41,590] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:09:41,592] {logging_mixin.py:112} INFO - [2022-02-17 06:09:41,592] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:09:42,191] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:09:42,247] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:09:42,255] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:09:42,260] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.675 seconds
[2022-02-17 06:09:54,905] {scheduler_job.py:155} INFO - Started process (PID=80448) to work on /airflow/dags/download_data.py
[2022-02-17 06:09:54,910] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:09:54,912] {logging_mixin.py:112} INFO - [2022-02-17 06:09:54,912] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:09:55,356] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:09:55,400] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:09:55,409] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:09:55,415] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 06:10:08,168] {scheduler_job.py:155} INFO - Started process (PID=80476) to work on /airflow/dags/download_data.py
[2022-02-17 06:10:08,178] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:10:08,181] {logging_mixin.py:112} INFO - [2022-02-17 06:10:08,180] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:10:08,621] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:10:08,665] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:10:08,672] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:10:08,677] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 06:10:21,458] {scheduler_job.py:155} INFO - Started process (PID=80502) to work on /airflow/dags/download_data.py
[2022-02-17 06:10:21,464] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:10:21,467] {logging_mixin.py:112} INFO - [2022-02-17 06:10:21,466] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:10:22,004] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:10:22,055] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:10:22,061] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:10:22,066] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-17 06:10:34,788] {scheduler_job.py:155} INFO - Started process (PID=80530) to work on /airflow/dags/download_data.py
[2022-02-17 06:10:34,796] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:10:34,807] {logging_mixin.py:112} INFO - [2022-02-17 06:10:34,806] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:10:35,266] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:10:35,322] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:10:35,331] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:10:35,334] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 06:10:48,049] {scheduler_job.py:155} INFO - Started process (PID=80556) to work on /airflow/dags/download_data.py
[2022-02-17 06:10:48,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:10:48,056] {logging_mixin.py:112} INFO - [2022-02-17 06:10:48,056] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:10:48,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:10:48,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:10:48,603] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:10:48,607] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 06:11:01,379] {scheduler_job.py:155} INFO - Started process (PID=80584) to work on /airflow/dags/download_data.py
[2022-02-17 06:11:01,390] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:11:01,391] {logging_mixin.py:112} INFO - [2022-02-17 06:11:01,391] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:11:01,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:11:01,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:11:01,857] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:11:01,863] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-17 06:11:14,642] {scheduler_job.py:155} INFO - Started process (PID=80610) to work on /airflow/dags/download_data.py
[2022-02-17 06:11:14,646] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:11:14,648] {logging_mixin.py:112} INFO - [2022-02-17 06:11:14,648] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:11:15,100] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:11:15,150] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:11:15,158] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:11:15,162] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 06:11:27,926] {scheduler_job.py:155} INFO - Started process (PID=80636) to work on /airflow/dags/download_data.py
[2022-02-17 06:11:27,933] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:11:27,936] {logging_mixin.py:112} INFO - [2022-02-17 06:11:27,935] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:11:28,387] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:11:28,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:11:28,452] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:11:28,461] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 06:11:41,184] {scheduler_job.py:155} INFO - Started process (PID=80664) to work on /airflow/dags/download_data.py
[2022-02-17 06:11:41,195] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:11:41,197] {logging_mixin.py:112} INFO - [2022-02-17 06:11:41,197] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:11:41,654] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:11:41,704] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:11:41,711] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:11:41,718] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 06:11:54,457] {scheduler_job.py:155} INFO - Started process (PID=80690) to work on /airflow/dags/download_data.py
[2022-02-17 06:11:54,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:11:54,464] {logging_mixin.py:112} INFO - [2022-02-17 06:11:54,463] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:11:54,896] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:11:54,946] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:11:54,955] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:11:54,962] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 06:12:07,718] {scheduler_job.py:155} INFO - Started process (PID=80718) to work on /airflow/dags/download_data.py
[2022-02-17 06:12:07,725] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:12:07,727] {logging_mixin.py:112} INFO - [2022-02-17 06:12:07,727] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:12:08,208] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:12:08,258] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:12:08,270] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:12:08,277] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 06:12:21,016] {scheduler_job.py:155} INFO - Started process (PID=80744) to work on /airflow/dags/download_data.py
[2022-02-17 06:12:21,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:12:21,025] {logging_mixin.py:112} INFO - [2022-02-17 06:12:21,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:12:21,530] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:12:21,595] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:12:21,606] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:12:21,610] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 06:12:34,323] {scheduler_job.py:155} INFO - Started process (PID=80772) to work on /airflow/dags/download_data.py
[2022-02-17 06:12:34,329] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:12:34,332] {logging_mixin.py:112} INFO - [2022-02-17 06:12:34,331] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:12:34,802] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:12:34,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:12:34,850] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:12:34,855] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 06:12:47,560] {scheduler_job.py:155} INFO - Started process (PID=80798) to work on /airflow/dags/download_data.py
[2022-02-17 06:12:47,567] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:12:47,569] {logging_mixin.py:112} INFO - [2022-02-17 06:12:47,569] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:12:48,053] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:12:48,106] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:12:48,114] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:12:48,118] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 06:13:00,860] {scheduler_job.py:155} INFO - Started process (PID=80826) to work on /airflow/dags/download_data.py
[2022-02-17 06:13:00,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:13:00,871] {logging_mixin.py:112} INFO - [2022-02-17 06:13:00,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:13:01,549] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:13:01,606] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:13:01,620] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:13:01,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.770 seconds
[2022-02-17 06:13:14,139] {scheduler_job.py:155} INFO - Started process (PID=80852) to work on /airflow/dags/download_data.py
[2022-02-17 06:13:14,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:13:14,149] {logging_mixin.py:112} INFO - [2022-02-17 06:13:14,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:13:14,620] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:13:14,658] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:13:14,663] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:13:14,667] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 06:13:27,453] {scheduler_job.py:155} INFO - Started process (PID=80878) to work on /airflow/dags/download_data.py
[2022-02-17 06:13:27,469] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:13:27,471] {logging_mixin.py:112} INFO - [2022-02-17 06:13:27,470] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:13:27,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:13:27,991] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:13:28,002] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:13:28,009] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 06:13:40,697] {scheduler_job.py:155} INFO - Started process (PID=80906) to work on /airflow/dags/download_data.py
[2022-02-17 06:13:40,704] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:13:40,707] {logging_mixin.py:112} INFO - [2022-02-17 06:13:40,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:13:41,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:13:41,196] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:13:41,203] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:13:41,207] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 06:13:53,984] {scheduler_job.py:155} INFO - Started process (PID=80932) to work on /airflow/dags/download_data.py
[2022-02-17 06:13:53,994] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:13:53,997] {logging_mixin.py:112} INFO - [2022-02-17 06:13:53,996] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:13:54,449] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:13:54,498] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:13:54,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:13:54,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 06:14:07,281] {scheduler_job.py:155} INFO - Started process (PID=80960) to work on /airflow/dags/download_data.py
[2022-02-17 06:14:07,288] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:14:07,291] {logging_mixin.py:112} INFO - [2022-02-17 06:14:07,290] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:14:07,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:14:07,792] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:14:07,801] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:14:07,806] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 06:14:20,573] {scheduler_job.py:155} INFO - Started process (PID=80986) to work on /airflow/dags/download_data.py
[2022-02-17 06:14:20,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:14:20,593] {logging_mixin.py:112} INFO - [2022-02-17 06:14:20,593] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:14:21,119] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:14:21,163] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:14:21,170] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:14:21,173] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 06:14:33,872] {scheduler_job.py:155} INFO - Started process (PID=81014) to work on /airflow/dags/download_data.py
[2022-02-17 06:14:33,876] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:14:33,878] {logging_mixin.py:112} INFO - [2022-02-17 06:14:33,878] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:14:34,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:14:34,383] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:14:34,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:14:34,401] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 06:14:47,122] {scheduler_job.py:155} INFO - Started process (PID=81040) to work on /airflow/dags/download_data.py
[2022-02-17 06:14:47,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:14:47,133] {logging_mixin.py:112} INFO - [2022-02-17 06:14:47,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:14:47,589] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:14:47,638] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:14:47,647] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:14:47,653] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 06:15:00,448] {scheduler_job.py:155} INFO - Started process (PID=81066) to work on /airflow/dags/download_data.py
[2022-02-17 06:15:00,455] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:15:00,456] {logging_mixin.py:112} INFO - [2022-02-17 06:15:00,456] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:15:00,911] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:15:00,958] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:15:00,969] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:15:00,973] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 06:15:13,699] {scheduler_job.py:155} INFO - Started process (PID=81094) to work on /airflow/dags/download_data.py
[2022-02-17 06:15:13,703] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:15:13,705] {logging_mixin.py:112} INFO - [2022-02-17 06:15:13,705] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:15:14,155] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:15:14,194] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:15:14,204] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:15:14,209] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 06:15:27,025] {scheduler_job.py:155} INFO - Started process (PID=81120) to work on /airflow/dags/download_data.py
[2022-02-17 06:15:27,031] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:15:27,033] {logging_mixin.py:112} INFO - [2022-02-17 06:15:27,033] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:15:27,526] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:15:27,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:15:27,598] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:15:27,606] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 06:15:40,275] {scheduler_job.py:155} INFO - Started process (PID=81148) to work on /airflow/dags/download_data.py
[2022-02-17 06:15:40,281] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:15:40,283] {logging_mixin.py:112} INFO - [2022-02-17 06:15:40,282] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:15:40,754] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:15:40,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:15:40,817] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:15:40,822] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 06:15:53,601] {scheduler_job.py:155} INFO - Started process (PID=81174) to work on /airflow/dags/download_data.py
[2022-02-17 06:15:53,606] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:15:53,608] {logging_mixin.py:112} INFO - [2022-02-17 06:15:53,608] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:15:54,073] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:15:54,118] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:15:54,125] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:15:54,133] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 06:16:07,039] {scheduler_job.py:155} INFO - Started process (PID=81202) to work on /airflow/dags/download_data.py
[2022-02-17 06:16:07,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:16:07,047] {logging_mixin.py:112} INFO - [2022-02-17 06:16:07,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:16:07,509] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:16:07,553] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:16:07,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:16:07,568] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 06:16:20,325] {scheduler_job.py:155} INFO - Started process (PID=81228) to work on /airflow/dags/download_data.py
[2022-02-17 06:16:20,331] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:16:20,332] {logging_mixin.py:112} INFO - [2022-02-17 06:16:20,332] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:16:20,788] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:16:20,845] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:16:20,856] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:16:20,860] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 06:16:33,608] {scheduler_job.py:155} INFO - Started process (PID=81254) to work on /airflow/dags/download_data.py
[2022-02-17 06:16:33,615] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:16:33,618] {logging_mixin.py:112} INFO - [2022-02-17 06:16:33,617] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:16:34,078] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:16:34,132] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:16:34,138] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:16:34,145] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 06:16:46,932] {scheduler_job.py:155} INFO - Started process (PID=81282) to work on /airflow/dags/download_data.py
[2022-02-17 06:16:46,940] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:16:46,948] {logging_mixin.py:112} INFO - [2022-02-17 06:16:46,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:16:47,461] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:16:47,511] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:16:47,518] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:16:47,523] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 06:17:00,226] {scheduler_job.py:155} INFO - Started process (PID=81308) to work on /airflow/dags/download_data.py
[2022-02-17 06:17:00,233] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:17:00,235] {logging_mixin.py:112} INFO - [2022-02-17 06:17:00,235] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:17:00,680] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:17:00,734] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:17:00,742] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:17:00,748] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 06:17:13,465] {scheduler_job.py:155} INFO - Started process (PID=81336) to work on /airflow/dags/download_data.py
[2022-02-17 06:17:13,469] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:17:13,471] {logging_mixin.py:112} INFO - [2022-02-17 06:17:13,470] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:17:13,960] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:17:14,019] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:17:14,033] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:17:14,041] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-17 06:17:26,750] {scheduler_job.py:155} INFO - Started process (PID=81362) to work on /airflow/dags/download_data.py
[2022-02-17 06:17:26,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:17:26,765] {logging_mixin.py:112} INFO - [2022-02-17 06:17:26,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:17:27,209] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:17:27,254] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:17:27,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:17:27,268] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 06:17:39,984] {scheduler_job.py:155} INFO - Started process (PID=81390) to work on /airflow/dags/download_data.py
[2022-02-17 06:17:39,992] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:17:39,995] {logging_mixin.py:112} INFO - [2022-02-17 06:17:39,994] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:17:40,445] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:17:40,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:17:40,607] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:17:40,611] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-17 06:17:53,284] {scheduler_job.py:155} INFO - Started process (PID=81416) to work on /airflow/dags/download_data.py
[2022-02-17 06:17:53,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:17:53,298] {logging_mixin.py:112} INFO - [2022-02-17 06:17:53,298] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:17:53,768] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:17:53,816] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:17:53,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:17:53,828] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 06:18:06,531] {scheduler_job.py:155} INFO - Started process (PID=81443) to work on /airflow/dags/download_data.py
[2022-02-17 06:18:06,547] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:18:06,550] {logging_mixin.py:112} INFO - [2022-02-17 06:18:06,550] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:18:07,146] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:18:07,217] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:18:07,224] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:18:07,230] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.699 seconds
[2022-02-17 06:18:20,018] {scheduler_job.py:155} INFO - Started process (PID=81470) to work on /airflow/dags/download_data.py
[2022-02-17 06:18:20,024] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:18:20,026] {logging_mixin.py:112} INFO - [2022-02-17 06:18:20,026] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:18:20,514] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:18:20,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:18:20,578] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:18:20,585] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 06:18:33,331] {scheduler_job.py:155} INFO - Started process (PID=81496) to work on /airflow/dags/download_data.py
[2022-02-17 06:18:33,335] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:18:33,337] {logging_mixin.py:112} INFO - [2022-02-17 06:18:33,336] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:18:33,809] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:18:33,877] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:18:33,886] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:18:33,890] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 06:18:46,613] {scheduler_job.py:155} INFO - Started process (PID=81524) to work on /airflow/dags/download_data.py
[2022-02-17 06:18:46,618] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:18:46,622] {logging_mixin.py:112} INFO - [2022-02-17 06:18:46,621] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:18:47,477] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:18:47,540] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:18:47,549] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:18:47,561] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.948 seconds
[2022-02-17 06:18:59,907] {scheduler_job.py:155} INFO - Started process (PID=81550) to work on /airflow/dags/download_data.py
[2022-02-17 06:18:59,912] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:18:59,914] {logging_mixin.py:112} INFO - [2022-02-17 06:18:59,914] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:19:00,413] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:19:00,470] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:19:00,478] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:19:00,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 06:19:13,173] {scheduler_job.py:155} INFO - Started process (PID=81578) to work on /airflow/dags/download_data.py
[2022-02-17 06:19:13,184] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:19:13,187] {logging_mixin.py:112} INFO - [2022-02-17 06:19:13,186] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:19:13,713] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:19:13,776] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:19:13,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:19:13,790] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 06:19:26,467] {scheduler_job.py:155} INFO - Started process (PID=81604) to work on /airflow/dags/download_data.py
[2022-02-17 06:19:26,482] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:19:26,485] {logging_mixin.py:112} INFO - [2022-02-17 06:19:26,485] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:19:27,022] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:19:27,078] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:19:27,086] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:19:27,090] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-17 06:19:39,752] {scheduler_job.py:155} INFO - Started process (PID=81632) to work on /airflow/dags/download_data.py
[2022-02-17 06:19:39,775] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:19:39,778] {logging_mixin.py:112} INFO - [2022-02-17 06:19:39,778] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:19:40,387] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:19:40,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:19:40,465] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:19:40,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.718 seconds
[2022-02-17 06:19:53,088] {scheduler_job.py:155} INFO - Started process (PID=81658) to work on /airflow/dags/download_data.py
[2022-02-17 06:19:53,096] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:19:53,101] {logging_mixin.py:112} INFO - [2022-02-17 06:19:53,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:19:53,668] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:19:53,718] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:19:53,728] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:19:53,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-17 06:20:06,361] {scheduler_job.py:155} INFO - Started process (PID=81684) to work on /airflow/dags/download_data.py
[2022-02-17 06:20:06,365] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:20:06,368] {logging_mixin.py:112} INFO - [2022-02-17 06:20:06,368] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:20:06,822] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:20:06,867] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:20:06,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:20:06,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 06:20:19,628] {scheduler_job.py:155} INFO - Started process (PID=81712) to work on /airflow/dags/download_data.py
[2022-02-17 06:20:19,635] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:20:19,637] {logging_mixin.py:112} INFO - [2022-02-17 06:20:19,637] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:20:20,214] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:20:20,269] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:20:20,279] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:20:20,284] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-17 06:20:32,944] {scheduler_job.py:155} INFO - Started process (PID=81738) to work on /airflow/dags/download_data.py
[2022-02-17 06:20:32,949] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:20:32,950] {logging_mixin.py:112} INFO - [2022-02-17 06:20:32,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:20:33,434] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:20:33,492] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:20:33,503] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:20:33,513] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 06:20:46,222] {scheduler_job.py:155} INFO - Started process (PID=81766) to work on /airflow/dags/download_data.py
[2022-02-17 06:20:46,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:20:46,229] {logging_mixin.py:112} INFO - [2022-02-17 06:20:46,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:20:46,696] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:20:46,743] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:20:46,755] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:20:46,760] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 06:20:59,500] {scheduler_job.py:155} INFO - Started process (PID=81792) to work on /airflow/dags/download_data.py
[2022-02-17 06:20:59,507] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:20:59,509] {logging_mixin.py:112} INFO - [2022-02-17 06:20:59,509] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:20:59,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:21:00,036] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:21:00,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:21:00,052] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 06:21:12,757] {scheduler_job.py:155} INFO - Started process (PID=81820) to work on /airflow/dags/download_data.py
[2022-02-17 06:21:12,765] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:21:12,769] {logging_mixin.py:112} INFO - [2022-02-17 06:21:12,768] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:21:13,325] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:21:13,396] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:21:13,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:21:13,408] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.651 seconds
[2022-02-17 06:21:26,077] {scheduler_job.py:155} INFO - Started process (PID=81846) to work on /airflow/dags/download_data.py
[2022-02-17 06:21:26,081] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:21:26,083] {logging_mixin.py:112} INFO - [2022-02-17 06:21:26,083] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:21:26,552] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:21:26,608] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:21:26,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:21:26,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 06:21:39,361] {scheduler_job.py:155} INFO - Started process (PID=81872) to work on /airflow/dags/download_data.py
[2022-02-17 06:21:39,366] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:21:39,367] {logging_mixin.py:112} INFO - [2022-02-17 06:21:39,367] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:21:39,844] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:21:39,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:21:39,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:21:39,902] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 06:21:52,625] {scheduler_job.py:155} INFO - Started process (PID=81900) to work on /airflow/dags/download_data.py
[2022-02-17 06:21:52,636] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:21:52,638] {logging_mixin.py:112} INFO - [2022-02-17 06:21:52,638] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:21:53,113] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:21:53,159] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:21:53,166] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:21:53,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 06:22:05,868] {scheduler_job.py:155} INFO - Started process (PID=81926) to work on /airflow/dags/download_data.py
[2022-02-17 06:22:05,883] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:22:05,884] {logging_mixin.py:112} INFO - [2022-02-17 06:22:05,884] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:22:06,349] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:22:06,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:22:06,413] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:22:06,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 06:22:19,171] {scheduler_job.py:155} INFO - Started process (PID=81954) to work on /airflow/dags/download_data.py
[2022-02-17 06:22:19,184] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:22:19,186] {logging_mixin.py:112} INFO - [2022-02-17 06:22:19,186] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:22:19,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:22:19,665] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:22:19,670] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:22:19,674] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 06:22:32,448] {scheduler_job.py:155} INFO - Started process (PID=81980) to work on /airflow/dags/download_data.py
[2022-02-17 06:22:32,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:22:32,453] {logging_mixin.py:112} INFO - [2022-02-17 06:22:32,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:22:32,902] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:22:32,951] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:22:32,958] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:22:32,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 06:22:45,670] {scheduler_job.py:155} INFO - Started process (PID=82008) to work on /airflow/dags/download_data.py
[2022-02-17 06:22:45,677] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:22:45,679] {logging_mixin.py:112} INFO - [2022-02-17 06:22:45,678] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:22:46,142] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:22:46,187] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:22:46,198] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:22:46,204] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 06:22:58,967] {scheduler_job.py:155} INFO - Started process (PID=82034) to work on /airflow/dags/download_data.py
[2022-02-17 06:22:58,980] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:22:58,986] {logging_mixin.py:112} INFO - [2022-02-17 06:22:58,986] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:22:59,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:22:59,587] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:22:59,598] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:22:59,605] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-17 06:23:12,222] {scheduler_job.py:155} INFO - Started process (PID=82060) to work on /airflow/dags/download_data.py
[2022-02-17 06:23:12,229] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:23:12,231] {logging_mixin.py:112} INFO - [2022-02-17 06:23:12,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:23:12,863] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:23:12,911] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:23:12,916] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:23:12,920] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-17 06:23:25,534] {scheduler_job.py:155} INFO - Started process (PID=82088) to work on /airflow/dags/download_data.py
[2022-02-17 06:23:25,549] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:23:25,552] {logging_mixin.py:112} INFO - [2022-02-17 06:23:25,552] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:23:26,147] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:23:26,197] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:23:26,205] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:23:26,212] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-17 06:23:38,754] {scheduler_job.py:155} INFO - Started process (PID=82114) to work on /airflow/dags/download_data.py
[2022-02-17 06:23:38,759] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:23:38,760] {logging_mixin.py:112} INFO - [2022-02-17 06:23:38,760] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:23:39,214] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:23:39,256] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:23:39,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:23:39,265] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 06:23:52,038] {scheduler_job.py:155} INFO - Started process (PID=82142) to work on /airflow/dags/download_data.py
[2022-02-17 06:23:52,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:23:52,046] {logging_mixin.py:112} INFO - [2022-02-17 06:23:52,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:23:52,536] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:23:52,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:23:52,599] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:23:52,602] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 06:24:05,303] {scheduler_job.py:155} INFO - Started process (PID=82168) to work on /airflow/dags/download_data.py
[2022-02-17 06:24:05,311] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:24:05,313] {logging_mixin.py:112} INFO - [2022-02-17 06:24:05,313] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:24:05,807] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:24:05,862] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:24:05,868] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:24:05,876] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 06:24:18,623] {scheduler_job.py:155} INFO - Started process (PID=82196) to work on /airflow/dags/download_data.py
[2022-02-17 06:24:18,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:24:18,635] {logging_mixin.py:112} INFO - [2022-02-17 06:24:18,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:24:19,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:24:19,161] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:24:19,170] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:24:19,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 06:24:31,932] {scheduler_job.py:155} INFO - Started process (PID=82222) to work on /airflow/dags/download_data.py
[2022-02-17 06:24:31,937] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:24:31,939] {logging_mixin.py:112} INFO - [2022-02-17 06:24:31,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:24:32,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:24:32,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:24:32,476] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:24:32,480] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 06:24:45,195] {scheduler_job.py:155} INFO - Started process (PID=82250) to work on /airflow/dags/download_data.py
[2022-02-17 06:24:45,214] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:24:45,217] {logging_mixin.py:112} INFO - [2022-02-17 06:24:45,217] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:24:45,689] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:24:45,734] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:24:45,741] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:24:45,749] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 06:24:58,488] {scheduler_job.py:155} INFO - Started process (PID=82276) to work on /airflow/dags/download_data.py
[2022-02-17 06:24:58,494] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:24:58,496] {logging_mixin.py:112} INFO - [2022-02-17 06:24:58,496] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:24:59,004] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:24:59,053] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:24:59,064] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:24:59,070] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 06:25:11,729] {scheduler_job.py:155} INFO - Started process (PID=82302) to work on /airflow/dags/download_data.py
[2022-02-17 06:25:11,734] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:25:11,736] {logging_mixin.py:112} INFO - [2022-02-17 06:25:11,736] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:25:12,214] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:25:12,268] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:25:12,274] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:25:12,278] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 06:25:25,001] {scheduler_job.py:155} INFO - Started process (PID=82330) to work on /airflow/dags/download_data.py
[2022-02-17 06:25:25,006] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:25:25,010] {logging_mixin.py:112} INFO - [2022-02-17 06:25:25,009] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:25:25,482] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:25:25,539] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:25:25,547] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:25:25,554] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 06:25:38,336] {scheduler_job.py:155} INFO - Started process (PID=82356) to work on /airflow/dags/download_data.py
[2022-02-17 06:25:38,347] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:25:38,361] {logging_mixin.py:112} INFO - [2022-02-17 06:25:38,361] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:25:38,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:25:38,903] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:25:38,911] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:25:38,917] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 06:25:51,613] {scheduler_job.py:155} INFO - Started process (PID=82384) to work on /airflow/dags/download_data.py
[2022-02-17 06:25:51,621] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:25:51,624] {logging_mixin.py:112} INFO - [2022-02-17 06:25:51,623] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:25:52,121] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:25:52,155] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:25:52,163] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:25:52,167] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 06:26:04,919] {scheduler_job.py:155} INFO - Started process (PID=82410) to work on /airflow/dags/download_data.py
[2022-02-17 06:26:04,931] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:26:04,934] {logging_mixin.py:112} INFO - [2022-02-17 06:26:04,933] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:26:05,393] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:26:05,434] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:26:05,453] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:26:05,480] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 06:26:18,165] {scheduler_job.py:155} INFO - Started process (PID=82438) to work on /airflow/dags/download_data.py
[2022-02-17 06:26:18,170] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:26:18,173] {logging_mixin.py:112} INFO - [2022-02-17 06:26:18,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:26:18,660] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:26:18,756] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:26:18,767] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:26:18,784] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 06:26:31,452] {scheduler_job.py:155} INFO - Started process (PID=82464) to work on /airflow/dags/download_data.py
[2022-02-17 06:26:31,457] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:26:31,458] {logging_mixin.py:112} INFO - [2022-02-17 06:26:31,458] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:26:31,967] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:26:32,020] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:26:32,029] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:26:32,033] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 06:26:44,706] {scheduler_job.py:155} INFO - Started process (PID=82490) to work on /airflow/dags/download_data.py
[2022-02-17 06:26:44,712] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:26:44,717] {logging_mixin.py:112} INFO - [2022-02-17 06:26:44,717] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:26:45,215] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:26:45,264] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:26:45,277] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:26:45,284] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 06:26:57,967] {scheduler_job.py:155} INFO - Started process (PID=82518) to work on /airflow/dags/download_data.py
[2022-02-17 06:26:57,977] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:26:57,980] {logging_mixin.py:112} INFO - [2022-02-17 06:26:57,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:26:58,528] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:26:58,576] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:26:58,581] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:26:58,585] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 06:27:11,227] {scheduler_job.py:155} INFO - Started process (PID=82544) to work on /airflow/dags/download_data.py
[2022-02-17 06:27:11,232] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:27:11,234] {logging_mixin.py:112} INFO - [2022-02-17 06:27:11,234] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:27:11,719] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:27:11,772] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:27:11,778] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:27:11,785] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 06:27:24,540] {scheduler_job.py:155} INFO - Started process (PID=82572) to work on /airflow/dags/download_data.py
[2022-02-17 06:27:24,546] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:27:24,548] {logging_mixin.py:112} INFO - [2022-02-17 06:27:24,548] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:27:25,936] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:27:26,195] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:27:26,217] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:27:26,225] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.686 seconds
[2022-02-17 06:27:38,866] {scheduler_job.py:155} INFO - Started process (PID=82598) to work on /airflow/dags/download_data.py
[2022-02-17 06:27:38,874] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:27:38,876] {logging_mixin.py:112} INFO - [2022-02-17 06:27:38,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:27:39,373] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:27:39,430] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:27:39,445] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:27:39,451] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 06:27:51,132] {scheduler_job.py:155} INFO - Started process (PID=82625) to work on /airflow/dags/download_data.py
[2022-02-17 06:27:51,137] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:27:51,139] {logging_mixin.py:112} INFO - [2022-02-17 06:27:51,139] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:27:51,668] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:27:51,726] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:27:51,738] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:27:51,744] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-17 06:28:04,447] {scheduler_job.py:155} INFO - Started process (PID=82651) to work on /airflow/dags/download_data.py
[2022-02-17 06:28:04,457] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:28:04,459] {logging_mixin.py:112} INFO - [2022-02-17 06:28:04,458] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:28:05,024] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:28:05,120] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:28:05,136] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:28:05,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-17 06:28:17,696] {scheduler_job.py:155} INFO - Started process (PID=82677) to work on /airflow/dags/download_data.py
[2022-02-17 06:28:17,706] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:28:17,709] {logging_mixin.py:112} INFO - [2022-02-17 06:28:17,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:28:18,212] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:28:18,267] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:28:18,277] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:28:18,284] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 06:28:30,982] {scheduler_job.py:155} INFO - Started process (PID=82705) to work on /airflow/dags/download_data.py
[2022-02-17 06:28:31,003] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:28:31,008] {logging_mixin.py:112} INFO - [2022-02-17 06:28:31,007] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:28:31,809] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:28:31,861] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:28:31,867] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:28:31,874] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.892 seconds
[2022-02-17 06:28:44,258] {scheduler_job.py:155} INFO - Started process (PID=82731) to work on /airflow/dags/download_data.py
[2022-02-17 06:28:44,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:28:44,265] {logging_mixin.py:112} INFO - [2022-02-17 06:28:44,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:28:44,764] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:28:44,824] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:28:44,832] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:28:44,836] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 06:28:57,563] {scheduler_job.py:155} INFO - Started process (PID=82759) to work on /airflow/dags/download_data.py
[2022-02-17 06:28:57,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:28:57,570] {logging_mixin.py:112} INFO - [2022-02-17 06:28:57,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:28:58,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:28:58,118] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:28:58,133] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:28:58,140] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 06:29:10,857] {scheduler_job.py:155} INFO - Started process (PID=82785) to work on /airflow/dags/download_data.py
[2022-02-17 06:29:10,862] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:29:10,864] {logging_mixin.py:112} INFO - [2022-02-17 06:29:10,864] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:29:11,349] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:29:11,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:29:11,411] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:29:11,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 06:29:24,149] {scheduler_job.py:155} INFO - Started process (PID=82813) to work on /airflow/dags/download_data.py
[2022-02-17 06:29:24,162] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:29:24,170] {logging_mixin.py:112} INFO - [2022-02-17 06:29:24,170] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:29:24,701] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:29:24,744] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:29:24,753] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:29:24,759] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-17 06:29:37,430] {scheduler_job.py:155} INFO - Started process (PID=82839) to work on /airflow/dags/download_data.py
[2022-02-17 06:29:37,438] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:29:37,439] {logging_mixin.py:112} INFO - [2022-02-17 06:29:37,439] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:29:37,937] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:29:38,007] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:29:38,020] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:29:38,025] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 06:29:50,746] {scheduler_job.py:155} INFO - Started process (PID=82865) to work on /airflow/dags/download_data.py
[2022-02-17 06:29:50,751] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:29:50,753] {logging_mixin.py:112} INFO - [2022-02-17 06:29:50,753] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:29:51,245] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:29:51,297] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:29:51,307] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:29:51,312] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 06:30:04,055] {scheduler_job.py:155} INFO - Started process (PID=82893) to work on /airflow/dags/download_data.py
[2022-02-17 06:30:04,066] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:30:04,069] {logging_mixin.py:112} INFO - [2022-02-17 06:30:04,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:30:04,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:30:04,598] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:30:04,604] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:30:04,610] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 06:30:17,347] {scheduler_job.py:155} INFO - Started process (PID=82919) to work on /airflow/dags/download_data.py
[2022-02-17 06:30:17,352] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:30:17,353] {logging_mixin.py:112} INFO - [2022-02-17 06:30:17,353] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:30:17,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:30:17,900] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:30:17,912] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:30:17,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 06:30:30,667] {scheduler_job.py:155} INFO - Started process (PID=82947) to work on /airflow/dags/download_data.py
[2022-02-17 06:30:30,677] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:30:30,679] {logging_mixin.py:112} INFO - [2022-02-17 06:30:30,679] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:30:31,141] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:30:31,207] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:30:31,215] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:30:31,220] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 06:30:43,931] {scheduler_job.py:155} INFO - Started process (PID=82973) to work on /airflow/dags/download_data.py
[2022-02-17 06:30:43,936] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:30:43,937] {logging_mixin.py:112} INFO - [2022-02-17 06:30:43,937] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:30:44,457] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:30:44,505] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:30:44,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:30:44,523] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 06:30:57,303] {scheduler_job.py:155} INFO - Started process (PID=83001) to work on /airflow/dags/download_data.py
[2022-02-17 06:30:57,318] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:30:57,323] {logging_mixin.py:112} INFO - [2022-02-17 06:30:57,323] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:30:57,850] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:30:57,900] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:30:57,907] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:30:57,912] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-17 06:31:10,600] {scheduler_job.py:155} INFO - Started process (PID=83027) to work on /airflow/dags/download_data.py
[2022-02-17 06:31:10,612] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:31:10,614] {logging_mixin.py:112} INFO - [2022-02-17 06:31:10,614] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:31:11,080] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:31:11,136] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:31:11,146] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:31:11,152] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 06:31:23,879] {scheduler_job.py:155} INFO - Started process (PID=83054) to work on /airflow/dags/download_data.py
[2022-02-17 06:31:23,895] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:31:23,898] {logging_mixin.py:112} INFO - [2022-02-17 06:31:23,898] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:31:24,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:31:24,488] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:31:24,496] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:31:24,501] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-17 06:31:37,125] {scheduler_job.py:155} INFO - Started process (PID=83081) to work on /airflow/dags/download_data.py
[2022-02-17 06:31:37,133] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:31:37,137] {logging_mixin.py:112} INFO - [2022-02-17 06:31:37,136] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:31:37,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:31:37,694] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:31:37,701] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:31:37,707] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 06:31:50,405] {scheduler_job.py:155} INFO - Started process (PID=83107) to work on /airflow/dags/download_data.py
[2022-02-17 06:31:50,409] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:31:50,412] {logging_mixin.py:112} INFO - [2022-02-17 06:31:50,411] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:31:50,917] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:31:50,972] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:31:50,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:31:50,990] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 06:32:03,721] {scheduler_job.py:155} INFO - Started process (PID=83135) to work on /airflow/dags/download_data.py
[2022-02-17 06:32:03,729] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:32:03,731] {logging_mixin.py:112} INFO - [2022-02-17 06:32:03,731] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:32:04,216] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:32:04,273] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:32:04,283] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:32:04,290] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 06:32:17,021] {scheduler_job.py:155} INFO - Started process (PID=83161) to work on /airflow/dags/download_data.py
[2022-02-17 06:32:17,028] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:32:17,030] {logging_mixin.py:112} INFO - [2022-02-17 06:32:17,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:32:17,500] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:32:17,555] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:32:17,565] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:32:17,570] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 06:32:30,322] {scheduler_job.py:155} INFO - Started process (PID=83189) to work on /airflow/dags/download_data.py
[2022-02-17 06:32:30,336] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:32:30,340] {logging_mixin.py:112} INFO - [2022-02-17 06:32:30,340] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:32:31,004] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:32:31,058] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:32:31,065] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:32:31,070] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.748 seconds
[2022-02-17 06:32:43,618] {scheduler_job.py:155} INFO - Started process (PID=83215) to work on /airflow/dags/download_data.py
[2022-02-17 06:32:43,628] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:32:43,630] {logging_mixin.py:112} INFO - [2022-02-17 06:32:43,630] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:32:44,283] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:32:44,365] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:32:44,374] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:32:44,380] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.763 seconds
[2022-02-17 06:32:56,906] {scheduler_job.py:155} INFO - Started process (PID=83243) to work on /airflow/dags/download_data.py
[2022-02-17 06:32:56,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:32:56,933] {logging_mixin.py:112} INFO - [2022-02-17 06:32:56,932] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:32:57,611] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:32:57,713] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:32:57,740] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:32:57,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.844 seconds
[2022-02-17 06:33:10,174] {scheduler_job.py:155} INFO - Started process (PID=83269) to work on /airflow/dags/download_data.py
[2022-02-17 06:33:10,185] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:33:10,187] {logging_mixin.py:112} INFO - [2022-02-17 06:33:10,187] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:33:10,645] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:33:10,695] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:33:10,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:33:10,707] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 06:33:23,491] {scheduler_job.py:155} INFO - Started process (PID=83295) to work on /airflow/dags/download_data.py
[2022-02-17 06:33:23,499] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:33:23,501] {logging_mixin.py:112} INFO - [2022-02-17 06:33:23,501] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:33:23,975] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:33:24,017] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:33:24,029] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:33:24,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 06:33:36,710] {scheduler_job.py:155} INFO - Started process (PID=83323) to work on /airflow/dags/download_data.py
[2022-02-17 06:33:36,717] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:33:36,721] {logging_mixin.py:112} INFO - [2022-02-17 06:33:36,720] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:33:37,216] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:33:37,259] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:33:37,269] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:33:37,274] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 06:33:50,021] {scheduler_job.py:155} INFO - Started process (PID=83349) to work on /airflow/dags/download_data.py
[2022-02-17 06:33:50,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:33:50,029] {logging_mixin.py:112} INFO - [2022-02-17 06:33:50,029] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:33:50,501] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:33:50,567] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:33:50,574] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:33:50,582] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 06:34:03,329] {scheduler_job.py:155} INFO - Started process (PID=83377) to work on /airflow/dags/download_data.py
[2022-02-17 06:34:03,335] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:34:03,337] {logging_mixin.py:112} INFO - [2022-02-17 06:34:03,337] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:34:03,824] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:34:03,862] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:34:03,870] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:34:03,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 06:34:16,620] {scheduler_job.py:155} INFO - Started process (PID=83403) to work on /airflow/dags/download_data.py
[2022-02-17 06:34:16,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:34:16,627] {logging_mixin.py:112} INFO - [2022-02-17 06:34:16,627] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:34:17,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:34:17,125] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:34:17,133] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:34:17,138] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 06:34:29,909] {scheduler_job.py:155} INFO - Started process (PID=83431) to work on /airflow/dags/download_data.py
[2022-02-17 06:34:29,920] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:34:29,922] {logging_mixin.py:112} INFO - [2022-02-17 06:34:29,922] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:34:30,368] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:34:30,431] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:34:30,440] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:34:30,444] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 06:34:43,167] {scheduler_job.py:155} INFO - Started process (PID=83457) to work on /airflow/dags/download_data.py
[2022-02-17 06:34:43,171] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:34:43,173] {logging_mixin.py:112} INFO - [2022-02-17 06:34:43,173] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:34:43,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:34:43,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:34:43,695] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:34:43,701] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 06:34:56,464] {scheduler_job.py:155} INFO - Started process (PID=83483) to work on /airflow/dags/download_data.py
[2022-02-17 06:34:56,469] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:34:56,471] {logging_mixin.py:112} INFO - [2022-02-17 06:34:56,470] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:34:56,920] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:34:56,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:34:56,982] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:34:56,990] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 06:35:09,729] {scheduler_job.py:155} INFO - Started process (PID=83511) to work on /airflow/dags/download_data.py
[2022-02-17 06:35:09,739] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:35:09,741] {logging_mixin.py:112} INFO - [2022-02-17 06:35:09,741] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:35:10,233] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:35:10,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:35:10,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:35:10,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 06:35:23,040] {scheduler_job.py:155} INFO - Started process (PID=83537) to work on /airflow/dags/download_data.py
[2022-02-17 06:35:23,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:35:23,046] {logging_mixin.py:112} INFO - [2022-02-17 06:35:23,045] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:35:23,516] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:35:23,581] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:35:23,592] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:35:23,597] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 06:35:36,304] {scheduler_job.py:155} INFO - Started process (PID=83565) to work on /airflow/dags/download_data.py
[2022-02-17 06:35:36,309] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:35:36,310] {logging_mixin.py:112} INFO - [2022-02-17 06:35:36,310] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:35:36,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:35:36,821] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:35:36,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:35:36,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 06:35:49,599] {scheduler_job.py:155} INFO - Started process (PID=83591) to work on /airflow/dags/download_data.py
[2022-02-17 06:35:49,603] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:35:49,605] {logging_mixin.py:112} INFO - [2022-02-17 06:35:49,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:35:50,062] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:35:50,104] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:35:50,113] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:35:50,118] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 06:36:02,912] {scheduler_job.py:155} INFO - Started process (PID=83619) to work on /airflow/dags/download_data.py
[2022-02-17 06:36:02,924] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:36:02,927] {logging_mixin.py:112} INFO - [2022-02-17 06:36:02,927] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:36:03,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:36:03,555] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:36:03,569] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:36:03,578] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-17 06:36:16,183] {scheduler_job.py:155} INFO - Started process (PID=83645) to work on /airflow/dags/download_data.py
[2022-02-17 06:36:16,193] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:36:16,194] {logging_mixin.py:112} INFO - [2022-02-17 06:36:16,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:36:16,694] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:36:16,753] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:36:16,764] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:36:16,769] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 06:36:29,502] {scheduler_job.py:155} INFO - Started process (PID=83671) to work on /airflow/dags/download_data.py
[2022-02-17 06:36:29,509] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:36:29,513] {logging_mixin.py:112} INFO - [2022-02-17 06:36:29,512] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:36:30,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:36:30,085] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:36:30,097] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:36:30,103] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-17 06:36:42,727] {scheduler_job.py:155} INFO - Started process (PID=83699) to work on /airflow/dags/download_data.py
[2022-02-17 06:36:42,731] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:36:42,733] {logging_mixin.py:112} INFO - [2022-02-17 06:36:42,733] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:36:43,211] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:36:43,262] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:36:43,286] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:36:43,292] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 06:36:56,017] {scheduler_job.py:155} INFO - Started process (PID=83725) to work on /airflow/dags/download_data.py
[2022-02-17 06:36:56,024] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:36:56,027] {logging_mixin.py:112} INFO - [2022-02-17 06:36:56,026] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:36:56,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:36:56,524] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:36:56,531] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:36:56,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 06:37:09,262] {scheduler_job.py:155} INFO - Started process (PID=83753) to work on /airflow/dags/download_data.py
[2022-02-17 06:37:09,270] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:37:09,274] {logging_mixin.py:112} INFO - [2022-02-17 06:37:09,273] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:37:09,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:37:09,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:37:09,812] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:37:09,818] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 06:37:22,558] {scheduler_job.py:155} INFO - Started process (PID=83779) to work on /airflow/dags/download_data.py
[2022-02-17 06:37:22,563] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:37:22,564] {logging_mixin.py:112} INFO - [2022-02-17 06:37:22,564] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:37:23,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:37:23,089] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:37:23,102] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:37:23,107] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 06:37:35,838] {scheduler_job.py:155} INFO - Started process (PID=83807) to work on /airflow/dags/download_data.py
[2022-02-17 06:37:35,846] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:37:35,849] {logging_mixin.py:112} INFO - [2022-02-17 06:37:35,848] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:37:36,405] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:37:36,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:37:36,469] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:37:36,476] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-17 06:37:49,211] {scheduler_job.py:155} INFO - Started process (PID=83833) to work on /airflow/dags/download_data.py
[2022-02-17 06:37:49,228] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:37:49,232] {logging_mixin.py:112} INFO - [2022-02-17 06:37:49,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:37:49,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:37:49,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:37:49,799] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:37:49,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 06:38:02,470] {scheduler_job.py:155} INFO - Started process (PID=83859) to work on /airflow/dags/download_data.py
[2022-02-17 06:38:02,481] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:38:02,483] {logging_mixin.py:112} INFO - [2022-02-17 06:38:02,483] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:38:03,046] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:38:03,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:38:03,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:38:03,126] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.656 seconds
[2022-02-17 06:38:15,788] {scheduler_job.py:155} INFO - Started process (PID=83887) to work on /airflow/dags/download_data.py
[2022-02-17 06:38:15,799] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:38:15,803] {logging_mixin.py:112} INFO - [2022-02-17 06:38:15,802] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:38:16,324] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:38:16,376] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:38:16,384] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:38:16,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-17 06:38:29,087] {scheduler_job.py:155} INFO - Started process (PID=83913) to work on /airflow/dags/download_data.py
[2022-02-17 06:38:29,092] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:38:29,094] {logging_mixin.py:112} INFO - [2022-02-17 06:38:29,094] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:38:29,561] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:38:29,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:38:29,620] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:38:29,625] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 06:38:42,345] {scheduler_job.py:155} INFO - Started process (PID=83941) to work on /airflow/dags/download_data.py
[2022-02-17 06:38:42,351] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:38:42,354] {logging_mixin.py:112} INFO - [2022-02-17 06:38:42,353] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:38:42,857] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:38:42,904] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:38:42,914] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:38:42,926] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 06:38:55,650] {scheduler_job.py:155} INFO - Started process (PID=83967) to work on /airflow/dags/download_data.py
[2022-02-17 06:38:55,661] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:38:55,664] {logging_mixin.py:112} INFO - [2022-02-17 06:38:55,664] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:38:57,699] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:38:57,758] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:38:57,768] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:38:57,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.123 seconds
[2022-02-17 06:39:10,292] {scheduler_job.py:155} INFO - Started process (PID=83995) to work on /airflow/dags/download_data.py
[2022-02-17 06:39:10,315] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:39:10,329] {logging_mixin.py:112} INFO - [2022-02-17 06:39:10,323] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:39:11,502] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:39:11,602] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:39:11,617] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:39:11,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.332 seconds
[2022-02-17 06:39:23,596] {scheduler_job.py:155} INFO - Started process (PID=84020) to work on /airflow/dags/download_data.py
[2022-02-17 06:39:23,607] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:39:23,610] {logging_mixin.py:112} INFO - [2022-02-17 06:39:23,609] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:39:24,186] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:39:24,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:39:24,254] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:39:24,259] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.664 seconds
[2022-02-17 06:39:35,854] {scheduler_job.py:155} INFO - Started process (PID=84047) to work on /airflow/dags/download_data.py
[2022-02-17 06:39:35,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:39:35,867] {logging_mixin.py:112} INFO - [2022-02-17 06:39:35,866] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:39:36,349] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:39:36,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:39:36,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:39:36,430] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 06:39:49,209] {scheduler_job.py:155} INFO - Started process (PID=84073) to work on /airflow/dags/download_data.py
[2022-02-17 06:39:49,214] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:39:49,217] {logging_mixin.py:112} INFO - [2022-02-17 06:39:49,216] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:39:49,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:39:49,797] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:39:49,805] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:39:49,813] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-17 06:40:02,695] {scheduler_job.py:155} INFO - Started process (PID=84099) to work on /airflow/dags/download_data.py
[2022-02-17 06:40:02,702] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:40:02,704] {logging_mixin.py:112} INFO - [2022-02-17 06:40:02,703] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:40:03,202] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:40:03,244] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:40:03,257] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:40:03,264] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 06:40:15,965] {scheduler_job.py:155} INFO - Started process (PID=84127) to work on /airflow/dags/download_data.py
[2022-02-17 06:40:15,973] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:40:15,975] {logging_mixin.py:112} INFO - [2022-02-17 06:40:15,975] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:40:16,550] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:40:16,611] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:40:16,624] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:40:16,635] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.670 seconds
[2022-02-17 06:40:29,330] {scheduler_job.py:155} INFO - Started process (PID=84153) to work on /airflow/dags/download_data.py
[2022-02-17 06:40:29,344] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:40:29,348] {logging_mixin.py:112} INFO - [2022-02-17 06:40:29,347] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:40:29,963] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:40:30,003] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:40:30,013] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:40:30,020] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.690 seconds
[2022-02-17 06:40:42,577] {scheduler_job.py:155} INFO - Started process (PID=84181) to work on /airflow/dags/download_data.py
[2022-02-17 06:40:42,593] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:40:42,605] {logging_mixin.py:112} INFO - [2022-02-17 06:40:42,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:40:43,796] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:40:43,928] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:40:43,950] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:40:43,985] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.409 seconds
[2022-02-17 06:40:56,912] {scheduler_job.py:155} INFO - Started process (PID=84207) to work on /airflow/dags/download_data.py
[2022-02-17 06:40:56,920] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:40:56,923] {logging_mixin.py:112} INFO - [2022-02-17 06:40:56,923] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:40:57,473] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:40:57,526] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:40:57,535] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:40:57,541] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-17 06:41:09,161] {scheduler_job.py:155} INFO - Started process (PID=84234) to work on /airflow/dags/download_data.py
[2022-02-17 06:41:09,169] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:41:09,171] {logging_mixin.py:112} INFO - [2022-02-17 06:41:09,171] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:41:09,665] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:41:09,715] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:41:09,727] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:41:09,733] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 06:41:22,492] {scheduler_job.py:155} INFO - Started process (PID=84260) to work on /airflow/dags/download_data.py
[2022-02-17 06:41:22,500] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:41:22,503] {logging_mixin.py:112} INFO - [2022-02-17 06:41:22,503] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:41:23,057] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:41:23,140] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:41:23,153] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:41:23,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.668 seconds
[2022-02-17 06:41:35,747] {scheduler_job.py:155} INFO - Started process (PID=84286) to work on /airflow/dags/download_data.py
[2022-02-17 06:41:35,755] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:41:35,759] {logging_mixin.py:112} INFO - [2022-02-17 06:41:35,757] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:41:36,263] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:41:36,318] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:41:36,331] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:41:36,337] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 06:41:49,043] {scheduler_job.py:155} INFO - Started process (PID=84314) to work on /airflow/dags/download_data.py
[2022-02-17 06:41:49,047] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:41:49,049] {logging_mixin.py:112} INFO - [2022-02-17 06:41:49,049] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:41:49,509] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:41:49,566] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:41:49,574] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:41:49,581] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 06:42:02,369] {scheduler_job.py:155} INFO - Started process (PID=84340) to work on /airflow/dags/download_data.py
[2022-02-17 06:42:02,380] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:42:02,383] {logging_mixin.py:112} INFO - [2022-02-17 06:42:02,383] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:42:02,983] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:42:03,044] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:42:03,052] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:42:03,059] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.690 seconds
[2022-02-17 06:42:15,616] {scheduler_job.py:155} INFO - Started process (PID=84368) to work on /airflow/dags/download_data.py
[2022-02-17 06:42:15,623] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:42:15,626] {logging_mixin.py:112} INFO - [2022-02-17 06:42:15,625] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:42:16,126] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:42:16,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:42:16,186] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:42:16,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 06:42:28,942] {scheduler_job.py:155} INFO - Started process (PID=84394) to work on /airflow/dags/download_data.py
[2022-02-17 06:42:28,947] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:42:28,950] {logging_mixin.py:112} INFO - [2022-02-17 06:42:28,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:42:29,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:42:29,505] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:42:29,518] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:42:29,524] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 06:42:42,239] {scheduler_job.py:155} INFO - Started process (PID=84422) to work on /airflow/dags/download_data.py
[2022-02-17 06:42:42,245] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:42:42,247] {logging_mixin.py:112} INFO - [2022-02-17 06:42:42,247] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:42:42,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:42:42,854] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:42:42,865] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:42:42,872] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-17 06:42:55,559] {scheduler_job.py:155} INFO - Started process (PID=84448) to work on /airflow/dags/download_data.py
[2022-02-17 06:42:55,565] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:42:55,567] {logging_mixin.py:112} INFO - [2022-02-17 06:42:55,566] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:42:56,029] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:42:56,078] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:42:56,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:42:56,093] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 06:43:08,954] {scheduler_job.py:155} INFO - Started process (PID=84474) to work on /airflow/dags/download_data.py
[2022-02-17 06:43:08,966] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:43:08,971] {logging_mixin.py:112} INFO - [2022-02-17 06:43:08,970] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:43:09,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:43:09,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:43:09,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:43:09,591] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-17 06:43:22,319] {scheduler_job.py:155} INFO - Started process (PID=84502) to work on /airflow/dags/download_data.py
[2022-02-17 06:43:22,324] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:43:22,325] {logging_mixin.py:112} INFO - [2022-02-17 06:43:22,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:43:22,852] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:43:22,899] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:43:22,908] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:43:22,914] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 06:43:51,458] {scheduler_job.py:155} INFO - Started process (PID=84530) to work on /airflow/dags/download_data.py
[2022-02-17 06:43:51,464] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:43:51,466] {logging_mixin.py:112} INFO - [2022-02-17 06:43:51,465] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:43:59,453] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:44:00,645] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:44:00,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:44:00,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 9.395 seconds
[2022-02-17 06:44:11,982] {scheduler_job.py:155} INFO - Started process (PID=84556) to work on /airflow/dags/download_data.py
[2022-02-17 06:44:11,988] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:44:11,990] {logging_mixin.py:112} INFO - [2022-02-17 06:44:11,990] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:44:12,432] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:44:12,473] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:44:12,482] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:44:12,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 06:44:25,283] {scheduler_job.py:155} INFO - Started process (PID=84584) to work on /airflow/dags/download_data.py
[2022-02-17 06:44:25,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:44:25,288] {logging_mixin.py:112} INFO - [2022-02-17 06:44:25,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:44:25,758] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:44:25,807] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:44:25,819] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:44:25,826] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 06:44:39,985] {scheduler_job.py:155} INFO - Started process (PID=84610) to work on /airflow/dags/download_data.py
[2022-02-17 06:44:39,993] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 06:44:39,997] {logging_mixin.py:112} INFO - [2022-02-17 06:44:39,997] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 06:44:40,538] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 06:44:40,579] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 06:44:40,589] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 06:44:40,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-17 07:13:49,222] {scheduler_job.py:155} INFO - Started process (PID=84646) to work on /airflow/dags/download_data.py
[2022-02-17 07:13:49,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:13:49,229] {logging_mixin.py:112} INFO - [2022-02-17 07:13:49,228] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:13:49,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:13:49,778] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:13:49,791] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:13:49,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 07:14:02,517] {scheduler_job.py:155} INFO - Started process (PID=84672) to work on /airflow/dags/download_data.py
[2022-02-17 07:14:02,523] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:14:02,524] {logging_mixin.py:112} INFO - [2022-02-17 07:14:02,524] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:14:03,151] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:14:03,192] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:14:03,199] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:14:03,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.687 seconds
[2022-02-17 07:14:15,818] {scheduler_job.py:155} INFO - Started process (PID=84700) to work on /airflow/dags/download_data.py
[2022-02-17 07:14:15,828] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:14:15,831] {logging_mixin.py:112} INFO - [2022-02-17 07:14:15,831] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:14:16,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:14:16,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:14:16,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:14:16,435] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 07:14:29,115] {scheduler_job.py:155} INFO - Started process (PID=84726) to work on /airflow/dags/download_data.py
[2022-02-17 07:14:29,120] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:14:29,121] {logging_mixin.py:112} INFO - [2022-02-17 07:14:29,121] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:14:29,705] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:14:29,755] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:14:29,763] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:14:29,768] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.653 seconds
[2022-02-17 07:14:42,438] {scheduler_job.py:155} INFO - Started process (PID=84754) to work on /airflow/dags/download_data.py
[2022-02-17 07:14:42,443] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:14:42,444] {logging_mixin.py:112} INFO - [2022-02-17 07:14:42,444] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:14:43,003] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:14:43,061] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:14:43,070] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:14:43,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.639 seconds
[2022-02-17 07:14:55,757] {scheduler_job.py:155} INFO - Started process (PID=84780) to work on /airflow/dags/download_data.py
[2022-02-17 07:14:55,767] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:14:55,769] {logging_mixin.py:112} INFO - [2022-02-17 07:14:55,769] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:14:56,314] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:14:56,362] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:14:56,374] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:14:56,382] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-17 07:15:09,033] {scheduler_job.py:155} INFO - Started process (PID=84806) to work on /airflow/dags/download_data.py
[2022-02-17 07:15:09,041] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:15:09,044] {logging_mixin.py:112} INFO - [2022-02-17 07:15:09,043] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:15:09,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:15:09,647] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:15:09,653] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:15:09,658] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-17 07:15:22,387] {scheduler_job.py:155} INFO - Started process (PID=84834) to work on /airflow/dags/download_data.py
[2022-02-17 07:15:22,401] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:15:22,403] {logging_mixin.py:112} INFO - [2022-02-17 07:15:22,403] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:15:23,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:15:23,139] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:15:23,146] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:15:23,151] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.765 seconds
[2022-02-17 07:15:35,700] {scheduler_job.py:155} INFO - Started process (PID=84860) to work on /airflow/dags/download_data.py
[2022-02-17 07:15:35,705] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:15:35,707] {logging_mixin.py:112} INFO - [2022-02-17 07:15:35,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:15:36,242] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:15:36,291] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:15:36,301] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:15:36,307] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-17 07:15:48,962] {scheduler_job.py:155} INFO - Started process (PID=84888) to work on /airflow/dags/download_data.py
[2022-02-17 07:15:48,966] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:15:48,968] {logging_mixin.py:112} INFO - [2022-02-17 07:15:48,967] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:15:49,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:15:49,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:15:49,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:15:49,606] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-17 07:16:02,290] {scheduler_job.py:155} INFO - Started process (PID=84914) to work on /airflow/dags/download_data.py
[2022-02-17 07:16:02,298] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:16:02,301] {logging_mixin.py:112} INFO - [2022-02-17 07:16:02,300] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:16:02,952] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:16:03,006] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:16:03,018] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:16:03,024] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.734 seconds
[2022-02-17 07:16:15,570] {scheduler_job.py:155} INFO - Started process (PID=84942) to work on /airflow/dags/download_data.py
[2022-02-17 07:16:15,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:16:15,579] {logging_mixin.py:112} INFO - [2022-02-17 07:16:15,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:16:16,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:16:16,229] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:16:16,242] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:16:16,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-17 07:16:28,912] {scheduler_job.py:155} INFO - Started process (PID=84968) to work on /airflow/dags/download_data.py
[2022-02-17 07:16:28,923] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:16:28,926] {logging_mixin.py:112} INFO - [2022-02-17 07:16:28,926] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:16:29,461] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:16:29,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:16:29,523] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:16:29,528] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 07:16:42,221] {scheduler_job.py:155} INFO - Started process (PID=84996) to work on /airflow/dags/download_data.py
[2022-02-17 07:16:42,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:16:42,238] {logging_mixin.py:112} INFO - [2022-02-17 07:16:42,237] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:16:42,877] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:16:42,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:16:42,950] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:16:42,957] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.735 seconds
[2022-02-17 07:16:55,547] {scheduler_job.py:155} INFO - Started process (PID=85022) to work on /airflow/dags/download_data.py
[2022-02-17 07:16:55,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:16:55,556] {logging_mixin.py:112} INFO - [2022-02-17 07:16:55,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:16:56,005] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:16:56,062] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:16:56,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:16:56,083] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 07:17:08,811] {scheduler_job.py:155} INFO - Started process (PID=85048) to work on /airflow/dags/download_data.py
[2022-02-17 07:17:08,816] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:17:08,818] {logging_mixin.py:112} INFO - [2022-02-17 07:17:08,818] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:17:09,284] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:17:09,339] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:17:09,348] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:17:09,359] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 07:17:22,117] {scheduler_job.py:155} INFO - Started process (PID=85076) to work on /airflow/dags/download_data.py
[2022-02-17 07:17:22,130] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:17:22,133] {logging_mixin.py:112} INFO - [2022-02-17 07:17:22,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:17:22,607] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:17:22,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:17:22,678] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:17:22,682] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 07:17:35,437] {scheduler_job.py:155} INFO - Started process (PID=85102) to work on /airflow/dags/download_data.py
[2022-02-17 07:17:35,442] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:17:35,443] {logging_mixin.py:112} INFO - [2022-02-17 07:17:35,443] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:17:35,896] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:17:35,947] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:17:35,960] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:17:35,967] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 07:17:48,739] {scheduler_job.py:155} INFO - Started process (PID=85130) to work on /airflow/dags/download_data.py
[2022-02-17 07:17:48,744] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:17:48,746] {logging_mixin.py:112} INFO - [2022-02-17 07:17:48,746] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:17:49,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:17:49,263] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:17:49,279] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:17:49,288] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 07:18:02,016] {scheduler_job.py:155} INFO - Started process (PID=85156) to work on /airflow/dags/download_data.py
[2022-02-17 07:18:02,021] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:18:02,022] {logging_mixin.py:112} INFO - [2022-02-17 07:18:02,022] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:18:02,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:18:02,576] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:18:02,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:18:02,590] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-17 07:18:15,291] {scheduler_job.py:155} INFO - Started process (PID=85184) to work on /airflow/dags/download_data.py
[2022-02-17 07:18:15,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:18:15,298] {logging_mixin.py:112} INFO - [2022-02-17 07:18:15,297] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:18:15,764] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:18:15,805] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:18:15,814] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:18:15,823] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 07:18:28,647] {scheduler_job.py:155} INFO - Started process (PID=85210) to work on /airflow/dags/download_data.py
[2022-02-17 07:18:28,658] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:18:28,664] {logging_mixin.py:112} INFO - [2022-02-17 07:18:28,664] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:18:29,227] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:18:29,288] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:18:29,298] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:18:29,303] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.656 seconds
[2022-02-17 07:18:41,948] {scheduler_job.py:155} INFO - Started process (PID=85236) to work on /airflow/dags/download_data.py
[2022-02-17 07:18:41,957] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:18:41,960] {logging_mixin.py:112} INFO - [2022-02-17 07:18:41,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:18:42,425] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:18:42,488] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:18:42,494] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:18:42,499] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 07:18:55,296] {scheduler_job.py:155} INFO - Started process (PID=85264) to work on /airflow/dags/download_data.py
[2022-02-17 07:18:55,301] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:18:55,303] {logging_mixin.py:112} INFO - [2022-02-17 07:18:55,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:18:55,773] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:18:55,826] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:18:55,834] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:18:55,837] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 07:19:08,586] {scheduler_job.py:155} INFO - Started process (PID=85290) to work on /airflow/dags/download_data.py
[2022-02-17 07:19:08,592] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:19:08,593] {logging_mixin.py:112} INFO - [2022-02-17 07:19:08,593] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:19:09,156] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:19:09,213] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:19:09,223] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:19:09,228] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-17 07:19:21,885] {scheduler_job.py:155} INFO - Started process (PID=85318) to work on /airflow/dags/download_data.py
[2022-02-17 07:19:21,889] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:19:21,891] {logging_mixin.py:112} INFO - [2022-02-17 07:19:21,891] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:19:22,380] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:19:22,436] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:19:22,446] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:19:22,451] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 07:19:35,212] {scheduler_job.py:155} INFO - Started process (PID=85344) to work on /airflow/dags/download_data.py
[2022-02-17 07:19:35,219] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:19:35,222] {logging_mixin.py:112} INFO - [2022-02-17 07:19:35,221] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:19:35,635] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:19:35,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:19:35,693] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:19:35,697] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-17 07:19:48,459] {scheduler_job.py:155} INFO - Started process (PID=85372) to work on /airflow/dags/download_data.py
[2022-02-17 07:19:48,469] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:19:48,475] {logging_mixin.py:112} INFO - [2022-02-17 07:19:48,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:19:48,952] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:19:49,014] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:19:49,021] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:19:49,025] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 07:20:01,790] {scheduler_job.py:155} INFO - Started process (PID=85398) to work on /airflow/dags/download_data.py
[2022-02-17 07:20:01,799] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:20:01,802] {logging_mixin.py:112} INFO - [2022-02-17 07:20:01,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:20:02,334] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:20:02,385] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:20:02,396] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:20:02,405] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-17 07:20:15,064] {scheduler_job.py:155} INFO - Started process (PID=85424) to work on /airflow/dags/download_data.py
[2022-02-17 07:20:15,074] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:20:15,077] {logging_mixin.py:112} INFO - [2022-02-17 07:20:15,076] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:20:15,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:20:15,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:20:15,709] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:20:15,713] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.649 seconds
[2022-02-17 07:20:28,363] {scheduler_job.py:155} INFO - Started process (PID=85452) to work on /airflow/dags/download_data.py
[2022-02-17 07:20:28,370] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:20:28,372] {logging_mixin.py:112} INFO - [2022-02-17 07:20:28,371] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:20:28,941] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:20:28,992] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:20:29,001] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:20:29,005] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-17 07:20:41,637] {scheduler_job.py:155} INFO - Started process (PID=85478) to work on /airflow/dags/download_data.py
[2022-02-17 07:20:41,642] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:20:41,644] {logging_mixin.py:112} INFO - [2022-02-17 07:20:41,643] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:20:42,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:20:42,150] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:20:42,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:20:42,162] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 07:20:54,956] {scheduler_job.py:155} INFO - Started process (PID=85506) to work on /airflow/dags/download_data.py
[2022-02-17 07:20:54,969] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:20:54,971] {logging_mixin.py:112} INFO - [2022-02-17 07:20:54,971] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:20:55,438] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:20:55,482] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:20:55,488] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:20:55,494] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 07:21:08,239] {scheduler_job.py:155} INFO - Started process (PID=85532) to work on /airflow/dags/download_data.py
[2022-02-17 07:21:08,249] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:21:08,253] {logging_mixin.py:112} INFO - [2022-02-17 07:21:08,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:21:08,804] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:21:08,869] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:21:08,880] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:21:08,884] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.646 seconds
[2022-02-17 07:21:21,512] {scheduler_job.py:155} INFO - Started process (PID=85560) to work on /airflow/dags/download_data.py
[2022-02-17 07:21:21,519] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:21:21,521] {logging_mixin.py:112} INFO - [2022-02-17 07:21:21,520] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:21:21,991] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:21:22,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:21:22,051] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:21:22,057] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 07:21:34,836] {scheduler_job.py:155} INFO - Started process (PID=85586) to work on /airflow/dags/download_data.py
[2022-02-17 07:21:34,840] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:21:34,842] {logging_mixin.py:112} INFO - [2022-02-17 07:21:34,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:21:35,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:21:35,362] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:21:35,374] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:21:35,377] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 07:21:48,100] {scheduler_job.py:155} INFO - Started process (PID=85614) to work on /airflow/dags/download_data.py
[2022-02-17 07:21:48,116] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:21:48,120] {logging_mixin.py:112} INFO - [2022-02-17 07:21:48,119] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:21:48,600] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:21:48,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:21:48,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:21:48,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 07:22:01,402] {scheduler_job.py:155} INFO - Started process (PID=85640) to work on /airflow/dags/download_data.py
[2022-02-17 07:22:01,407] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:22:01,410] {logging_mixin.py:112} INFO - [2022-02-17 07:22:01,409] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:22:01,919] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:22:01,972] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:22:01,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:22:01,988] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 07:22:14,658] {scheduler_job.py:155} INFO - Started process (PID=85666) to work on /airflow/dags/download_data.py
[2022-02-17 07:22:14,663] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:22:14,666] {logging_mixin.py:112} INFO - [2022-02-17 07:22:14,665] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:22:15,146] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:22:15,218] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:22:15,226] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:22:15,231] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 07:22:27,963] {scheduler_job.py:155} INFO - Started process (PID=85694) to work on /airflow/dags/download_data.py
[2022-02-17 07:22:27,969] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:22:27,971] {logging_mixin.py:112} INFO - [2022-02-17 07:22:27,971] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:22:28,511] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:22:28,562] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:22:28,570] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:22:28,575] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-17 07:22:41,220] {scheduler_job.py:155} INFO - Started process (PID=85720) to work on /airflow/dags/download_data.py
[2022-02-17 07:22:41,229] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:22:41,231] {logging_mixin.py:112} INFO - [2022-02-17 07:22:41,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:22:41,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:22:41,762] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:22:41,774] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:22:41,779] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 07:22:54,543] {scheduler_job.py:155} INFO - Started process (PID=85748) to work on /airflow/dags/download_data.py
[2022-02-17 07:22:54,552] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:22:54,563] {logging_mixin.py:112} INFO - [2022-02-17 07:22:54,562] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:22:55,014] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:22:55,057] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:22:55,064] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:22:55,069] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 07:23:07,802] {scheduler_job.py:155} INFO - Started process (PID=85774) to work on /airflow/dags/download_data.py
[2022-02-17 07:23:07,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:23:07,810] {logging_mixin.py:112} INFO - [2022-02-17 07:23:07,810] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:23:08,372] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:23:08,412] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:23:08,419] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:23:08,425] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-17 07:23:21,221] {scheduler_job.py:155} INFO - Started process (PID=85802) to work on /airflow/dags/download_data.py
[2022-02-17 07:23:21,226] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:23:21,227] {logging_mixin.py:112} INFO - [2022-02-17 07:23:21,227] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:23:21,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:23:21,752] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:23:21,762] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:23:21,768] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 07:23:34,587] {scheduler_job.py:155} INFO - Started process (PID=85828) to work on /airflow/dags/download_data.py
[2022-02-17 07:23:34,595] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:23:34,598] {logging_mixin.py:112} INFO - [2022-02-17 07:23:34,597] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:23:35,073] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:23:35,121] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:23:35,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:23:35,134] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 07:23:47,860] {scheduler_job.py:155} INFO - Started process (PID=85854) to work on /airflow/dags/download_data.py
[2022-02-17 07:23:47,865] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:23:47,867] {logging_mixin.py:112} INFO - [2022-02-17 07:23:47,867] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:23:48,299] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:23:48,347] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:23:48,353] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:23:48,358] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 07:24:01,152] {scheduler_job.py:155} INFO - Started process (PID=85882) to work on /airflow/dags/download_data.py
[2022-02-17 07:24:01,157] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:24:01,159] {logging_mixin.py:112} INFO - [2022-02-17 07:24:01,158] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:24:01,625] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:24:01,692] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:24:01,705] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:24:01,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 07:24:14,463] {scheduler_job.py:155} INFO - Started process (PID=85908) to work on /airflow/dags/download_data.py
[2022-02-17 07:24:14,467] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:24:14,469] {logging_mixin.py:112} INFO - [2022-02-17 07:24:14,469] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:24:14,983] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:24:15,027] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:24:15,035] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:24:15,040] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 07:24:27,744] {scheduler_job.py:155} INFO - Started process (PID=85936) to work on /airflow/dags/download_data.py
[2022-02-17 07:24:27,750] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:24:27,752] {logging_mixin.py:112} INFO - [2022-02-17 07:24:27,752] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:24:28,238] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:24:28,294] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:24:28,302] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:24:28,309] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 07:24:41,009] {scheduler_job.py:155} INFO - Started process (PID=85962) to work on /airflow/dags/download_data.py
[2022-02-17 07:24:41,017] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:24:41,019] {logging_mixin.py:112} INFO - [2022-02-17 07:24:41,019] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:24:41,461] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:24:41,501] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:24:41,508] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:24:41,511] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 07:24:54,308] {scheduler_job.py:155} INFO - Started process (PID=85990) to work on /airflow/dags/download_data.py
[2022-02-17 07:24:54,321] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:24:54,324] {logging_mixin.py:112} INFO - [2022-02-17 07:24:54,323] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:24:54,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:24:54,836] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:24:54,844] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:24:54,849] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 07:25:07,563] {scheduler_job.py:155} INFO - Started process (PID=86016) to work on /airflow/dags/download_data.py
[2022-02-17 07:25:07,569] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:25:07,571] {logging_mixin.py:112} INFO - [2022-02-17 07:25:07,571] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:25:08,038] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:25:08,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:25:08,113] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:25:08,120] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 07:25:20,862] {scheduler_job.py:155} INFO - Started process (PID=86042) to work on /airflow/dags/download_data.py
[2022-02-17 07:25:20,871] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:25:20,873] {logging_mixin.py:112} INFO - [2022-02-17 07:25:20,873] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:25:21,312] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:25:21,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:25:21,372] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:25:21,378] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 07:25:34,166] {scheduler_job.py:155} INFO - Started process (PID=86070) to work on /airflow/dags/download_data.py
[2022-02-17 07:25:34,175] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:25:34,177] {logging_mixin.py:112} INFO - [2022-02-17 07:25:34,177] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:25:34,604] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:25:34,648] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:25:34,655] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:25:34,661] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 07:25:47,399] {scheduler_job.py:155} INFO - Started process (PID=86096) to work on /airflow/dags/download_data.py
[2022-02-17 07:25:47,404] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:25:47,406] {logging_mixin.py:112} INFO - [2022-02-17 07:25:47,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:25:47,843] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:25:47,890] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:25:47,900] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:25:47,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 07:26:00,694] {scheduler_job.py:155} INFO - Started process (PID=86124) to work on /airflow/dags/download_data.py
[2022-02-17 07:26:00,701] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:26:00,703] {logging_mixin.py:112} INFO - [2022-02-17 07:26:00,703] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:26:01,192] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:26:01,249] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:26:01,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:26:01,268] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 07:26:13,966] {scheduler_job.py:155} INFO - Started process (PID=86150) to work on /airflow/dags/download_data.py
[2022-02-17 07:26:13,972] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:26:13,973] {logging_mixin.py:112} INFO - [2022-02-17 07:26:13,973] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:26:14,451] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:26:14,504] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:26:14,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:26:14,520] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 07:26:27,295] {scheduler_job.py:155} INFO - Started process (PID=86178) to work on /airflow/dags/download_data.py
[2022-02-17 07:26:27,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:26:27,301] {logging_mixin.py:112} INFO - [2022-02-17 07:26:27,301] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:26:27,749] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:26:27,813] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:26:27,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:26:27,836] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 07:26:40,596] {scheduler_job.py:155} INFO - Started process (PID=86204) to work on /airflow/dags/download_data.py
[2022-02-17 07:26:40,600] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:26:40,604] {logging_mixin.py:112} INFO - [2022-02-17 07:26:40,604] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:26:41,036] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:26:41,075] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:26:41,081] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:26:41,085] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-17 07:26:53,892] {scheduler_job.py:155} INFO - Started process (PID=86231) to work on /airflow/dags/download_data.py
[2022-02-17 07:26:53,901] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:26:53,902] {logging_mixin.py:112} INFO - [2022-02-17 07:26:53,902] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:26:54,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:26:54,434] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:26:54,439] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:26:54,443] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 07:27:07,161] {scheduler_job.py:155} INFO - Started process (PID=86258) to work on /airflow/dags/download_data.py
[2022-02-17 07:27:07,167] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:27:07,169] {logging_mixin.py:112} INFO - [2022-02-17 07:27:07,169] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:27:07,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:27:07,692] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:27:07,706] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:27:07,713] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 07:27:20,501] {scheduler_job.py:155} INFO - Started process (PID=86284) to work on /airflow/dags/download_data.py
[2022-02-17 07:27:20,506] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:27:20,508] {logging_mixin.py:112} INFO - [2022-02-17 07:27:20,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:27:20,948] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:27:20,997] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:27:21,004] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:27:21,011] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 07:27:33,793] {scheduler_job.py:155} INFO - Started process (PID=86312) to work on /airflow/dags/download_data.py
[2022-02-17 07:27:33,798] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:27:33,800] {logging_mixin.py:112} INFO - [2022-02-17 07:27:33,800] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:27:34,242] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:27:34,293] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:27:34,302] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:27:34,309] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 07:27:47,040] {scheduler_job.py:155} INFO - Started process (PID=86338) to work on /airflow/dags/download_data.py
[2022-02-17 07:27:47,045] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:27:47,047] {logging_mixin.py:112} INFO - [2022-02-17 07:27:47,047] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:27:47,487] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:27:47,538] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:27:47,548] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:27:47,556] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 07:28:00,346] {scheduler_job.py:155} INFO - Started process (PID=86366) to work on /airflow/dags/download_data.py
[2022-02-17 07:28:00,353] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:28:00,355] {logging_mixin.py:112} INFO - [2022-02-17 07:28:00,355] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:28:00,826] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:28:00,882] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:28:00,890] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:28:00,901] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 07:28:13,615] {scheduler_job.py:155} INFO - Started process (PID=86392) to work on /airflow/dags/download_data.py
[2022-02-17 07:28:13,619] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:28:13,621] {logging_mixin.py:112} INFO - [2022-02-17 07:28:13,621] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:28:14,084] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:28:14,138] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:28:14,149] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:28:14,153] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 07:28:26,918] {scheduler_job.py:155} INFO - Started process (PID=86420) to work on /airflow/dags/download_data.py
[2022-02-17 07:28:26,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:28:26,929] {logging_mixin.py:112} INFO - [2022-02-17 07:28:26,929] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:28:27,369] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:28:27,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:28:27,424] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:28:27,429] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 07:28:40,196] {scheduler_job.py:155} INFO - Started process (PID=86446) to work on /airflow/dags/download_data.py
[2022-02-17 07:28:40,205] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:28:40,207] {logging_mixin.py:112} INFO - [2022-02-17 07:28:40,207] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:28:40,650] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:28:40,701] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:28:40,708] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:28:40,712] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 07:28:53,507] {scheduler_job.py:155} INFO - Started process (PID=86472) to work on /airflow/dags/download_data.py
[2022-02-17 07:28:53,513] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:28:53,516] {logging_mixin.py:112} INFO - [2022-02-17 07:28:53,515] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:28:53,950] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:28:54,000] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:28:54,011] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:28:54,015] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 07:29:06,758] {scheduler_job.py:155} INFO - Started process (PID=86500) to work on /airflow/dags/download_data.py
[2022-02-17 07:29:06,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:29:06,764] {logging_mixin.py:112} INFO - [2022-02-17 07:29:06,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:29:07,231] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:29:07,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:29:07,291] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:29:07,296] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 07:29:20,053] {scheduler_job.py:155} INFO - Started process (PID=86526) to work on /airflow/dags/download_data.py
[2022-02-17 07:29:20,058] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:29:20,065] {logging_mixin.py:112} INFO - [2022-02-17 07:29:20,061] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:29:20,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:29:20,550] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:29:20,559] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:29:20,564] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 07:29:33,353] {scheduler_job.py:155} INFO - Started process (PID=86554) to work on /airflow/dags/download_data.py
[2022-02-17 07:29:33,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:29:33,359] {logging_mixin.py:112} INFO - [2022-02-17 07:29:33,359] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:29:33,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:29:33,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:29:33,860] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:29:33,865] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 07:29:46,626] {scheduler_job.py:155} INFO - Started process (PID=86580) to work on /airflow/dags/download_data.py
[2022-02-17 07:29:46,635] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:29:46,637] {logging_mixin.py:112} INFO - [2022-02-17 07:29:46,637] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:29:47,064] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:29:47,114] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:29:47,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:29:47,128] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 07:29:59,948] {scheduler_job.py:155} INFO - Started process (PID=86608) to work on /airflow/dags/download_data.py
[2022-02-17 07:29:59,956] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:29:59,959] {logging_mixin.py:112} INFO - [2022-02-17 07:29:59,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:30:00,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:30:00,428] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:30:00,437] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:30:00,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 07:30:13,203] {scheduler_job.py:155} INFO - Started process (PID=86634) to work on /airflow/dags/download_data.py
[2022-02-17 07:30:13,209] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:30:13,210] {logging_mixin.py:112} INFO - [2022-02-17 07:30:13,210] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:30:13,665] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:30:13,725] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:30:13,736] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:30:13,741] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 07:30:26,507] {scheduler_job.py:155} INFO - Started process (PID=86660) to work on /airflow/dags/download_data.py
[2022-02-17 07:30:26,514] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:30:26,516] {logging_mixin.py:112} INFO - [2022-02-17 07:30:26,515] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:30:26,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:30:27,005] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:30:27,013] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:30:27,018] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 07:30:39,758] {scheduler_job.py:155} INFO - Started process (PID=86688) to work on /airflow/dags/download_data.py
[2022-02-17 07:30:39,766] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:30:39,768] {logging_mixin.py:112} INFO - [2022-02-17 07:30:39,768] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:30:40,313] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:30:40,365] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:30:40,375] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:30:40,381] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-17 07:30:53,035] {scheduler_job.py:155} INFO - Started process (PID=86714) to work on /airflow/dags/download_data.py
[2022-02-17 07:30:53,040] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:30:53,041] {logging_mixin.py:112} INFO - [2022-02-17 07:30:53,041] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:30:53,472] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:30:53,522] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:30:53,530] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:30:53,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 07:31:06,307] {scheduler_job.py:155} INFO - Started process (PID=86742) to work on /airflow/dags/download_data.py
[2022-02-17 07:31:06,313] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:31:06,315] {logging_mixin.py:112} INFO - [2022-02-17 07:31:06,315] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:31:06,781] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:31:06,841] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:31:06,849] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:31:06,856] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 07:31:19,615] {scheduler_job.py:155} INFO - Started process (PID=86768) to work on /airflow/dags/download_data.py
[2022-02-17 07:31:19,622] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:31:19,624] {logging_mixin.py:112} INFO - [2022-02-17 07:31:19,624] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:31:20,052] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:31:20,104] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:31:20,114] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:31:20,119] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 07:31:32,896] {scheduler_job.py:155} INFO - Started process (PID=86796) to work on /airflow/dags/download_data.py
[2022-02-17 07:31:32,907] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:31:32,909] {logging_mixin.py:112} INFO - [2022-02-17 07:31:32,909] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:31:33,349] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:31:33,389] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:31:33,397] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:31:33,400] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 07:31:46,170] {scheduler_job.py:155} INFO - Started process (PID=86822) to work on /airflow/dags/download_data.py
[2022-02-17 07:31:46,174] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:31:46,177] {logging_mixin.py:112} INFO - [2022-02-17 07:31:46,176] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:31:46,626] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:31:46,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:31:46,676] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:31:46,682] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 07:31:59,517] {scheduler_job.py:155} INFO - Started process (PID=86848) to work on /airflow/dags/download_data.py
[2022-02-17 07:31:59,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:31:59,529] {logging_mixin.py:112} INFO - [2022-02-17 07:31:59,529] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:31:59,984] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:32:00,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:32:00,058] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:32:00,062] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 07:32:12,752] {scheduler_job.py:155} INFO - Started process (PID=86876) to work on /airflow/dags/download_data.py
[2022-02-17 07:32:12,757] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:32:12,758] {logging_mixin.py:112} INFO - [2022-02-17 07:32:12,758] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:32:13,218] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:32:13,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:32:13,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:32:13,296] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 07:32:26,058] {scheduler_job.py:155} INFO - Started process (PID=86902) to work on /airflow/dags/download_data.py
[2022-02-17 07:32:26,062] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:32:26,063] {logging_mixin.py:112} INFO - [2022-02-17 07:32:26,063] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:32:26,511] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:32:26,551] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:32:26,558] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:32:26,562] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 07:32:39,344] {scheduler_job.py:155} INFO - Started process (PID=86930) to work on /airflow/dags/download_data.py
[2022-02-17 07:32:39,352] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:32:39,354] {logging_mixin.py:112} INFO - [2022-02-17 07:32:39,354] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:32:39,781] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:32:39,822] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:32:39,830] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:32:39,835] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 07:32:52,600] {scheduler_job.py:155} INFO - Started process (PID=86956) to work on /airflow/dags/download_data.py
[2022-02-17 07:32:52,606] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:32:52,608] {logging_mixin.py:112} INFO - [2022-02-17 07:32:52,607] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:32:53,039] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:32:53,091] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:32:53,099] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:32:53,105] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 07:33:05,885] {scheduler_job.py:155} INFO - Started process (PID=86984) to work on /airflow/dags/download_data.py
[2022-02-17 07:33:05,896] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:33:05,899] {logging_mixin.py:112} INFO - [2022-02-17 07:33:05,898] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:33:06,328] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:33:06,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:33:06,395] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:33:06,402] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 07:33:19,175] {scheduler_job.py:155} INFO - Started process (PID=87010) to work on /airflow/dags/download_data.py
[2022-02-17 07:33:19,181] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:33:19,183] {logging_mixin.py:112} INFO - [2022-02-17 07:33:19,183] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:33:19,615] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:33:19,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:33:19,664] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:33:19,669] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 07:33:32,459] {scheduler_job.py:155} INFO - Started process (PID=87036) to work on /airflow/dags/download_data.py
[2022-02-17 07:33:32,463] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:33:32,465] {logging_mixin.py:112} INFO - [2022-02-17 07:33:32,465] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:33:32,949] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:33:33,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:33:33,015] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:33:33,018] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 07:33:45,773] {scheduler_job.py:155} INFO - Started process (PID=87064) to work on /airflow/dags/download_data.py
[2022-02-17 07:33:45,777] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:33:45,779] {logging_mixin.py:112} INFO - [2022-02-17 07:33:45,778] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:33:46,225] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:33:46,266] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:33:46,272] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:33:46,276] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 07:33:59,085] {scheduler_job.py:155} INFO - Started process (PID=87090) to work on /airflow/dags/download_data.py
[2022-02-17 07:33:59,091] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:33:59,094] {logging_mixin.py:112} INFO - [2022-02-17 07:33:59,094] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:33:59,590] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:33:59,652] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:33:59,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:33:59,668] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 07:34:12,317] {scheduler_job.py:155} INFO - Started process (PID=87118) to work on /airflow/dags/download_data.py
[2022-02-17 07:34:12,321] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:34:12,323] {logging_mixin.py:112} INFO - [2022-02-17 07:34:12,322] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:34:12,793] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:34:12,838] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:34:12,847] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:34:12,852] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 07:34:25,631] {scheduler_job.py:155} INFO - Started process (PID=87144) to work on /airflow/dags/download_data.py
[2022-02-17 07:34:25,639] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:34:25,641] {logging_mixin.py:112} INFO - [2022-02-17 07:34:25,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:34:26,071] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:34:26,124] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:34:26,132] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:34:26,137] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 07:34:38,892] {scheduler_job.py:155} INFO - Started process (PID=87172) to work on /airflow/dags/download_data.py
[2022-02-17 07:34:38,900] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:34:38,903] {logging_mixin.py:112} INFO - [2022-02-17 07:34:38,902] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:34:39,347] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:34:39,400] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:34:39,409] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:34:39,415] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 07:34:52,197] {scheduler_job.py:155} INFO - Started process (PID=87198) to work on /airflow/dags/download_data.py
[2022-02-17 07:34:52,202] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:34:52,204] {logging_mixin.py:112} INFO - [2022-02-17 07:34:52,203] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:34:52,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:34:52,683] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:34:52,690] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:34:52,695] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 07:35:05,494] {scheduler_job.py:155} INFO - Started process (PID=87226) to work on /airflow/dags/download_data.py
[2022-02-17 07:35:05,508] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:35:05,510] {logging_mixin.py:112} INFO - [2022-02-17 07:35:05,509] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:35:06,011] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:35:06,057] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:35:06,064] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:35:06,070] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-17 07:35:18,828] {scheduler_job.py:155} INFO - Started process (PID=87252) to work on /airflow/dags/download_data.py
[2022-02-17 07:35:18,832] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:35:18,834] {logging_mixin.py:112} INFO - [2022-02-17 07:35:18,834] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:35:19,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:35:19,321] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:35:19,327] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:35:19,331] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 07:35:32,155] {scheduler_job.py:155} INFO - Started process (PID=87278) to work on /airflow/dags/download_data.py
[2022-02-17 07:35:32,165] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:35:32,167] {logging_mixin.py:112} INFO - [2022-02-17 07:35:32,167] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:35:32,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:35:32,651] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:35:32,660] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:35:32,663] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 07:35:45,422] {scheduler_job.py:155} INFO - Started process (PID=87306) to work on /airflow/dags/download_data.py
[2022-02-17 07:35:45,427] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:35:45,430] {logging_mixin.py:112} INFO - [2022-02-17 07:35:45,430] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:35:45,883] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:35:45,920] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:35:45,930] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:35:45,933] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 07:35:58,695] {scheduler_job.py:155} INFO - Started process (PID=87332) to work on /airflow/dags/download_data.py
[2022-02-17 07:35:58,699] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:35:58,701] {logging_mixin.py:112} INFO - [2022-02-17 07:35:58,701] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:35:59,171] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:35:59,218] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:35:59,227] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:35:59,233] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 07:36:11,959] {scheduler_job.py:155} INFO - Started process (PID=87360) to work on /airflow/dags/download_data.py
[2022-02-17 07:36:11,971] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:36:11,973] {logging_mixin.py:112} INFO - [2022-02-17 07:36:11,973] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:36:12,448] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:36:12,498] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:36:12,511] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:36:12,516] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 07:36:25,232] {scheduler_job.py:155} INFO - Started process (PID=87386) to work on /airflow/dags/download_data.py
[2022-02-17 07:36:25,236] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:36:25,238] {logging_mixin.py:112} INFO - [2022-02-17 07:36:25,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:36:25,677] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:36:25,719] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:36:25,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:36:25,729] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 07:36:38,527] {scheduler_job.py:155} INFO - Started process (PID=87414) to work on /airflow/dags/download_data.py
[2022-02-17 07:36:38,533] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:36:38,534] {logging_mixin.py:112} INFO - [2022-02-17 07:36:38,534] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:36:38,978] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:36:39,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:36:39,025] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:36:39,030] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 07:36:51,818] {scheduler_job.py:155} INFO - Started process (PID=87440) to work on /airflow/dags/download_data.py
[2022-02-17 07:36:51,824] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:36:51,825] {logging_mixin.py:112} INFO - [2022-02-17 07:36:51,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:36:52,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:36:52,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:36:52,308] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:36:52,312] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 07:37:05,116] {scheduler_job.py:155} INFO - Started process (PID=87466) to work on /airflow/dags/download_data.py
[2022-02-17 07:37:05,124] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:37:05,127] {logging_mixin.py:112} INFO - [2022-02-17 07:37:05,126] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:37:05,567] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:37:05,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:37:05,639] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:37:05,644] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 07:37:18,414] {scheduler_job.py:155} INFO - Started process (PID=87494) to work on /airflow/dags/download_data.py
[2022-02-17 07:37:18,419] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:37:18,421] {logging_mixin.py:112} INFO - [2022-02-17 07:37:18,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:37:18,847] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:37:18,893] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:37:18,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:37:18,902] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 07:37:31,695] {scheduler_job.py:155} INFO - Started process (PID=87520) to work on /airflow/dags/download_data.py
[2022-02-17 07:37:31,699] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:37:31,700] {logging_mixin.py:112} INFO - [2022-02-17 07:37:31,700] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:37:32,128] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:37:32,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:37:32,193] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:37:32,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 07:37:44,949] {scheduler_job.py:155} INFO - Started process (PID=87548) to work on /airflow/dags/download_data.py
[2022-02-17 07:37:44,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:37:44,955] {logging_mixin.py:112} INFO - [2022-02-17 07:37:44,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:37:45,406] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:37:45,455] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:37:45,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:37:45,466] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 07:37:58,247] {scheduler_job.py:155} INFO - Started process (PID=87574) to work on /airflow/dags/download_data.py
[2022-02-17 07:37:58,251] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:37:58,254] {logging_mixin.py:112} INFO - [2022-02-17 07:37:58,253] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:37:58,708] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:37:58,768] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:37:58,781] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:37:58,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 07:38:11,545] {scheduler_job.py:155} INFO - Started process (PID=87602) to work on /airflow/dags/download_data.py
[2022-02-17 07:38:11,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:38:11,558] {logging_mixin.py:112} INFO - [2022-02-17 07:38:11,558] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:38:12,044] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:38:12,098] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:38:12,107] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:38:12,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 07:38:24,856] {scheduler_job.py:155} INFO - Started process (PID=87628) to work on /airflow/dags/download_data.py
[2022-02-17 07:38:24,860] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:38:24,862] {logging_mixin.py:112} INFO - [2022-02-17 07:38:24,862] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:38:25,287] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:38:25,329] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:38:25,337] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:38:25,342] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.486 seconds
[2022-02-17 07:38:38,120] {scheduler_job.py:155} INFO - Started process (PID=87654) to work on /airflow/dags/download_data.py
[2022-02-17 07:38:38,125] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:38:38,126] {logging_mixin.py:112} INFO - [2022-02-17 07:38:38,126] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:38:38,564] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:38:38,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:38:38,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:38:38,626] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 07:38:51,456] {scheduler_job.py:155} INFO - Started process (PID=87682) to work on /airflow/dags/download_data.py
[2022-02-17 07:38:51,467] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:38:51,469] {logging_mixin.py:112} INFO - [2022-02-17 07:38:51,469] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:38:51,893] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:38:51,945] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:38:51,954] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:38:51,960] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 07:39:04,743] {scheduler_job.py:155} INFO - Started process (PID=87708) to work on /airflow/dags/download_data.py
[2022-02-17 07:39:04,750] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:39:04,752] {logging_mixin.py:112} INFO - [2022-02-17 07:39:04,752] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:39:05,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:39:05,232] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:39:05,240] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:39:05,244] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 07:39:18,040] {scheduler_job.py:155} INFO - Started process (PID=87736) to work on /airflow/dags/download_data.py
[2022-02-17 07:39:18,049] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:39:18,050] {logging_mixin.py:112} INFO - [2022-02-17 07:39:18,050] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:39:18,491] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:39:18,544] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:39:18,555] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:39:18,561] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 07:39:31,311] {scheduler_job.py:155} INFO - Started process (PID=87762) to work on /airflow/dags/download_data.py
[2022-02-17 07:39:31,317] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:39:31,319] {logging_mixin.py:112} INFO - [2022-02-17 07:39:31,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:39:31,753] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:39:31,794] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:39:31,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:39:31,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 07:39:44,516] {scheduler_job.py:155} INFO - Started process (PID=87790) to work on /airflow/dags/download_data.py
[2022-02-17 07:39:44,520] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:39:44,521] {logging_mixin.py:112} INFO - [2022-02-17 07:39:44,521] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:39:44,964] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:39:45,010] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:39:45,016] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:39:45,021] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 07:39:57,816] {scheduler_job.py:155} INFO - Started process (PID=87816) to work on /airflow/dags/download_data.py
[2022-02-17 07:39:57,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:39:57,824] {logging_mixin.py:112} INFO - [2022-02-17 07:39:57,824] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:39:58,339] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:39:58,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:39:58,415] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:39:58,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-17 07:40:11,092] {scheduler_job.py:155} INFO - Started process (PID=87843) to work on /airflow/dags/download_data.py
[2022-02-17 07:40:11,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:40:11,103] {logging_mixin.py:112} INFO - [2022-02-17 07:40:11,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:40:11,661] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:40:11,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:40:11,709] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:40:11,713] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-17 07:40:24,387] {scheduler_job.py:155} INFO - Started process (PID=87870) to work on /airflow/dags/download_data.py
[2022-02-17 07:40:24,395] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:40:24,397] {logging_mixin.py:112} INFO - [2022-02-17 07:40:24,397] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:40:24,840] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:40:24,892] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:40:24,899] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:40:24,905] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 07:40:37,656] {scheduler_job.py:155} INFO - Started process (PID=87896) to work on /airflow/dags/download_data.py
[2022-02-17 07:40:37,662] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:40:37,665] {logging_mixin.py:112} INFO - [2022-02-17 07:40:37,664] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:40:38,108] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:40:38,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:40:38,175] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:40:38,180] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 07:40:50,981] {scheduler_job.py:155} INFO - Started process (PID=87924) to work on /airflow/dags/download_data.py
[2022-02-17 07:40:50,985] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:40:50,987] {logging_mixin.py:112} INFO - [2022-02-17 07:40:50,987] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:40:51,411] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:40:51,453] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:40:51,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:40:51,465] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-17 07:41:04,295] {scheduler_job.py:155} INFO - Started process (PID=87950) to work on /airflow/dags/download_data.py
[2022-02-17 07:41:04,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:41:04,300] {logging_mixin.py:112} INFO - [2022-02-17 07:41:04,300] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:41:04,721] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:41:04,769] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:41:04,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:41:04,782] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.487 seconds
[2022-02-17 07:41:17,563] {scheduler_job.py:155} INFO - Started process (PID=87978) to work on /airflow/dags/download_data.py
[2022-02-17 07:41:17,567] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:41:17,568] {logging_mixin.py:112} INFO - [2022-02-17 07:41:17,568] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:41:18,016] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:41:18,071] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:41:18,080] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:41:18,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 07:41:30,867] {scheduler_job.py:155} INFO - Started process (PID=88004) to work on /airflow/dags/download_data.py
[2022-02-17 07:41:30,871] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:41:30,872] {logging_mixin.py:112} INFO - [2022-02-17 07:41:30,872] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:41:31,307] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:41:31,359] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:41:31,366] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:41:31,373] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 07:41:44,129] {scheduler_job.py:155} INFO - Started process (PID=88032) to work on /airflow/dags/download_data.py
[2022-02-17 07:41:44,150] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:41:44,152] {logging_mixin.py:112} INFO - [2022-02-17 07:41:44,151] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:41:44,608] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:41:44,645] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:41:44,660] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:41:44,673] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 07:41:57,400] {scheduler_job.py:155} INFO - Started process (PID=88058) to work on /airflow/dags/download_data.py
[2022-02-17 07:41:57,409] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:41:57,411] {logging_mixin.py:112} INFO - [2022-02-17 07:41:57,411] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:41:57,910] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:41:57,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:41:57,960] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:41:57,965] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 07:42:10,650] {scheduler_job.py:155} INFO - Started process (PID=88084) to work on /airflow/dags/download_data.py
[2022-02-17 07:42:10,656] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:42:10,659] {logging_mixin.py:112} INFO - [2022-02-17 07:42:10,659] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:42:11,136] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:42:11,196] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:42:11,208] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:42:11,213] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 07:42:23,952] {scheduler_job.py:155} INFO - Started process (PID=88112) to work on /airflow/dags/download_data.py
[2022-02-17 07:42:23,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:42:23,961] {logging_mixin.py:112} INFO - [2022-02-17 07:42:23,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:42:24,391] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:42:24,445] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:42:24,453] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:42:24,458] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 07:42:37,218] {scheduler_job.py:155} INFO - Started process (PID=88138) to work on /airflow/dags/download_data.py
[2022-02-17 07:42:37,223] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:42:37,225] {logging_mixin.py:112} INFO - [2022-02-17 07:42:37,225] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:42:37,662] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:42:37,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:42:37,707] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:42:37,711] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 07:42:50,678] {scheduler_job.py:155} INFO - Started process (PID=88166) to work on /airflow/dags/download_data.py
[2022-02-17 07:42:50,682] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:42:50,684] {logging_mixin.py:112} INFO - [2022-02-17 07:42:50,684] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:42:51,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:42:51,155] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:42:51,164] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:42:51,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 07:43:03,969] {scheduler_job.py:155} INFO - Started process (PID=88192) to work on /airflow/dags/download_data.py
[2022-02-17 07:43:03,974] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:43:03,975] {logging_mixin.py:112} INFO - [2022-02-17 07:43:03,975] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:43:04,383] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:43:04,439] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:43:04,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:43:04,460] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 07:43:17,247] {scheduler_job.py:155} INFO - Started process (PID=88220) to work on /airflow/dags/download_data.py
[2022-02-17 07:43:17,254] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:43:17,256] {logging_mixin.py:112} INFO - [2022-02-17 07:43:17,256] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:43:17,677] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:43:17,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:43:17,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:43:17,762] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 07:43:31,659] {scheduler_job.py:155} INFO - Started process (PID=88246) to work on /airflow/dags/download_data.py
[2022-02-17 07:43:31,664] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 07:43:31,665] {logging_mixin.py:112} INFO - [2022-02-17 07:43:31,665] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 07:43:32,160] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 07:43:32,203] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 07:43:32,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 07:43:32,215] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 08:43:50,604] {scheduler_job.py:155} INFO - Started process (PID=88282) to work on /airflow/dags/download_data.py
[2022-02-17 08:43:50,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:43:50,617] {logging_mixin.py:112} INFO - [2022-02-17 08:43:50,617] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:43:51,146] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:43:51,187] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:43:51,194] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:43:51,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 08:44:04,135] {scheduler_job.py:155} INFO - Started process (PID=88310) to work on /airflow/dags/download_data.py
[2022-02-17 08:44:04,149] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:44:04,151] {logging_mixin.py:112} INFO - [2022-02-17 08:44:04,151] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:44:04,662] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:44:04,759] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:44:04,772] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:44:04,783] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-17 08:44:17,428] {scheduler_job.py:155} INFO - Started process (PID=88336) to work on /airflow/dags/download_data.py
[2022-02-17 08:44:17,433] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:44:17,435] {logging_mixin.py:112} INFO - [2022-02-17 08:44:17,435] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:44:17,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:44:17,927] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:44:17,934] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:44:17,940] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 08:44:30,767] {scheduler_job.py:155} INFO - Started process (PID=88362) to work on /airflow/dags/download_data.py
[2022-02-17 08:44:30,774] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:44:30,777] {logging_mixin.py:112} INFO - [2022-02-17 08:44:30,777] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:44:31,221] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:44:31,290] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:44:31,305] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:44:31,310] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 08:44:43,999] {scheduler_job.py:155} INFO - Started process (PID=88390) to work on /airflow/dags/download_data.py
[2022-02-17 08:44:44,003] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:44:44,004] {logging_mixin.py:112} INFO - [2022-02-17 08:44:44,004] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:44:44,445] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:44:44,494] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:44:44,504] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:44:44,510] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 08:44:57,292] {scheduler_job.py:155} INFO - Started process (PID=88416) to work on /airflow/dags/download_data.py
[2022-02-17 08:44:57,297] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:44:57,299] {logging_mixin.py:112} INFO - [2022-02-17 08:44:57,298] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:44:57,755] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:44:57,807] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:44:57,818] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:44:57,824] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 08:45:10,576] {scheduler_job.py:155} INFO - Started process (PID=88444) to work on /airflow/dags/download_data.py
[2022-02-17 08:45:10,582] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:45:10,584] {logging_mixin.py:112} INFO - [2022-02-17 08:45:10,584] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:45:11,008] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:45:11,055] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:45:11,064] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:45:11,070] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 08:45:23,852] {scheduler_job.py:155} INFO - Started process (PID=88470) to work on /airflow/dags/download_data.py
[2022-02-17 08:45:23,856] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:45:23,857] {logging_mixin.py:112} INFO - [2022-02-17 08:45:23,857] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:45:24,295] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:45:24,341] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:45:24,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:45:24,357] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 08:45:37,125] {scheduler_job.py:155} INFO - Started process (PID=88498) to work on /airflow/dags/download_data.py
[2022-02-17 08:45:37,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:45:37,133] {logging_mixin.py:112} INFO - [2022-02-17 08:45:37,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:45:37,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:45:37,677] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:45:37,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:45:37,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 08:45:50,365] {scheduler_job.py:155} INFO - Started process (PID=88524) to work on /airflow/dags/download_data.py
[2022-02-17 08:45:50,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:45:50,375] {logging_mixin.py:112} INFO - [2022-02-17 08:45:50,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:45:50,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:45:50,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:45:50,856] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:45:50,862] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 08:46:03,617] {scheduler_job.py:155} INFO - Started process (PID=88550) to work on /airflow/dags/download_data.py
[2022-02-17 08:46:03,624] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:46:03,626] {logging_mixin.py:112} INFO - [2022-02-17 08:46:03,626] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:46:04,107] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:46:04,168] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:46:04,180] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:46:04,184] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 08:46:16,941] {scheduler_job.py:155} INFO - Started process (PID=88578) to work on /airflow/dags/download_data.py
[2022-02-17 08:46:16,947] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:46:16,950] {logging_mixin.py:112} INFO - [2022-02-17 08:46:16,949] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:46:17,426] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:46:17,467] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:46:17,476] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:46:17,481] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 08:46:30,240] {scheduler_job.py:155} INFO - Started process (PID=88604) to work on /airflow/dags/download_data.py
[2022-02-17 08:46:30,249] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:46:30,252] {logging_mixin.py:112} INFO - [2022-02-17 08:46:30,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:46:30,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:46:30,822] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:46:30,837] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:46:30,845] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 08:46:43,599] {scheduler_job.py:155} INFO - Started process (PID=88632) to work on /airflow/dags/download_data.py
[2022-02-17 08:46:43,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:46:43,606] {logging_mixin.py:112} INFO - [2022-02-17 08:46:43,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:46:44,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:46:44,112] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:46:44,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:46:44,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 08:46:56,864] {scheduler_job.py:155} INFO - Started process (PID=88658) to work on /airflow/dags/download_data.py
[2022-02-17 08:46:56,876] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:46:56,878] {logging_mixin.py:112} INFO - [2022-02-17 08:46:56,877] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:46:57,318] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:46:57,373] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:46:57,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:46:57,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 08:47:10,166] {scheduler_job.py:155} INFO - Started process (PID=88686) to work on /airflow/dags/download_data.py
[2022-02-17 08:47:10,174] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:47:10,176] {logging_mixin.py:112} INFO - [2022-02-17 08:47:10,176] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:47:10,612] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:47:10,662] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:47:10,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:47:10,678] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 08:47:23,445] {scheduler_job.py:155} INFO - Started process (PID=88712) to work on /airflow/dags/download_data.py
[2022-02-17 08:47:23,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:47:23,455] {logging_mixin.py:112} INFO - [2022-02-17 08:47:23,455] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:47:23,894] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:47:23,946] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:47:23,954] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:47:23,958] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 08:47:36,706] {scheduler_job.py:155} INFO - Started process (PID=88738) to work on /airflow/dags/download_data.py
[2022-02-17 08:47:36,711] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:47:36,713] {logging_mixin.py:112} INFO - [2022-02-17 08:47:36,712] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:47:37,144] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:47:37,196] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:47:37,203] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:47:37,208] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 08:47:50,043] {scheduler_job.py:155} INFO - Started process (PID=88766) to work on /airflow/dags/download_data.py
[2022-02-17 08:47:50,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:47:50,057] {logging_mixin.py:112} INFO - [2022-02-17 08:47:50,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:47:50,485] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:47:50,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:47:50,537] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:47:50,545] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 08:48:03,340] {scheduler_job.py:155} INFO - Started process (PID=88792) to work on /airflow/dags/download_data.py
[2022-02-17 08:48:03,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:48:03,350] {logging_mixin.py:112} INFO - [2022-02-17 08:48:03,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:48:03,804] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:48:03,865] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:48:03,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:48:03,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 08:48:16,641] {scheduler_job.py:155} INFO - Started process (PID=88820) to work on /airflow/dags/download_data.py
[2022-02-17 08:48:16,646] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:48:16,647] {logging_mixin.py:112} INFO - [2022-02-17 08:48:16,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:48:17,079] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:48:17,132] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:48:17,141] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:48:17,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 08:48:29,960] {scheduler_job.py:155} INFO - Started process (PID=88846) to work on /airflow/dags/download_data.py
[2022-02-17 08:48:29,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:48:29,971] {logging_mixin.py:112} INFO - [2022-02-17 08:48:29,971] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:48:30,439] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:48:30,482] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:48:30,488] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:48:30,494] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 08:48:43,250] {scheduler_job.py:155} INFO - Started process (PID=88874) to work on /airflow/dags/download_data.py
[2022-02-17 08:48:43,256] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:48:43,258] {logging_mixin.py:112} INFO - [2022-02-17 08:48:43,257] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:48:43,735] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:48:43,785] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:48:43,793] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:48:43,799] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 08:48:56,549] {scheduler_job.py:155} INFO - Started process (PID=88900) to work on /airflow/dags/download_data.py
[2022-02-17 08:48:56,555] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:48:56,557] {logging_mixin.py:112} INFO - [2022-02-17 08:48:56,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:48:57,017] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:48:57,074] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:48:57,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:48:57,094] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 08:49:09,783] {scheduler_job.py:155} INFO - Started process (PID=88928) to work on /airflow/dags/download_data.py
[2022-02-17 08:49:09,798] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:49:09,801] {logging_mixin.py:112} INFO - [2022-02-17 08:49:09,800] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:49:10,238] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:49:10,317] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:49:10,327] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:49:10,333] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 08:49:23,088] {scheduler_job.py:155} INFO - Started process (PID=88954) to work on /airflow/dags/download_data.py
[2022-02-17 08:49:23,094] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:49:23,097] {logging_mixin.py:112} INFO - [2022-02-17 08:49:23,097] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:49:23,548] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:49:23,586] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:49:23,594] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:49:23,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 08:49:36,336] {scheduler_job.py:155} INFO - Started process (PID=88980) to work on /airflow/dags/download_data.py
[2022-02-17 08:49:36,340] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:49:36,341] {logging_mixin.py:112} INFO - [2022-02-17 08:49:36,341] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:49:36,776] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:49:36,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:49:36,823] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:49:36,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 08:49:49,615] {scheduler_job.py:155} INFO - Started process (PID=89008) to work on /airflow/dags/download_data.py
[2022-02-17 08:49:49,619] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:49:49,621] {logging_mixin.py:112} INFO - [2022-02-17 08:49:49,621] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:49:50,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:49:50,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:49:50,108] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:49:50,113] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 08:50:02,893] {scheduler_job.py:155} INFO - Started process (PID=89034) to work on /airflow/dags/download_data.py
[2022-02-17 08:50:02,898] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:50:02,899] {logging_mixin.py:112} INFO - [2022-02-17 08:50:02,899] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:50:03,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:50:03,411] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:50:03,422] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:50:03,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 08:50:16,224] {scheduler_job.py:155} INFO - Started process (PID=89062) to work on /airflow/dags/download_data.py
[2022-02-17 08:50:16,230] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:50:16,233] {logging_mixin.py:112} INFO - [2022-02-17 08:50:16,232] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:50:16,660] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:50:16,709] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:50:16,720] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:50:16,726] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 08:50:29,501] {scheduler_job.py:155} INFO - Started process (PID=89088) to work on /airflow/dags/download_data.py
[2022-02-17 08:50:29,506] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:50:29,507] {logging_mixin.py:112} INFO - [2022-02-17 08:50:29,507] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:50:29,975] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:50:30,034] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:50:30,044] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:50:30,051] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 08:50:42,859] {scheduler_job.py:155} INFO - Started process (PID=89116) to work on /airflow/dags/download_data.py
[2022-02-17 08:50:42,863] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:50:42,865] {logging_mixin.py:112} INFO - [2022-02-17 08:50:42,865] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:50:43,287] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:50:43,321] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:50:43,326] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:50:43,330] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.471 seconds
[2022-02-17 08:50:56,152] {scheduler_job.py:155} INFO - Started process (PID=89142) to work on /airflow/dags/download_data.py
[2022-02-17 08:50:56,157] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:50:56,158] {logging_mixin.py:112} INFO - [2022-02-17 08:50:56,158] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:50:56,620] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:50:56,679] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:50:56,688] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:50:56,694] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 08:51:09,384] {scheduler_job.py:155} INFO - Started process (PID=89168) to work on /airflow/dags/download_data.py
[2022-02-17 08:51:09,388] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:51:09,390] {logging_mixin.py:112} INFO - [2022-02-17 08:51:09,390] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:51:09,829] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:51:09,879] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:51:09,887] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:51:09,892] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 08:51:22,683] {scheduler_job.py:155} INFO - Started process (PID=89196) to work on /airflow/dags/download_data.py
[2022-02-17 08:51:22,689] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:51:22,691] {logging_mixin.py:112} INFO - [2022-02-17 08:51:22,691] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:51:23,131] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:51:23,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:51:23,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:51:23,198] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 08:51:35,926] {scheduler_job.py:155} INFO - Started process (PID=89222) to work on /airflow/dags/download_data.py
[2022-02-17 08:51:35,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:51:35,932] {logging_mixin.py:112} INFO - [2022-02-17 08:51:35,932] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:51:36,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:51:36,409] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:51:36,417] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:51:36,422] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 08:51:49,201] {scheduler_job.py:155} INFO - Started process (PID=89250) to work on /airflow/dags/download_data.py
[2022-02-17 08:51:49,205] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:51:49,207] {logging_mixin.py:112} INFO - [2022-02-17 08:51:49,207] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:51:49,646] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:51:49,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:51:49,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:51:49,694] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 08:52:02,444] {scheduler_job.py:155} INFO - Started process (PID=89276) to work on /airflow/dags/download_data.py
[2022-02-17 08:52:02,449] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:52:02,452] {logging_mixin.py:112} INFO - [2022-02-17 08:52:02,451] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:52:02,917] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:52:02,976] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:52:02,986] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:52:02,991] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 08:52:15,753] {scheduler_job.py:155} INFO - Started process (PID=89304) to work on /airflow/dags/download_data.py
[2022-02-17 08:52:15,759] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:52:15,761] {logging_mixin.py:112} INFO - [2022-02-17 08:52:15,761] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:52:16,192] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:52:16,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:52:16,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:52:16,252] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 08:52:29,039] {scheduler_job.py:155} INFO - Started process (PID=89330) to work on /airflow/dags/download_data.py
[2022-02-17 08:52:29,045] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:52:29,047] {logging_mixin.py:112} INFO - [2022-02-17 08:52:29,047] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:52:29,507] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:52:29,550] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:52:29,560] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:52:29,566] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 08:52:42,266] {scheduler_job.py:155} INFO - Started process (PID=89356) to work on /airflow/dags/download_data.py
[2022-02-17 08:52:42,272] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:52:42,273] {logging_mixin.py:112} INFO - [2022-02-17 08:52:42,273] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:52:42,700] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:52:42,737] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:52:42,742] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:52:42,746] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.480 seconds
[2022-02-17 08:52:55,572] {scheduler_job.py:155} INFO - Started process (PID=89384) to work on /airflow/dags/download_data.py
[2022-02-17 08:52:55,587] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:52:55,589] {logging_mixin.py:112} INFO - [2022-02-17 08:52:55,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:52:56,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:52:56,229] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:52:56,236] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:52:56,241] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.669 seconds
[2022-02-17 08:53:08,820] {scheduler_job.py:155} INFO - Started process (PID=89410) to work on /airflow/dags/download_data.py
[2022-02-17 08:53:08,825] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:53:08,826] {logging_mixin.py:112} INFO - [2022-02-17 08:53:08,826] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:53:09,343] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:53:09,398] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:53:09,404] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:53:09,409] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 08:53:22,097] {scheduler_job.py:155} INFO - Started process (PID=89438) to work on /airflow/dags/download_data.py
[2022-02-17 08:53:22,104] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:53:22,106] {logging_mixin.py:112} INFO - [2022-02-17 08:53:22,105] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:53:22,541] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:53:22,586] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:53:22,592] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:53:22,597] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 08:53:35,370] {scheduler_job.py:155} INFO - Started process (PID=89464) to work on /airflow/dags/download_data.py
[2022-02-17 08:53:35,382] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:53:35,384] {logging_mixin.py:112} INFO - [2022-02-17 08:53:35,384] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:53:35,815] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:53:35,857] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:53:35,863] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:53:35,867] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 08:53:48,641] {scheduler_job.py:155} INFO - Started process (PID=89492) to work on /airflow/dags/download_data.py
[2022-02-17 08:53:48,645] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:53:48,647] {logging_mixin.py:112} INFO - [2022-02-17 08:53:48,646] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:53:49,104] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:53:49,147] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:53:49,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:53:49,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 08:54:01,932] {scheduler_job.py:155} INFO - Started process (PID=89518) to work on /airflow/dags/download_data.py
[2022-02-17 08:54:01,938] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:54:01,940] {logging_mixin.py:112} INFO - [2022-02-17 08:54:01,940] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:54:02,397] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:54:02,460] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:54:02,473] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:54:02,479] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 08:54:15,233] {scheduler_job.py:155} INFO - Started process (PID=89545) to work on /airflow/dags/download_data.py
[2022-02-17 08:54:15,241] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:54:15,243] {logging_mixin.py:112} INFO - [2022-02-17 08:54:15,242] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:54:15,742] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:54:15,781] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:54:15,787] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:54:15,791] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 08:54:28,506] {scheduler_job.py:155} INFO - Started process (PID=89572) to work on /airflow/dags/download_data.py
[2022-02-17 08:54:28,510] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:54:28,512] {logging_mixin.py:112} INFO - [2022-02-17 08:54:28,512] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:54:28,989] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:54:29,044] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:54:29,053] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:54:29,058] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 08:54:41,789] {scheduler_job.py:155} INFO - Started process (PID=89598) to work on /airflow/dags/download_data.py
[2022-02-17 08:54:41,796] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:54:41,798] {logging_mixin.py:112} INFO - [2022-02-17 08:54:41,798] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:54:42,270] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:54:42,323] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:54:42,333] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:54:42,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 08:54:55,069] {scheduler_job.py:155} INFO - Started process (PID=89626) to work on /airflow/dags/download_data.py
[2022-02-17 08:54:55,073] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:54:55,075] {logging_mixin.py:112} INFO - [2022-02-17 08:54:55,075] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:54:55,525] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:54:55,585] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:54:55,595] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:54:55,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 08:55:08,334] {scheduler_job.py:155} INFO - Started process (PID=89652) to work on /airflow/dags/download_data.py
[2022-02-17 08:55:08,338] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:55:08,340] {logging_mixin.py:112} INFO - [2022-02-17 08:55:08,340] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:55:08,789] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:55:08,841] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:55:08,851] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:55:08,857] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 08:55:21,652] {scheduler_job.py:155} INFO - Started process (PID=89680) to work on /airflow/dags/download_data.py
[2022-02-17 08:55:21,656] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:55:21,658] {logging_mixin.py:112} INFO - [2022-02-17 08:55:21,658] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:55:22,108] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:55:22,153] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:55:22,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:55:22,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 08:55:34,896] {scheduler_job.py:155} INFO - Started process (PID=89706) to work on /airflow/dags/download_data.py
[2022-02-17 08:55:34,901] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:55:34,903] {logging_mixin.py:112} INFO - [2022-02-17 08:55:34,903] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:55:35,348] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:55:35,389] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:55:35,398] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:55:35,405] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 08:55:48,244] {scheduler_job.py:155} INFO - Started process (PID=89734) to work on /airflow/dags/download_data.py
[2022-02-17 08:55:48,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:55:48,258] {logging_mixin.py:112} INFO - [2022-02-17 08:55:48,258] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:55:48,713] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:55:48,764] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:55:48,773] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:55:48,777] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 08:56:01,489] {scheduler_job.py:155} INFO - Started process (PID=89760) to work on /airflow/dags/download_data.py
[2022-02-17 08:56:01,495] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:56:01,496] {logging_mixin.py:112} INFO - [2022-02-17 08:56:01,496] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:56:01,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:56:01,997] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:56:02,006] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:56:02,014] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 08:56:14,799] {scheduler_job.py:155} INFO - Started process (PID=89786) to work on /airflow/dags/download_data.py
[2022-02-17 08:56:14,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:56:14,807] {logging_mixin.py:112} INFO - [2022-02-17 08:56:14,807] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:56:15,227] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:56:15,279] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:56:15,286] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:56:15,290] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 08:56:28,082] {scheduler_job.py:155} INFO - Started process (PID=89814) to work on /airflow/dags/download_data.py
[2022-02-17 08:56:28,088] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:56:28,091] {logging_mixin.py:112} INFO - [2022-02-17 08:56:28,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:56:28,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:56:28,583] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:56:28,597] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:56:28,603] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 08:56:41,339] {scheduler_job.py:155} INFO - Started process (PID=89840) to work on /airflow/dags/download_data.py
[2022-02-17 08:56:41,345] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:56:41,348] {logging_mixin.py:112} INFO - [2022-02-17 08:56:41,347] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:56:41,821] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:56:41,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:56:41,904] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:56:41,909] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 08:56:54,610] {scheduler_job.py:155} INFO - Started process (PID=89868) to work on /airflow/dags/download_data.py
[2022-02-17 08:56:54,615] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:56:54,617] {logging_mixin.py:112} INFO - [2022-02-17 08:56:54,617] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:56:55,068] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:56:55,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:56:55,117] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:56:55,121] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 08:57:07,877] {scheduler_job.py:155} INFO - Started process (PID=89894) to work on /airflow/dags/download_data.py
[2022-02-17 08:57:07,881] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:57:07,883] {logging_mixin.py:112} INFO - [2022-02-17 08:57:07,882] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:57:08,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:57:08,356] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:57:08,361] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:57:08,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 08:57:21,182] {scheduler_job.py:155} INFO - Started process (PID=89922) to work on /airflow/dags/download_data.py
[2022-02-17 08:57:21,188] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:57:21,190] {logging_mixin.py:112} INFO - [2022-02-17 08:57:21,190] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:57:21,620] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:57:21,669] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:57:21,679] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:57:21,683] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 08:57:34,474] {scheduler_job.py:155} INFO - Started process (PID=89948) to work on /airflow/dags/download_data.py
[2022-02-17 08:57:34,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:57:34,480] {logging_mixin.py:112} INFO - [2022-02-17 08:57:34,480] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:57:34,926] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:57:34,978] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:57:34,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:57:34,989] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 08:57:47,789] {scheduler_job.py:155} INFO - Started process (PID=89974) to work on /airflow/dags/download_data.py
[2022-02-17 08:57:47,795] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:57:47,796] {logging_mixin.py:112} INFO - [2022-02-17 08:57:47,796] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:57:48,233] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:57:48,292] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:57:48,300] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:57:48,307] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 08:58:01,038] {scheduler_job.py:155} INFO - Started process (PID=90002) to work on /airflow/dags/download_data.py
[2022-02-17 08:58:01,045] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:58:01,046] {logging_mixin.py:112} INFO - [2022-02-17 08:58:01,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:58:01,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:58:01,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:58:01,538] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:58:01,542] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 08:58:14,320] {scheduler_job.py:155} INFO - Started process (PID=90028) to work on /airflow/dags/download_data.py
[2022-02-17 08:58:14,329] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:58:14,330] {logging_mixin.py:112} INFO - [2022-02-17 08:58:14,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:58:14,759] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:58:14,803] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:58:14,809] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:58:14,814] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 08:58:27,619] {scheduler_job.py:155} INFO - Started process (PID=90056) to work on /airflow/dags/download_data.py
[2022-02-17 08:58:27,624] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:58:27,626] {logging_mixin.py:112} INFO - [2022-02-17 08:58:27,625] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:58:28,081] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:58:28,145] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:58:28,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:58:28,164] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 08:58:40,886] {scheduler_job.py:155} INFO - Started process (PID=90082) to work on /airflow/dags/download_data.py
[2022-02-17 08:58:40,893] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:58:40,895] {logging_mixin.py:112} INFO - [2022-02-17 08:58:40,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:58:41,324] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:58:41,374] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:58:41,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:58:41,386] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 08:58:54,157] {scheduler_job.py:155} INFO - Started process (PID=90110) to work on /airflow/dags/download_data.py
[2022-02-17 08:58:54,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:58:54,171] {logging_mixin.py:112} INFO - [2022-02-17 08:58:54,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:58:54,641] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:58:54,675] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:58:54,680] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:58:54,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 08:59:07,381] {scheduler_job.py:155} INFO - Started process (PID=90136) to work on /airflow/dags/download_data.py
[2022-02-17 08:59:07,386] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:59:07,387] {logging_mixin.py:112} INFO - [2022-02-17 08:59:07,387] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:59:07,827] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:59:07,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:59:07,885] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:59:07,890] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 08:59:20,667] {scheduler_job.py:155} INFO - Started process (PID=90162) to work on /airflow/dags/download_data.py
[2022-02-17 08:59:20,671] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:59:20,673] {logging_mixin.py:112} INFO - [2022-02-17 08:59:20,673] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:59:21,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:59:21,171] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:59:21,179] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:59:21,184] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 08:59:33,928] {scheduler_job.py:155} INFO - Started process (PID=90190) to work on /airflow/dags/download_data.py
[2022-02-17 08:59:33,932] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:59:33,934] {logging_mixin.py:112} INFO - [2022-02-17 08:59:33,934] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:59:34,385] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:59:34,438] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:59:34,443] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:59:34,447] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 08:59:47,218] {scheduler_job.py:155} INFO - Started process (PID=90216) to work on /airflow/dags/download_data.py
[2022-02-17 08:59:47,222] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 08:59:47,224] {logging_mixin.py:112} INFO - [2022-02-17 08:59:47,224] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 08:59:47,671] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 08:59:47,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 08:59:47,723] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 08:59:47,728] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 09:00:00,510] {scheduler_job.py:155} INFO - Started process (PID=90244) to work on /airflow/dags/download_data.py
[2022-02-17 09:00:00,515] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:00:00,517] {logging_mixin.py:112} INFO - [2022-02-17 09:00:00,516] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:00:00,990] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:00:01,010] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:00:01,019] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:00:01,025] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 09:00:13,791] {scheduler_job.py:155} INFO - Started process (PID=90270) to work on /airflow/dags/download_data.py
[2022-02-17 09:00:13,799] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:00:13,801] {logging_mixin.py:112} INFO - [2022-02-17 09:00:13,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:00:14,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:00:14,310] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:00:14,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:00:14,325] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 09:00:27,105] {scheduler_job.py:155} INFO - Started process (PID=90298) to work on /airflow/dags/download_data.py
[2022-02-17 09:00:27,111] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:00:27,113] {logging_mixin.py:112} INFO - [2022-02-17 09:00:27,113] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:00:27,555] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:00:27,617] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:00:27,624] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:00:27,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 09:00:40,357] {scheduler_job.py:155} INFO - Started process (PID=90324) to work on /airflow/dags/download_data.py
[2022-02-17 09:00:40,362] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:00:40,364] {logging_mixin.py:112} INFO - [2022-02-17 09:00:40,363] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:00:40,812] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:00:40,860] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:00:40,870] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:00:40,876] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 09:00:53,654] {scheduler_job.py:155} INFO - Started process (PID=90351) to work on /airflow/dags/download_data.py
[2022-02-17 09:00:53,665] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:00:53,669] {logging_mixin.py:112} INFO - [2022-02-17 09:00:53,669] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:00:54,162] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:00:54,212] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:00:54,220] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:00:54,225] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 09:01:06,942] {scheduler_job.py:155} INFO - Started process (PID=90378) to work on /airflow/dags/download_data.py
[2022-02-17 09:01:06,948] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:01:06,950] {logging_mixin.py:112} INFO - [2022-02-17 09:01:06,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:01:07,376] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:01:07,429] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:01:07,439] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:01:07,443] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 09:01:20,235] {scheduler_job.py:155} INFO - Started process (PID=90404) to work on /airflow/dags/download_data.py
[2022-02-17 09:01:20,241] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:01:20,243] {logging_mixin.py:112} INFO - [2022-02-17 09:01:20,243] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:01:20,671] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:01:20,722] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:01:20,728] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:01:20,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 09:01:33,449] {scheduler_job.py:155} INFO - Started process (PID=90432) to work on /airflow/dags/download_data.py
[2022-02-17 09:01:33,458] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:01:33,461] {logging_mixin.py:112} INFO - [2022-02-17 09:01:33,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:01:33,909] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:01:33,956] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:01:33,966] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:01:33,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 09:01:46,756] {scheduler_job.py:155} INFO - Started process (PID=90458) to work on /airflow/dags/download_data.py
[2022-02-17 09:01:46,760] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:01:46,761] {logging_mixin.py:112} INFO - [2022-02-17 09:01:46,761] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:01:47,201] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:01:47,253] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:01:47,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:01:47,269] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 09:02:00,042] {scheduler_job.py:155} INFO - Started process (PID=90486) to work on /airflow/dags/download_data.py
[2022-02-17 09:02:00,050] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:02:00,055] {logging_mixin.py:112} INFO - [2022-02-17 09:02:00,055] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:02:00,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:02:00,561] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:02:00,571] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:02:00,577] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 09:02:13,331] {scheduler_job.py:155} INFO - Started process (PID=90512) to work on /airflow/dags/download_data.py
[2022-02-17 09:02:13,335] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:02:13,337] {logging_mixin.py:112} INFO - [2022-02-17 09:02:13,337] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:02:13,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:02:13,845] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:02:13,856] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:02:13,863] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 09:02:26,641] {scheduler_job.py:155} INFO - Started process (PID=90540) to work on /airflow/dags/download_data.py
[2022-02-17 09:02:26,645] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:02:26,647] {logging_mixin.py:112} INFO - [2022-02-17 09:02:26,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:02:27,109] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:02:27,184] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:02:27,193] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:02:27,207] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 09:02:39,873] {scheduler_job.py:155} INFO - Started process (PID=90566) to work on /airflow/dags/download_data.py
[2022-02-17 09:02:39,877] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:02:39,879] {logging_mixin.py:112} INFO - [2022-02-17 09:02:39,879] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:02:40,341] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:02:40,385] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:02:40,390] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:02:40,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 09:02:53,199] {scheduler_job.py:155} INFO - Started process (PID=90592) to work on /airflow/dags/download_data.py
[2022-02-17 09:02:53,209] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:02:53,213] {logging_mixin.py:112} INFO - [2022-02-17 09:02:53,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:02:53,662] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:02:53,713] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:02:53,723] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:02:53,726] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 09:03:06,504] {scheduler_job.py:155} INFO - Started process (PID=90620) to work on /airflow/dags/download_data.py
[2022-02-17 09:03:06,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:03:06,514] {logging_mixin.py:112} INFO - [2022-02-17 09:03:06,514] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:03:06,946] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:03:06,992] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:03:07,001] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:03:07,008] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 09:03:19,781] {scheduler_job.py:155} INFO - Started process (PID=90646) to work on /airflow/dags/download_data.py
[2022-02-17 09:03:19,793] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:03:19,795] {logging_mixin.py:112} INFO - [2022-02-17 09:03:19,795] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:03:20,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:03:20,283] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:03:20,289] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:03:20,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 09:03:33,081] {scheduler_job.py:155} INFO - Started process (PID=90674) to work on /airflow/dags/download_data.py
[2022-02-17 09:03:33,089] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:03:33,091] {logging_mixin.py:112} INFO - [2022-02-17 09:03:33,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:03:33,526] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:03:33,573] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:03:33,582] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:03:33,587] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 09:03:46,425] {scheduler_job.py:155} INFO - Started process (PID=90700) to work on /airflow/dags/download_data.py
[2022-02-17 09:03:46,431] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:03:46,433] {logging_mixin.py:112} INFO - [2022-02-17 09:03:46,433] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:03:46,866] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:03:46,906] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:03:46,913] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:03:46,916] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 09:03:59,733] {scheduler_job.py:155} INFO - Started process (PID=90728) to work on /airflow/dags/download_data.py
[2022-02-17 09:03:59,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:03:59,745] {logging_mixin.py:112} INFO - [2022-02-17 09:03:59,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:04:00,170] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:04:00,239] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:04:00,249] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:04:00,253] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 09:04:12,974] {scheduler_job.py:155} INFO - Started process (PID=90754) to work on /airflow/dags/download_data.py
[2022-02-17 09:04:12,981] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:04:12,983] {logging_mixin.py:112} INFO - [2022-02-17 09:04:12,983] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:04:13,474] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:04:13,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:04:13,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:04:13,527] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 09:04:26,260] {scheduler_job.py:155} INFO - Started process (PID=90780) to work on /airflow/dags/download_data.py
[2022-02-17 09:04:26,268] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:04:26,270] {logging_mixin.py:112} INFO - [2022-02-17 09:04:26,270] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:04:26,796] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:04:26,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:04:26,860] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:04:26,865] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 09:04:39,527] {scheduler_job.py:155} INFO - Started process (PID=90808) to work on /airflow/dags/download_data.py
[2022-02-17 09:04:39,531] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:04:39,533] {logging_mixin.py:112} INFO - [2022-02-17 09:04:39,532] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:04:40,087] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:04:40,144] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:04:40,153] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:04:40,159] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-17 09:04:52,839] {scheduler_job.py:155} INFO - Started process (PID=90834) to work on /airflow/dags/download_data.py
[2022-02-17 09:04:52,844] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:04:52,846] {logging_mixin.py:112} INFO - [2022-02-17 09:04:52,846] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:04:53,270] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:04:53,309] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:04:53,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:04:53,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.481 seconds
[2022-02-17 09:05:06,108] {scheduler_job.py:155} INFO - Started process (PID=90862) to work on /airflow/dags/download_data.py
[2022-02-17 09:05:06,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:05:06,115] {logging_mixin.py:112} INFO - [2022-02-17 09:05:06,115] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:05:06,584] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:05:06,627] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:05:06,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:05:06,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 09:05:19,376] {scheduler_job.py:155} INFO - Started process (PID=90888) to work on /airflow/dags/download_data.py
[2022-02-17 09:05:19,381] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:05:19,382] {logging_mixin.py:112} INFO - [2022-02-17 09:05:19,382] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:05:19,812] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:05:19,865] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:05:19,870] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:05:19,874] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 09:05:32,642] {scheduler_job.py:155} INFO - Started process (PID=90916) to work on /airflow/dags/download_data.py
[2022-02-17 09:05:32,650] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:05:32,654] {logging_mixin.py:112} INFO - [2022-02-17 09:05:32,652] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:05:33,114] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:05:33,163] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:05:33,170] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:05:33,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 09:05:45,928] {scheduler_job.py:155} INFO - Started process (PID=90942) to work on /airflow/dags/download_data.py
[2022-02-17 09:05:45,943] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:05:45,945] {logging_mixin.py:112} INFO - [2022-02-17 09:05:45,944] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:05:46,381] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:05:46,436] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:05:46,441] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:05:46,444] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 09:05:59,205] {scheduler_job.py:155} INFO - Started process (PID=90968) to work on /airflow/dags/download_data.py
[2022-02-17 09:05:59,211] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:05:59,212] {logging_mixin.py:112} INFO - [2022-02-17 09:05:59,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:05:59,677] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:05:59,724] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:05:59,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:05:59,740] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 09:06:12,464] {scheduler_job.py:155} INFO - Started process (PID=90996) to work on /airflow/dags/download_data.py
[2022-02-17 09:06:12,468] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:06:12,470] {logging_mixin.py:112} INFO - [2022-02-17 09:06:12,470] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:06:12,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:06:12,972] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:06:12,978] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:06:12,985] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 09:06:25,764] {scheduler_job.py:155} INFO - Started process (PID=91022) to work on /airflow/dags/download_data.py
[2022-02-17 09:06:25,770] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:06:25,772] {logging_mixin.py:112} INFO - [2022-02-17 09:06:25,772] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:06:26,278] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:06:26,326] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:06:26,333] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:06:26,338] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 09:06:39,015] {scheduler_job.py:155} INFO - Started process (PID=91050) to work on /airflow/dags/download_data.py
[2022-02-17 09:06:39,022] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:06:39,025] {logging_mixin.py:112} INFO - [2022-02-17 09:06:39,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:06:39,451] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:06:39,495] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:06:39,506] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:06:39,510] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 09:06:52,316] {scheduler_job.py:155} INFO - Started process (PID=91076) to work on /airflow/dags/download_data.py
[2022-02-17 09:06:52,320] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:06:52,322] {logging_mixin.py:112} INFO - [2022-02-17 09:06:52,322] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:06:52,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:06:52,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:06:52,818] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:06:52,823] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 09:07:05,579] {scheduler_job.py:155} INFO - Started process (PID=91104) to work on /airflow/dags/download_data.py
[2022-02-17 09:07:05,584] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:07:05,586] {logging_mixin.py:112} INFO - [2022-02-17 09:07:05,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:07:06,064] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:07:06,118] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:07:06,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:07:06,136] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 09:07:18,872] {scheduler_job.py:155} INFO - Started process (PID=91130) to work on /airflow/dags/download_data.py
[2022-02-17 09:07:18,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:07:18,879] {logging_mixin.py:112} INFO - [2022-02-17 09:07:18,879] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:07:19,311] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:07:19,359] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:07:19,367] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:07:19,371] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 09:07:32,117] {scheduler_job.py:155} INFO - Started process (PID=91157) to work on /airflow/dags/download_data.py
[2022-02-17 09:07:32,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:07:32,132] {logging_mixin.py:112} INFO - [2022-02-17 09:07:32,131] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:07:32,670] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:07:32,711] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:07:32,720] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:07:32,726] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-17 09:07:45,384] {scheduler_job.py:155} INFO - Started process (PID=91184) to work on /airflow/dags/download_data.py
[2022-02-17 09:07:45,388] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:07:45,390] {logging_mixin.py:112} INFO - [2022-02-17 09:07:45,390] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:07:45,826] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:07:45,876] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:07:45,883] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:07:45,899] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 09:07:58,683] {scheduler_job.py:155} INFO - Started process (PID=91210) to work on /airflow/dags/download_data.py
[2022-02-17 09:07:58,687] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:07:58,690] {logging_mixin.py:112} INFO - [2022-02-17 09:07:58,689] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:07:59,149] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:07:59,208] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:07:59,221] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:07:59,234] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 09:08:11,942] {scheduler_job.py:155} INFO - Started process (PID=91238) to work on /airflow/dags/download_data.py
[2022-02-17 09:08:11,947] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:08:11,949] {logging_mixin.py:112} INFO - [2022-02-17 09:08:11,948] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:08:12,392] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:08:12,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:08:12,453] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:08:12,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 09:08:25,247] {scheduler_job.py:155} INFO - Started process (PID=91264) to work on /airflow/dags/download_data.py
[2022-02-17 09:08:25,251] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:08:25,253] {logging_mixin.py:112} INFO - [2022-02-17 09:08:25,253] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:08:25,745] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:08:25,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:08:25,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:08:25,823] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-17 09:08:38,549] {scheduler_job.py:155} INFO - Started process (PID=91292) to work on /airflow/dags/download_data.py
[2022-02-17 09:08:38,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:08:38,558] {logging_mixin.py:112} INFO - [2022-02-17 09:08:38,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:08:38,985] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:08:39,034] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:08:39,041] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:08:39,048] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 09:08:51,836] {scheduler_job.py:155} INFO - Started process (PID=91318) to work on /airflow/dags/download_data.py
[2022-02-17 09:08:51,843] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:08:51,845] {logging_mixin.py:112} INFO - [2022-02-17 09:08:51,845] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:08:52,275] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:08:52,318] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:08:52,324] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:08:52,328] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 09:09:05,092] {scheduler_job.py:155} INFO - Started process (PID=91346) to work on /airflow/dags/download_data.py
[2022-02-17 09:09:05,112] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:09:05,114] {logging_mixin.py:112} INFO - [2022-02-17 09:09:05,114] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:09:05,583] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:09:05,625] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:09:05,636] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:09:05,640] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 09:09:18,425] {scheduler_job.py:155} INFO - Started process (PID=91372) to work on /airflow/dags/download_data.py
[2022-02-17 09:09:18,433] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:09:18,435] {logging_mixin.py:112} INFO - [2022-02-17 09:09:18,434] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:09:18,868] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:09:18,915] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:09:18,924] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:09:18,930] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 09:09:31,709] {scheduler_job.py:155} INFO - Started process (PID=91398) to work on /airflow/dags/download_data.py
[2022-02-17 09:09:31,713] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:09:31,715] {logging_mixin.py:112} INFO - [2022-02-17 09:09:31,714] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:09:32,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:09:32,234] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:09:32,243] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:09:32,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 09:09:45,012] {scheduler_job.py:155} INFO - Started process (PID=91426) to work on /airflow/dags/download_data.py
[2022-02-17 09:09:45,019] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:09:45,021] {logging_mixin.py:112} INFO - [2022-02-17 09:09:45,020] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:09:45,449] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:09:45,502] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:09:45,510] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:09:45,515] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 09:09:58,281] {scheduler_job.py:155} INFO - Started process (PID=91452) to work on /airflow/dags/download_data.py
[2022-02-17 09:09:58,286] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:09:58,289] {logging_mixin.py:112} INFO - [2022-02-17 09:09:58,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:09:58,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:09:58,818] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:09:58,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:09:58,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 09:10:11,552] {scheduler_job.py:155} INFO - Started process (PID=91480) to work on /airflow/dags/download_data.py
[2022-02-17 09:10:11,557] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:10:11,558] {logging_mixin.py:112} INFO - [2022-02-17 09:10:11,558] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:10:11,982] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:10:12,033] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:10:12,041] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:10:12,045] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 09:10:24,833] {scheduler_job.py:155} INFO - Started process (PID=91506) to work on /airflow/dags/download_data.py
[2022-02-17 09:10:24,837] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:10:24,839] {logging_mixin.py:112} INFO - [2022-02-17 09:10:24,839] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:10:25,282] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:10:25,328] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:10:25,336] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:10:25,341] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 09:10:38,089] {scheduler_job.py:155} INFO - Started process (PID=91534) to work on /airflow/dags/download_data.py
[2022-02-17 09:10:38,096] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:10:38,100] {logging_mixin.py:112} INFO - [2022-02-17 09:10:38,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:10:38,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:10:38,585] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:10:38,595] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:10:38,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 09:10:51,401] {scheduler_job.py:155} INFO - Started process (PID=91560) to work on /airflow/dags/download_data.py
[2022-02-17 09:10:51,407] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:10:51,409] {logging_mixin.py:112} INFO - [2022-02-17 09:10:51,408] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:10:51,843] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:10:51,883] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:10:51,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:10:51,898] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 09:11:04,685] {scheduler_job.py:155} INFO - Started process (PID=91586) to work on /airflow/dags/download_data.py
[2022-02-17 09:11:04,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:11:04,692] {logging_mixin.py:112} INFO - [2022-02-17 09:11:04,692] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:11:05,165] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:11:05,208] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:11:05,217] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:11:05,222] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 09:11:17,969] {scheduler_job.py:155} INFO - Started process (PID=91614) to work on /airflow/dags/download_data.py
[2022-02-17 09:11:17,977] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:11:17,979] {logging_mixin.py:112} INFO - [2022-02-17 09:11:17,979] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:11:18,410] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:11:18,461] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:11:18,471] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:11:18,477] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 09:11:31,245] {scheduler_job.py:155} INFO - Started process (PID=91640) to work on /airflow/dags/download_data.py
[2022-02-17 09:11:31,250] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:11:31,252] {logging_mixin.py:112} INFO - [2022-02-17 09:11:31,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:11:31,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:11:31,753] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:11:31,762] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:11:31,767] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 09:11:44,595] {scheduler_job.py:155} INFO - Started process (PID=91668) to work on /airflow/dags/download_data.py
[2022-02-17 09:11:44,600] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:11:44,602] {logging_mixin.py:112} INFO - [2022-02-17 09:11:44,602] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:11:45,065] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:11:45,114] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:11:45,130] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:11:45,134] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 09:11:57,897] {scheduler_job.py:155} INFO - Started process (PID=91694) to work on /airflow/dags/download_data.py
[2022-02-17 09:11:57,903] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:11:57,905] {logging_mixin.py:112} INFO - [2022-02-17 09:11:57,905] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:11:58,387] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:11:58,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:11:58,453] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:11:58,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 09:12:11,214] {scheduler_job.py:155} INFO - Started process (PID=91722) to work on /airflow/dags/download_data.py
[2022-02-17 09:12:11,223] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:12:11,226] {logging_mixin.py:112} INFO - [2022-02-17 09:12:11,225] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:12:11,694] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:12:11,742] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:12:11,752] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:12:11,756] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 09:12:24,488] {scheduler_job.py:155} INFO - Started process (PID=91748) to work on /airflow/dags/download_data.py
[2022-02-17 09:12:24,492] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:12:24,494] {logging_mixin.py:112} INFO - [2022-02-17 09:12:24,493] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:12:24,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:12:24,971] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:12:24,977] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:12:24,981] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 09:12:37,766] {scheduler_job.py:155} INFO - Started process (PID=91774) to work on /airflow/dags/download_data.py
[2022-02-17 09:12:37,772] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:12:37,774] {logging_mixin.py:112} INFO - [2022-02-17 09:12:37,774] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:12:38,199] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:12:38,249] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:12:38,259] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:12:38,264] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 09:12:51,062] {scheduler_job.py:155} INFO - Started process (PID=91802) to work on /airflow/dags/download_data.py
[2022-02-17 09:12:51,067] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:12:51,069] {logging_mixin.py:112} INFO - [2022-02-17 09:12:51,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:12:51,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:12:51,547] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:12:51,555] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:12:51,560] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 09:13:04,365] {scheduler_job.py:155} INFO - Started process (PID=91828) to work on /airflow/dags/download_data.py
[2022-02-17 09:13:04,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:13:04,377] {logging_mixin.py:112} INFO - [2022-02-17 09:13:04,377] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:13:04,830] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:13:04,890] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:13:04,903] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:13:04,909] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 09:13:17,642] {scheduler_job.py:155} INFO - Started process (PID=91856) to work on /airflow/dags/download_data.py
[2022-02-17 09:13:17,651] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:13:17,653] {logging_mixin.py:112} INFO - [2022-02-17 09:13:17,652] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:13:18,079] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:13:18,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:13:18,135] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:13:18,140] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 09:13:30,899] {scheduler_job.py:155} INFO - Started process (PID=91882) to work on /airflow/dags/download_data.py
[2022-02-17 09:13:30,906] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:13:30,908] {logging_mixin.py:112} INFO - [2022-02-17 09:13:30,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:13:31,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:13:31,398] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:13:31,406] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:13:31,412] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 09:13:44,273] {scheduler_job.py:155} INFO - Started process (PID=91910) to work on /airflow/dags/download_data.py
[2022-02-17 09:13:44,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:13:44,280] {logging_mixin.py:112} INFO - [2022-02-17 09:13:44,280] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:13:44,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:13:44,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:13:44,770] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:13:44,777] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 09:13:57,575] {scheduler_job.py:155} INFO - Started process (PID=91936) to work on /airflow/dags/download_data.py
[2022-02-17 09:13:57,584] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:13:57,586] {logging_mixin.py:112} INFO - [2022-02-17 09:13:57,586] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:13:58,045] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:13:58,103] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:13:58,115] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:13:58,119] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 09:14:10,825] {scheduler_job.py:155} INFO - Started process (PID=91964) to work on /airflow/dags/download_data.py
[2022-02-17 09:14:10,834] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:14:10,837] {logging_mixin.py:112} INFO - [2022-02-17 09:14:10,836] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:14:11,297] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:14:11,352] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:14:11,364] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:14:11,369] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 09:14:24,088] {scheduler_job.py:155} INFO - Started process (PID=91990) to work on /airflow/dags/download_data.py
[2022-02-17 09:14:24,092] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:14:24,093] {logging_mixin.py:112} INFO - [2022-02-17 09:14:24,093] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:14:24,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:14:24,585] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:14:24,593] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:14:24,598] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 09:14:37,378] {scheduler_job.py:155} INFO - Started process (PID=92016) to work on /airflow/dags/download_data.py
[2022-02-17 09:14:37,382] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:14:37,383] {logging_mixin.py:112} INFO - [2022-02-17 09:14:37,383] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:14:37,842] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:14:37,892] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:14:37,899] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:14:37,906] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 09:14:50,665] {scheduler_job.py:155} INFO - Started process (PID=92044) to work on /airflow/dags/download_data.py
[2022-02-17 09:14:50,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:14:50,672] {logging_mixin.py:112} INFO - [2022-02-17 09:14:50,671] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:14:51,099] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:14:51,149] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:14:51,157] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:14:51,162] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 09:15:03,923] {scheduler_job.py:155} INFO - Started process (PID=92070) to work on /airflow/dags/download_data.py
[2022-02-17 09:15:03,929] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:15:03,930] {logging_mixin.py:112} INFO - [2022-02-17 09:15:03,930] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:15:04,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:15:04,430] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:15:04,440] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:15:04,446] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 09:15:17,249] {scheduler_job.py:155} INFO - Started process (PID=92098) to work on /airflow/dags/download_data.py
[2022-02-17 09:15:17,256] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:15:17,258] {logging_mixin.py:112} INFO - [2022-02-17 09:15:17,257] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:15:17,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:15:17,734] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:15:17,740] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:15:17,743] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 09:15:30,512] {scheduler_job.py:155} INFO - Started process (PID=92124) to work on /airflow/dags/download_data.py
[2022-02-17 09:15:30,523] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:15:30,526] {logging_mixin.py:112} INFO - [2022-02-17 09:15:30,526] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:15:30,965] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:15:31,008] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:15:31,015] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:15:31,022] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 09:15:43,816] {scheduler_job.py:155} INFO - Started process (PID=92152) to work on /airflow/dags/download_data.py
[2022-02-17 09:15:43,821] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:15:43,822] {logging_mixin.py:112} INFO - [2022-02-17 09:15:43,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:15:44,247] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:15:44,302] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:15:44,312] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:15:44,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 09:15:57,109] {scheduler_job.py:155} INFO - Started process (PID=92178) to work on /airflow/dags/download_data.py
[2022-02-17 09:15:57,115] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:15:57,116] {logging_mixin.py:112} INFO - [2022-02-17 09:15:57,116] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:15:57,557] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:15:57,614] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:15:57,628] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:15:57,634] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 09:16:10,351] {scheduler_job.py:155} INFO - Started process (PID=92204) to work on /airflow/dags/download_data.py
[2022-02-17 09:16:10,355] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:16:10,357] {logging_mixin.py:112} INFO - [2022-02-17 09:16:10,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:16:10,796] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:16:10,846] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:16:10,855] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:16:10,860] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 09:16:23,660] {scheduler_job.py:155} INFO - Started process (PID=92232) to work on /airflow/dags/download_data.py
[2022-02-17 09:16:23,664] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:16:23,665] {logging_mixin.py:112} INFO - [2022-02-17 09:16:23,665] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:16:24,095] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:16:24,147] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:16:24,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:16:24,157] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 09:16:36,912] {scheduler_job.py:155} INFO - Started process (PID=92258) to work on /airflow/dags/download_data.py
[2022-02-17 09:16:36,921] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:16:36,923] {logging_mixin.py:112} INFO - [2022-02-17 09:16:36,922] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:16:37,352] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:16:37,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:16:37,408] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:16:37,412] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 09:16:50,187] {scheduler_job.py:155} INFO - Started process (PID=92286) to work on /airflow/dags/download_data.py
[2022-02-17 09:16:50,191] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:16:50,193] {logging_mixin.py:112} INFO - [2022-02-17 09:16:50,192] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:16:50,625] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:16:50,673] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:16:50,682] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:16:50,686] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 09:17:03,443] {scheduler_job.py:155} INFO - Started process (PID=92312) to work on /airflow/dags/download_data.py
[2022-02-17 09:17:03,448] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:17:03,449] {logging_mixin.py:112} INFO - [2022-02-17 09:17:03,449] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:17:03,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:17:03,959] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:17:03,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:17:03,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 09:17:16,687] {scheduler_job.py:155} INFO - Started process (PID=92340) to work on /airflow/dags/download_data.py
[2022-02-17 09:17:16,691] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:17:16,693] {logging_mixin.py:112} INFO - [2022-02-17 09:17:16,693] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:17:17,136] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:17:17,167] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:17:17,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:17:17,181] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 09:17:30,022] {scheduler_job.py:155} INFO - Started process (PID=92366) to work on /airflow/dags/download_data.py
[2022-02-17 09:17:30,028] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:17:30,030] {logging_mixin.py:112} INFO - [2022-02-17 09:17:30,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:17:30,433] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:17:30,479] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:17:30,488] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:17:30,492] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.470 seconds
[2022-02-17 09:17:43,311] {scheduler_job.py:155} INFO - Started process (PID=92392) to work on /airflow/dags/download_data.py
[2022-02-17 09:17:43,322] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:17:43,325] {logging_mixin.py:112} INFO - [2022-02-17 09:17:43,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:17:43,762] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:17:43,813] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:17:43,822] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:17:43,828] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 09:17:56,643] {scheduler_job.py:155} INFO - Started process (PID=92420) to work on /airflow/dags/download_data.py
[2022-02-17 09:17:56,651] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:17:56,653] {logging_mixin.py:112} INFO - [2022-02-17 09:17:56,653] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:17:57,099] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:17:57,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:17:57,155] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:17:57,159] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 09:18:09,904] {scheduler_job.py:155} INFO - Started process (PID=92446) to work on /airflow/dags/download_data.py
[2022-02-17 09:18:09,909] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:18:09,911] {logging_mixin.py:112} INFO - [2022-02-17 09:18:09,911] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:18:10,380] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:18:10,425] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:18:10,435] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:18:10,439] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 09:18:23,221] {scheduler_job.py:155} INFO - Started process (PID=92474) to work on /airflow/dags/download_data.py
[2022-02-17 09:18:23,225] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:18:23,227] {logging_mixin.py:112} INFO - [2022-02-17 09:18:23,226] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:18:23,664] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:18:23,715] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:18:23,721] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:18:23,725] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 09:18:36,486] {scheduler_job.py:155} INFO - Started process (PID=92500) to work on /airflow/dags/download_data.py
[2022-02-17 09:18:36,490] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:18:36,491] {logging_mixin.py:112} INFO - [2022-02-17 09:18:36,491] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:18:36,933] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:18:36,982] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:18:36,992] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:18:36,995] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 09:18:49,776] {scheduler_job.py:155} INFO - Started process (PID=92528) to work on /airflow/dags/download_data.py
[2022-02-17 09:18:49,783] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:18:49,785] {logging_mixin.py:112} INFO - [2022-02-17 09:18:49,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:18:50,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:18:50,513] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:18:50,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:18:50,528] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.753 seconds
[2022-02-17 09:19:03,051] {scheduler_job.py:155} INFO - Started process (PID=92554) to work on /airflow/dags/download_data.py
[2022-02-17 09:19:03,060] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:19:03,063] {logging_mixin.py:112} INFO - [2022-02-17 09:19:03,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:19:03,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:19:03,594] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:19:03,609] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:19:03,616] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 09:19:16,376] {scheduler_job.py:155} INFO - Started process (PID=92580) to work on /airflow/dags/download_data.py
[2022-02-17 09:19:16,383] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:19:16,385] {logging_mixin.py:112} INFO - [2022-02-17 09:19:16,385] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:19:16,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:19:16,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:19:16,849] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:19:16,852] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.477 seconds
[2022-02-17 09:19:29,680] {scheduler_job.py:155} INFO - Started process (PID=92608) to work on /airflow/dags/download_data.py
[2022-02-17 09:19:29,687] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:19:29,689] {logging_mixin.py:112} INFO - [2022-02-17 09:19:29,689] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:19:30,086] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:19:30,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:19:30,144] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:19:30,147] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.467 seconds
[2022-02-17 09:19:44,313] {scheduler_job.py:155} INFO - Started process (PID=92634) to work on /airflow/dags/download_data.py
[2022-02-17 09:19:44,339] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 09:19:44,341] {logging_mixin.py:112} INFO - [2022-02-17 09:19:44,341] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 09:19:45,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 09:19:45,143] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 09:19:45,159] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 09:19:45,231] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.918 seconds
[2022-02-17 10:20:02,619] {scheduler_job.py:155} INFO - Started process (PID=92668) to work on /airflow/dags/download_data.py
[2022-02-17 10:20:02,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:20:02,663] {logging_mixin.py:112} INFO - [2022-02-17 10:20:02,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:20:05,007] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:20:05,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:20:05,127] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:20:05,140] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.522 seconds
[2022-02-17 10:20:16,925] {scheduler_job.py:155} INFO - Started process (PID=92698) to work on /airflow/dags/download_data.py
[2022-02-17 10:20:16,938] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:20:16,940] {logging_mixin.py:112} INFO - [2022-02-17 10:20:16,940] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:20:17,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:20:17,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:20:17,462] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:20:17,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 10:20:30,202] {scheduler_job.py:155} INFO - Started process (PID=92726) to work on /airflow/dags/download_data.py
[2022-02-17 10:20:30,205] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:20:30,207] {logging_mixin.py:112} INFO - [2022-02-17 10:20:30,207] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:20:30,642] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:20:30,689] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:20:30,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:20:30,702] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 10:20:43,534] {scheduler_job.py:155} INFO - Started process (PID=92752) to work on /airflow/dags/download_data.py
[2022-02-17 10:20:43,538] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:20:43,540] {logging_mixin.py:112} INFO - [2022-02-17 10:20:43,540] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:20:43,996] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:20:44,044] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:20:44,051] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:20:44,056] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 10:20:56,832] {scheduler_job.py:155} INFO - Started process (PID=92778) to work on /airflow/dags/download_data.py
[2022-02-17 10:20:56,839] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:20:56,841] {logging_mixin.py:112} INFO - [2022-02-17 10:20:56,840] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:20:57,273] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:20:57,327] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:20:57,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:20:57,338] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 10:21:10,129] {scheduler_job.py:155} INFO - Started process (PID=92806) to work on /airflow/dags/download_data.py
[2022-02-17 10:21:10,133] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:21:10,134] {logging_mixin.py:112} INFO - [2022-02-17 10:21:10,134] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:21:10,595] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:21:10,642] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:21:10,653] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:21:10,658] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 10:21:23,430] {scheduler_job.py:155} INFO - Started process (PID=92832) to work on /airflow/dags/download_data.py
[2022-02-17 10:21:23,434] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:21:23,437] {logging_mixin.py:112} INFO - [2022-02-17 10:21:23,437] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:21:23,870] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:21:23,917] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:21:23,925] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:21:23,930] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 10:21:36,695] {scheduler_job.py:155} INFO - Started process (PID=92860) to work on /airflow/dags/download_data.py
[2022-02-17 10:21:36,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:21:36,702] {logging_mixin.py:112} INFO - [2022-02-17 10:21:36,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:21:37,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:21:37,168] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:21:37,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:21:37,177] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.481 seconds
[2022-02-17 10:21:50,015] {scheduler_job.py:155} INFO - Started process (PID=92886) to work on /airflow/dags/download_data.py
[2022-02-17 10:21:50,019] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:21:50,021] {logging_mixin.py:112} INFO - [2022-02-17 10:21:50,021] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:21:50,454] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:21:50,506] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:21:50,520] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:21:50,525] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 10:22:03,246] {scheduler_job.py:155} INFO - Started process (PID=92914) to work on /airflow/dags/download_data.py
[2022-02-17 10:22:03,250] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:22:03,252] {logging_mixin.py:112} INFO - [2022-02-17 10:22:03,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:22:03,800] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:22:03,855] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:22:03,866] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:22:03,872] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-17 10:22:16,564] {scheduler_job.py:155} INFO - Started process (PID=92940) to work on /airflow/dags/download_data.py
[2022-02-17 10:22:16,569] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:22:16,570] {logging_mixin.py:112} INFO - [2022-02-17 10:22:16,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:22:17,016] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:22:17,058] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:22:17,065] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:22:17,068] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 10:22:29,804] {scheduler_job.py:155} INFO - Started process (PID=92966) to work on /airflow/dags/download_data.py
[2022-02-17 10:22:29,817] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:22:29,819] {logging_mixin.py:112} INFO - [2022-02-17 10:22:29,819] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:22:30,261] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:22:30,312] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:22:30,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:22:30,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 10:22:43,069] {scheduler_job.py:155} INFO - Started process (PID=92994) to work on /airflow/dags/download_data.py
[2022-02-17 10:22:43,078] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:22:43,080] {logging_mixin.py:112} INFO - [2022-02-17 10:22:43,080] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:22:43,504] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:22:43,558] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:22:43,568] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:22:43,574] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 10:22:56,413] {scheduler_job.py:155} INFO - Started process (PID=93020) to work on /airflow/dags/download_data.py
[2022-02-17 10:22:56,427] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:22:56,433] {logging_mixin.py:112} INFO - [2022-02-17 10:22:56,431] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:22:56,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:22:56,945] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:22:56,953] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:22:56,958] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 10:23:09,686] {scheduler_job.py:155} INFO - Started process (PID=93048) to work on /airflow/dags/download_data.py
[2022-02-17 10:23:09,694] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:23:09,696] {logging_mixin.py:112} INFO - [2022-02-17 10:23:09,696] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:23:10,124] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:23:10,175] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:23:10,183] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:23:10,188] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 10:23:22,970] {scheduler_job.py:155} INFO - Started process (PID=93074) to work on /airflow/dags/download_data.py
[2022-02-17 10:23:22,975] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:23:22,977] {logging_mixin.py:112} INFO - [2022-02-17 10:23:22,977] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:23:23,425] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:23:23,481] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:23:23,487] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:23:23,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 10:23:36,228] {scheduler_job.py:155} INFO - Started process (PID=93102) to work on /airflow/dags/download_data.py
[2022-02-17 10:23:36,234] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:23:36,236] {logging_mixin.py:112} INFO - [2022-02-17 10:23:36,236] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:23:36,668] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:23:36,714] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:23:36,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:23:36,730] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 10:23:49,508] {scheduler_job.py:155} INFO - Started process (PID=93128) to work on /airflow/dags/download_data.py
[2022-02-17 10:23:49,512] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:23:49,514] {logging_mixin.py:112} INFO - [2022-02-17 10:23:49,514] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:23:49,953] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:23:49,994] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:23:50,000] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:23:50,006] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 10:24:02,785] {scheduler_job.py:155} INFO - Started process (PID=93155) to work on /airflow/dags/download_data.py
[2022-02-17 10:24:02,806] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:24:02,809] {logging_mixin.py:112} INFO - [2022-02-17 10:24:02,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:24:03,432] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:24:03,481] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:24:03,494] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:24:03,499] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.714 seconds
[2022-02-17 10:24:16,067] {scheduler_job.py:155} INFO - Started process (PID=93182) to work on /airflow/dags/download_data.py
[2022-02-17 10:24:16,071] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:24:16,072] {logging_mixin.py:112} INFO - [2022-02-17 10:24:16,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:24:16,503] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:24:16,555] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:24:16,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:24:16,565] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 10:24:29,338] {scheduler_job.py:155} INFO - Started process (PID=93208) to work on /airflow/dags/download_data.py
[2022-02-17 10:24:29,342] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:24:29,344] {logging_mixin.py:112} INFO - [2022-02-17 10:24:29,344] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:24:29,797] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:24:29,851] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:24:29,858] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:24:29,863] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 10:24:42,635] {scheduler_job.py:155} INFO - Started process (PID=93236) to work on /airflow/dags/download_data.py
[2022-02-17 10:24:42,639] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:24:42,641] {logging_mixin.py:112} INFO - [2022-02-17 10:24:42,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:24:43,079] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:24:43,132] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:24:43,142] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:24:43,147] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 10:24:55,957] {scheduler_job.py:155} INFO - Started process (PID=93262) to work on /airflow/dags/download_data.py
[2022-02-17 10:24:55,963] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:24:55,965] {logging_mixin.py:112} INFO - [2022-02-17 10:24:55,965] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:24:56,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:24:56,445] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:24:56,454] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:24:56,458] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 10:25:09,235] {scheduler_job.py:155} INFO - Started process (PID=93290) to work on /airflow/dags/download_data.py
[2022-02-17 10:25:09,241] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:25:09,243] {logging_mixin.py:112} INFO - [2022-02-17 10:25:09,243] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:25:09,677] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:25:09,726] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:25:09,732] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:25:09,737] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 10:25:22,515] {scheduler_job.py:155} INFO - Started process (PID=93316) to work on /airflow/dags/download_data.py
[2022-02-17 10:25:22,519] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:25:22,521] {logging_mixin.py:112} INFO - [2022-02-17 10:25:22,521] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:25:22,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:25:23,012] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:25:23,021] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:25:23,025] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 10:25:35,774] {scheduler_job.py:155} INFO - Started process (PID=93344) to work on /airflow/dags/download_data.py
[2022-02-17 10:25:35,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:25:35,789] {logging_mixin.py:112} INFO - [2022-02-17 10:25:35,789] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:25:36,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:25:36,319] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:25:36,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:25:36,335] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 10:25:49,085] {scheduler_job.py:155} INFO - Started process (PID=93370) to work on /airflow/dags/download_data.py
[2022-02-17 10:25:49,089] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:25:49,093] {logging_mixin.py:112} INFO - [2022-02-17 10:25:49,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:25:49,514] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:25:49,552] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:25:49,560] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:25:49,564] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.479 seconds
[2022-02-17 10:26:02,326] {scheduler_job.py:155} INFO - Started process (PID=93396) to work on /airflow/dags/download_data.py
[2022-02-17 10:26:02,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:26:02,334] {logging_mixin.py:112} INFO - [2022-02-17 10:26:02,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:26:02,785] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:26:02,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:26:02,852] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:26:02,857] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 10:26:15,655] {scheduler_job.py:155} INFO - Started process (PID=93424) to work on /airflow/dags/download_data.py
[2022-02-17 10:26:15,667] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:26:15,669] {logging_mixin.py:112} INFO - [2022-02-17 10:26:15,669] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:26:16,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:26:16,156] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:26:16,163] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:26:16,169] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 10:26:28,923] {scheduler_job.py:155} INFO - Started process (PID=93450) to work on /airflow/dags/download_data.py
[2022-02-17 10:26:28,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:26:28,929] {logging_mixin.py:112} INFO - [2022-02-17 10:26:28,929] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:26:29,390] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:26:29,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:26:29,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:26:29,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 10:26:42,216] {scheduler_job.py:155} INFO - Started process (PID=93478) to work on /airflow/dags/download_data.py
[2022-02-17 10:26:42,219] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:26:42,221] {logging_mixin.py:112} INFO - [2022-02-17 10:26:42,221] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:26:42,663] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:26:42,714] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:26:42,722] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:26:42,727] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 10:26:55,509] {scheduler_job.py:155} INFO - Started process (PID=93504) to work on /airflow/dags/download_data.py
[2022-02-17 10:26:55,515] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:26:55,517] {logging_mixin.py:112} INFO - [2022-02-17 10:26:55,516] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:26:56,005] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:26:56,050] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:26:56,056] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:26:56,062] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 10:27:08,744] {scheduler_job.py:155} INFO - Started process (PID=93532) to work on /airflow/dags/download_data.py
[2022-02-17 10:27:08,756] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:27:08,758] {logging_mixin.py:112} INFO - [2022-02-17 10:27:08,757] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:27:09,180] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:27:09,224] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:27:09,230] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:27:09,234] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 10:27:22,028] {scheduler_job.py:155} INFO - Started process (PID=93558) to work on /airflow/dags/download_data.py
[2022-02-17 10:27:22,035] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:27:22,036] {logging_mixin.py:112} INFO - [2022-02-17 10:27:22,036] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:27:22,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:27:22,521] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:27:22,529] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:27:22,534] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 10:27:35,295] {scheduler_job.py:155} INFO - Started process (PID=93584) to work on /airflow/dags/download_data.py
[2022-02-17 10:27:35,301] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:27:35,302] {logging_mixin.py:112} INFO - [2022-02-17 10:27:35,302] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:27:35,734] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:27:35,786] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:27:35,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:27:35,798] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 10:27:48,632] {scheduler_job.py:155} INFO - Started process (PID=93612) to work on /airflow/dags/download_data.py
[2022-02-17 10:27:48,637] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:27:48,640] {logging_mixin.py:112} INFO - [2022-02-17 10:27:48,640] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:27:49,072] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:27:49,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:27:49,132] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:27:49,137] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 10:28:01,886] {scheduler_job.py:155} INFO - Started process (PID=93638) to work on /airflow/dags/download_data.py
[2022-02-17 10:28:01,896] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:28:01,898] {logging_mixin.py:112} INFO - [2022-02-17 10:28:01,898] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:28:02,417] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:28:02,471] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:28:02,480] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:28:02,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-17 10:28:15,171] {scheduler_job.py:155} INFO - Started process (PID=93666) to work on /airflow/dags/download_data.py
[2022-02-17 10:28:15,176] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:28:15,179] {logging_mixin.py:112} INFO - [2022-02-17 10:28:15,179] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:28:15,618] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:28:15,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:28:15,680] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:28:15,687] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 10:28:28,423] {scheduler_job.py:155} INFO - Started process (PID=93692) to work on /airflow/dags/download_data.py
[2022-02-17 10:28:28,428] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:28:28,430] {logging_mixin.py:112} INFO - [2022-02-17 10:28:28,429] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:28:28,893] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:28:28,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:28:28,947] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:28:28,953] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 10:28:41,674] {scheduler_job.py:155} INFO - Started process (PID=93720) to work on /airflow/dags/download_data.py
[2022-02-17 10:28:41,679] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:28:41,681] {logging_mixin.py:112} INFO - [2022-02-17 10:28:41,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:28:42,127] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:28:42,166] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:28:42,177] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:28:42,182] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 10:28:55,003] {scheduler_job.py:155} INFO - Started process (PID=93746) to work on /airflow/dags/download_data.py
[2022-02-17 10:28:55,012] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:28:55,014] {logging_mixin.py:112} INFO - [2022-02-17 10:28:55,014] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:28:55,468] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:28:55,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:28:55,545] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:28:55,551] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 10:29:08,271] {scheduler_job.py:155} INFO - Started process (PID=93772) to work on /airflow/dags/download_data.py
[2022-02-17 10:29:08,277] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:29:08,279] {logging_mixin.py:112} INFO - [2022-02-17 10:29:08,279] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:29:08,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:29:08,756] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:29:08,765] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:29:08,772] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 10:29:21,568] {scheduler_job.py:155} INFO - Started process (PID=93800) to work on /airflow/dags/download_data.py
[2022-02-17 10:29:21,575] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:29:21,577] {logging_mixin.py:112} INFO - [2022-02-17 10:29:21,577] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:29:21,999] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:29:22,050] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:29:22,058] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:29:22,063] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 10:29:34,841] {scheduler_job.py:155} INFO - Started process (PID=93826) to work on /airflow/dags/download_data.py
[2022-02-17 10:29:34,847] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:29:34,849] {logging_mixin.py:112} INFO - [2022-02-17 10:29:34,849] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:29:35,275] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:29:35,315] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:29:35,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:29:35,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.486 seconds
[2022-02-17 10:29:48,185] {scheduler_job.py:155} INFO - Started process (PID=93854) to work on /airflow/dags/download_data.py
[2022-02-17 10:29:48,191] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:29:48,194] {logging_mixin.py:112} INFO - [2022-02-17 10:29:48,193] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:29:48,629] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:29:48,671] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:29:48,677] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:29:48,682] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 10:30:01,447] {scheduler_job.py:155} INFO - Started process (PID=93880) to work on /airflow/dags/download_data.py
[2022-02-17 10:30:01,458] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:30:01,460] {logging_mixin.py:112} INFO - [2022-02-17 10:30:01,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:30:01,921] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:30:01,969] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:30:01,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:30:01,986] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 10:30:14,751] {scheduler_job.py:155} INFO - Started process (PID=93908) to work on /airflow/dags/download_data.py
[2022-02-17 10:30:14,756] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:30:14,758] {logging_mixin.py:112} INFO - [2022-02-17 10:30:14,758] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:30:15,195] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:30:15,239] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:30:15,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:30:15,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 10:30:28,038] {scheduler_job.py:155} INFO - Started process (PID=93934) to work on /airflow/dags/download_data.py
[2022-02-17 10:30:28,043] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:30:28,044] {logging_mixin.py:112} INFO - [2022-02-17 10:30:28,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:30:28,503] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:30:28,560] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:30:28,570] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:30:28,577] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 10:30:41,333] {scheduler_job.py:155} INFO - Started process (PID=93962) to work on /airflow/dags/download_data.py
[2022-02-17 10:30:41,343] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:30:41,345] {logging_mixin.py:112} INFO - [2022-02-17 10:30:41,344] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:30:41,846] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:30:41,905] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:30:41,911] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:30:41,914] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 10:30:54,651] {scheduler_job.py:155} INFO - Started process (PID=93988) to work on /airflow/dags/download_data.py
[2022-02-17 10:30:54,655] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:30:54,657] {logging_mixin.py:112} INFO - [2022-02-17 10:30:54,656] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:30:55,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:30:55,159] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:30:55,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:30:55,179] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 10:31:07,896] {scheduler_job.py:155} INFO - Started process (PID=94014) to work on /airflow/dags/download_data.py
[2022-02-17 10:31:07,901] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:31:07,902] {logging_mixin.py:112} INFO - [2022-02-17 10:31:07,902] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:31:08,343] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:31:08,393] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:31:08,399] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:31:08,405] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 10:31:21,223] {scheduler_job.py:155} INFO - Started process (PID=94042) to work on /airflow/dags/download_data.py
[2022-02-17 10:31:21,229] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:31:21,230] {logging_mixin.py:112} INFO - [2022-02-17 10:31:21,230] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:31:21,669] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:31:21,720] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:31:21,726] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:31:21,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 10:31:34,476] {scheduler_job.py:155} INFO - Started process (PID=94068) to work on /airflow/dags/download_data.py
[2022-02-17 10:31:34,481] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:31:34,483] {logging_mixin.py:112} INFO - [2022-02-17 10:31:34,483] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:31:34,925] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:31:34,977] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:31:34,987] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:31:34,993] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 10:31:47,809] {scheduler_job.py:155} INFO - Started process (PID=94096) to work on /airflow/dags/download_data.py
[2022-02-17 10:31:47,815] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:31:47,817] {logging_mixin.py:112} INFO - [2022-02-17 10:31:47,816] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:31:48,247] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:31:48,289] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:31:48,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:31:48,300] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 10:32:01,064] {scheduler_job.py:155} INFO - Started process (PID=94122) to work on /airflow/dags/download_data.py
[2022-02-17 10:32:01,073] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:32:01,075] {logging_mixin.py:112} INFO - [2022-02-17 10:32:01,075] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:32:01,516] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:32:01,576] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:32:01,584] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:32:01,593] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 10:32:14,354] {scheduler_job.py:155} INFO - Started process (PID=94150) to work on /airflow/dags/download_data.py
[2022-02-17 10:32:14,365] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:32:14,366] {logging_mixin.py:112} INFO - [2022-02-17 10:32:14,366] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:32:14,787] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:32:14,835] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:32:14,842] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:32:14,851] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 10:32:27,626] {scheduler_job.py:155} INFO - Started process (PID=94176) to work on /airflow/dags/download_data.py
[2022-02-17 10:32:27,630] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:32:27,634] {logging_mixin.py:112} INFO - [2022-02-17 10:32:27,633] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:32:28,096] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:32:28,154] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:32:28,164] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:32:28,172] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 10:32:40,923] {scheduler_job.py:155} INFO - Started process (PID=94202) to work on /airflow/dags/download_data.py
[2022-02-17 10:32:40,927] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:32:40,935] {logging_mixin.py:112} INFO - [2022-02-17 10:32:40,935] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:32:41,375] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:32:41,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:32:41,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:32:41,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 10:32:54,249] {scheduler_job.py:155} INFO - Started process (PID=94230) to work on /airflow/dags/download_data.py
[2022-02-17 10:32:54,254] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:32:54,257] {logging_mixin.py:112} INFO - [2022-02-17 10:32:54,256] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:32:54,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:32:54,799] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:32:54,808] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:32:54,813] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 10:33:07,545] {scheduler_job.py:155} INFO - Started process (PID=94256) to work on /airflow/dags/download_data.py
[2022-02-17 10:33:07,550] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:33:07,552] {logging_mixin.py:112} INFO - [2022-02-17 10:33:07,551] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:33:07,983] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:33:08,025] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:33:08,031] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:33:08,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-17 10:33:20,831] {scheduler_job.py:155} INFO - Started process (PID=94284) to work on /airflow/dags/download_data.py
[2022-02-17 10:33:20,836] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:33:20,839] {logging_mixin.py:112} INFO - [2022-02-17 10:33:20,839] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:33:21,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:33:21,311] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:33:21,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:33:21,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 10:33:34,082] {scheduler_job.py:155} INFO - Started process (PID=94310) to work on /airflow/dags/download_data.py
[2022-02-17 10:33:34,088] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:33:34,090] {logging_mixin.py:112} INFO - [2022-02-17 10:33:34,090] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:33:34,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:33:34,582] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:33:34,590] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:33:34,595] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 10:33:47,378] {scheduler_job.py:155} INFO - Started process (PID=94338) to work on /airflow/dags/download_data.py
[2022-02-17 10:33:47,385] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:33:47,387] {logging_mixin.py:112} INFO - [2022-02-17 10:33:47,387] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:33:47,816] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:33:47,868] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:33:47,876] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:33:47,882] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 10:34:00,673] {scheduler_job.py:155} INFO - Started process (PID=94364) to work on /airflow/dags/download_data.py
[2022-02-17 10:34:00,681] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:34:00,683] {logging_mixin.py:112} INFO - [2022-02-17 10:34:00,683] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:34:01,145] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:34:01,185] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:34:01,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:34:01,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 10:34:13,915] {scheduler_job.py:155} INFO - Started process (PID=94390) to work on /airflow/dags/download_data.py
[2022-02-17 10:34:13,920] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:34:13,922] {logging_mixin.py:112} INFO - [2022-02-17 10:34:13,922] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:34:14,390] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:34:14,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:34:14,453] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:34:14,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 10:34:27,200] {scheduler_job.py:155} INFO - Started process (PID=94418) to work on /airflow/dags/download_data.py
[2022-02-17 10:34:27,208] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:34:27,211] {logging_mixin.py:112} INFO - [2022-02-17 10:34:27,210] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:34:27,651] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:34:27,710] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:34:27,717] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:34:27,721] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 10:34:40,484] {scheduler_job.py:155} INFO - Started process (PID=94444) to work on /airflow/dags/download_data.py
[2022-02-17 10:34:40,489] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:34:40,490] {logging_mixin.py:112} INFO - [2022-02-17 10:34:40,490] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:34:41,020] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:34:41,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:34:41,070] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:34:41,073] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 10:34:53,775] {scheduler_job.py:155} INFO - Started process (PID=94472) to work on /airflow/dags/download_data.py
[2022-02-17 10:34:53,780] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:34:53,782] {logging_mixin.py:112} INFO - [2022-02-17 10:34:53,782] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:34:54,245] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:34:54,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:34:54,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:34:54,325] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 10:35:07,072] {scheduler_job.py:155} INFO - Started process (PID=94498) to work on /airflow/dags/download_data.py
[2022-02-17 10:35:07,076] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:35:07,078] {logging_mixin.py:112} INFO - [2022-02-17 10:35:07,077] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:35:07,521] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:35:07,572] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:35:07,583] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:35:07,587] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 10:35:20,334] {scheduler_job.py:155} INFO - Started process (PID=94526) to work on /airflow/dags/download_data.py
[2022-02-17 10:35:20,343] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:35:20,346] {logging_mixin.py:112} INFO - [2022-02-17 10:35:20,345] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:35:20,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:35:20,830] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:35:20,842] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:35:20,846] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 10:35:33,598] {scheduler_job.py:155} INFO - Started process (PID=94552) to work on /airflow/dags/download_data.py
[2022-02-17 10:35:33,602] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:35:33,604] {logging_mixin.py:112} INFO - [2022-02-17 10:35:33,604] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:35:34,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:35:34,092] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:35:34,099] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:35:34,104] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 10:35:46,936] {scheduler_job.py:155} INFO - Started process (PID=94578) to work on /airflow/dags/download_data.py
[2022-02-17 10:35:46,951] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:35:46,954] {logging_mixin.py:112} INFO - [2022-02-17 10:35:46,953] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:35:47,462] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:35:47,508] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:35:47,516] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:35:47,522] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 10:36:00,159] {scheduler_job.py:155} INFO - Started process (PID=94606) to work on /airflow/dags/download_data.py
[2022-02-17 10:36:00,164] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:36:00,166] {logging_mixin.py:112} INFO - [2022-02-17 10:36:00,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:36:00,624] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:36:00,681] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:36:00,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:36:00,698] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 10:36:13,465] {scheduler_job.py:155} INFO - Started process (PID=94632) to work on /airflow/dags/download_data.py
[2022-02-17 10:36:13,476] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:36:13,477] {logging_mixin.py:112} INFO - [2022-02-17 10:36:13,477] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:36:13,918] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:36:13,971] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:36:13,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:36:13,988] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 10:36:26,721] {scheduler_job.py:155} INFO - Started process (PID=94660) to work on /airflow/dags/download_data.py
[2022-02-17 10:36:26,729] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:36:26,732] {logging_mixin.py:112} INFO - [2022-02-17 10:36:26,732] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:36:27,176] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:36:27,235] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:36:27,249] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:36:27,255] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 10:36:40,037] {scheduler_job.py:155} INFO - Started process (PID=94686) to work on /airflow/dags/download_data.py
[2022-02-17 10:36:40,042] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:36:40,044] {logging_mixin.py:112} INFO - [2022-02-17 10:36:40,043] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:36:40,473] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:36:40,519] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:36:40,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:36:40,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 10:36:53,312] {scheduler_job.py:155} INFO - Started process (PID=94714) to work on /airflow/dags/download_data.py
[2022-02-17 10:36:53,317] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:36:53,319] {logging_mixin.py:112} INFO - [2022-02-17 10:36:53,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:36:53,767] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:36:53,829] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:36:53,840] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:36:53,844] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 10:37:06,598] {scheduler_job.py:155} INFO - Started process (PID=94740) to work on /airflow/dags/download_data.py
[2022-02-17 10:37:06,609] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:37:06,612] {logging_mixin.py:112} INFO - [2022-02-17 10:37:06,611] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:37:07,076] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:37:07,127] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:37:07,133] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:37:07,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 10:37:19,835] {scheduler_job.py:155} INFO - Started process (PID=94768) to work on /airflow/dags/download_data.py
[2022-02-17 10:37:19,839] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:37:19,841] {logging_mixin.py:112} INFO - [2022-02-17 10:37:19,841] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:37:20,267] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:37:20,317] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:37:20,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:37:20,334] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 10:37:33,094] {scheduler_job.py:155} INFO - Started process (PID=94794) to work on /airflow/dags/download_data.py
[2022-02-17 10:37:33,098] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:37:33,099] {logging_mixin.py:112} INFO - [2022-02-17 10:37:33,099] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:37:33,549] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:37:33,593] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:37:33,603] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:37:33,610] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 10:37:46,411] {scheduler_job.py:155} INFO - Started process (PID=94820) to work on /airflow/dags/download_data.py
[2022-02-17 10:37:46,417] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:37:46,419] {logging_mixin.py:112} INFO - [2022-02-17 10:37:46,419] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:37:46,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:37:46,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:37:46,907] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:37:46,912] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 10:37:59,700] {scheduler_job.py:155} INFO - Started process (PID=94848) to work on /airflow/dags/download_data.py
[2022-02-17 10:37:59,705] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:37:59,706] {logging_mixin.py:112} INFO - [2022-02-17 10:37:59,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:38:00,163] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:38:00,206] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:38:00,214] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:38:00,219] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 10:38:12,993] {scheduler_job.py:155} INFO - Started process (PID=94874) to work on /airflow/dags/download_data.py
[2022-02-17 10:38:12,997] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:38:12,999] {logging_mixin.py:112} INFO - [2022-02-17 10:38:12,999] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:38:13,449] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:38:13,494] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:38:13,500] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:38:13,504] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 10:38:26,257] {scheduler_job.py:155} INFO - Started process (PID=94902) to work on /airflow/dags/download_data.py
[2022-02-17 10:38:26,262] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:38:26,265] {logging_mixin.py:112} INFO - [2022-02-17 10:38:26,264] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:38:26,727] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:38:26,772] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:38:26,778] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:38:26,782] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 10:38:39,579] {scheduler_job.py:155} INFO - Started process (PID=94928) to work on /airflow/dags/download_data.py
[2022-02-17 10:38:39,583] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:38:39,585] {logging_mixin.py:112} INFO - [2022-02-17 10:38:39,584] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:38:40,026] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:38:40,081] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:38:40,088] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:38:40,095] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 10:38:52,849] {scheduler_job.py:155} INFO - Started process (PID=94956) to work on /airflow/dags/download_data.py
[2022-02-17 10:38:52,857] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:38:52,859] {logging_mixin.py:112} INFO - [2022-02-17 10:38:52,859] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:38:53,358] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:38:53,419] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:38:53,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:38:53,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 10:39:06,125] {scheduler_job.py:155} INFO - Started process (PID=94982) to work on /airflow/dags/download_data.py
[2022-02-17 10:39:06,129] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:39:06,131] {logging_mixin.py:112} INFO - [2022-02-17 10:39:06,131] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:39:06,599] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:39:06,654] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:39:06,660] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:39:06,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 10:39:19,403] {scheduler_job.py:155} INFO - Started process (PID=95008) to work on /airflow/dags/download_data.py
[2022-02-17 10:39:19,407] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:39:19,409] {logging_mixin.py:112} INFO - [2022-02-17 10:39:19,408] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:39:19,865] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:39:19,917] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:39:19,923] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:39:19,929] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 10:39:32,641] {scheduler_job.py:155} INFO - Started process (PID=95036) to work on /airflow/dags/download_data.py
[2022-02-17 10:39:32,647] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:39:32,651] {logging_mixin.py:112} INFO - [2022-02-17 10:39:32,648] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:39:33,083] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:39:33,125] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:39:33,136] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:39:33,143] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 10:39:45,865] {scheduler_job.py:155} INFO - Started process (PID=95062) to work on /airflow/dags/download_data.py
[2022-02-17 10:39:45,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:39:45,871] {logging_mixin.py:112} INFO - [2022-02-17 10:39:45,871] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:39:46,340] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:39:46,390] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:39:46,398] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:39:46,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 10:39:59,189] {scheduler_job.py:155} INFO - Started process (PID=95090) to work on /airflow/dags/download_data.py
[2022-02-17 10:39:59,193] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:39:59,195] {logging_mixin.py:112} INFO - [2022-02-17 10:39:59,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:39:59,684] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:39:59,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:39:59,762] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:39:59,769] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 10:40:12,532] {scheduler_job.py:155} INFO - Started process (PID=95116) to work on /airflow/dags/download_data.py
[2022-02-17 10:40:12,536] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:40:12,539] {logging_mixin.py:112} INFO - [2022-02-17 10:40:12,538] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:40:12,970] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:40:13,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:40:13,029] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:40:13,033] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 10:40:25,831] {scheduler_job.py:155} INFO - Started process (PID=95144) to work on /airflow/dags/download_data.py
[2022-02-17 10:40:25,837] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:40:25,841] {logging_mixin.py:112} INFO - [2022-02-17 10:40:25,840] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:40:26,332] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:40:26,393] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:40:26,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:40:26,409] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 10:40:39,143] {scheduler_job.py:155} INFO - Started process (PID=95170) to work on /airflow/dags/download_data.py
[2022-02-17 10:40:39,153] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:40:39,159] {logging_mixin.py:112} INFO - [2022-02-17 10:40:39,159] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:40:39,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:40:39,678] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:40:39,689] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:40:39,695] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 10:40:52,422] {scheduler_job.py:155} INFO - Started process (PID=95196) to work on /airflow/dags/download_data.py
[2022-02-17 10:40:52,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:40:52,432] {logging_mixin.py:112} INFO - [2022-02-17 10:40:52,432] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:40:52,869] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:40:52,929] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:40:52,942] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:40:52,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 10:41:05,704] {scheduler_job.py:155} INFO - Started process (PID=95224) to work on /airflow/dags/download_data.py
[2022-02-17 10:41:05,713] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:41:05,715] {logging_mixin.py:112} INFO - [2022-02-17 10:41:05,714] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:41:06,143] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:41:06,179] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:41:06,185] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:41:06,190] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.487 seconds
[2022-02-17 10:41:19,019] {scheduler_job.py:155} INFO - Started process (PID=95250) to work on /airflow/dags/download_data.py
[2022-02-17 10:41:19,024] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:41:19,026] {logging_mixin.py:112} INFO - [2022-02-17 10:41:19,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:41:19,472] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:41:19,523] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:41:19,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:41:19,537] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 10:41:32,263] {scheduler_job.py:155} INFO - Started process (PID=95278) to work on /airflow/dags/download_data.py
[2022-02-17 10:41:32,269] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:41:32,271] {logging_mixin.py:112} INFO - [2022-02-17 10:41:32,271] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:41:32,726] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:41:32,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:41:32,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:41:32,790] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 10:41:45,561] {scheduler_job.py:155} INFO - Started process (PID=95304) to work on /airflow/dags/download_data.py
[2022-02-17 10:41:45,566] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:41:45,568] {logging_mixin.py:112} INFO - [2022-02-17 10:41:45,567] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:41:46,014] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:41:46,056] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:41:46,067] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:41:46,072] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 10:41:58,813] {scheduler_job.py:155} INFO - Started process (PID=95332) to work on /airflow/dags/download_data.py
[2022-02-17 10:41:58,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:41:58,819] {logging_mixin.py:112} INFO - [2022-02-17 10:41:58,819] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:41:59,272] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:41:59,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:41:59,321] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:41:59,325] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 10:42:12,143] {scheduler_job.py:155} INFO - Started process (PID=95358) to work on /airflow/dags/download_data.py
[2022-02-17 10:42:12,148] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:42:12,149] {logging_mixin.py:112} INFO - [2022-02-17 10:42:12,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:42:12,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:42:12,627] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:42:12,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:42:12,637] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 10:42:25,458] {scheduler_job.py:155} INFO - Started process (PID=95386) to work on /airflow/dags/download_data.py
[2022-02-17 10:42:25,477] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:42:25,480] {logging_mixin.py:112} INFO - [2022-02-17 10:42:25,479] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:42:26,024] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:42:26,077] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:42:26,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:42:26,097] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-17 10:42:38,703] {scheduler_job.py:155} INFO - Started process (PID=95412) to work on /airflow/dags/download_data.py
[2022-02-17 10:42:38,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:42:38,709] {logging_mixin.py:112} INFO - [2022-02-17 10:42:38,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:42:39,228] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:42:39,365] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:42:39,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:42:39,376] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.673 seconds
[2022-02-17 10:42:51,956] {scheduler_job.py:155} INFO - Started process (PID=95438) to work on /airflow/dags/download_data.py
[2022-02-17 10:42:51,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:42:51,963] {logging_mixin.py:112} INFO - [2022-02-17 10:42:51,962] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:42:52,395] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:42:52,434] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:42:52,439] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:42:52,443] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.487 seconds
[2022-02-17 10:43:05,227] {scheduler_job.py:155} INFO - Started process (PID=95466) to work on /airflow/dags/download_data.py
[2022-02-17 10:43:05,232] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:43:05,233] {logging_mixin.py:112} INFO - [2022-02-17 10:43:05,233] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:43:05,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:43:05,716] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:43:05,726] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:43:05,730] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 10:43:18,527] {scheduler_job.py:155} INFO - Started process (PID=95492) to work on /airflow/dags/download_data.py
[2022-02-17 10:43:18,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:43:18,533] {logging_mixin.py:112} INFO - [2022-02-17 10:43:18,533] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:43:18,974] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:43:19,025] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:43:19,033] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:43:19,038] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 10:43:31,813] {scheduler_job.py:155} INFO - Started process (PID=95520) to work on /airflow/dags/download_data.py
[2022-02-17 10:43:31,817] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:43:31,819] {logging_mixin.py:112} INFO - [2022-02-17 10:43:31,819] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:43:32,251] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:43:32,307] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:43:32,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:43:32,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 10:43:45,147] {scheduler_job.py:155} INFO - Started process (PID=95546) to work on /airflow/dags/download_data.py
[2022-02-17 10:43:45,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:43:45,153] {logging_mixin.py:112} INFO - [2022-02-17 10:43:45,152] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:43:45,605] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:43:45,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:43:45,664] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:43:45,671] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 10:43:58,406] {scheduler_job.py:155} INFO - Started process (PID=95574) to work on /airflow/dags/download_data.py
[2022-02-17 10:43:58,412] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:43:58,413] {logging_mixin.py:112} INFO - [2022-02-17 10:43:58,413] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:43:58,888] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:43:58,921] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:43:58,931] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:43:58,940] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 10:44:11,729] {scheduler_job.py:155} INFO - Started process (PID=95600) to work on /airflow/dags/download_data.py
[2022-02-17 10:44:11,736] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:44:11,738] {logging_mixin.py:112} INFO - [2022-02-17 10:44:11,738] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:44:12,193] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:44:12,233] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:44:12,243] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:44:12,249] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 10:44:25,039] {scheduler_job.py:155} INFO - Started process (PID=95626) to work on /airflow/dags/download_data.py
[2022-02-17 10:44:25,047] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:44:25,050] {logging_mixin.py:112} INFO - [2022-02-17 10:44:25,049] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:44:25,564] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:44:25,622] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:44:25,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:44:25,639] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 10:44:38,309] {scheduler_job.py:155} INFO - Started process (PID=95654) to work on /airflow/dags/download_data.py
[2022-02-17 10:44:38,313] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:44:38,316] {logging_mixin.py:112} INFO - [2022-02-17 10:44:38,315] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:44:38,753] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:44:38,794] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:44:38,801] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:44:38,806] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 10:44:51,614] {scheduler_job.py:155} INFO - Started process (PID=95680) to work on /airflow/dags/download_data.py
[2022-02-17 10:44:51,618] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:44:51,620] {logging_mixin.py:112} INFO - [2022-02-17 10:44:51,620] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:44:52,053] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:44:52,096] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:44:52,102] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:44:52,105] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 10:45:04,926] {scheduler_job.py:155} INFO - Started process (PID=95708) to work on /airflow/dags/download_data.py
[2022-02-17 10:45:04,932] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:45:04,934] {logging_mixin.py:112} INFO - [2022-02-17 10:45:04,934] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:45:05,358] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:45:05,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:45:05,420] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:45:05,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 10:45:18,212] {scheduler_job.py:155} INFO - Started process (PID=95734) to work on /airflow/dags/download_data.py
[2022-02-17 10:45:18,218] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:45:18,219] {logging_mixin.py:112} INFO - [2022-02-17 10:45:18,219] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:45:18,652] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:45:18,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:45:18,707] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:45:18,711] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 10:45:31,498] {scheduler_job.py:155} INFO - Started process (PID=95762) to work on /airflow/dags/download_data.py
[2022-02-17 10:45:31,507] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:45:31,510] {logging_mixin.py:112} INFO - [2022-02-17 10:45:31,510] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:45:31,950] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:45:31,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:45:32,019] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:45:32,024] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 10:45:44,794] {scheduler_job.py:155} INFO - Started process (PID=95788) to work on /airflow/dags/download_data.py
[2022-02-17 10:45:44,800] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:45:44,802] {logging_mixin.py:112} INFO - [2022-02-17 10:45:44,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:45:45,244] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:45:45,297] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:45:45,304] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:45:45,308] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 10:45:58,072] {scheduler_job.py:155} INFO - Started process (PID=95814) to work on /airflow/dags/download_data.py
[2022-02-17 10:45:58,084] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:45:58,087] {logging_mixin.py:112} INFO - [2022-02-17 10:45:58,086] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:45:58,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:45:58,628] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:45:58,636] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:45:58,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 10:46:11,377] {scheduler_job.py:155} INFO - Started process (PID=95842) to work on /airflow/dags/download_data.py
[2022-02-17 10:46:11,382] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:46:11,385] {logging_mixin.py:112} INFO - [2022-02-17 10:46:11,384] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:46:11,830] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:46:11,881] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:46:11,887] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:46:11,891] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 10:46:24,707] {scheduler_job.py:155} INFO - Started process (PID=95868) to work on /airflow/dags/download_data.py
[2022-02-17 10:46:24,715] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:46:24,722] {logging_mixin.py:112} INFO - [2022-02-17 10:46:24,720] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:46:25,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:46:25,224] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:46:25,239] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:46:25,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 10:46:37,996] {scheduler_job.py:155} INFO - Started process (PID=95896) to work on /airflow/dags/download_data.py
[2022-02-17 10:46:38,007] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:46:38,009] {logging_mixin.py:112} INFO - [2022-02-17 10:46:38,008] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:46:38,437] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:46:38,483] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:46:38,493] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:46:38,499] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 10:46:51,247] {scheduler_job.py:155} INFO - Started process (PID=95922) to work on /airflow/dags/download_data.py
[2022-02-17 10:46:51,251] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:46:51,253] {logging_mixin.py:112} INFO - [2022-02-17 10:46:51,253] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:46:51,697] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:46:51,751] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:46:51,761] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:46:51,766] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 10:47:04,496] {scheduler_job.py:155} INFO - Started process (PID=95950) to work on /airflow/dags/download_data.py
[2022-02-17 10:47:04,501] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:47:04,503] {logging_mixin.py:112} INFO - [2022-02-17 10:47:04,503] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:47:04,924] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:47:04,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:47:04,980] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:47:04,984] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 10:47:17,842] {scheduler_job.py:155} INFO - Started process (PID=95976) to work on /airflow/dags/download_data.py
[2022-02-17 10:47:17,850] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:47:17,852] {logging_mixin.py:112} INFO - [2022-02-17 10:47:17,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:47:18,295] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:47:18,335] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:47:18,341] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:47:18,345] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 10:47:31,104] {scheduler_job.py:155} INFO - Started process (PID=96004) to work on /airflow/dags/download_data.py
[2022-02-17 10:47:31,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:47:31,115] {logging_mixin.py:112} INFO - [2022-02-17 10:47:31,114] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:47:31,645] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:47:31,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:47:31,712] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:47:31,718] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-17 10:47:44,397] {scheduler_job.py:155} INFO - Started process (PID=96030) to work on /airflow/dags/download_data.py
[2022-02-17 10:47:44,403] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:47:44,405] {logging_mixin.py:112} INFO - [2022-02-17 10:47:44,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:47:44,851] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:47:44,894] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:47:44,902] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:47:44,906] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 10:47:57,638] {scheduler_job.py:155} INFO - Started process (PID=96056) to work on /airflow/dags/download_data.py
[2022-02-17 10:47:57,647] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:47:57,649] {logging_mixin.py:112} INFO - [2022-02-17 10:47:57,649] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:47:58,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:47:58,175] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:47:58,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:47:58,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 10:48:10,908] {scheduler_job.py:155} INFO - Started process (PID=96084) to work on /airflow/dags/download_data.py
[2022-02-17 10:48:10,911] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:48:10,917] {logging_mixin.py:112} INFO - [2022-02-17 10:48:10,916] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:48:11,366] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:48:11,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:48:11,426] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:48:11,431] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 10:48:24,203] {scheduler_job.py:155} INFO - Started process (PID=96110) to work on /airflow/dags/download_data.py
[2022-02-17 10:48:24,210] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:48:24,213] {logging_mixin.py:112} INFO - [2022-02-17 10:48:24,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:48:24,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:48:24,712] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:48:24,720] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:48:24,726] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 10:48:37,458] {scheduler_job.py:155} INFO - Started process (PID=96138) to work on /airflow/dags/download_data.py
[2022-02-17 10:48:37,467] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:48:37,470] {logging_mixin.py:112} INFO - [2022-02-17 10:48:37,470] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:48:37,913] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:48:37,963] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:48:37,970] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:48:37,975] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 10:48:50,796] {scheduler_job.py:155} INFO - Started process (PID=96164) to work on /airflow/dags/download_data.py
[2022-02-17 10:48:50,804] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:48:50,806] {logging_mixin.py:112} INFO - [2022-02-17 10:48:50,805] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:48:51,239] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:48:51,289] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:48:51,295] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:48:51,298] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 10:49:04,044] {scheduler_job.py:155} INFO - Started process (PID=96192) to work on /airflow/dags/download_data.py
[2022-02-17 10:49:04,060] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:49:04,067] {logging_mixin.py:112} INFO - [2022-02-17 10:49:04,066] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:49:04,519] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:49:04,572] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:49:04,581] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:49:04,585] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 10:49:17,334] {scheduler_job.py:155} INFO - Started process (PID=96218) to work on /airflow/dags/download_data.py
[2022-02-17 10:49:17,340] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:49:17,343] {logging_mixin.py:112} INFO - [2022-02-17 10:49:17,343] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:49:17,779] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:49:17,818] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:49:17,825] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:49:17,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 10:49:30,566] {scheduler_job.py:155} INFO - Started process (PID=96244) to work on /airflow/dags/download_data.py
[2022-02-17 10:49:30,570] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:49:30,571] {logging_mixin.py:112} INFO - [2022-02-17 10:49:30,571] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:49:30,988] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:49:31,030] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:49:31,036] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:49:31,040] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.474 seconds
[2022-02-17 10:49:43,916] {scheduler_job.py:155} INFO - Started process (PID=96272) to work on /airflow/dags/download_data.py
[2022-02-17 10:49:43,921] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 10:49:43,924] {logging_mixin.py:112} INFO - [2022-02-17 10:49:43,923] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 10:49:44,402] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 10:49:44,458] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 10:49:44,465] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 10:49:44,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 11:49:56,417] {scheduler_job.py:155} INFO - Started process (PID=96308) to work on /airflow/dags/download_data.py
[2022-02-17 11:49:56,425] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:49:56,428] {logging_mixin.py:112} INFO - [2022-02-17 11:49:56,428] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:49:57,808] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:49:57,854] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:49:57,861] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:49:57,869] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.452 seconds
[2022-02-17 11:50:15,531] {scheduler_job.py:155} INFO - Started process (PID=96334) to work on /airflow/dags/download_data.py
[2022-02-17 11:50:15,540] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:50:15,542] {logging_mixin.py:112} INFO - [2022-02-17 11:50:15,542] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:50:15,993] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:50:16,050] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:50:16,062] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:50:16,066] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 11:50:25,736] {scheduler_job.py:155} INFO - Started process (PID=96361) to work on /airflow/dags/download_data.py
[2022-02-17 11:50:25,741] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:50:25,743] {logging_mixin.py:112} INFO - [2022-02-17 11:50:25,743] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:50:26,190] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:50:26,252] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:50:26,266] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:50:26,274] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 11:50:32,704] {scheduler_job.py:155} INFO - Started process (PID=96386) to work on /airflow/dags/download_data.py
[2022-02-17 11:50:32,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:50:32,711] {logging_mixin.py:112} INFO - [2022-02-17 11:50:32,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:50:33,202] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:50:33,253] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:50:33,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:50:33,270] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 11:50:39,869] {scheduler_job.py:155} INFO - Started process (PID=96413) to work on /airflow/dags/download_data.py
[2022-02-17 11:50:39,874] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:50:39,876] {logging_mixin.py:112} INFO - [2022-02-17 11:50:39,875] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:50:40,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:50:40,401] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:50:40,412] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:50:40,417] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 11:50:50,118] {scheduler_job.py:155} INFO - Started process (PID=96440) to work on /airflow/dags/download_data.py
[2022-02-17 11:50:50,122] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:50:50,123] {logging_mixin.py:112} INFO - [2022-02-17 11:50:50,123] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:50:50,661] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:50:50,725] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:50:50,738] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:50:50,744] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-17 11:51:03,443] {scheduler_job.py:155} INFO - Started process (PID=96469) to work on /airflow/dags/download_data.py
[2022-02-17 11:51:03,450] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:51:03,452] {logging_mixin.py:112} INFO - [2022-02-17 11:51:03,452] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:51:03,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:51:03,949] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:51:03,957] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:51:03,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 11:51:16,758] {scheduler_job.py:155} INFO - Started process (PID=96495) to work on /airflow/dags/download_data.py
[2022-02-17 11:51:16,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:51:16,764] {logging_mixin.py:112} INFO - [2022-02-17 11:51:16,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:51:17,212] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:51:17,261] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:51:17,269] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:51:17,273] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 11:51:30,023] {scheduler_job.py:155} INFO - Started process (PID=96523) to work on /airflow/dags/download_data.py
[2022-02-17 11:51:30,035] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:51:30,037] {logging_mixin.py:112} INFO - [2022-02-17 11:51:30,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:51:30,474] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:51:30,528] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:51:30,539] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:51:30,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 11:51:43,344] {scheduler_job.py:155} INFO - Started process (PID=96549) to work on /airflow/dags/download_data.py
[2022-02-17 11:51:43,349] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:51:43,350] {logging_mixin.py:112} INFO - [2022-02-17 11:51:43,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:51:43,789] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:51:43,829] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:51:43,835] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:51:43,839] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 11:51:56,671] {scheduler_job.py:155} INFO - Started process (PID=96577) to work on /airflow/dags/download_data.py
[2022-02-17 11:51:56,686] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:51:56,688] {logging_mixin.py:112} INFO - [2022-02-17 11:51:56,687] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:51:57,291] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:51:57,336] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:51:57,349] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:51:57,354] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.683 seconds
[2022-02-17 11:52:09,928] {scheduler_job.py:155} INFO - Started process (PID=96603) to work on /airflow/dags/download_data.py
[2022-02-17 11:52:09,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:52:09,938] {logging_mixin.py:112} INFO - [2022-02-17 11:52:09,938] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:52:10,373] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:52:10,425] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:52:10,435] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:52:10,441] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 11:52:23,195] {scheduler_job.py:155} INFO - Started process (PID=96629) to work on /airflow/dags/download_data.py
[2022-02-17 11:52:23,201] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:52:23,202] {logging_mixin.py:112} INFO - [2022-02-17 11:52:23,202] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:52:23,660] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:52:23,725] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:52:23,736] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:52:23,741] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 11:52:36,550] {scheduler_job.py:155} INFO - Started process (PID=96657) to work on /airflow/dags/download_data.py
[2022-02-17 11:52:36,555] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:52:36,559] {logging_mixin.py:112} INFO - [2022-02-17 11:52:36,558] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:52:37,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:52:37,084] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:52:37,093] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:52:37,099] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 11:52:49,798] {scheduler_job.py:155} INFO - Started process (PID=96683) to work on /airflow/dags/download_data.py
[2022-02-17 11:52:49,803] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:52:49,804] {logging_mixin.py:112} INFO - [2022-02-17 11:52:49,804] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:52:50,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:52:50,299] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:52:50,308] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:52:50,313] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 11:53:03,057] {scheduler_job.py:155} INFO - Started process (PID=96711) to work on /airflow/dags/download_data.py
[2022-02-17 11:53:03,060] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:53:03,062] {logging_mixin.py:112} INFO - [2022-02-17 11:53:03,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:53:03,503] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:53:03,555] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:53:03,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:53:03,567] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 11:53:16,367] {scheduler_job.py:155} INFO - Started process (PID=96737) to work on /airflow/dags/download_data.py
[2022-02-17 11:53:16,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:53:16,374] {logging_mixin.py:112} INFO - [2022-02-17 11:53:16,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:53:16,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:53:16,867] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:53:16,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:53:16,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 11:53:29,640] {scheduler_job.py:155} INFO - Started process (PID=96765) to work on /airflow/dags/download_data.py
[2022-02-17 11:53:29,645] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:53:29,647] {logging_mixin.py:112} INFO - [2022-02-17 11:53:29,646] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:53:30,078] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:53:30,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:53:30,139] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:53:30,145] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 11:53:42,979] {scheduler_job.py:155} INFO - Started process (PID=96791) to work on /airflow/dags/download_data.py
[2022-02-17 11:53:42,988] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:53:42,989] {logging_mixin.py:112} INFO - [2022-02-17 11:53:42,989] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:53:43,434] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:53:43,490] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:53:43,497] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:53:43,503] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 11:53:56,228] {scheduler_job.py:155} INFO - Started process (PID=96817) to work on /airflow/dags/download_data.py
[2022-02-17 11:53:56,236] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:53:56,239] {logging_mixin.py:112} INFO - [2022-02-17 11:53:56,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:53:56,709] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:53:56,767] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:53:56,780] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:53:56,785] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 11:54:09,628] {scheduler_job.py:155} INFO - Started process (PID=96845) to work on /airflow/dags/download_data.py
[2022-02-17 11:54:09,635] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:54:09,637] {logging_mixin.py:112} INFO - [2022-02-17 11:54:09,636] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:54:10,075] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:54:10,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:54:10,128] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:54:10,134] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 11:54:22,889] {scheduler_job.py:155} INFO - Started process (PID=96871) to work on /airflow/dags/download_data.py
[2022-02-17 11:54:22,897] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:54:22,900] {logging_mixin.py:112} INFO - [2022-02-17 11:54:22,899] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:54:23,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:54:23,415] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:54:23,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:54:23,432] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 11:54:36,177] {scheduler_job.py:155} INFO - Started process (PID=96899) to work on /airflow/dags/download_data.py
[2022-02-17 11:54:36,182] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:54:36,184] {logging_mixin.py:112} INFO - [2022-02-17 11:54:36,183] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:54:36,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:54:36,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:54:36,710] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:54:36,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 11:54:49,469] {scheduler_job.py:155} INFO - Started process (PID=96925) to work on /airflow/dags/download_data.py
[2022-02-17 11:54:49,474] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:54:49,475] {logging_mixin.py:112} INFO - [2022-02-17 11:54:49,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:54:49,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:54:49,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:54:49,968] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:54:49,972] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 11:55:02,775] {scheduler_job.py:155} INFO - Started process (PID=96953) to work on /airflow/dags/download_data.py
[2022-02-17 11:55:02,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:55:02,785] {logging_mixin.py:112} INFO - [2022-02-17 11:55:02,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:55:03,263] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:55:03,308] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:55:03,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:55:03,325] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 11:55:16,069] {scheduler_job.py:155} INFO - Started process (PID=96979) to work on /airflow/dags/download_data.py
[2022-02-17 11:55:16,077] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:55:16,079] {logging_mixin.py:112} INFO - [2022-02-17 11:55:16,078] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:55:16,512] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:55:16,563] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:55:16,572] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:55:16,575] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 11:55:29,318] {scheduler_job.py:155} INFO - Started process (PID=97005) to work on /airflow/dags/download_data.py
[2022-02-17 11:55:29,327] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:55:29,329] {logging_mixin.py:112} INFO - [2022-02-17 11:55:29,329] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:55:29,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:55:29,825] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:55:29,836] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:55:29,844] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 11:55:42,586] {scheduler_job.py:155} INFO - Started process (PID=97033) to work on /airflow/dags/download_data.py
[2022-02-17 11:55:42,593] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:55:42,595] {logging_mixin.py:112} INFO - [2022-02-17 11:55:42,595] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:55:43,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:55:43,062] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:55:43,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:55:43,078] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 11:55:55,851] {scheduler_job.py:155} INFO - Started process (PID=97059) to work on /airflow/dags/download_data.py
[2022-02-17 11:55:55,858] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:55:55,861] {logging_mixin.py:112} INFO - [2022-02-17 11:55:55,860] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:55:56,308] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:55:56,363] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:55:56,374] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:55:56,381] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 11:56:09,121] {scheduler_job.py:155} INFO - Started process (PID=97087) to work on /airflow/dags/download_data.py
[2022-02-17 11:56:09,129] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:56:09,132] {logging_mixin.py:112} INFO - [2022-02-17 11:56:09,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:56:09,598] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:56:09,649] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:56:09,656] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:56:09,663] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 11:56:22,400] {scheduler_job.py:155} INFO - Started process (PID=97113) to work on /airflow/dags/download_data.py
[2022-02-17 11:56:22,406] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:56:22,408] {logging_mixin.py:112} INFO - [2022-02-17 11:56:22,408] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:56:22,874] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:56:22,936] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:56:22,946] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:56:22,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 11:56:35,706] {scheduler_job.py:155} INFO - Started process (PID=97141) to work on /airflow/dags/download_data.py
[2022-02-17 11:56:35,711] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:56:35,713] {logging_mixin.py:112} INFO - [2022-02-17 11:56:35,713] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:56:36,144] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:56:36,195] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:56:36,202] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:56:36,208] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 11:56:48,972] {scheduler_job.py:155} INFO - Started process (PID=97167) to work on /airflow/dags/download_data.py
[2022-02-17 11:56:48,978] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:56:48,980] {logging_mixin.py:112} INFO - [2022-02-17 11:56:48,979] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:56:49,413] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:56:49,467] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:56:49,474] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:56:49,477] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 11:57:02,275] {scheduler_job.py:155} INFO - Started process (PID=97195) to work on /airflow/dags/download_data.py
[2022-02-17 11:57:02,291] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:57:02,296] {logging_mixin.py:112} INFO - [2022-02-17 11:57:02,294] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:57:02,813] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:57:02,854] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:57:02,868] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:57:02,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 11:57:15,752] {scheduler_job.py:155} INFO - Started process (PID=97221) to work on /airflow/dags/download_data.py
[2022-02-17 11:57:15,756] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:57:15,758] {logging_mixin.py:112} INFO - [2022-02-17 11:57:15,757] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:57:16,203] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:57:16,251] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:57:16,257] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:57:16,262] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 11:57:29,025] {scheduler_job.py:155} INFO - Started process (PID=97247) to work on /airflow/dags/download_data.py
[2022-02-17 11:57:29,029] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:57:29,031] {logging_mixin.py:112} INFO - [2022-02-17 11:57:29,031] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:57:29,466] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:57:29,514] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:57:29,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:57:29,528] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 11:57:42,389] {scheduler_job.py:155} INFO - Started process (PID=97275) to work on /airflow/dags/download_data.py
[2022-02-17 11:57:42,393] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:57:42,394] {logging_mixin.py:112} INFO - [2022-02-17 11:57:42,394] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:57:42,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:57:42,875] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:57:42,885] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:57:42,889] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 11:57:55,676] {scheduler_job.py:155} INFO - Started process (PID=97301) to work on /airflow/dags/download_data.py
[2022-02-17 11:57:55,681] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:57:55,683] {logging_mixin.py:112} INFO - [2022-02-17 11:57:55,683] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:57:56,162] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:57:56,197] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:57:56,204] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:57:56,208] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 11:58:09,029] {scheduler_job.py:155} INFO - Started process (PID=97329) to work on /airflow/dags/download_data.py
[2022-02-17 11:58:09,037] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:58:09,039] {logging_mixin.py:112} INFO - [2022-02-17 11:58:09,039] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:58:09,460] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:58:09,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:58:09,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:58:09,519] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-17 11:58:22,300] {scheduler_job.py:155} INFO - Started process (PID=97355) to work on /airflow/dags/download_data.py
[2022-02-17 11:58:22,305] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:58:22,307] {logging_mixin.py:112} INFO - [2022-02-17 11:58:22,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:58:22,741] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:58:22,799] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:58:22,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:58:22,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 11:58:35,577] {scheduler_job.py:155} INFO - Started process (PID=97383) to work on /airflow/dags/download_data.py
[2022-02-17 11:58:35,581] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:58:35,583] {logging_mixin.py:112} INFO - [2022-02-17 11:58:35,583] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:58:36,001] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:58:36,040] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:58:36,046] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:58:36,049] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.472 seconds
[2022-02-17 11:58:48,870] {scheduler_job.py:155} INFO - Started process (PID=97409) to work on /airflow/dags/download_data.py
[2022-02-17 11:58:48,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:58:48,877] {logging_mixin.py:112} INFO - [2022-02-17 11:58:48,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:58:49,293] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:58:49,333] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:58:49,339] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:58:49,342] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.472 seconds
[2022-02-17 11:59:02,154] {scheduler_job.py:155} INFO - Started process (PID=97435) to work on /airflow/dags/download_data.py
[2022-02-17 11:59:02,160] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:59:02,161] {logging_mixin.py:112} INFO - [2022-02-17 11:59:02,161] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:59:02,616] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:59:02,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:59:02,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:59:02,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 11:59:15,480] {scheduler_job.py:155} INFO - Started process (PID=97463) to work on /airflow/dags/download_data.py
[2022-02-17 11:59:15,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:59:15,489] {logging_mixin.py:112} INFO - [2022-02-17 11:59:15,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:59:15,924] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:59:15,970] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:59:15,979] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:59:15,984] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 11:59:28,751] {scheduler_job.py:155} INFO - Started process (PID=97489) to work on /airflow/dags/download_data.py
[2022-02-17 11:59:28,759] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:59:28,761] {logging_mixin.py:112} INFO - [2022-02-17 11:59:28,761] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:59:29,213] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:59:29,257] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:59:29,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:59:29,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 11:59:42,077] {scheduler_job.py:155} INFO - Started process (PID=97517) to work on /airflow/dags/download_data.py
[2022-02-17 11:59:42,089] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:59:42,091] {logging_mixin.py:112} INFO - [2022-02-17 11:59:42,090] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:59:42,540] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:59:42,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:59:42,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:59:42,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 11:59:55,366] {scheduler_job.py:155} INFO - Started process (PID=97543) to work on /airflow/dags/download_data.py
[2022-02-17 11:59:55,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 11:59:55,379] {logging_mixin.py:112} INFO - [2022-02-17 11:59:55,378] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 11:59:55,840] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 11:59:55,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 11:59:55,909] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 11:59:55,915] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 12:00:08,694] {scheduler_job.py:155} INFO - Started process (PID=97571) to work on /airflow/dags/download_data.py
[2022-02-17 12:00:08,698] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:00:08,699] {logging_mixin.py:112} INFO - [2022-02-17 12:00:08,699] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:00:09,147] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:00:09,196] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:00:09,210] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:00:09,216] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 12:00:21,967] {scheduler_job.py:155} INFO - Started process (PID=97597) to work on /airflow/dags/download_data.py
[2022-02-17 12:00:21,971] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:00:21,973] {logging_mixin.py:112} INFO - [2022-02-17 12:00:21,973] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:00:22,425] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:00:22,468] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:00:22,476] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:00:22,483] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 12:00:35,218] {scheduler_job.py:155} INFO - Started process (PID=97623) to work on /airflow/dags/download_data.py
[2022-02-17 12:00:35,225] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:00:35,227] {logging_mixin.py:112} INFO - [2022-02-17 12:00:35,227] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:00:35,660] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:00:35,708] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:00:35,715] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:00:35,718] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 12:00:48,569] {scheduler_job.py:155} INFO - Started process (PID=97651) to work on /airflow/dags/download_data.py
[2022-02-17 12:00:48,573] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:00:48,575] {logging_mixin.py:112} INFO - [2022-02-17 12:00:48,575] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:00:49,008] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:00:49,059] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:00:49,068] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:00:49,074] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 12:01:01,817] {scheduler_job.py:155} INFO - Started process (PID=97677) to work on /airflow/dags/download_data.py
[2022-02-17 12:01:01,832] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:01:01,835] {logging_mixin.py:112} INFO - [2022-02-17 12:01:01,834] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:01:02,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:01:02,319] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:01:02,326] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:01:02,331] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 12:01:15,093] {scheduler_job.py:155} INFO - Started process (PID=97705) to work on /airflow/dags/download_data.py
[2022-02-17 12:01:15,100] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:01:15,102] {logging_mixin.py:112} INFO - [2022-02-17 12:01:15,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:01:15,530] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:01:15,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:01:15,584] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:01:15,587] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 12:01:28,346] {scheduler_job.py:155} INFO - Started process (PID=97731) to work on /airflow/dags/download_data.py
[2022-02-17 12:01:28,354] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:01:28,356] {logging_mixin.py:112} INFO - [2022-02-17 12:01:28,355] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:01:28,786] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:01:28,836] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:01:28,842] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:01:28,846] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 12:01:41,645] {scheduler_job.py:155} INFO - Started process (PID=97759) to work on /airflow/dags/download_data.py
[2022-02-17 12:01:41,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:01:41,655] {logging_mixin.py:112} INFO - [2022-02-17 12:01:41,654] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:01:42,083] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:01:42,135] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:01:42,142] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:01:42,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 12:01:54,926] {scheduler_job.py:155} INFO - Started process (PID=97785) to work on /airflow/dags/download_data.py
[2022-02-17 12:01:54,931] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:01:54,933] {logging_mixin.py:112} INFO - [2022-02-17 12:01:54,933] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:01:55,420] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:01:55,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:01:55,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:01:55,488] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 12:02:08,203] {scheduler_job.py:155} INFO - Started process (PID=97812) to work on /airflow/dags/download_data.py
[2022-02-17 12:02:08,215] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:02:08,217] {logging_mixin.py:112} INFO - [2022-02-17 12:02:08,217] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:02:08,775] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:02:08,824] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:02:08,832] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:02:08,836] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.634 seconds
[2022-02-17 12:02:21,549] {scheduler_job.py:155} INFO - Started process (PID=97839) to work on /airflow/dags/download_data.py
[2022-02-17 12:02:21,555] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:02:21,556] {logging_mixin.py:112} INFO - [2022-02-17 12:02:21,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:02:22,019] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:02:22,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:02:22,075] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:02:22,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 12:02:34,835] {scheduler_job.py:155} INFO - Started process (PID=97865) to work on /airflow/dags/download_data.py
[2022-02-17 12:02:34,843] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:02:34,845] {logging_mixin.py:112} INFO - [2022-02-17 12:02:34,844] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:02:35,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:02:35,318] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:02:35,324] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:02:35,330] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 12:02:48,136] {scheduler_job.py:155} INFO - Started process (PID=97893) to work on /airflow/dags/download_data.py
[2022-02-17 12:02:48,142] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:02:48,144] {logging_mixin.py:112} INFO - [2022-02-17 12:02:48,144] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:02:48,571] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:02:48,622] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:02:48,631] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:02:48,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 12:03:01,680] {scheduler_job.py:155} INFO - Started process (PID=97919) to work on /airflow/dags/download_data.py
[2022-02-17 12:03:01,684] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:03:01,686] {logging_mixin.py:112} INFO - [2022-02-17 12:03:01,685] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:03:02,138] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:03:02,178] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:03:02,186] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:03:02,190] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 12:03:14,994] {scheduler_job.py:155} INFO - Started process (PID=97947) to work on /airflow/dags/download_data.py
[2022-02-17 12:03:14,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:03:15,000] {logging_mixin.py:112} INFO - [2022-02-17 12:03:15,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:03:15,442] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:03:15,486] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:03:15,493] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:03:15,498] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 12:03:28,237] {scheduler_job.py:155} INFO - Started process (PID=97973) to work on /airflow/dags/download_data.py
[2022-02-17 12:03:28,244] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:03:28,246] {logging_mixin.py:112} INFO - [2022-02-17 12:03:28,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:03:28,669] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:03:28,710] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:03:28,721] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:03:28,724] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 12:03:41,552] {scheduler_job.py:155} INFO - Started process (PID=98001) to work on /airflow/dags/download_data.py
[2022-02-17 12:03:41,561] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:03:41,562] {logging_mixin.py:112} INFO - [2022-02-17 12:03:41,562] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:03:41,970] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:03:42,004] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:03:42,010] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:03:42,013] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.461 seconds
[2022-02-17 12:03:54,844] {scheduler_job.py:155} INFO - Started process (PID=98027) to work on /airflow/dags/download_data.py
[2022-02-17 12:03:54,851] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:03:54,853] {logging_mixin.py:112} INFO - [2022-02-17 12:03:54,853] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:03:55,301] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:03:55,351] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:03:55,362] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:03:55,366] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 12:04:08,129] {scheduler_job.py:155} INFO - Started process (PID=98053) to work on /airflow/dags/download_data.py
[2022-02-17 12:04:08,136] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:04:08,137] {logging_mixin.py:112} INFO - [2022-02-17 12:04:08,137] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:04:08,570] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:04:08,624] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:04:08,630] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:04:08,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 12:04:21,451] {scheduler_job.py:155} INFO - Started process (PID=98081) to work on /airflow/dags/download_data.py
[2022-02-17 12:04:21,457] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:04:21,458] {logging_mixin.py:112} INFO - [2022-02-17 12:04:21,458] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:04:21,929] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:04:21,976] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:04:21,990] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:04:21,996] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 12:04:34,755] {scheduler_job.py:155} INFO - Started process (PID=98107) to work on /airflow/dags/download_data.py
[2022-02-17 12:04:34,764] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:04:34,766] {logging_mixin.py:112} INFO - [2022-02-17 12:04:34,766] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:04:35,195] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:04:35,245] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:04:35,256] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:04:35,263] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 12:04:48,066] {scheduler_job.py:155} INFO - Started process (PID=98135) to work on /airflow/dags/download_data.py
[2022-02-17 12:04:48,075] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:04:48,077] {logging_mixin.py:112} INFO - [2022-02-17 12:04:48,076] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:04:48,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:04:48,567] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:04:48,576] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:04:48,581] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 12:05:01,330] {scheduler_job.py:155} INFO - Started process (PID=98161) to work on /airflow/dags/download_data.py
[2022-02-17 12:05:01,336] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:05:01,338] {logging_mixin.py:112} INFO - [2022-02-17 12:05:01,337] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:05:01,797] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:05:01,842] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:05:01,853] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:05:01,858] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 12:05:14,642] {scheduler_job.py:155} INFO - Started process (PID=98189) to work on /airflow/dags/download_data.py
[2022-02-17 12:05:14,647] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:05:14,648] {logging_mixin.py:112} INFO - [2022-02-17 12:05:14,648] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:05:15,082] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:05:15,133] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:05:15,139] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:05:15,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 12:05:27,928] {scheduler_job.py:155} INFO - Started process (PID=98215) to work on /airflow/dags/download_data.py
[2022-02-17 12:05:27,937] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:05:27,939] {logging_mixin.py:112} INFO - [2022-02-17 12:05:27,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:05:28,379] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:05:28,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:05:28,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:05:28,432] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 12:05:41,234] {scheduler_job.py:155} INFO - Started process (PID=98241) to work on /airflow/dags/download_data.py
[2022-02-17 12:05:41,242] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:05:41,244] {logging_mixin.py:112} INFO - [2022-02-17 12:05:41,243] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:05:41,686] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:05:41,732] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:05:41,738] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:05:41,743] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 12:05:54,511] {scheduler_job.py:155} INFO - Started process (PID=98269) to work on /airflow/dags/download_data.py
[2022-02-17 12:05:54,519] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:05:54,522] {logging_mixin.py:112} INFO - [2022-02-17 12:05:54,521] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:05:54,971] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:05:55,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:05:55,043] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:05:55,055] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 12:06:07,783] {scheduler_job.py:155} INFO - Started process (PID=98295) to work on /airflow/dags/download_data.py
[2022-02-17 12:06:07,798] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:06:07,800] {logging_mixin.py:112} INFO - [2022-02-17 12:06:07,800] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:06:08,267] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:06:08,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:06:08,324] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:06:08,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 12:06:21,065] {scheduler_job.py:155} INFO - Started process (PID=98323) to work on /airflow/dags/download_data.py
[2022-02-17 12:06:21,070] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:06:21,072] {logging_mixin.py:112} INFO - [2022-02-17 12:06:21,071] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:06:21,555] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:06:21,611] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:06:21,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:06:21,625] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 12:06:34,324] {scheduler_job.py:155} INFO - Started process (PID=98349) to work on /airflow/dags/download_data.py
[2022-02-17 12:06:34,328] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:06:34,330] {logging_mixin.py:112} INFO - [2022-02-17 12:06:34,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:06:34,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:06:34,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:06:34,825] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:06:34,832] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 12:06:47,630] {scheduler_job.py:155} INFO - Started process (PID=98377) to work on /airflow/dags/download_data.py
[2022-02-17 12:06:47,635] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:06:47,637] {logging_mixin.py:112} INFO - [2022-02-17 12:06:47,637] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:06:48,076] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:06:48,130] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:06:48,140] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:06:48,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 12:07:00,888] {scheduler_job.py:155} INFO - Started process (PID=98403) to work on /airflow/dags/download_data.py
[2022-02-17 12:07:00,898] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:07:00,900] {logging_mixin.py:112} INFO - [2022-02-17 12:07:00,900] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:07:01,348] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:07:01,392] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:07:01,398] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:07:01,402] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 12:07:14,188] {scheduler_job.py:155} INFO - Started process (PID=98429) to work on /airflow/dags/download_data.py
[2022-02-17 12:07:14,193] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:07:14,195] {logging_mixin.py:112} INFO - [2022-02-17 12:07:14,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:07:14,672] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:07:14,713] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:07:14,719] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:07:14,724] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 12:07:27,442] {scheduler_job.py:155} INFO - Started process (PID=98457) to work on /airflow/dags/download_data.py
[2022-02-17 12:07:27,450] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:07:27,452] {logging_mixin.py:112} INFO - [2022-02-17 12:07:27,452] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:07:27,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:07:27,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:07:27,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:07:27,953] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 12:07:40,744] {scheduler_job.py:155} INFO - Started process (PID=98483) to work on /airflow/dags/download_data.py
[2022-02-17 12:07:40,756] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:07:40,758] {logging_mixin.py:112} INFO - [2022-02-17 12:07:40,758] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:07:41,201] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:07:41,253] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:07:41,262] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:07:41,268] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 12:07:53,988] {scheduler_job.py:155} INFO - Started process (PID=98511) to work on /airflow/dags/download_data.py
[2022-02-17 12:07:53,992] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:07:53,994] {logging_mixin.py:112} INFO - [2022-02-17 12:07:53,994] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:07:54,449] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:07:54,508] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:07:54,517] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:07:54,523] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 12:08:07,273] {scheduler_job.py:155} INFO - Started process (PID=98537) to work on /airflow/dags/download_data.py
[2022-02-17 12:08:07,279] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:08:07,281] {logging_mixin.py:112} INFO - [2022-02-17 12:08:07,281] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:08:07,710] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:08:07,766] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:08:07,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:08:07,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 12:08:20,558] {scheduler_job.py:155} INFO - Started process (PID=98565) to work on /airflow/dags/download_data.py
[2022-02-17 12:08:20,563] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:08:20,564] {logging_mixin.py:112} INFO - [2022-02-17 12:08:20,564] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:08:21,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:08:21,093] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:08:21,106] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:08:21,113] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 12:08:33,813] {scheduler_job.py:155} INFO - Started process (PID=98591) to work on /airflow/dags/download_data.py
[2022-02-17 12:08:33,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:08:33,821] {logging_mixin.py:112} INFO - [2022-02-17 12:08:33,820] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:08:34,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:08:34,308] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:08:34,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:08:34,323] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 12:08:47,118] {scheduler_job.py:155} INFO - Started process (PID=98619) to work on /airflow/dags/download_data.py
[2022-02-17 12:08:47,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:08:47,132] {logging_mixin.py:112} INFO - [2022-02-17 12:08:47,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:08:47,600] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:08:47,649] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:08:47,656] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:08:47,662] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 12:09:00,395] {scheduler_job.py:155} INFO - Started process (PID=98645) to work on /airflow/dags/download_data.py
[2022-02-17 12:09:00,402] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:09:00,405] {logging_mixin.py:112} INFO - [2022-02-17 12:09:00,404] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:09:00,854] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:09:00,900] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:09:00,908] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:09:00,913] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 12:09:13,676] {scheduler_job.py:155} INFO - Started process (PID=98671) to work on /airflow/dags/download_data.py
[2022-02-17 12:09:13,680] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:09:13,682] {logging_mixin.py:112} INFO - [2022-02-17 12:09:13,682] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:09:14,114] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:09:14,162] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:09:14,168] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:09:14,174] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 12:09:26,922] {scheduler_job.py:155} INFO - Started process (PID=98699) to work on /airflow/dags/download_data.py
[2022-02-17 12:09:26,926] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:09:26,927] {logging_mixin.py:112} INFO - [2022-02-17 12:09:26,927] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:09:27,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:09:27,406] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:09:27,412] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:09:27,416] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 12:09:40,225] {scheduler_job.py:155} INFO - Started process (PID=98725) to work on /airflow/dags/download_data.py
[2022-02-17 12:09:40,230] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:09:40,231] {logging_mixin.py:112} INFO - [2022-02-17 12:09:40,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:09:40,668] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:09:40,724] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:09:40,731] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:09:40,738] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 12:09:53,507] {scheduler_job.py:155} INFO - Started process (PID=98753) to work on /airflow/dags/download_data.py
[2022-02-17 12:09:53,515] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:09:53,517] {logging_mixin.py:112} INFO - [2022-02-17 12:09:53,517] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:09:53,963] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:09:54,019] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:09:54,033] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:09:54,042] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 12:10:06,839] {scheduler_job.py:155} INFO - Started process (PID=98779) to work on /airflow/dags/download_data.py
[2022-02-17 12:10:06,847] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:10:06,850] {logging_mixin.py:112} INFO - [2022-02-17 12:10:06,849] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:10:07,329] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:10:07,383] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:10:07,392] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:10:07,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 12:10:20,124] {scheduler_job.py:155} INFO - Started process (PID=98807) to work on /airflow/dags/download_data.py
[2022-02-17 12:10:20,130] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:10:20,133] {logging_mixin.py:112} INFO - [2022-02-17 12:10:20,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:10:20,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:10:20,702] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:10:20,718] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:10:20,727] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 12:10:33,391] {scheduler_job.py:155} INFO - Started process (PID=98833) to work on /airflow/dags/download_data.py
[2022-02-17 12:10:33,396] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:10:33,398] {logging_mixin.py:112} INFO - [2022-02-17 12:10:33,398] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:10:33,835] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:10:33,888] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:10:33,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:10:33,900] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 12:10:46,716] {scheduler_job.py:155} INFO - Started process (PID=98859) to work on /airflow/dags/download_data.py
[2022-02-17 12:10:46,724] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:10:46,726] {logging_mixin.py:112} INFO - [2022-02-17 12:10:46,726] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:10:47,154] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:10:47,197] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:10:47,207] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:10:47,213] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 12:10:59,983] {scheduler_job.py:155} INFO - Started process (PID=98887) to work on /airflow/dags/download_data.py
[2022-02-17 12:10:59,987] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:10:59,989] {logging_mixin.py:112} INFO - [2022-02-17 12:10:59,989] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:11:00,453] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:11:00,513] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:11:00,527] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:11:00,533] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 12:11:13,299] {scheduler_job.py:155} INFO - Started process (PID=98913) to work on /airflow/dags/download_data.py
[2022-02-17 12:11:13,312] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:11:13,315] {logging_mixin.py:112} INFO - [2022-02-17 12:11:13,315] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:11:13,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:11:13,797] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:11:13,805] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:11:13,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 12:11:26,550] {scheduler_job.py:155} INFO - Started process (PID=98941) to work on /airflow/dags/download_data.py
[2022-02-17 12:11:26,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:11:26,556] {logging_mixin.py:112} INFO - [2022-02-17 12:11:26,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:11:27,053] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:11:27,107] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:11:27,116] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:11:27,121] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 12:11:39,814] {scheduler_job.py:155} INFO - Started process (PID=98967) to work on /airflow/dags/download_data.py
[2022-02-17 12:11:39,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:11:39,821] {logging_mixin.py:112} INFO - [2022-02-17 12:11:39,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:11:40,247] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:11:40,300] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:11:40,310] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:11:40,316] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 12:11:53,070] {scheduler_job.py:155} INFO - Started process (PID=98995) to work on /airflow/dags/download_data.py
[2022-02-17 12:11:53,083] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:11:53,086] {logging_mixin.py:112} INFO - [2022-02-17 12:11:53,086] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:11:53,609] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:11:53,661] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:11:53,670] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:11:53,674] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-17 12:12:06,373] {scheduler_job.py:155} INFO - Started process (PID=99021) to work on /airflow/dags/download_data.py
[2022-02-17 12:12:06,377] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:12:06,379] {logging_mixin.py:112} INFO - [2022-02-17 12:12:06,379] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:12:06,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:12:06,870] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:12:06,879] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:12:06,886] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 12:12:19,673] {scheduler_job.py:155} INFO - Started process (PID=99047) to work on /airflow/dags/download_data.py
[2022-02-17 12:12:19,677] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:12:19,679] {logging_mixin.py:112} INFO - [2022-02-17 12:12:19,678] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:12:20,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:12:20,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:12:20,163] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:12:20,168] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 12:12:32,948] {scheduler_job.py:155} INFO - Started process (PID=99075) to work on /airflow/dags/download_data.py
[2022-02-17 12:12:32,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:12:32,956] {logging_mixin.py:112} INFO - [2022-02-17 12:12:32,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:12:33,404] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:12:33,455] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:12:33,462] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:12:33,466] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 12:12:46,190] {scheduler_job.py:155} INFO - Started process (PID=99101) to work on /airflow/dags/download_data.py
[2022-02-17 12:12:46,196] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:12:46,197] {logging_mixin.py:112} INFO - [2022-02-17 12:12:46,197] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:12:46,625] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:12:46,664] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:12:46,671] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:12:46,676] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-17 12:12:59,474] {scheduler_job.py:155} INFO - Started process (PID=99129) to work on /airflow/dags/download_data.py
[2022-02-17 12:12:59,479] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:12:59,481] {logging_mixin.py:112} INFO - [2022-02-17 12:12:59,481] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:12:59,942] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:12:59,997] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:13:00,008] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:13:00,012] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 12:13:12,797] {scheduler_job.py:155} INFO - Started process (PID=99155) to work on /airflow/dags/download_data.py
[2022-02-17 12:13:12,807] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:13:12,809] {logging_mixin.py:112} INFO - [2022-02-17 12:13:12,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:13:13,249] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:13:13,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:13:13,312] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:13:13,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 12:13:26,014] {scheduler_job.py:155} INFO - Started process (PID=99183) to work on /airflow/dags/download_data.py
[2022-02-17 12:13:26,018] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:13:26,020] {logging_mixin.py:112} INFO - [2022-02-17 12:13:26,020] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:13:26,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:13:26,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:13:26,516] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:13:26,522] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 12:13:39,318] {scheduler_job.py:155} INFO - Started process (PID=99209) to work on /airflow/dags/download_data.py
[2022-02-17 12:13:39,322] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:13:39,323] {logging_mixin.py:112} INFO - [2022-02-17 12:13:39,323] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:13:39,774] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:13:39,822] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:13:39,831] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:13:39,836] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 12:13:52,625] {scheduler_job.py:155} INFO - Started process (PID=99236) to work on /airflow/dags/download_data.py
[2022-02-17 12:13:52,640] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:13:52,646] {logging_mixin.py:112} INFO - [2022-02-17 12:13:52,644] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:13:53,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:13:53,416] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:13:53,427] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:13:53,433] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.809 seconds
[2022-02-17 12:14:05,862] {scheduler_job.py:155} INFO - Started process (PID=99263) to work on /airflow/dags/download_data.py
[2022-02-17 12:14:05,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:14:05,871] {logging_mixin.py:112} INFO - [2022-02-17 12:14:05,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:14:06,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:14:06,357] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:14:06,367] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:14:06,373] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 12:14:19,166] {scheduler_job.py:155} INFO - Started process (PID=99289) to work on /airflow/dags/download_data.py
[2022-02-17 12:14:19,170] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:14:19,172] {logging_mixin.py:112} INFO - [2022-02-17 12:14:19,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:14:19,614] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:14:19,653] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:14:19,661] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:14:19,670] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 12:14:32,426] {scheduler_job.py:155} INFO - Started process (PID=99317) to work on /airflow/dags/download_data.py
[2022-02-17 12:14:32,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:14:32,439] {logging_mixin.py:112} INFO - [2022-02-17 12:14:32,438] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:14:32,880] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:14:32,920] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:14:32,928] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:14:32,933] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 12:14:45,694] {scheduler_job.py:155} INFO - Started process (PID=99343) to work on /airflow/dags/download_data.py
[2022-02-17 12:14:45,699] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:14:45,701] {logging_mixin.py:112} INFO - [2022-02-17 12:14:45,700] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:14:46,136] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:14:46,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:14:46,184] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:14:46,188] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 12:14:59,021] {scheduler_job.py:155} INFO - Started process (PID=99371) to work on /airflow/dags/download_data.py
[2022-02-17 12:14:59,025] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:14:59,027] {logging_mixin.py:112} INFO - [2022-02-17 12:14:59,026] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:14:59,487] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:14:59,529] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:14:59,536] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:14:59,544] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 12:15:12,319] {scheduler_job.py:155} INFO - Started process (PID=99397) to work on /airflow/dags/download_data.py
[2022-02-17 12:15:12,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:15:12,328] {logging_mixin.py:112} INFO - [2022-02-17 12:15:12,327] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:15:12,775] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:15:12,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:15:12,836] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:15:12,841] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 12:15:25,566] {scheduler_job.py:155} INFO - Started process (PID=99425) to work on /airflow/dags/download_data.py
[2022-02-17 12:15:25,580] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:15:25,583] {logging_mixin.py:112} INFO - [2022-02-17 12:15:25,582] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:15:26,046] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:15:26,096] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:15:26,106] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:15:26,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 12:15:38,910] {scheduler_job.py:155} INFO - Started process (PID=99451) to work on /airflow/dags/download_data.py
[2022-02-17 12:15:38,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:15:38,919] {logging_mixin.py:112} INFO - [2022-02-17 12:15:38,919] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:15:39,352] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:15:39,396] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:15:39,402] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:15:39,405] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 12:15:52,177] {scheduler_job.py:155} INFO - Started process (PID=99477) to work on /airflow/dags/download_data.py
[2022-02-17 12:15:52,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:15:52,197] {logging_mixin.py:112} INFO - [2022-02-17 12:15:52,197] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:15:52,658] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:15:52,699] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:15:52,706] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:15:52,711] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 12:16:05,479] {scheduler_job.py:155} INFO - Started process (PID=99505) to work on /airflow/dags/download_data.py
[2022-02-17 12:16:05,483] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:16:05,485] {logging_mixin.py:112} INFO - [2022-02-17 12:16:05,485] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:16:05,930] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:16:05,979] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:16:05,986] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:16:05,991] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 12:16:18,789] {scheduler_job.py:155} INFO - Started process (PID=99531) to work on /airflow/dags/download_data.py
[2022-02-17 12:16:18,793] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:16:18,795] {logging_mixin.py:112} INFO - [2022-02-17 12:16:18,795] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:16:19,228] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:16:19,278] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:16:19,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:16:19,294] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 12:16:32,069] {scheduler_job.py:155} INFO - Started process (PID=99559) to work on /airflow/dags/download_data.py
[2022-02-17 12:16:32,074] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:16:32,076] {logging_mixin.py:112} INFO - [2022-02-17 12:16:32,076] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:16:32,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:16:32,582] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:16:32,589] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:16:32,594] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 12:16:45,385] {scheduler_job.py:155} INFO - Started process (PID=99585) to work on /airflow/dags/download_data.py
[2022-02-17 12:16:45,390] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:16:45,392] {logging_mixin.py:112} INFO - [2022-02-17 12:16:45,392] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:16:45,824] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:16:45,865] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:16:45,871] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:16:45,876] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 12:16:58,614] {scheduler_job.py:155} INFO - Started process (PID=99613) to work on /airflow/dags/download_data.py
[2022-02-17 12:16:58,618] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:16:58,620] {logging_mixin.py:112} INFO - [2022-02-17 12:16:58,620] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:16:59,069] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:16:59,120] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:16:59,133] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:16:59,139] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 12:17:11,970] {scheduler_job.py:155} INFO - Started process (PID=99639) to work on /airflow/dags/download_data.py
[2022-02-17 12:17:11,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:17:11,977] {logging_mixin.py:112} INFO - [2022-02-17 12:17:11,977] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:17:12,475] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:17:12,523] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:17:12,530] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:17:12,536] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 12:17:25,210] {scheduler_job.py:155} INFO - Started process (PID=99665) to work on /airflow/dags/download_data.py
[2022-02-17 12:17:25,217] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:17:25,219] {logging_mixin.py:112} INFO - [2022-02-17 12:17:25,219] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:17:25,638] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:17:25,678] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:17:25,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:17:25,688] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.478 seconds
[2022-02-17 12:17:38,478] {scheduler_job.py:155} INFO - Started process (PID=99693) to work on /airflow/dags/download_data.py
[2022-02-17 12:17:38,486] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:17:38,489] {logging_mixin.py:112} INFO - [2022-02-17 12:17:38,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:17:38,919] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:17:38,967] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:17:38,976] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:17:38,981] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 12:17:51,751] {scheduler_job.py:155} INFO - Started process (PID=99719) to work on /airflow/dags/download_data.py
[2022-02-17 12:17:51,759] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:17:51,761] {logging_mixin.py:112} INFO - [2022-02-17 12:17:51,761] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:17:52,243] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:17:52,304] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:17:52,311] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:17:52,317] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 12:18:05,086] {scheduler_job.py:155} INFO - Started process (PID=99747) to work on /airflow/dags/download_data.py
[2022-02-17 12:18:05,090] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:18:05,092] {logging_mixin.py:112} INFO - [2022-02-17 12:18:05,092] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:18:05,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:18:05,576] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:18:05,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:18:05,591] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 12:18:18,389] {scheduler_job.py:155} INFO - Started process (PID=99773) to work on /airflow/dags/download_data.py
[2022-02-17 12:18:18,393] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:18:18,394] {logging_mixin.py:112} INFO - [2022-02-17 12:18:18,394] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:18:18,858] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:18:18,908] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:18:18,918] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:18:18,922] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 12:18:31,673] {scheduler_job.py:155} INFO - Started process (PID=99801) to work on /airflow/dags/download_data.py
[2022-02-17 12:18:31,689] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:18:31,691] {logging_mixin.py:112} INFO - [2022-02-17 12:18:31,691] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:18:32,145] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:18:32,195] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:18:32,202] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:18:32,206] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 12:18:44,934] {scheduler_job.py:155} INFO - Started process (PID=99827) to work on /airflow/dags/download_data.py
[2022-02-17 12:18:44,938] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:18:44,940] {logging_mixin.py:112} INFO - [2022-02-17 12:18:44,940] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:18:45,361] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:18:45,400] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:18:45,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:18:45,409] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.475 seconds
[2022-02-17 12:18:58,179] {scheduler_job.py:155} INFO - Started process (PID=99853) to work on /airflow/dags/download_data.py
[2022-02-17 12:18:58,184] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:18:58,187] {logging_mixin.py:112} INFO - [2022-02-17 12:18:58,186] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:18:58,660] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:18:58,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:18:58,728] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:18:58,733] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 12:19:11,451] {scheduler_job.py:155} INFO - Started process (PID=99881) to work on /airflow/dags/download_data.py
[2022-02-17 12:19:11,455] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:19:11,456] {logging_mixin.py:112} INFO - [2022-02-17 12:19:11,456] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:19:11,894] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:19:11,946] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:19:11,956] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:19:11,960] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 12:19:24,706] {scheduler_job.py:155} INFO - Started process (PID=99907) to work on /airflow/dags/download_data.py
[2022-02-17 12:19:24,710] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:19:24,712] {logging_mixin.py:112} INFO - [2022-02-17 12:19:24,712] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:19:25,143] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:19:25,192] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:19:25,199] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:19:25,204] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 12:19:37,959] {scheduler_job.py:155} INFO - Started process (PID=99935) to work on /airflow/dags/download_data.py
[2022-02-17 12:19:37,975] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:19:37,999] {logging_mixin.py:112} INFO - [2022-02-17 12:19:37,999] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:19:38,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:19:38,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:19:38,509] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:19:38,513] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 12:19:51,265] {scheduler_job.py:155} INFO - Started process (PID=99961) to work on /airflow/dags/download_data.py
[2022-02-17 12:19:51,275] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:19:51,277] {logging_mixin.py:112} INFO - [2022-02-17 12:19:51,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:19:51,751] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:19:51,798] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:19:51,809] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:19:51,815] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 12:20:06,073] {scheduler_job.py:155} INFO - Started process (PID=99989) to work on /airflow/dags/download_data.py
[2022-02-17 12:20:06,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 12:20:06,084] {logging_mixin.py:112} INFO - [2022-02-17 12:20:06,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 12:20:06,560] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 12:20:06,607] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 12:20:06,617] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 12:20:06,621] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 13:20:18,908] {scheduler_job.py:155} INFO - Started process (PID=317) to work on /airflow/dags/download_data.py
[2022-02-17 13:20:18,921] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:20:18,925] {logging_mixin.py:112} INFO - [2022-02-17 13:20:18,924] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:20:21,313] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:20:21,426] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:20:21,438] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:20:21,449] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.542 seconds
[2022-02-17 13:20:33,243] {scheduler_job.py:155} INFO - Started process (PID=352) to work on /airflow/dags/download_data.py
[2022-02-17 13:20:33,252] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:20:33,254] {logging_mixin.py:112} INFO - [2022-02-17 13:20:33,253] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:20:33,758] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:20:33,835] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:20:33,843] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:20:33,848] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 13:20:46,532] {scheduler_job.py:155} INFO - Started process (PID=378) to work on /airflow/dags/download_data.py
[2022-02-17 13:20:46,538] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:20:46,540] {logging_mixin.py:112} INFO - [2022-02-17 13:20:46,540] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:20:47,093] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:20:47,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:20:47,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:20:47,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-17 13:20:59,796] {scheduler_job.py:155} INFO - Started process (PID=406) to work on /airflow/dags/download_data.py
[2022-02-17 13:20:59,800] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:20:59,802] {logging_mixin.py:112} INFO - [2022-02-17 13:20:59,802] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:21:00,259] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:21:00,310] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:21:00,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:21:00,319] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 13:21:13,105] {scheduler_job.py:155} INFO - Started process (PID=432) to work on /airflow/dags/download_data.py
[2022-02-17 13:21:13,111] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:21:13,113] {logging_mixin.py:112} INFO - [2022-02-17 13:21:13,113] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:21:13,543] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:21:13,591] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:21:13,597] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:21:13,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 13:21:26,423] {scheduler_job.py:155} INFO - Started process (PID=460) to work on /airflow/dags/download_data.py
[2022-02-17 13:21:26,428] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:21:26,433] {logging_mixin.py:112} INFO - [2022-02-17 13:21:26,433] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:21:26,863] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:21:26,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:21:26,903] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:21:26,909] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.486 seconds
[2022-02-17 13:21:39,685] {scheduler_job.py:155} INFO - Started process (PID=486) to work on /airflow/dags/download_data.py
[2022-02-17 13:21:39,689] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:21:39,691] {logging_mixin.py:112} INFO - [2022-02-17 13:21:39,691] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:21:40,134] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:21:40,185] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:21:40,194] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:21:40,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 13:21:53,057] {scheduler_job.py:155} INFO - Started process (PID=514) to work on /airflow/dags/download_data.py
[2022-02-17 13:21:53,062] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:21:53,063] {logging_mixin.py:112} INFO - [2022-02-17 13:21:53,063] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:21:53,497] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:21:53,541] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:21:53,549] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:21:53,553] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 13:22:06,348] {scheduler_job.py:155} INFO - Started process (PID=540) to work on /airflow/dags/download_data.py
[2022-02-17 13:22:06,353] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:22:06,356] {logging_mixin.py:112} INFO - [2022-02-17 13:22:06,356] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:22:06,776] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:22:06,817] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:22:06,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:22:06,832] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-17 13:22:19,613] {scheduler_job.py:155} INFO - Started process (PID=566) to work on /airflow/dags/download_data.py
[2022-02-17 13:22:19,617] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:22:19,619] {logging_mixin.py:112} INFO - [2022-02-17 13:22:19,619] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:22:20,092] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:22:20,154] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:22:20,168] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:22:20,173] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 13:22:32,947] {scheduler_job.py:155} INFO - Started process (PID=594) to work on /airflow/dags/download_data.py
[2022-02-17 13:22:32,951] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:22:32,952] {logging_mixin.py:112} INFO - [2022-02-17 13:22:32,952] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:22:33,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:22:33,437] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:22:33,443] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:22:33,447] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 13:22:46,234] {scheduler_job.py:155} INFO - Started process (PID=620) to work on /airflow/dags/download_data.py
[2022-02-17 13:22:46,238] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:22:46,240] {logging_mixin.py:112} INFO - [2022-02-17 13:22:46,240] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:22:46,684] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:22:46,734] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:22:46,746] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:22:46,753] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 13:22:59,504] {scheduler_job.py:155} INFO - Started process (PID=648) to work on /airflow/dags/download_data.py
[2022-02-17 13:22:59,508] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:22:59,510] {logging_mixin.py:112} INFO - [2022-02-17 13:22:59,510] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:22:59,935] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:22:59,975] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:22:59,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:22:59,989] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-17 13:23:12,824] {scheduler_job.py:155} INFO - Started process (PID=674) to work on /airflow/dags/download_data.py
[2022-02-17 13:23:12,828] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:23:12,829] {logging_mixin.py:112} INFO - [2022-02-17 13:23:12,829] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:23:13,283] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:23:13,336] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:23:13,345] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:23:13,351] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 13:23:26,082] {scheduler_job.py:155} INFO - Started process (PID=702) to work on /airflow/dags/download_data.py
[2022-02-17 13:23:26,087] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:23:26,089] {logging_mixin.py:112} INFO - [2022-02-17 13:23:26,089] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:23:26,546] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:23:26,594] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:23:26,602] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:23:26,607] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 13:23:39,395] {scheduler_job.py:155} INFO - Started process (PID=728) to work on /airflow/dags/download_data.py
[2022-02-17 13:23:39,400] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:23:39,401] {logging_mixin.py:112} INFO - [2022-02-17 13:23:39,401] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:23:39,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:23:39,903] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:23:39,909] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:23:39,913] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 13:23:52,681] {scheduler_job.py:155} INFO - Started process (PID=754) to work on /airflow/dags/download_data.py
[2022-02-17 13:23:52,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:23:52,692] {logging_mixin.py:112} INFO - [2022-02-17 13:23:52,692] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:23:53,385] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:23:53,431] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:23:53,438] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:23:53,441] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.761 seconds
[2022-02-17 13:24:05,970] {scheduler_job.py:155} INFO - Started process (PID=782) to work on /airflow/dags/download_data.py
[2022-02-17 13:24:05,975] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:24:05,976] {logging_mixin.py:112} INFO - [2022-02-17 13:24:05,976] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:24:06,412] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:24:06,459] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:24:06,465] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:24:06,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 13:24:19,228] {scheduler_job.py:155} INFO - Started process (PID=808) to work on /airflow/dags/download_data.py
[2022-02-17 13:24:19,233] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:24:19,234] {logging_mixin.py:112} INFO - [2022-02-17 13:24:19,234] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:24:19,700] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:24:19,755] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:24:19,767] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:24:19,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 13:24:32,539] {scheduler_job.py:155} INFO - Started process (PID=836) to work on /airflow/dags/download_data.py
[2022-02-17 13:24:32,546] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:24:32,547] {logging_mixin.py:112} INFO - [2022-02-17 13:24:32,547] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:24:32,987] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:24:33,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:24:33,048] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:24:33,052] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 13:24:45,841] {scheduler_job.py:155} INFO - Started process (PID=862) to work on /airflow/dags/download_data.py
[2022-02-17 13:24:45,846] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:24:45,847] {logging_mixin.py:112} INFO - [2022-02-17 13:24:45,847] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:24:46,285] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:24:46,338] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:24:46,346] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:24:46,351] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 13:24:59,111] {scheduler_job.py:155} INFO - Started process (PID=890) to work on /airflow/dags/download_data.py
[2022-02-17 13:24:59,116] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:24:59,117] {logging_mixin.py:112} INFO - [2022-02-17 13:24:59,117] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:24:59,701] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:24:59,754] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:24:59,764] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:24:59,769] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.658 seconds
[2022-02-17 13:25:12,411] {scheduler_job.py:155} INFO - Started process (PID=916) to work on /airflow/dags/download_data.py
[2022-02-17 13:25:12,417] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:25:12,420] {logging_mixin.py:112} INFO - [2022-02-17 13:25:12,419] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:25:12,847] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:25:12,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:25:12,906] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:25:12,911] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 13:25:25,710] {scheduler_job.py:155} INFO - Started process (PID=944) to work on /airflow/dags/download_data.py
[2022-02-17 13:25:25,714] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:25:25,715] {logging_mixin.py:112} INFO - [2022-02-17 13:25:25,715] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:25:26,146] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:25:26,204] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:25:26,214] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:25:26,219] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 13:25:39,012] {scheduler_job.py:155} INFO - Started process (PID=970) to work on /airflow/dags/download_data.py
[2022-02-17 13:25:39,019] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:25:39,021] {logging_mixin.py:112} INFO - [2022-02-17 13:25:39,021] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:25:39,443] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:25:39,494] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:25:39,503] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:25:39,508] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 13:25:52,302] {scheduler_job.py:155} INFO - Started process (PID=996) to work on /airflow/dags/download_data.py
[2022-02-17 13:25:52,311] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:25:52,313] {logging_mixin.py:112} INFO - [2022-02-17 13:25:52,313] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:25:52,807] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:25:52,869] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:25:52,879] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:25:52,885] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 13:26:05,568] {scheduler_job.py:155} INFO - Started process (PID=1024) to work on /airflow/dags/download_data.py
[2022-02-17 13:26:05,583] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:26:05,584] {logging_mixin.py:112} INFO - [2022-02-17 13:26:05,584] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:26:06,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:26:06,063] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:26:06,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:26:06,080] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 13:26:18,882] {scheduler_job.py:155} INFO - Started process (PID=1050) to work on /airflow/dags/download_data.py
[2022-02-17 13:26:18,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:26:18,889] {logging_mixin.py:112} INFO - [2022-02-17 13:26:18,889] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:26:19,350] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:26:19,398] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:26:19,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:26:19,409] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 13:26:32,173] {scheduler_job.py:155} INFO - Started process (PID=1078) to work on /airflow/dags/download_data.py
[2022-02-17 13:26:32,177] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:26:32,179] {logging_mixin.py:112} INFO - [2022-02-17 13:26:32,179] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:26:32,634] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:26:32,688] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:26:32,698] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:26:32,704] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 13:26:45,495] {scheduler_job.py:155} INFO - Started process (PID=1104) to work on /airflow/dags/download_data.py
[2022-02-17 13:26:45,502] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:26:45,504] {logging_mixin.py:112} INFO - [2022-02-17 13:26:45,503] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:26:45,932] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:26:45,980] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:26:45,991] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:26:45,998] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 13:26:58,801] {scheduler_job.py:155} INFO - Started process (PID=1132) to work on /airflow/dags/download_data.py
[2022-02-17 13:26:58,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:26:58,811] {logging_mixin.py:112} INFO - [2022-02-17 13:26:58,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:26:59,243] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:26:59,292] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:26:59,302] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:26:59,307] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 13:27:12,043] {scheduler_job.py:155} INFO - Started process (PID=1158) to work on /airflow/dags/download_data.py
[2022-02-17 13:27:12,050] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:27:12,053] {logging_mixin.py:112} INFO - [2022-02-17 13:27:12,053] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:27:12,573] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:27:12,619] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:27:12,628] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:27:12,634] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 13:27:25,311] {scheduler_job.py:155} INFO - Started process (PID=1184) to work on /airflow/dags/download_data.py
[2022-02-17 13:27:25,315] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:27:25,317] {logging_mixin.py:112} INFO - [2022-02-17 13:27:25,316] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:27:25,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:27:25,793] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:27:25,799] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:27:25,803] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 13:27:38,638] {scheduler_job.py:155} INFO - Started process (PID=1212) to work on /airflow/dags/download_data.py
[2022-02-17 13:27:38,644] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:27:38,646] {logging_mixin.py:112} INFO - [2022-02-17 13:27:38,646] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:27:39,082] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:27:39,120] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:27:39,127] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:27:39,131] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 13:27:51,877] {scheduler_job.py:155} INFO - Started process (PID=1238) to work on /airflow/dags/download_data.py
[2022-02-17 13:27:51,883] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:27:51,886] {logging_mixin.py:112} INFO - [2022-02-17 13:27:51,885] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:27:52,346] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:27:52,406] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:27:52,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:27:52,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 13:28:05,160] {scheduler_job.py:155} INFO - Started process (PID=1266) to work on /airflow/dags/download_data.py
[2022-02-17 13:28:05,164] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:28:05,166] {logging_mixin.py:112} INFO - [2022-02-17 13:28:05,166] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:28:05,618] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:28:05,668] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:28:05,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:28:05,678] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 13:28:18,398] {scheduler_job.py:155} INFO - Started process (PID=1292) to work on /airflow/dags/download_data.py
[2022-02-17 13:28:18,407] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:28:18,409] {logging_mixin.py:112} INFO - [2022-02-17 13:28:18,409] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:28:18,870] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:28:18,928] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:28:18,938] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:28:18,945] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 13:28:31,712] {scheduler_job.py:155} INFO - Started process (PID=1320) to work on /airflow/dags/download_data.py
[2022-02-17 13:28:31,725] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:28:31,730] {logging_mixin.py:112} INFO - [2022-02-17 13:28:31,729] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:28:32,193] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:28:32,231] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:28:32,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:28:32,253] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 13:28:45,011] {scheduler_job.py:155} INFO - Started process (PID=1346) to work on /airflow/dags/download_data.py
[2022-02-17 13:28:45,020] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:28:45,022] {logging_mixin.py:112} INFO - [2022-02-17 13:28:45,022] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:28:45,476] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:28:45,527] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:28:45,536] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:28:45,542] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 13:28:58,280] {scheduler_job.py:155} INFO - Started process (PID=1372) to work on /airflow/dags/download_data.py
[2022-02-17 13:28:58,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:28:58,301] {logging_mixin.py:112} INFO - [2022-02-17 13:28:58,300] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:28:58,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:28:58,847] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:28:58,856] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:28:58,866] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 13:29:11,599] {scheduler_job.py:155} INFO - Started process (PID=1400) to work on /airflow/dags/download_data.py
[2022-02-17 13:29:11,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:29:11,606] {logging_mixin.py:112} INFO - [2022-02-17 13:29:11,606] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:29:12,074] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:29:12,112] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:29:12,117] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:29:12,120] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 13:29:24,864] {scheduler_job.py:155} INFO - Started process (PID=1426) to work on /airflow/dags/download_data.py
[2022-02-17 13:29:24,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:29:24,871] {logging_mixin.py:112} INFO - [2022-02-17 13:29:24,871] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:29:25,312] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:29:25,358] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:29:25,367] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:29:25,373] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 13:29:38,136] {scheduler_job.py:155} INFO - Started process (PID=1453) to work on /airflow/dags/download_data.py
[2022-02-17 13:29:38,145] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:29:38,147] {logging_mixin.py:112} INFO - [2022-02-17 13:29:38,146] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:29:38,578] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:29:38,631] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:29:38,638] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:29:38,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 13:29:50,386] {scheduler_job.py:155} INFO - Started process (PID=1478) to work on /airflow/dags/download_data.py
[2022-02-17 13:29:50,399] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:29:50,401] {logging_mixin.py:112} INFO - [2022-02-17 13:29:50,401] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:29:50,856] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:29:50,916] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:29:50,928] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:29:50,933] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 13:30:03,710] {scheduler_job.py:155} INFO - Started process (PID=1506) to work on /airflow/dags/download_data.py
[2022-02-17 13:30:03,719] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:30:03,724] {logging_mixin.py:112} INFO - [2022-02-17 13:30:03,724] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:30:04,193] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:30:04,246] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:30:04,252] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:30:04,259] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 13:30:17,006] {scheduler_job.py:155} INFO - Started process (PID=1532) to work on /airflow/dags/download_data.py
[2022-02-17 13:30:17,012] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:30:17,013] {logging_mixin.py:112} INFO - [2022-02-17 13:30:17,013] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:30:17,453] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:30:17,486] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:30:17,495] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:30:17,500] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 13:30:30,295] {scheduler_job.py:155} INFO - Started process (PID=1558) to work on /airflow/dags/download_data.py
[2022-02-17 13:30:30,300] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:30:30,301] {logging_mixin.py:112} INFO - [2022-02-17 13:30:30,301] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:30:30,740] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:30:30,793] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:30:30,804] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:30:30,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 13:30:43,584] {scheduler_job.py:155} INFO - Started process (PID=1586) to work on /airflow/dags/download_data.py
[2022-02-17 13:30:43,588] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:30:43,589] {logging_mixin.py:112} INFO - [2022-02-17 13:30:43,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:30:44,038] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:30:44,084] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:30:44,093] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:30:44,099] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 13:30:56,847] {scheduler_job.py:155} INFO - Started process (PID=1612) to work on /airflow/dags/download_data.py
[2022-02-17 13:30:56,852] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:30:56,854] {logging_mixin.py:112} INFO - [2022-02-17 13:30:56,854] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:30:57,366] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:30:57,415] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:30:57,425] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:30:57,429] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 13:31:10,125] {scheduler_job.py:155} INFO - Started process (PID=1640) to work on /airflow/dags/download_data.py
[2022-02-17 13:31:10,129] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:31:10,131] {logging_mixin.py:112} INFO - [2022-02-17 13:31:10,130] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:31:10,580] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:31:10,631] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:31:10,642] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:31:10,649] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 13:31:23,378] {scheduler_job.py:155} INFO - Started process (PID=1666) to work on /airflow/dags/download_data.py
[2022-02-17 13:31:23,383] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:31:23,385] {logging_mixin.py:112} INFO - [2022-02-17 13:31:23,385] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:31:23,827] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:31:23,892] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:31:23,900] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:31:23,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 13:31:36,646] {scheduler_job.py:155} INFO - Started process (PID=1694) to work on /airflow/dags/download_data.py
[2022-02-17 13:31:36,650] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:31:36,652] {logging_mixin.py:112} INFO - [2022-02-17 13:31:36,652] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:31:37,089] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:31:37,143] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:31:37,152] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:31:37,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 13:31:49,901] {scheduler_job.py:155} INFO - Started process (PID=1720) to work on /airflow/dags/download_data.py
[2022-02-17 13:31:49,913] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:31:49,917] {logging_mixin.py:112} INFO - [2022-02-17 13:31:49,916] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:31:50,470] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:31:50,513] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:31:50,521] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:31:50,525] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-17 13:32:03,195] {scheduler_job.py:155} INFO - Started process (PID=1748) to work on /airflow/dags/download_data.py
[2022-02-17 13:32:03,200] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:32:03,208] {logging_mixin.py:112} INFO - [2022-02-17 13:32:03,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:32:03,677] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:32:03,725] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:32:03,730] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:32:03,734] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 13:32:16,509] {scheduler_job.py:155} INFO - Started process (PID=1774) to work on /airflow/dags/download_data.py
[2022-02-17 13:32:16,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:32:16,518] {logging_mixin.py:112} INFO - [2022-02-17 13:32:16,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:32:16,949] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:32:16,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:32:16,996] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:32:16,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 13:32:29,755] {scheduler_job.py:155} INFO - Started process (PID=1800) to work on /airflow/dags/download_data.py
[2022-02-17 13:32:29,761] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:32:29,763] {logging_mixin.py:112} INFO - [2022-02-17 13:32:29,763] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:32:30,192] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:32:30,249] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:32:30,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:32:30,269] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 13:32:43,080] {scheduler_job.py:155} INFO - Started process (PID=1828) to work on /airflow/dags/download_data.py
[2022-02-17 13:32:43,086] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:32:43,088] {logging_mixin.py:112} INFO - [2022-02-17 13:32:43,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:32:43,510] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:32:43,559] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:32:43,567] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:32:43,570] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 13:32:56,363] {scheduler_job.py:155} INFO - Started process (PID=1854) to work on /airflow/dags/download_data.py
[2022-02-17 13:32:56,368] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:32:56,370] {logging_mixin.py:112} INFO - [2022-02-17 13:32:56,369] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:32:56,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:32:56,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:32:56,889] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:32:56,894] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 13:33:09,653] {scheduler_job.py:155} INFO - Started process (PID=1882) to work on /airflow/dags/download_data.py
[2022-02-17 13:33:09,658] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:33:09,659] {logging_mixin.py:112} INFO - [2022-02-17 13:33:09,659] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:33:10,100] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:33:10,142] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:33:10,148] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:33:10,152] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 13:33:22,946] {scheduler_job.py:155} INFO - Started process (PID=1908) to work on /airflow/dags/download_data.py
[2022-02-17 13:33:22,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:33:22,955] {logging_mixin.py:112} INFO - [2022-02-17 13:33:22,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:33:23,391] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:33:23,435] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:33:23,441] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:33:23,446] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 13:33:36,247] {scheduler_job.py:155} INFO - Started process (PID=1936) to work on /airflow/dags/download_data.py
[2022-02-17 13:33:36,252] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:33:36,254] {logging_mixin.py:112} INFO - [2022-02-17 13:33:36,254] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:33:36,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:33:36,757] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:33:36,769] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:33:36,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 13:33:49,558] {scheduler_job.py:155} INFO - Started process (PID=1962) to work on /airflow/dags/download_data.py
[2022-02-17 13:33:49,567] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:33:49,569] {logging_mixin.py:112} INFO - [2022-02-17 13:33:49,569] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:33:50,024] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:33:50,064] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:33:50,070] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:33:50,074] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 13:34:02,850] {scheduler_job.py:155} INFO - Started process (PID=1988) to work on /airflow/dags/download_data.py
[2022-02-17 13:34:02,855] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:34:02,858] {logging_mixin.py:112} INFO - [2022-02-17 13:34:02,857] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:34:03,311] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:34:03,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:34:03,370] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:34:03,375] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 13:34:16,137] {scheduler_job.py:155} INFO - Started process (PID=2016) to work on /airflow/dags/download_data.py
[2022-02-17 13:34:16,143] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:34:16,145] {logging_mixin.py:112} INFO - [2022-02-17 13:34:16,145] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:34:16,582] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:34:16,633] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:34:16,638] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:34:16,642] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 13:34:29,450] {scheduler_job.py:155} INFO - Started process (PID=2042) to work on /airflow/dags/download_data.py
[2022-02-17 13:34:29,458] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:34:29,460] {logging_mixin.py:112} INFO - [2022-02-17 13:34:29,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:34:29,888] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:34:29,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:34:29,952] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:34:29,958] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 13:34:42,742] {scheduler_job.py:155} INFO - Started process (PID=2070) to work on /airflow/dags/download_data.py
[2022-02-17 13:34:42,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:34:42,748] {logging_mixin.py:112} INFO - [2022-02-17 13:34:42,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:34:43,203] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:34:43,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:34:43,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:34:43,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 13:34:55,989] {scheduler_job.py:155} INFO - Started process (PID=2096) to work on /airflow/dags/download_data.py
[2022-02-17 13:34:56,002] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:34:56,007] {logging_mixin.py:112} INFO - [2022-02-17 13:34:56,005] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:34:56,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:34:56,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:34:56,527] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:34:56,534] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 13:35:09,273] {scheduler_job.py:155} INFO - Started process (PID=2124) to work on /airflow/dags/download_data.py
[2022-02-17 13:35:09,277] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:35:09,279] {logging_mixin.py:112} INFO - [2022-02-17 13:35:09,279] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:35:09,735] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:35:09,783] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:35:09,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:35:09,798] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 13:35:22,563] {scheduler_job.py:155} INFO - Started process (PID=2150) to work on /airflow/dags/download_data.py
[2022-02-17 13:35:22,569] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:35:22,571] {logging_mixin.py:112} INFO - [2022-02-17 13:35:22,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:35:23,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:35:23,079] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:35:23,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:35:23,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 13:35:35,865] {scheduler_job.py:155} INFO - Started process (PID=2176) to work on /airflow/dags/download_data.py
[2022-02-17 13:35:35,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:35:35,870] {logging_mixin.py:112} INFO - [2022-02-17 13:35:35,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:35:36,295] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:35:36,343] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:35:36,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:35:36,355] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 13:35:49,152] {scheduler_job.py:155} INFO - Started process (PID=2204) to work on /airflow/dags/download_data.py
[2022-02-17 13:35:49,158] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:35:49,160] {logging_mixin.py:112} INFO - [2022-02-17 13:35:49,159] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:35:49,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:35:49,692] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:35:49,702] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:35:49,707] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 13:36:02,486] {scheduler_job.py:155} INFO - Started process (PID=2230) to work on /airflow/dags/download_data.py
[2022-02-17 13:36:02,494] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:36:02,496] {logging_mixin.py:112} INFO - [2022-02-17 13:36:02,496] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:36:02,919] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:36:02,958] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:36:02,964] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:36:02,968] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.482 seconds
[2022-02-17 13:36:15,771] {scheduler_job.py:155} INFO - Started process (PID=2258) to work on /airflow/dags/download_data.py
[2022-02-17 13:36:15,775] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:36:15,776] {logging_mixin.py:112} INFO - [2022-02-17 13:36:15,776] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:36:16,228] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:36:16,277] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:36:16,289] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:36:16,294] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 13:36:29,045] {scheduler_job.py:155} INFO - Started process (PID=2284) to work on /airflow/dags/download_data.py
[2022-02-17 13:36:29,053] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:36:29,056] {logging_mixin.py:112} INFO - [2022-02-17 13:36:29,055] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:36:29,480] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:36:29,531] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:36:29,539] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:36:29,545] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 13:36:42,311] {scheduler_job.py:155} INFO - Started process (PID=2312) to work on /airflow/dags/download_data.py
[2022-02-17 13:36:42,334] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:36:42,336] {logging_mixin.py:112} INFO - [2022-02-17 13:36:42,336] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:36:42,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:36:42,818] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:36:42,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:36:42,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 13:36:55,590] {scheduler_job.py:155} INFO - Started process (PID=2338) to work on /airflow/dags/download_data.py
[2022-02-17 13:36:55,599] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:36:55,601] {logging_mixin.py:112} INFO - [2022-02-17 13:36:55,601] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:36:56,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:36:56,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:36:56,107] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:36:56,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 13:37:08,930] {scheduler_job.py:155} INFO - Started process (PID=2366) to work on /airflow/dags/download_data.py
[2022-02-17 13:37:08,942] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:37:08,945] {logging_mixin.py:112} INFO - [2022-02-17 13:37:08,945] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:37:09,457] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:37:09,507] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:37:09,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:37:09,520] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 13:37:22,196] {scheduler_job.py:155} INFO - Started process (PID=2392) to work on /airflow/dags/download_data.py
[2022-02-17 13:37:22,201] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:37:22,202] {logging_mixin.py:112} INFO - [2022-02-17 13:37:22,202] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:37:22,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:37:22,690] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:37:22,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:37:22,702] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 13:37:35,501] {scheduler_job.py:155} INFO - Started process (PID=2418) to work on /airflow/dags/download_data.py
[2022-02-17 13:37:35,509] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:37:35,511] {logging_mixin.py:112} INFO - [2022-02-17 13:37:35,511] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:37:35,944] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:37:35,994] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:37:36,005] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:37:36,009] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 13:37:48,795] {scheduler_job.py:155} INFO - Started process (PID=2446) to work on /airflow/dags/download_data.py
[2022-02-17 13:37:48,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:37:48,807] {logging_mixin.py:112} INFO - [2022-02-17 13:37:48,807] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:37:49,254] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:37:49,307] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:37:49,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:37:49,320] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 13:38:02,076] {scheduler_job.py:155} INFO - Started process (PID=2472) to work on /airflow/dags/download_data.py
[2022-02-17 13:38:02,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:38:02,084] {logging_mixin.py:112} INFO - [2022-02-17 13:38:02,083] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:38:02,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:38:02,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:38:02,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:38:02,591] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 13:38:15,368] {scheduler_job.py:155} INFO - Started process (PID=2500) to work on /airflow/dags/download_data.py
[2022-02-17 13:38:15,379] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:38:15,381] {logging_mixin.py:112} INFO - [2022-02-17 13:38:15,381] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:38:15,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:38:15,880] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:38:15,887] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:38:15,892] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 13:38:28,658] {scheduler_job.py:155} INFO - Started process (PID=2526) to work on /airflow/dags/download_data.py
[2022-02-17 13:38:28,670] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:38:28,671] {logging_mixin.py:112} INFO - [2022-02-17 13:38:28,671] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:38:29,109] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:38:29,153] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:38:29,159] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:38:29,163] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 13:38:41,948] {scheduler_job.py:155} INFO - Started process (PID=2554) to work on /airflow/dags/download_data.py
[2022-02-17 13:38:41,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:38:41,956] {logging_mixin.py:112} INFO - [2022-02-17 13:38:41,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:38:42,371] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:38:42,417] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:38:42,426] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:38:42,432] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-17 13:38:55,213] {scheduler_job.py:155} INFO - Started process (PID=2580) to work on /airflow/dags/download_data.py
[2022-02-17 13:38:55,219] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:38:55,221] {logging_mixin.py:112} INFO - [2022-02-17 13:38:55,221] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:38:55,700] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:38:55,750] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:38:55,758] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:38:55,762] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 13:39:08,525] {scheduler_job.py:155} INFO - Started process (PID=2606) to work on /airflow/dags/download_data.py
[2022-02-17 13:39:08,530] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:39:08,532] {logging_mixin.py:112} INFO - [2022-02-17 13:39:08,531] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:39:08,967] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:39:09,022] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:39:09,028] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:39:09,031] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 13:39:21,803] {scheduler_job.py:155} INFO - Started process (PID=2634) to work on /airflow/dags/download_data.py
[2022-02-17 13:39:21,813] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:39:21,815] {logging_mixin.py:112} INFO - [2022-02-17 13:39:21,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:39:22,238] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:39:22,290] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:39:22,298] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:39:22,305] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 13:39:35,062] {scheduler_job.py:155} INFO - Started process (PID=2660) to work on /airflow/dags/download_data.py
[2022-02-17 13:39:35,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:39:35,069] {logging_mixin.py:112} INFO - [2022-02-17 13:39:35,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:39:35,536] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:39:35,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:39:35,584] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:39:35,589] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 13:39:48,331] {scheduler_job.py:155} INFO - Started process (PID=2688) to work on /airflow/dags/download_data.py
[2022-02-17 13:39:48,337] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:39:48,339] {logging_mixin.py:112} INFO - [2022-02-17 13:39:48,339] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:39:48,800] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:39:48,855] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:39:48,864] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:39:48,872] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 13:40:01,643] {scheduler_job.py:155} INFO - Started process (PID=2714) to work on /airflow/dags/download_data.py
[2022-02-17 13:40:01,648] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:40:01,649] {logging_mixin.py:112} INFO - [2022-02-17 13:40:01,649] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:40:02,116] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:40:02,178] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:40:02,191] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:40:02,197] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 13:40:14,918] {scheduler_job.py:155} INFO - Started process (PID=2742) to work on /airflow/dags/download_data.py
[2022-02-17 13:40:14,922] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:40:14,923] {logging_mixin.py:112} INFO - [2022-02-17 13:40:14,923] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:40:15,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:40:15,430] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:40:15,440] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:40:15,446] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 13:40:28,209] {scheduler_job.py:155} INFO - Started process (PID=2768) to work on /airflow/dags/download_data.py
[2022-02-17 13:40:28,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:40:28,216] {logging_mixin.py:112} INFO - [2022-02-17 13:40:28,215] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:40:28,647] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:40:28,688] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:40:28,694] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:40:28,698] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-17 13:40:41,572] {scheduler_job.py:155} INFO - Started process (PID=2794) to work on /airflow/dags/download_data.py
[2022-02-17 13:40:41,587] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:40:41,589] {logging_mixin.py:112} INFO - [2022-02-17 13:40:41,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:40:42,029] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:40:42,088] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:40:42,100] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:40:42,104] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 13:40:54,822] {scheduler_job.py:155} INFO - Started process (PID=2822) to work on /airflow/dags/download_data.py
[2022-02-17 13:40:54,828] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:40:54,830] {logging_mixin.py:112} INFO - [2022-02-17 13:40:54,829] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:40:55,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:40:55,364] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:40:55,377] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:40:55,383] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 13:41:08,124] {scheduler_job.py:155} INFO - Started process (PID=2848) to work on /airflow/dags/download_data.py
[2022-02-17 13:41:08,133] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:41:08,137] {logging_mixin.py:112} INFO - [2022-02-17 13:41:08,135] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:41:08,578] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:41:08,626] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:41:08,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:41:08,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 13:41:21,382] {scheduler_job.py:155} INFO - Started process (PID=2876) to work on /airflow/dags/download_data.py
[2022-02-17 13:41:21,391] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:41:21,393] {logging_mixin.py:112} INFO - [2022-02-17 13:41:21,393] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:41:21,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:41:21,875] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:41:21,884] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:41:21,888] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 13:41:34,629] {scheduler_job.py:155} INFO - Started process (PID=2902) to work on /airflow/dags/download_data.py
[2022-02-17 13:41:34,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:41:34,635] {logging_mixin.py:112} INFO - [2022-02-17 13:41:34,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:41:35,098] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:41:35,140] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:41:35,146] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:41:35,151] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 13:41:47,898] {scheduler_job.py:155} INFO - Started process (PID=2930) to work on /airflow/dags/download_data.py
[2022-02-17 13:41:47,905] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:41:47,907] {logging_mixin.py:112} INFO - [2022-02-17 13:41:47,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:41:48,371] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:41:48,421] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:41:48,432] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:41:48,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 13:42:01,188] {scheduler_job.py:155} INFO - Started process (PID=2956) to work on /airflow/dags/download_data.py
[2022-02-17 13:42:01,194] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:42:01,195] {logging_mixin.py:112} INFO - [2022-02-17 13:42:01,195] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:42:01,658] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:42:01,709] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:42:01,718] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:42:01,723] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 13:42:14,488] {scheduler_job.py:155} INFO - Started process (PID=2982) to work on /airflow/dags/download_data.py
[2022-02-17 13:42:14,497] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:42:14,499] {logging_mixin.py:112} INFO - [2022-02-17 13:42:14,499] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:42:14,921] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:42:14,961] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:42:14,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:42:14,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.483 seconds
[2022-02-17 13:42:27,782] {scheduler_job.py:155} INFO - Started process (PID=3010) to work on /airflow/dags/download_data.py
[2022-02-17 13:42:27,790] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:42:27,796] {logging_mixin.py:112} INFO - [2022-02-17 13:42:27,795] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:42:28,221] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:42:28,264] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:42:28,271] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:42:28,276] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 13:42:41,068] {scheduler_job.py:155} INFO - Started process (PID=3036) to work on /airflow/dags/download_data.py
[2022-02-17 13:42:41,077] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:42:41,079] {logging_mixin.py:112} INFO - [2022-02-17 13:42:41,079] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:42:41,524] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:42:41,566] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:42:41,574] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:42:41,580] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 13:42:54,336] {scheduler_job.py:155} INFO - Started process (PID=3064) to work on /airflow/dags/download_data.py
[2022-02-17 13:42:54,341] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:42:54,345] {logging_mixin.py:112} INFO - [2022-02-17 13:42:54,344] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:42:54,780] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:42:54,836] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:42:54,843] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:42:54,847] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 13:43:07,677] {scheduler_job.py:155} INFO - Started process (PID=3090) to work on /airflow/dags/download_data.py
[2022-02-17 13:43:07,683] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:43:07,685] {logging_mixin.py:112} INFO - [2022-02-17 13:43:07,685] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:43:08,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:43:08,162] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:43:08,172] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:43:08,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 13:43:20,953] {scheduler_job.py:155} INFO - Started process (PID=3118) to work on /airflow/dags/download_data.py
[2022-02-17 13:43:20,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:43:20,960] {logging_mixin.py:112} INFO - [2022-02-17 13:43:20,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:43:21,391] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:43:21,439] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:43:21,447] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:43:21,452] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 13:43:34,253] {scheduler_job.py:155} INFO - Started process (PID=3144) to work on /airflow/dags/download_data.py
[2022-02-17 13:43:34,260] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:43:34,263] {logging_mixin.py:112} INFO - [2022-02-17 13:43:34,263] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:43:34,735] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:43:34,781] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:43:34,790] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:43:34,797] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 13:43:47,529] {scheduler_job.py:155} INFO - Started process (PID=3172) to work on /airflow/dags/download_data.py
[2022-02-17 13:43:47,548] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:43:47,552] {logging_mixin.py:112} INFO - [2022-02-17 13:43:47,551] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:43:48,289] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:43:48,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:43:48,354] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:43:48,361] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.833 seconds
[2022-02-17 13:44:00,818] {scheduler_job.py:155} INFO - Started process (PID=3198) to work on /airflow/dags/download_data.py
[2022-02-17 13:44:00,824] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:44:00,825] {logging_mixin.py:112} INFO - [2022-02-17 13:44:00,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:44:01,294] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:44:01,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:44:01,359] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:44:01,363] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 13:44:14,082] {scheduler_job.py:155} INFO - Started process (PID=3224) to work on /airflow/dags/download_data.py
[2022-02-17 13:44:14,088] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:44:14,090] {logging_mixin.py:112} INFO - [2022-02-17 13:44:14,090] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:44:14,535] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:44:14,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:44:14,598] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:44:14,604] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 13:44:27,345] {scheduler_job.py:155} INFO - Started process (PID=3252) to work on /airflow/dags/download_data.py
[2022-02-17 13:44:27,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:44:27,352] {logging_mixin.py:112} INFO - [2022-02-17 13:44:27,352] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:44:27,795] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:44:27,850] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:44:27,857] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:44:27,862] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 13:44:40,665] {scheduler_job.py:155} INFO - Started process (PID=3278) to work on /airflow/dags/download_data.py
[2022-02-17 13:44:40,674] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:44:40,685] {logging_mixin.py:112} INFO - [2022-02-17 13:44:40,685] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:44:41,228] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:44:41,286] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:44:41,292] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:44:41,295] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-17 13:44:53,965] {scheduler_job.py:155} INFO - Started process (PID=3306) to work on /airflow/dags/download_data.py
[2022-02-17 13:44:53,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:44:53,971] {logging_mixin.py:112} INFO - [2022-02-17 13:44:53,971] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:44:54,451] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:44:54,506] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:44:54,517] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:44:54,523] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 13:45:07,256] {scheduler_job.py:155} INFO - Started process (PID=3332) to work on /airflow/dags/download_data.py
[2022-02-17 13:45:07,262] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:45:07,265] {logging_mixin.py:112} INFO - [2022-02-17 13:45:07,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:45:07,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:45:07,743] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:45:07,752] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:45:07,757] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 13:45:20,485] {scheduler_job.py:155} INFO - Started process (PID=3360) to work on /airflow/dags/download_data.py
[2022-02-17 13:45:20,489] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:45:20,491] {logging_mixin.py:112} INFO - [2022-02-17 13:45:20,491] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:45:20,927] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:45:20,971] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:45:20,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:45:20,986] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 13:45:33,846] {scheduler_job.py:155} INFO - Started process (PID=3386) to work on /airflow/dags/download_data.py
[2022-02-17 13:45:33,858] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:45:33,862] {logging_mixin.py:112} INFO - [2022-02-17 13:45:33,861] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:45:34,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:45:34,359] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:45:34,370] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:45:34,375] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 13:45:47,103] {scheduler_job.py:155} INFO - Started process (PID=3412) to work on /airflow/dags/download_data.py
[2022-02-17 13:45:47,108] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:45:47,109] {logging_mixin.py:112} INFO - [2022-02-17 13:45:47,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:45:47,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:45:47,688] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:45:47,700] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:45:47,706] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 13:46:00,409] {scheduler_job.py:155} INFO - Started process (PID=3440) to work on /airflow/dags/download_data.py
[2022-02-17 13:46:00,420] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:46:00,421] {logging_mixin.py:112} INFO - [2022-02-17 13:46:00,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:46:00,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:46:00,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:46:00,953] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:46:00,960] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 13:46:13,714] {scheduler_job.py:155} INFO - Started process (PID=3466) to work on /airflow/dags/download_data.py
[2022-02-17 13:46:13,721] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:46:13,723] {logging_mixin.py:112} INFO - [2022-02-17 13:46:13,723] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:46:14,148] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:46:14,191] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:46:14,201] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:46:14,207] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 13:46:26,977] {scheduler_job.py:155} INFO - Started process (PID=3494) to work on /airflow/dags/download_data.py
[2022-02-17 13:46:26,981] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:46:26,983] {logging_mixin.py:112} INFO - [2022-02-17 13:46:26,983] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:46:27,430] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:46:27,477] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:46:27,487] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:46:27,494] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 13:46:40,309] {scheduler_job.py:155} INFO - Started process (PID=3520) to work on /airflow/dags/download_data.py
[2022-02-17 13:46:40,314] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:46:40,316] {logging_mixin.py:112} INFO - [2022-02-17 13:46:40,316] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:46:40,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:46:40,798] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:46:40,805] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:46:40,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 13:46:53,616] {scheduler_job.py:155} INFO - Started process (PID=3548) to work on /airflow/dags/download_data.py
[2022-02-17 13:46:53,627] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:46:53,631] {logging_mixin.py:112} INFO - [2022-02-17 13:46:53,630] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:46:54,151] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:46:54,211] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:46:54,220] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:46:54,224] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-17 13:47:06,888] {scheduler_job.py:155} INFO - Started process (PID=3574) to work on /airflow/dags/download_data.py
[2022-02-17 13:47:06,895] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:47:06,897] {logging_mixin.py:112} INFO - [2022-02-17 13:47:06,897] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:47:07,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:47:07,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:47:07,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:47:07,436] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 13:47:20,142] {scheduler_job.py:155} INFO - Started process (PID=3600) to work on /airflow/dags/download_data.py
[2022-02-17 13:47:20,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:47:20,154] {logging_mixin.py:112} INFO - [2022-02-17 13:47:20,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:47:20,596] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:47:20,636] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:47:20,647] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:47:20,650] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 13:47:33,465] {scheduler_job.py:155} INFO - Started process (PID=3628) to work on /airflow/dags/download_data.py
[2022-02-17 13:47:33,473] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:47:33,474] {logging_mixin.py:112} INFO - [2022-02-17 13:47:33,474] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:47:34,150] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:47:34,207] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:47:34,223] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:47:34,242] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.777 seconds
[2022-02-17 13:47:46,754] {scheduler_job.py:155} INFO - Started process (PID=3654) to work on /airflow/dags/download_data.py
[2022-02-17 13:47:46,764] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:47:46,766] {logging_mixin.py:112} INFO - [2022-02-17 13:47:46,766] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:47:47,198] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:47:47,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:47:47,257] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:47:47,264] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 13:48:00,045] {scheduler_job.py:155} INFO - Started process (PID=3682) to work on /airflow/dags/download_data.py
[2022-02-17 13:48:00,054] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:48:00,056] {logging_mixin.py:112} INFO - [2022-02-17 13:48:00,056] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:48:00,510] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:48:00,571] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:48:00,582] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:48:00,589] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 13:48:13,308] {scheduler_job.py:155} INFO - Started process (PID=3708) to work on /airflow/dags/download_data.py
[2022-02-17 13:48:13,315] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:48:13,317] {logging_mixin.py:112} INFO - [2022-02-17 13:48:13,316] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:48:13,754] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:48:13,805] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:48:13,816] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:48:13,822] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 13:48:26,567] {scheduler_job.py:155} INFO - Started process (PID=3736) to work on /airflow/dags/download_data.py
[2022-02-17 13:48:26,572] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:48:26,573] {logging_mixin.py:112} INFO - [2022-02-17 13:48:26,573] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:48:27,018] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:48:27,072] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:48:27,083] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:48:27,088] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 13:48:39,846] {scheduler_job.py:155} INFO - Started process (PID=3762) to work on /airflow/dags/download_data.py
[2022-02-17 13:48:39,851] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:48:39,853] {logging_mixin.py:112} INFO - [2022-02-17 13:48:39,853] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:48:40,304] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:48:40,357] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:48:40,367] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:48:40,372] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 13:48:53,121] {scheduler_job.py:155} INFO - Started process (PID=3788) to work on /airflow/dags/download_data.py
[2022-02-17 13:48:53,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:48:53,128] {logging_mixin.py:112} INFO - [2022-02-17 13:48:53,128] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:48:53,813] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:48:53,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:48:53,890] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:48:53,894] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.772 seconds
[2022-02-17 13:49:06,483] {scheduler_job.py:155} INFO - Started process (PID=3816) to work on /airflow/dags/download_data.py
[2022-02-17 13:49:06,488] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:49:06,489] {logging_mixin.py:112} INFO - [2022-02-17 13:49:06,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:49:06,936] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:49:06,987] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:49:06,998] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:49:07,002] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 13:49:19,736] {scheduler_job.py:155} INFO - Started process (PID=3842) to work on /airflow/dags/download_data.py
[2022-02-17 13:49:19,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:49:19,745] {logging_mixin.py:112} INFO - [2022-02-17 13:49:19,744] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:49:20,186] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:49:20,235] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:49:20,244] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:49:20,248] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 13:49:33,044] {scheduler_job.py:155} INFO - Started process (PID=3870) to work on /airflow/dags/download_data.py
[2022-02-17 13:49:33,052] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:49:33,054] {logging_mixin.py:112} INFO - [2022-02-17 13:49:33,053] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:49:33,497] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:49:33,549] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:49:33,555] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:49:33,560] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 13:49:46,324] {scheduler_job.py:155} INFO - Started process (PID=3896) to work on /airflow/dags/download_data.py
[2022-02-17 13:49:46,331] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:49:46,333] {logging_mixin.py:112} INFO - [2022-02-17 13:49:46,332] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:49:46,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:49:46,786] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:49:46,793] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:49:46,798] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.475 seconds
[2022-02-17 13:49:59,645] {scheduler_job.py:155} INFO - Started process (PID=3924) to work on /airflow/dags/download_data.py
[2022-02-17 13:49:59,650] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:49:59,651] {logging_mixin.py:112} INFO - [2022-02-17 13:49:59,651] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:50:00,102] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:50:00,158] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:50:00,166] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:50:00,170] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 13:50:12,943] {scheduler_job.py:155} INFO - Started process (PID=3950) to work on /airflow/dags/download_data.py
[2022-02-17 13:50:12,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:50:12,956] {logging_mixin.py:112} INFO - [2022-02-17 13:50:12,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:50:13,392] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:50:13,439] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:50:13,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:50:13,456] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 13:50:26,253] {scheduler_job.py:155} INFO - Started process (PID=3978) to work on /airflow/dags/download_data.py
[2022-02-17 13:50:26,257] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:50:26,258] {logging_mixin.py:112} INFO - [2022-02-17 13:50:26,258] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:50:26,688] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:50:26,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:50:26,744] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:50:26,747] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 13:50:39,578] {scheduler_job.py:155} INFO - Started process (PID=4004) to work on /airflow/dags/download_data.py
[2022-02-17 13:50:39,586] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:50:39,589] {logging_mixin.py:112} INFO - [2022-02-17 13:50:39,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:50:40,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:50:40,051] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:50:40,060] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:50:40,063] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-17 13:50:52,833] {scheduler_job.py:155} INFO - Started process (PID=4030) to work on /airflow/dags/download_data.py
[2022-02-17 13:50:52,839] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:50:52,840] {logging_mixin.py:112} INFO - [2022-02-17 13:50:52,840] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:50:53,318] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:50:53,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:50:53,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:50:53,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 13:51:06,138] {scheduler_job.py:155} INFO - Started process (PID=4058) to work on /airflow/dags/download_data.py
[2022-02-17 13:51:06,144] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:51:06,146] {logging_mixin.py:112} INFO - [2022-02-17 13:51:06,146] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:51:06,573] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:51:06,621] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:51:06,627] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:51:06,633] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 13:51:19,414] {scheduler_job.py:155} INFO - Started process (PID=4084) to work on /airflow/dags/download_data.py
[2022-02-17 13:51:19,421] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:51:19,427] {logging_mixin.py:112} INFO - [2022-02-17 13:51:19,427] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:51:19,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:51:19,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:51:19,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:51:19,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 13:51:32,706] {scheduler_job.py:155} INFO - Started process (PID=4112) to work on /airflow/dags/download_data.py
[2022-02-17 13:51:32,711] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:51:32,712] {logging_mixin.py:112} INFO - [2022-02-17 13:51:32,712] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:51:33,143] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:51:33,194] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:51:33,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:51:33,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 13:51:45,994] {scheduler_job.py:155} INFO - Started process (PID=4138) to work on /airflow/dags/download_data.py
[2022-02-17 13:51:46,003] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:51:46,006] {logging_mixin.py:112} INFO - [2022-02-17 13:51:46,005] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:51:46,411] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:51:46,460] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:51:46,469] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:51:46,474] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.480 seconds
[2022-02-17 13:51:59,259] {scheduler_job.py:155} INFO - Started process (PID=4166) to work on /airflow/dags/download_data.py
[2022-02-17 13:51:59,265] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:51:59,266] {logging_mixin.py:112} INFO - [2022-02-17 13:51:59,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:51:59,699] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:51:59,751] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:51:59,764] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:51:59,770] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 13:52:12,567] {scheduler_job.py:155} INFO - Started process (PID=4192) to work on /airflow/dags/download_data.py
[2022-02-17 13:52:12,575] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:52:12,577] {logging_mixin.py:112} INFO - [2022-02-17 13:52:12,577] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:52:13,014] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:52:13,059] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:52:13,067] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:52:13,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 13:52:25,821] {scheduler_job.py:155} INFO - Started process (PID=4218) to work on /airflow/dags/download_data.py
[2022-02-17 13:52:25,826] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:52:25,827] {logging_mixin.py:112} INFO - [2022-02-17 13:52:25,827] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:52:26,270] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:52:26,319] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:52:26,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:52:26,335] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 13:52:39,086] {scheduler_job.py:155} INFO - Started process (PID=4246) to work on /airflow/dags/download_data.py
[2022-02-17 13:52:39,090] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:52:39,092] {logging_mixin.py:112} INFO - [2022-02-17 13:52:39,092] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:52:39,529] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:52:39,582] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:52:39,589] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:52:39,595] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 13:52:52,374] {scheduler_job.py:155} INFO - Started process (PID=4272) to work on /airflow/dags/download_data.py
[2022-02-17 13:52:52,381] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:52:52,384] {logging_mixin.py:112} INFO - [2022-02-17 13:52:52,384] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:52:52,827] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:52:52,888] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:52:52,894] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:52:52,899] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 13:53:05,708] {scheduler_job.py:155} INFO - Started process (PID=4300) to work on /airflow/dags/download_data.py
[2022-02-17 13:53:05,712] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:53:05,713] {logging_mixin.py:112} INFO - [2022-02-17 13:53:05,713] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:53:06,144] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:53:06,197] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:53:06,204] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:53:06,209] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 13:53:18,995] {scheduler_job.py:155} INFO - Started process (PID=4326) to work on /airflow/dags/download_data.py
[2022-02-17 13:53:18,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:53:19,001] {logging_mixin.py:112} INFO - [2022-02-17 13:53:19,001] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:53:19,440] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:53:19,490] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:53:19,495] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:53:19,498] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 13:53:32,264] {scheduler_job.py:155} INFO - Started process (PID=4354) to work on /airflow/dags/download_data.py
[2022-02-17 13:53:32,268] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:53:32,270] {logging_mixin.py:112} INFO - [2022-02-17 13:53:32,269] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 13:53:32,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 13:53:32,775] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 13:53:32,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 13:53:32,786] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 13:53:46,060] {scheduler_job.py:155} INFO - Started process (PID=4380) to work on /airflow/dags/download_data.py
[2022-02-17 13:53:46,069] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 13:53:46,072] {logging_mixin.py:112} INFO - [2022-02-17 13:53:46,071] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:53:43,743] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:53:43,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:53:43,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:53:43,799] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 3597.739 seconds
[2022-02-17 14:54:05,837] {scheduler_job.py:155} INFO - Started process (PID=4416) to work on /airflow/dags/download_data.py
[2022-02-17 14:54:05,845] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:54:05,846] {logging_mixin.py:112} INFO - [2022-02-17 14:54:05,846] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:54:06,382] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:54:06,433] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:54:06,442] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:54:06,448] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-17 14:54:19,408] {scheduler_job.py:155} INFO - Started process (PID=4444) to work on /airflow/dags/download_data.py
[2022-02-17 14:54:19,415] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:54:19,417] {logging_mixin.py:112} INFO - [2022-02-17 14:54:19,417] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:54:19,880] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:54:19,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:54:19,955] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:54:19,960] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 14:54:32,692] {scheduler_job.py:155} INFO - Started process (PID=4470) to work on /airflow/dags/download_data.py
[2022-02-17 14:54:32,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:54:32,702] {logging_mixin.py:112} INFO - [2022-02-17 14:54:32,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:54:33,131] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:54:33,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:54:33,179] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:54:33,182] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 14:54:46,002] {scheduler_job.py:155} INFO - Started process (PID=4498) to work on /airflow/dags/download_data.py
[2022-02-17 14:54:46,007] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:54:46,008] {logging_mixin.py:112} INFO - [2022-02-17 14:54:46,008] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:54:46,431] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:54:46,506] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:54:46,527] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:54:46,536] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 14:54:59,349] {scheduler_job.py:155} INFO - Started process (PID=4524) to work on /airflow/dags/download_data.py
[2022-02-17 14:54:59,358] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:54:59,365] {logging_mixin.py:112} INFO - [2022-02-17 14:54:59,365] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:54:59,813] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:54:59,849] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:54:59,857] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:54:59,863] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 14:55:12,660] {scheduler_job.py:155} INFO - Started process (PID=4550) to work on /airflow/dags/download_data.py
[2022-02-17 14:55:12,667] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:55:12,669] {logging_mixin.py:112} INFO - [2022-02-17 14:55:12,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:55:13,106] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:55:13,149] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:55:13,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:55:13,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 14:55:25,954] {scheduler_job.py:155} INFO - Started process (PID=4578) to work on /airflow/dags/download_data.py
[2022-02-17 14:55:25,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:55:25,961] {logging_mixin.py:112} INFO - [2022-02-17 14:55:25,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:55:26,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:55:26,445] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:55:26,456] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:55:26,462] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 14:55:39,254] {scheduler_job.py:155} INFO - Started process (PID=4604) to work on /airflow/dags/download_data.py
[2022-02-17 14:55:39,259] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:55:39,261] {logging_mixin.py:112} INFO - [2022-02-17 14:55:39,260] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:55:39,694] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:55:39,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:55:39,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:55:39,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 14:55:52,500] {scheduler_job.py:155} INFO - Started process (PID=4632) to work on /airflow/dags/download_data.py
[2022-02-17 14:55:52,505] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:55:52,507] {logging_mixin.py:112} INFO - [2022-02-17 14:55:52,507] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:55:52,998] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:55:53,076] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:55:53,089] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:55:53,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 14:56:05,796] {scheduler_job.py:155} INFO - Started process (PID=4658) to work on /airflow/dags/download_data.py
[2022-02-17 14:56:05,804] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:56:05,806] {logging_mixin.py:112} INFO - [2022-02-17 14:56:05,806] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:56:06,239] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:56:06,288] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:56:06,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:56:06,301] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 14:56:19,089] {scheduler_job.py:155} INFO - Started process (PID=4686) to work on /airflow/dags/download_data.py
[2022-02-17 14:56:19,097] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:56:19,099] {logging_mixin.py:112} INFO - [2022-02-17 14:56:19,098] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:56:19,526] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:56:19,591] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:56:19,598] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:56:19,602] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 14:56:32,410] {scheduler_job.py:155} INFO - Started process (PID=4712) to work on /airflow/dags/download_data.py
[2022-02-17 14:56:32,419] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:56:32,421] {logging_mixin.py:112} INFO - [2022-02-17 14:56:32,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:56:32,891] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:56:32,937] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:56:32,945] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:56:32,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 14:56:45,694] {scheduler_job.py:155} INFO - Started process (PID=4738) to work on /airflow/dags/download_data.py
[2022-02-17 14:56:45,698] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:56:45,700] {logging_mixin.py:112} INFO - [2022-02-17 14:56:45,699] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:56:46,160] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:56:46,204] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:56:46,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:56:46,217] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 14:56:58,997] {scheduler_job.py:155} INFO - Started process (PID=4766) to work on /airflow/dags/download_data.py
[2022-02-17 14:56:59,001] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:56:59,003] {logging_mixin.py:112} INFO - [2022-02-17 14:56:59,003] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:56:59,466] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:56:59,508] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:56:59,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:56:59,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 14:57:12,309] {scheduler_job.py:155} INFO - Started process (PID=4792) to work on /airflow/dags/download_data.py
[2022-02-17 14:57:12,316] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:57:12,318] {logging_mixin.py:112} INFO - [2022-02-17 14:57:12,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:57:12,759] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:57:12,824] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:57:12,833] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:57:12,839] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 14:57:25,539] {scheduler_job.py:155} INFO - Started process (PID=4820) to work on /airflow/dags/download_data.py
[2022-02-17 14:57:25,543] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:57:25,545] {logging_mixin.py:112} INFO - [2022-02-17 14:57:25,544] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:57:25,980] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:57:26,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:57:26,037] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:57:26,041] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 14:57:38,862] {scheduler_job.py:155} INFO - Started process (PID=4846) to work on /airflow/dags/download_data.py
[2022-02-17 14:57:38,866] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:57:38,867] {logging_mixin.py:112} INFO - [2022-02-17 14:57:38,867] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:57:39,315] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:57:39,374] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:57:39,383] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:57:39,389] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 14:57:52,126] {scheduler_job.py:155} INFO - Started process (PID=4874) to work on /airflow/dags/download_data.py
[2022-02-17 14:57:52,134] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:57:52,136] {logging_mixin.py:112} INFO - [2022-02-17 14:57:52,135] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:57:52,584] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:57:52,641] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:57:52,653] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:57:52,660] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 14:58:05,423] {scheduler_job.py:155} INFO - Started process (PID=4900) to work on /airflow/dags/download_data.py
[2022-02-17 14:58:05,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:58:05,432] {logging_mixin.py:112} INFO - [2022-02-17 14:58:05,432] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:58:05,869] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:58:05,914] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:58:05,920] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:58:05,924] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 14:58:18,681] {scheduler_job.py:155} INFO - Started process (PID=4926) to work on /airflow/dags/download_data.py
[2022-02-17 14:58:18,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:58:18,693] {logging_mixin.py:112} INFO - [2022-02-17 14:58:18,692] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:58:19,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:58:19,362] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:58:19,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:58:19,376] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.696 seconds
[2022-02-17 14:58:31,953] {scheduler_job.py:155} INFO - Started process (PID=4954) to work on /airflow/dags/download_data.py
[2022-02-17 14:58:31,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:58:31,959] {logging_mixin.py:112} INFO - [2022-02-17 14:58:31,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:58:32,413] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:58:32,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:58:32,471] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:58:32,477] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 14:58:45,247] {scheduler_job.py:155} INFO - Started process (PID=4980) to work on /airflow/dags/download_data.py
[2022-02-17 14:58:45,258] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:58:45,261] {logging_mixin.py:112} INFO - [2022-02-17 14:58:45,260] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:58:45,724] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:58:45,786] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:58:45,795] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:58:45,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 14:58:58,570] {scheduler_job.py:155} INFO - Started process (PID=5008) to work on /airflow/dags/download_data.py
[2022-02-17 14:58:58,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:58:58,580] {logging_mixin.py:112} INFO - [2022-02-17 14:58:58,580] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:58:59,013] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:58:59,067] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:58:59,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:58:59,078] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 14:59:11,845] {scheduler_job.py:155} INFO - Started process (PID=5034) to work on /airflow/dags/download_data.py
[2022-02-17 14:59:11,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:59:11,850] {logging_mixin.py:112} INFO - [2022-02-17 14:59:11,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:59:12,298] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:59:12,343] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:59:12,352] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:59:12,358] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 14:59:25,132] {scheduler_job.py:155} INFO - Started process (PID=5062) to work on /airflow/dags/download_data.py
[2022-02-17 14:59:25,137] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:59:25,138] {logging_mixin.py:112} INFO - [2022-02-17 14:59:25,138] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:59:25,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:59:25,627] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:59:25,635] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:59:25,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 14:59:38,397] {scheduler_job.py:155} INFO - Started process (PID=5088) to work on /airflow/dags/download_data.py
[2022-02-17 14:59:38,402] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:59:38,403] {logging_mixin.py:112} INFO - [2022-02-17 14:59:38,403] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:59:38,844] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:59:38,879] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:59:38,885] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:59:38,890] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 14:59:51,705] {scheduler_job.py:155} INFO - Started process (PID=5116) to work on /airflow/dags/download_data.py
[2022-02-17 14:59:51,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 14:59:51,710] {logging_mixin.py:112} INFO - [2022-02-17 14:59:51,710] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 14:59:52,208] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 14:59:52,262] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 14:59:52,274] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 14:59:52,278] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 15:00:05,006] {scheduler_job.py:155} INFO - Started process (PID=5142) to work on /airflow/dags/download_data.py
[2022-02-17 15:00:05,010] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:00:05,013] {logging_mixin.py:112} INFO - [2022-02-17 15:00:05,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:00:05,449] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:00:05,498] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:00:05,506] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:00:05,511] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 15:00:18,290] {scheduler_job.py:155} INFO - Started process (PID=5168) to work on /airflow/dags/download_data.py
[2022-02-17 15:00:18,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:00:18,301] {logging_mixin.py:112} INFO - [2022-02-17 15:00:18,301] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:00:18,745] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:00:18,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:00:18,809] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:00:18,813] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 15:00:31,561] {scheduler_job.py:155} INFO - Started process (PID=5196) to work on /airflow/dags/download_data.py
[2022-02-17 15:00:31,569] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:00:31,574] {logging_mixin.py:112} INFO - [2022-02-17 15:00:31,573] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:00:32,148] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:00:32,202] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:00:32,209] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:00:32,212] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.652 seconds
[2022-02-17 15:00:44,811] {scheduler_job.py:155} INFO - Started process (PID=5222) to work on /airflow/dags/download_data.py
[2022-02-17 15:00:44,816] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:00:44,818] {logging_mixin.py:112} INFO - [2022-02-17 15:00:44,818] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:00:45,322] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:00:45,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:00:45,396] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:00:45,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 15:00:58,135] {scheduler_job.py:155} INFO - Started process (PID=5250) to work on /airflow/dags/download_data.py
[2022-02-17 15:00:58,141] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:00:58,144] {logging_mixin.py:112} INFO - [2022-02-17 15:00:58,143] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:00:58,599] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:00:58,646] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:00:58,654] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:00:58,659] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 15:01:11,424] {scheduler_job.py:155} INFO - Started process (PID=5276) to work on /airflow/dags/download_data.py
[2022-02-17 15:01:11,436] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:01:11,439] {logging_mixin.py:112} INFO - [2022-02-17 15:01:11,438] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:01:11,876] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:01:11,917] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:01:11,925] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:01:11,930] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 15:01:24,688] {scheduler_job.py:155} INFO - Started process (PID=5304) to work on /airflow/dags/download_data.py
[2022-02-17 15:01:24,694] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:01:24,696] {logging_mixin.py:112} INFO - [2022-02-17 15:01:24,695] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:01:25,111] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:01:25,159] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:01:25,165] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:01:25,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.483 seconds
[2022-02-17 15:01:38,002] {scheduler_job.py:155} INFO - Started process (PID=5330) to work on /airflow/dags/download_data.py
[2022-02-17 15:01:38,014] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:01:38,024] {logging_mixin.py:112} INFO - [2022-02-17 15:01:38,023] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:01:38,475] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:01:38,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:01:38,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:01:38,527] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 15:01:51,245] {scheduler_job.py:155} INFO - Started process (PID=5356) to work on /airflow/dags/download_data.py
[2022-02-17 15:01:51,252] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:01:51,254] {logging_mixin.py:112} INFO - [2022-02-17 15:01:51,254] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:01:51,698] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:01:51,750] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:01:51,761] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:01:51,766] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 15:02:04,544] {scheduler_job.py:155} INFO - Started process (PID=5384) to work on /airflow/dags/download_data.py
[2022-02-17 15:02:04,553] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:02:04,564] {logging_mixin.py:112} INFO - [2022-02-17 15:02:04,563] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:02:05,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:02:05,091] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:02:05,098] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:02:05,103] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 15:02:17,804] {scheduler_job.py:155} INFO - Started process (PID=5410) to work on /airflow/dags/download_data.py
[2022-02-17 15:02:17,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:02:17,810] {logging_mixin.py:112} INFO - [2022-02-17 15:02:17,810] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:02:18,274] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:02:18,331] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:02:18,342] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:02:18,349] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 15:02:31,132] {scheduler_job.py:155} INFO - Started process (PID=5438) to work on /airflow/dags/download_data.py
[2022-02-17 15:02:31,139] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:02:31,141] {logging_mixin.py:112} INFO - [2022-02-17 15:02:31,141] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:02:31,688] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:02:31,722] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:02:31,730] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:02:31,741] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-17 15:02:44,426] {scheduler_job.py:155} INFO - Started process (PID=5464) to work on /airflow/dags/download_data.py
[2022-02-17 15:02:44,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:02:44,438] {logging_mixin.py:112} INFO - [2022-02-17 15:02:44,437] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:02:44,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:02:44,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:02:45,004] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:02:45,011] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 15:02:57,717] {scheduler_job.py:155} INFO - Started process (PID=5492) to work on /airflow/dags/download_data.py
[2022-02-17 15:02:57,728] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:02:57,729] {logging_mixin.py:112} INFO - [2022-02-17 15:02:57,729] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:02:58,248] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:02:58,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:02:58,308] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:02:58,312] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 15:03:11,002] {scheduler_job.py:155} INFO - Started process (PID=5518) to work on /airflow/dags/download_data.py
[2022-02-17 15:03:11,006] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:03:11,007] {logging_mixin.py:112} INFO - [2022-02-17 15:03:11,007] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:03:11,448] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:03:11,493] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:03:11,500] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:03:11,505] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 15:03:24,227] {scheduler_job.py:155} INFO - Started process (PID=5544) to work on /airflow/dags/download_data.py
[2022-02-17 15:03:24,234] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:03:24,237] {logging_mixin.py:112} INFO - [2022-02-17 15:03:24,237] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:03:24,661] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:03:24,714] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:03:24,720] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:03:24,727] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 15:03:37,511] {scheduler_job.py:155} INFO - Started process (PID=5572) to work on /airflow/dags/download_data.py
[2022-02-17 15:03:37,515] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:03:37,517] {logging_mixin.py:112} INFO - [2022-02-17 15:03:37,517] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:03:37,953] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:03:37,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:03:37,996] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:03:37,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 15:03:50,812] {scheduler_job.py:155} INFO - Started process (PID=5598) to work on /airflow/dags/download_data.py
[2022-02-17 15:03:50,817] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:03:50,819] {logging_mixin.py:112} INFO - [2022-02-17 15:03:50,819] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:03:51,283] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:03:51,339] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:03:51,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:03:51,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 15:04:04,110] {scheduler_job.py:155} INFO - Started process (PID=5626) to work on /airflow/dags/download_data.py
[2022-02-17 15:04:04,117] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:04:04,120] {logging_mixin.py:112} INFO - [2022-02-17 15:04:04,119] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:04:04,561] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:04:04,597] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:04:04,607] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:04:04,612] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 15:04:17,368] {scheduler_job.py:155} INFO - Started process (PID=5652) to work on /airflow/dags/download_data.py
[2022-02-17 15:04:17,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:04:17,375] {logging_mixin.py:112} INFO - [2022-02-17 15:04:17,375] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:04:17,865] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:04:17,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:04:17,937] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:04:17,947] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-17 15:04:30,703] {scheduler_job.py:155} INFO - Started process (PID=5680) to work on /airflow/dags/download_data.py
[2022-02-17 15:04:30,708] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:04:30,710] {logging_mixin.py:112} INFO - [2022-02-17 15:04:30,710] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:04:31,251] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:04:31,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:04:31,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:04:31,333] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-17 15:04:43,941] {scheduler_job.py:155} INFO - Started process (PID=5706) to work on /airflow/dags/download_data.py
[2022-02-17 15:04:43,947] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:04:43,949] {logging_mixin.py:112} INFO - [2022-02-17 15:04:43,949] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:04:44,383] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:04:44,420] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:04:44,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:04:44,435] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 15:04:57,287] {scheduler_job.py:155} INFO - Started process (PID=5732) to work on /airflow/dags/download_data.py
[2022-02-17 15:04:57,302] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:04:57,304] {logging_mixin.py:112} INFO - [2022-02-17 15:04:57,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:04:57,842] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:04:57,892] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:04:57,905] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:04:57,910] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-17 15:05:10,556] {scheduler_job.py:155} INFO - Started process (PID=5760) to work on /airflow/dags/download_data.py
[2022-02-17 15:05:10,564] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:05:10,567] {logging_mixin.py:112} INFO - [2022-02-17 15:05:10,566] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:05:11,008] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:05:11,059] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:05:11,067] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:05:11,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 15:05:23,842] {scheduler_job.py:155} INFO - Started process (PID=5786) to work on /airflow/dags/download_data.py
[2022-02-17 15:05:23,847] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:05:23,849] {logging_mixin.py:112} INFO - [2022-02-17 15:05:23,849] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:05:24,285] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:05:24,335] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:05:24,342] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:05:24,346] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 15:05:37,145] {scheduler_job.py:155} INFO - Started process (PID=5814) to work on /airflow/dags/download_data.py
[2022-02-17 15:05:37,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:05:37,152] {logging_mixin.py:112} INFO - [2022-02-17 15:05:37,152] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:05:37,583] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:05:37,633] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:05:37,641] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:05:37,646] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 15:05:50,388] {scheduler_job.py:155} INFO - Started process (PID=5840) to work on /airflow/dags/download_data.py
[2022-02-17 15:05:50,399] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:05:50,402] {logging_mixin.py:112} INFO - [2022-02-17 15:05:50,401] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:05:50,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:05:50,885] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:05:50,894] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:05:50,898] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 15:06:03,685] {scheduler_job.py:155} INFO - Started process (PID=5868) to work on /airflow/dags/download_data.py
[2022-02-17 15:06:03,689] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:06:03,691] {logging_mixin.py:112} INFO - [2022-02-17 15:06:03,690] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:06:04,124] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:06:04,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:06:04,179] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:06:04,182] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 15:06:16,986] {scheduler_job.py:155} INFO - Started process (PID=5894) to work on /airflow/dags/download_data.py
[2022-02-17 15:06:16,991] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:06:16,993] {logging_mixin.py:112} INFO - [2022-02-17 15:06:16,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:06:17,468] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:06:17,524] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:06:17,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:06:17,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 15:06:30,317] {scheduler_job.py:155} INFO - Started process (PID=5922) to work on /airflow/dags/download_data.py
[2022-02-17 15:06:30,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:06:30,334] {logging_mixin.py:112} INFO - [2022-02-17 15:06:30,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:06:30,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:06:30,823] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:06:30,831] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:06:30,834] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 15:06:43,629] {scheduler_job.py:155} INFO - Started process (PID=5948) to work on /airflow/dags/download_data.py
[2022-02-17 15:06:43,640] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:06:43,643] {logging_mixin.py:112} INFO - [2022-02-17 15:06:43,643] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:06:44,088] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:06:44,129] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:06:44,139] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:06:44,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 15:06:56,904] {scheduler_job.py:155} INFO - Started process (PID=5974) to work on /airflow/dags/download_data.py
[2022-02-17 15:06:56,908] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:06:56,910] {logging_mixin.py:112} INFO - [2022-02-17 15:06:56,910] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:06:57,361] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:06:57,425] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:06:57,432] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:06:57,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 15:07:10,213] {scheduler_job.py:155} INFO - Started process (PID=6002) to work on /airflow/dags/download_data.py
[2022-02-17 15:07:10,217] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:07:10,219] {logging_mixin.py:112} INFO - [2022-02-17 15:07:10,219] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:07:10,674] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:07:10,728] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:07:10,738] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:07:10,744] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 15:07:23,463] {scheduler_job.py:155} INFO - Started process (PID=6028) to work on /airflow/dags/download_data.py
[2022-02-17 15:07:23,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:07:23,472] {logging_mixin.py:112} INFO - [2022-02-17 15:07:23,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:07:23,903] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:07:23,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:07:23,961] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:07:23,965] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 15:07:36,816] {scheduler_job.py:155} INFO - Started process (PID=6056) to work on /airflow/dags/download_data.py
[2022-02-17 15:07:36,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:07:36,825] {logging_mixin.py:112} INFO - [2022-02-17 15:07:36,824] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:07:37,270] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:07:37,315] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:07:37,323] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:07:37,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 15:07:50,072] {scheduler_job.py:155} INFO - Started process (PID=6082) to work on /airflow/dags/download_data.py
[2022-02-17 15:07:50,079] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:07:50,081] {logging_mixin.py:112} INFO - [2022-02-17 15:07:50,080] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:07:50,549] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:07:50,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:07:50,623] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:07:50,628] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 15:08:03,403] {scheduler_job.py:155} INFO - Started process (PID=6110) to work on /airflow/dags/download_data.py
[2022-02-17 15:08:03,410] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:08:03,412] {logging_mixin.py:112} INFO - [2022-02-17 15:08:03,411] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:08:03,831] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:08:03,883] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:08:03,890] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:08:03,894] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 15:08:16,669] {scheduler_job.py:155} INFO - Started process (PID=6136) to work on /airflow/dags/download_data.py
[2022-02-17 15:08:16,679] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:08:16,682] {logging_mixin.py:112} INFO - [2022-02-17 15:08:16,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:08:17,153] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:08:17,190] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:08:17,195] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:08:17,198] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 15:08:29,956] {scheduler_job.py:155} INFO - Started process (PID=6162) to work on /airflow/dags/download_data.py
[2022-02-17 15:08:29,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:08:29,963] {logging_mixin.py:112} INFO - [2022-02-17 15:08:29,962] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:08:30,396] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:08:30,428] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:08:30,434] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:08:30,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.481 seconds
[2022-02-17 15:08:43,215] {scheduler_job.py:155} INFO - Started process (PID=6190) to work on /airflow/dags/download_data.py
[2022-02-17 15:08:43,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:08:43,231] {logging_mixin.py:112} INFO - [2022-02-17 15:08:43,230] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:08:43,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:08:43,842] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:08:43,848] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:08:43,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-17 15:08:56,556] {scheduler_job.py:155} INFO - Started process (PID=6216) to work on /airflow/dags/download_data.py
[2022-02-17 15:08:56,565] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:08:56,568] {logging_mixin.py:112} INFO - [2022-02-17 15:08:56,567] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:08:57,046] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:08:57,096] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:08:57,103] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:08:57,107] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 15:09:09,855] {scheduler_job.py:155} INFO - Started process (PID=6244) to work on /airflow/dags/download_data.py
[2022-02-17 15:09:09,862] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:09:09,865] {logging_mixin.py:112} INFO - [2022-02-17 15:09:09,864] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:09:10,288] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:09:10,339] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:09:10,345] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:09:10,350] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 15:09:23,095] {scheduler_job.py:155} INFO - Started process (PID=6270) to work on /airflow/dags/download_data.py
[2022-02-17 15:09:23,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:09:23,100] {logging_mixin.py:112} INFO - [2022-02-17 15:09:23,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:09:23,554] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:09:23,601] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:09:23,610] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:09:23,617] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 15:09:36,392] {scheduler_job.py:155} INFO - Started process (PID=6298) to work on /airflow/dags/download_data.py
[2022-02-17 15:09:36,399] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:09:36,401] {logging_mixin.py:112} INFO - [2022-02-17 15:09:36,401] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:09:36,839] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:09:36,888] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:09:36,897] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:09:36,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 15:09:49,667] {scheduler_job.py:155} INFO - Started process (PID=6324) to work on /airflow/dags/download_data.py
[2022-02-17 15:09:49,673] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:09:49,675] {logging_mixin.py:112} INFO - [2022-02-17 15:09:49,675] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:09:50,132] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:09:50,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:09:50,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:09:50,194] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 15:10:02,997] {scheduler_job.py:155} INFO - Started process (PID=6350) to work on /airflow/dags/download_data.py
[2022-02-17 15:10:03,005] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:10:03,007] {logging_mixin.py:112} INFO - [2022-02-17 15:10:03,007] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:10:03,450] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:10:03,500] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:10:03,509] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:10:03,516] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 15:10:16,244] {scheduler_job.py:155} INFO - Started process (PID=6378) to work on /airflow/dags/download_data.py
[2022-02-17 15:10:16,249] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:10:16,251] {logging_mixin.py:112} INFO - [2022-02-17 15:10:16,251] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:10:16,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:10:16,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:10:16,768] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:10:16,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 15:10:29,536] {scheduler_job.py:155} INFO - Started process (PID=6404) to work on /airflow/dags/download_data.py
[2022-02-17 15:10:29,541] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:10:29,542] {logging_mixin.py:112} INFO - [2022-02-17 15:10:29,542] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:10:29,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:10:30,019] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:10:30,027] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:10:30,032] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 15:10:42,826] {scheduler_job.py:155} INFO - Started process (PID=6432) to work on /airflow/dags/download_data.py
[2022-02-17 15:10:42,839] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:10:42,841] {logging_mixin.py:112} INFO - [2022-02-17 15:10:42,841] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:10:43,279] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:10:43,330] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:10:43,338] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:10:43,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 15:10:56,141] {scheduler_job.py:155} INFO - Started process (PID=6458) to work on /airflow/dags/download_data.py
[2022-02-17 15:10:56,148] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:10:56,151] {logging_mixin.py:112} INFO - [2022-02-17 15:10:56,150] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:10:56,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:10:56,637] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:10:56,644] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:10:56,648] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 15:11:09,423] {scheduler_job.py:155} INFO - Started process (PID=6486) to work on /airflow/dags/download_data.py
[2022-02-17 15:11:09,427] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:11:09,429] {logging_mixin.py:112} INFO - [2022-02-17 15:11:09,429] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:11:09,863] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:11:09,895] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:11:09,900] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:11:09,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.481 seconds
[2022-02-17 15:11:22,714] {scheduler_job.py:155} INFO - Started process (PID=6512) to work on /airflow/dags/download_data.py
[2022-02-17 15:11:22,724] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:11:22,727] {logging_mixin.py:112} INFO - [2022-02-17 15:11:22,726] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:11:23,176] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:11:23,224] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:11:23,231] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:11:23,238] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 15:11:36,181] {scheduler_job.py:155} INFO - Started process (PID=6540) to work on /airflow/dags/download_data.py
[2022-02-17 15:11:36,188] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:11:36,189] {logging_mixin.py:112} INFO - [2022-02-17 15:11:36,189] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:11:36,668] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:11:36,713] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:11:36,723] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:11:36,728] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 15:11:49,491] {scheduler_job.py:155} INFO - Started process (PID=6566) to work on /airflow/dags/download_data.py
[2022-02-17 15:11:49,495] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:11:49,497] {logging_mixin.py:112} INFO - [2022-02-17 15:11:49,496] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:11:49,935] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:11:49,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:11:50,004] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:11:50,012] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 15:12:02,784] {scheduler_job.py:155} INFO - Started process (PID=6592) to work on /airflow/dags/download_data.py
[2022-02-17 15:12:02,790] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:12:02,794] {logging_mixin.py:112} INFO - [2022-02-17 15:12:02,794] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:12:03,238] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:12:03,282] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:12:03,290] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:12:03,295] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 15:12:16,032] {scheduler_job.py:155} INFO - Started process (PID=6620) to work on /airflow/dags/download_data.py
[2022-02-17 15:12:16,036] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:12:16,038] {logging_mixin.py:112} INFO - [2022-02-17 15:12:16,038] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:12:16,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:12:16,551] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:12:16,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:12:16,570] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 15:12:29,306] {scheduler_job.py:155} INFO - Started process (PID=6646) to work on /airflow/dags/download_data.py
[2022-02-17 15:12:29,311] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:12:29,312] {logging_mixin.py:112} INFO - [2022-02-17 15:12:29,312] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:12:29,779] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:12:29,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:12:29,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:12:29,832] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 15:12:42,660] {scheduler_job.py:155} INFO - Started process (PID=6674) to work on /airflow/dags/download_data.py
[2022-02-17 15:12:42,670] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:12:42,672] {logging_mixin.py:112} INFO - [2022-02-17 15:12:42,672] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:12:43,082] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:12:43,131] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:12:43,138] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:12:43,143] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.483 seconds
[2022-02-17 15:12:55,911] {scheduler_job.py:155} INFO - Started process (PID=6700) to work on /airflow/dags/download_data.py
[2022-02-17 15:12:55,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:12:55,919] {logging_mixin.py:112} INFO - [2022-02-17 15:12:55,919] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:12:56,390] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:12:56,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:12:56,450] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:12:56,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 15:13:09,164] {scheduler_job.py:155} INFO - Started process (PID=6728) to work on /airflow/dags/download_data.py
[2022-02-17 15:13:09,168] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:13:09,170] {logging_mixin.py:112} INFO - [2022-02-17 15:13:09,169] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:13:09,619] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:13:09,670] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:13:09,679] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:13:09,685] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 15:13:22,429] {scheduler_job.py:155} INFO - Started process (PID=6754) to work on /airflow/dags/download_data.py
[2022-02-17 15:13:22,433] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:13:22,435] {logging_mixin.py:112} INFO - [2022-02-17 15:13:22,435] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:13:22,866] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:13:22,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:13:22,938] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:13:22,944] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 15:13:35,739] {scheduler_job.py:155} INFO - Started process (PID=6780) to work on /airflow/dags/download_data.py
[2022-02-17 15:13:35,745] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:13:35,746] {logging_mixin.py:112} INFO - [2022-02-17 15:13:35,746] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:13:36,199] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:13:36,236] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:13:36,245] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:13:36,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 15:13:49,045] {scheduler_job.py:155} INFO - Started process (PID=6808) to work on /airflow/dags/download_data.py
[2022-02-17 15:13:49,051] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:13:49,053] {logging_mixin.py:112} INFO - [2022-02-17 15:13:49,053] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:13:49,494] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:13:49,535] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:13:49,545] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:13:49,549] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 15:14:02,331] {scheduler_job.py:155} INFO - Started process (PID=6834) to work on /airflow/dags/download_data.py
[2022-02-17 15:14:02,338] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:14:02,342] {logging_mixin.py:112} INFO - [2022-02-17 15:14:02,341] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:14:02,774] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:14:02,818] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:14:02,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:14:02,832] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 15:14:15,625] {scheduler_job.py:155} INFO - Started process (PID=6862) to work on /airflow/dags/download_data.py
[2022-02-17 15:14:15,637] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:14:15,641] {logging_mixin.py:112} INFO - [2022-02-17 15:14:15,640] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:14:16,079] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:14:16,142] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:14:16,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:14:16,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 15:14:28,926] {scheduler_job.py:155} INFO - Started process (PID=6888) to work on /airflow/dags/download_data.py
[2022-02-17 15:14:28,932] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:14:28,933] {logging_mixin.py:112} INFO - [2022-02-17 15:14:28,933] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:14:29,376] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:14:29,423] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:14:29,432] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:14:29,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 15:14:42,199] {scheduler_job.py:155} INFO - Started process (PID=6916) to work on /airflow/dags/download_data.py
[2022-02-17 15:14:42,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:14:42,211] {logging_mixin.py:112} INFO - [2022-02-17 15:14:42,211] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:14:42,888] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:14:42,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:14:42,950] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:14:42,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.755 seconds
[2022-02-17 15:14:55,477] {scheduler_job.py:155} INFO - Started process (PID=6942) to work on /airflow/dags/download_data.py
[2022-02-17 15:14:55,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:14:55,490] {logging_mixin.py:112} INFO - [2022-02-17 15:14:55,490] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:14:55,942] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:14:56,006] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:14:56,024] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:14:56,029] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 15:15:08,807] {scheduler_job.py:155} INFO - Started process (PID=6968) to work on /airflow/dags/download_data.py
[2022-02-17 15:15:08,816] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:15:08,818] {logging_mixin.py:112} INFO - [2022-02-17 15:15:08,817] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:15:09,242] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:15:09,285] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:15:09,291] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:15:09,295] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 15:15:22,037] {scheduler_job.py:155} INFO - Started process (PID=6996) to work on /airflow/dags/download_data.py
[2022-02-17 15:15:22,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:15:22,046] {logging_mixin.py:112} INFO - [2022-02-17 15:15:22,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:15:22,486] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:15:22,533] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:15:22,543] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:15:22,548] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 15:15:35,344] {scheduler_job.py:155} INFO - Started process (PID=7022) to work on /airflow/dags/download_data.py
[2022-02-17 15:15:35,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:15:35,351] {logging_mixin.py:112} INFO - [2022-02-17 15:15:35,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:15:35,789] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:15:35,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:15:35,852] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:15:35,856] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 15:15:48,641] {scheduler_job.py:155} INFO - Started process (PID=7050) to work on /airflow/dags/download_data.py
[2022-02-17 15:15:48,648] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:15:48,650] {logging_mixin.py:112} INFO - [2022-02-17 15:15:48,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:15:49,107] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:15:49,165] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:15:49,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:15:49,176] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 15:16:01,917] {scheduler_job.py:155} INFO - Started process (PID=7076) to work on /airflow/dags/download_data.py
[2022-02-17 15:16:01,923] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:16:01,926] {logging_mixin.py:112} INFO - [2022-02-17 15:16:01,925] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:16:02,379] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:16:02,430] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:16:02,441] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:16:02,446] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 15:16:15,179] {scheduler_job.py:155} INFO - Started process (PID=7104) to work on /airflow/dags/download_data.py
[2022-02-17 15:16:15,184] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:16:15,186] {logging_mixin.py:112} INFO - [2022-02-17 15:16:15,185] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:16:15,652] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:16:15,710] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:16:15,721] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:16:15,725] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 15:16:28,466] {scheduler_job.py:155} INFO - Started process (PID=7130) to work on /airflow/dags/download_data.py
[2022-02-17 15:16:28,471] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:16:28,473] {logging_mixin.py:112} INFO - [2022-02-17 15:16:28,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:16:28,921] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:16:28,969] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:16:28,977] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:16:28,982] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 15:16:41,804] {scheduler_job.py:155} INFO - Started process (PID=7156) to work on /airflow/dags/download_data.py
[2022-02-17 15:16:41,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:16:41,810] {logging_mixin.py:112} INFO - [2022-02-17 15:16:41,810] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:16:42,245] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:16:42,291] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:16:42,305] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:16:42,311] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 15:16:55,105] {scheduler_job.py:155} INFO - Started process (PID=7184) to work on /airflow/dags/download_data.py
[2022-02-17 15:16:55,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:16:55,116] {logging_mixin.py:112} INFO - [2022-02-17 15:16:55,115] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:16:55,559] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:16:55,606] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:16:55,611] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:16:55,615] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 15:17:08,418] {scheduler_job.py:155} INFO - Started process (PID=7210) to work on /airflow/dags/download_data.py
[2022-02-17 15:17:08,425] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:17:08,427] {logging_mixin.py:112} INFO - [2022-02-17 15:17:08,426] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:17:08,872] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:17:08,921] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:17:08,927] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:17:08,931] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 15:17:21,658] {scheduler_job.py:155} INFO - Started process (PID=7238) to work on /airflow/dags/download_data.py
[2022-02-17 15:17:21,668] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:17:21,671] {logging_mixin.py:112} INFO - [2022-02-17 15:17:21,670] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:17:22,100] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:17:22,141] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:17:22,148] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:17:22,153] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 15:17:34,939] {scheduler_job.py:155} INFO - Started process (PID=7264) to work on /airflow/dags/download_data.py
[2022-02-17 15:17:34,945] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:17:34,947] {logging_mixin.py:112} INFO - [2022-02-17 15:17:34,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:17:35,370] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:17:35,411] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:17:35,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:17:35,422] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.483 seconds
[2022-02-17 15:17:48,168] {scheduler_job.py:155} INFO - Started process (PID=7292) to work on /airflow/dags/download_data.py
[2022-02-17 15:17:48,172] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:17:48,174] {logging_mixin.py:112} INFO - [2022-02-17 15:17:48,174] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:17:48,629] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:17:48,673] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:17:48,679] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:17:48,685] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 15:18:01,475] {scheduler_job.py:155} INFO - Started process (PID=7318) to work on /airflow/dags/download_data.py
[2022-02-17 15:18:01,482] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:18:01,484] {logging_mixin.py:112} INFO - [2022-02-17 15:18:01,484] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:18:01,917] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:18:01,967] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:18:01,973] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:18:01,978] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 15:18:14,721] {scheduler_job.py:155} INFO - Started process (PID=7346) to work on /airflow/dags/download_data.py
[2022-02-17 15:18:14,726] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:18:14,729] {logging_mixin.py:112} INFO - [2022-02-17 15:18:14,728] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:18:15,259] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:18:15,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:18:15,323] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:18:15,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 15:18:28,048] {scheduler_job.py:155} INFO - Started process (PID=7372) to work on /airflow/dags/download_data.py
[2022-02-17 15:18:28,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:18:28,057] {logging_mixin.py:112} INFO - [2022-02-17 15:18:28,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:18:28,483] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:18:28,527] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:18:28,534] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:18:28,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 15:18:41,338] {scheduler_job.py:155} INFO - Started process (PID=7398) to work on /airflow/dags/download_data.py
[2022-02-17 15:18:41,344] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:18:41,347] {logging_mixin.py:112} INFO - [2022-02-17 15:18:41,346] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:18:41,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:18:41,829] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:18:41,838] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:18:41,844] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 15:18:54,625] {scheduler_job.py:155} INFO - Started process (PID=7426) to work on /airflow/dags/download_data.py
[2022-02-17 15:18:54,632] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:18:54,634] {logging_mixin.py:112} INFO - [2022-02-17 15:18:54,634] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:18:55,119] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:18:55,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:18:55,184] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:18:55,191] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 15:19:07,941] {scheduler_job.py:155} INFO - Started process (PID=7452) to work on /airflow/dags/download_data.py
[2022-02-17 15:19:07,949] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:19:07,951] {logging_mixin.py:112} INFO - [2022-02-17 15:19:07,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:19:08,383] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:19:08,433] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:19:08,442] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:19:08,448] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 15:19:21,229] {scheduler_job.py:155} INFO - Started process (PID=7480) to work on /airflow/dags/download_data.py
[2022-02-17 15:19:21,237] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:19:21,240] {logging_mixin.py:112} INFO - [2022-02-17 15:19:21,240] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:19:21,699] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:19:21,754] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:19:21,763] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:19:21,768] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 15:19:34,513] {scheduler_job.py:155} INFO - Started process (PID=7506) to work on /airflow/dags/download_data.py
[2022-02-17 15:19:34,518] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:19:34,519] {logging_mixin.py:112} INFO - [2022-02-17 15:19:34,519] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:19:34,953] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:19:34,995] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:19:35,005] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:19:35,010] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 15:19:47,825] {scheduler_job.py:155} INFO - Started process (PID=7534) to work on /airflow/dags/download_data.py
[2022-02-17 15:19:47,829] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:19:47,831] {logging_mixin.py:112} INFO - [2022-02-17 15:19:47,831] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:19:48,293] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:19:48,358] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:19:48,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:19:48,376] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 15:20:01,198] {scheduler_job.py:155} INFO - Started process (PID=7560) to work on /airflow/dags/download_data.py
[2022-02-17 15:20:01,203] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:20:01,209] {logging_mixin.py:112} INFO - [2022-02-17 15:20:01,209] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:20:01,661] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:20:01,708] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:20:01,716] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:20:01,720] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 15:20:14,468] {scheduler_job.py:155} INFO - Started process (PID=7586) to work on /airflow/dags/download_data.py
[2022-02-17 15:20:14,475] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:20:14,478] {logging_mixin.py:112} INFO - [2022-02-17 15:20:14,478] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:20:14,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:20:14,946] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:20:14,952] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:20:14,958] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 15:20:27,794] {scheduler_job.py:155} INFO - Started process (PID=7614) to work on /airflow/dags/download_data.py
[2022-02-17 15:20:27,798] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:20:27,800] {logging_mixin.py:112} INFO - [2022-02-17 15:20:27,800] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:20:28,248] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:20:28,298] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:20:28,308] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:20:28,314] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 15:20:41,103] {scheduler_job.py:155} INFO - Started process (PID=7640) to work on /airflow/dags/download_data.py
[2022-02-17 15:20:41,116] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:20:41,118] {logging_mixin.py:112} INFO - [2022-02-17 15:20:41,118] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:20:41,553] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:20:41,598] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:20:41,605] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:20:41,611] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 15:20:54,343] {scheduler_job.py:155} INFO - Started process (PID=7668) to work on /airflow/dags/download_data.py
[2022-02-17 15:20:54,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:20:54,350] {logging_mixin.py:112} INFO - [2022-02-17 15:20:54,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:20:54,811] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:20:54,856] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:20:54,870] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:20:54,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 15:21:07,626] {scheduler_job.py:155} INFO - Started process (PID=7694) to work on /airflow/dags/download_data.py
[2022-02-17 15:21:07,630] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:21:07,632] {logging_mixin.py:112} INFO - [2022-02-17 15:21:07,632] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:21:08,080] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:21:08,129] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:21:08,137] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:21:08,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 15:21:20,859] {scheduler_job.py:155} INFO - Started process (PID=7722) to work on /airflow/dags/download_data.py
[2022-02-17 15:21:20,863] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:21:20,864] {logging_mixin.py:112} INFO - [2022-02-17 15:21:20,864] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:21:21,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:21:21,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:21:21,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:21:21,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 15:21:34,180] {scheduler_job.py:155} INFO - Started process (PID=7748) to work on /airflow/dags/download_data.py
[2022-02-17 15:21:34,184] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:21:34,186] {logging_mixin.py:112} INFO - [2022-02-17 15:21:34,186] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:21:34,616] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:21:34,662] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:21:34,671] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:21:34,677] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 15:21:47,472] {scheduler_job.py:155} INFO - Started process (PID=7774) to work on /airflow/dags/download_data.py
[2022-02-17 15:21:47,483] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:21:47,487] {logging_mixin.py:112} INFO - [2022-02-17 15:21:47,486] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:21:48,009] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:21:48,077] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:21:48,086] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:21:48,093] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-17 15:22:00,742] {scheduler_job.py:155} INFO - Started process (PID=7802) to work on /airflow/dags/download_data.py
[2022-02-17 15:22:00,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:22:00,755] {logging_mixin.py:112} INFO - [2022-02-17 15:22:00,749] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:22:01,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:22:01,228] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:22:01,236] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:22:01,244] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 15:22:14,024] {scheduler_job.py:155} INFO - Started process (PID=7828) to work on /airflow/dags/download_data.py
[2022-02-17 15:22:14,029] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:22:14,030] {logging_mixin.py:112} INFO - [2022-02-17 15:22:14,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:22:14,479] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:22:14,535] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:22:14,545] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:22:14,552] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 15:22:27,325] {scheduler_job.py:155} INFO - Started process (PID=7856) to work on /airflow/dags/download_data.py
[2022-02-17 15:22:27,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:22:27,334] {logging_mixin.py:112} INFO - [2022-02-17 15:22:27,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:22:27,767] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:22:27,820] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:22:27,826] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:22:27,829] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 15:22:40,649] {scheduler_job.py:155} INFO - Started process (PID=7882) to work on /airflow/dags/download_data.py
[2022-02-17 15:22:40,656] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:22:40,658] {logging_mixin.py:112} INFO - [2022-02-17 15:22:40,657] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:22:41,084] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:22:41,134] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:22:41,144] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:22:41,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 15:22:53,931] {scheduler_job.py:155} INFO - Started process (PID=7910) to work on /airflow/dags/download_data.py
[2022-02-17 15:22:53,940] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:22:53,942] {logging_mixin.py:112} INFO - [2022-02-17 15:22:53,942] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:22:54,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:22:54,433] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:22:54,443] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:22:54,448] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 15:23:07,185] {scheduler_job.py:155} INFO - Started process (PID=7936) to work on /airflow/dags/download_data.py
[2022-02-17 15:23:07,195] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:23:07,197] {logging_mixin.py:112} INFO - [2022-02-17 15:23:07,196] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:23:07,802] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:23:07,855] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:23:07,861] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:23:07,865] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.680 seconds
[2022-02-17 15:23:20,408] {scheduler_job.py:155} INFO - Started process (PID=7962) to work on /airflow/dags/download_data.py
[2022-02-17 15:23:20,412] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:23:20,414] {logging_mixin.py:112} INFO - [2022-02-17 15:23:20,414] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:23:20,920] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:23:20,970] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:23:20,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:23:20,986] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 15:23:33,692] {scheduler_job.py:155} INFO - Started process (PID=7990) to work on /airflow/dags/download_data.py
[2022-02-17 15:23:33,696] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:23:33,698] {logging_mixin.py:112} INFO - [2022-02-17 15:23:33,698] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:23:34,142] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:23:34,192] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:23:34,202] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:23:34,208] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 15:23:46,966] {scheduler_job.py:155} INFO - Started process (PID=8016) to work on /airflow/dags/download_data.py
[2022-02-17 15:23:46,971] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:23:46,973] {logging_mixin.py:112} INFO - [2022-02-17 15:23:46,973] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:23:47,420] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:23:47,484] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:23:47,489] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:23:47,493] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 15:24:00,295] {scheduler_job.py:155} INFO - Started process (PID=8044) to work on /airflow/dags/download_data.py
[2022-02-17 15:24:00,302] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:24:00,305] {logging_mixin.py:112} INFO - [2022-02-17 15:24:00,304] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:24:00,726] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:24:00,775] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:24:00,783] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:24:00,789] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 15:24:13,553] {scheduler_job.py:155} INFO - Started process (PID=8070) to work on /airflow/dags/download_data.py
[2022-02-17 15:24:13,559] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:24:13,560] {logging_mixin.py:112} INFO - [2022-02-17 15:24:13,560] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:24:14,018] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:24:14,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:24:14,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:24:14,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 15:24:26,891] {scheduler_job.py:155} INFO - Started process (PID=8098) to work on /airflow/dags/download_data.py
[2022-02-17 15:24:26,897] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:24:26,899] {logging_mixin.py:112} INFO - [2022-02-17 15:24:26,899] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:24:27,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:24:27,433] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:24:27,438] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:24:27,441] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 15:24:40,156] {scheduler_job.py:155} INFO - Started process (PID=8124) to work on /airflow/dags/download_data.py
[2022-02-17 15:24:40,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:24:40,167] {logging_mixin.py:112} INFO - [2022-02-17 15:24:40,167] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:24:40,643] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:24:40,695] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:24:40,704] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:24:40,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 15:24:53,399] {scheduler_job.py:155} INFO - Started process (PID=8152) to work on /airflow/dags/download_data.py
[2022-02-17 15:24:53,404] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:24:53,407] {logging_mixin.py:112} INFO - [2022-02-17 15:24:53,407] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:24:53,934] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:24:53,988] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:24:54,002] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:24:54,010] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-17 15:25:06,706] {scheduler_job.py:155} INFO - Started process (PID=8178) to work on /airflow/dags/download_data.py
[2022-02-17 15:25:06,710] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:25:06,712] {logging_mixin.py:112} INFO - [2022-02-17 15:25:06,712] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:25:07,139] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:25:07,187] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:25:07,194] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:25:07,198] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 15:25:19,943] {scheduler_job.py:155} INFO - Started process (PID=8204) to work on /airflow/dags/download_data.py
[2022-02-17 15:25:19,948] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:25:19,950] {logging_mixin.py:112} INFO - [2022-02-17 15:25:19,949] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:25:20,383] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:25:20,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:25:20,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:25:20,436] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 15:25:33,269] {scheduler_job.py:155} INFO - Started process (PID=8232) to work on /airflow/dags/download_data.py
[2022-02-17 15:25:33,274] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:25:33,276] {logging_mixin.py:112} INFO - [2022-02-17 15:25:33,276] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:25:33,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:25:33,762] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:25:33,770] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:25:33,775] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 15:25:46,559] {scheduler_job.py:155} INFO - Started process (PID=8258) to work on /airflow/dags/download_data.py
[2022-02-17 15:25:46,564] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:25:46,566] {logging_mixin.py:112} INFO - [2022-02-17 15:25:46,565] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:25:47,032] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:25:47,089] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:25:47,099] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:25:47,106] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 15:25:59,888] {scheduler_job.py:155} INFO - Started process (PID=8286) to work on /airflow/dags/download_data.py
[2022-02-17 15:25:59,899] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:25:59,901] {logging_mixin.py:112} INFO - [2022-02-17 15:25:59,901] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:26:00,348] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:26:00,395] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:26:00,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:26:00,411] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 15:26:13,143] {scheduler_job.py:155} INFO - Started process (PID=8312) to work on /airflow/dags/download_data.py
[2022-02-17 15:26:13,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:26:13,149] {logging_mixin.py:112} INFO - [2022-02-17 15:26:13,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:26:13,603] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:26:13,654] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:26:13,664] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:26:13,668] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 15:26:27,521] {scheduler_job.py:155} INFO - Started process (PID=8340) to work on /airflow/dags/download_data.py
[2022-02-17 15:26:27,525] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 15:26:27,533] {logging_mixin.py:112} INFO - [2022-02-17 15:26:27,532] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 15:26:28,008] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 15:26:28,055] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 15:26:28,063] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 15:26:28,069] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 16:00:27,212] {scheduler_job.py:155} INFO - Started process (PID=8376) to work on /airflow/dags/download_data.py
[2022-02-17 16:00:27,223] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:00:27,225] {logging_mixin.py:112} INFO - [2022-02-17 16:00:27,225] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:00:27,678] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:00:27,744] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:00:27,756] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:00:27,760] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 16:00:40,531] {scheduler_job.py:155} INFO - Started process (PID=8402) to work on /airflow/dags/download_data.py
[2022-02-17 16:00:40,545] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:00:40,547] {logging_mixin.py:112} INFO - [2022-02-17 16:00:40,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:00:41,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:00:41,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:00:41,053] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:00:41,058] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 16:00:53,828] {scheduler_job.py:155} INFO - Started process (PID=8430) to work on /airflow/dags/download_data.py
[2022-02-17 16:00:53,838] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:00:53,840] {logging_mixin.py:112} INFO - [2022-02-17 16:00:53,840] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:00:54,258] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:00:54,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:00:54,310] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:00:54,316] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 16:01:07,113] {scheduler_job.py:155} INFO - Started process (PID=8456) to work on /airflow/dags/download_data.py
[2022-02-17 16:01:07,117] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:01:07,119] {logging_mixin.py:112} INFO - [2022-02-17 16:01:07,119] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:01:07,551] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:01:07,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:01:07,609] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:01:07,612] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 16:01:20,429] {scheduler_job.py:155} INFO - Started process (PID=8482) to work on /airflow/dags/download_data.py
[2022-02-17 16:01:20,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:01:20,436] {logging_mixin.py:112} INFO - [2022-02-17 16:01:20,436] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:01:20,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:01:20,904] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:01:20,912] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:01:20,932] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 16:01:33,732] {scheduler_job.py:155} INFO - Started process (PID=8510) to work on /airflow/dags/download_data.py
[2022-02-17 16:01:33,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:01:33,745] {logging_mixin.py:112} INFO - [2022-02-17 16:01:33,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:01:34,217] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:01:34,279] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:01:34,287] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:01:34,295] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 16:01:46,986] {scheduler_job.py:155} INFO - Started process (PID=8536) to work on /airflow/dags/download_data.py
[2022-02-17 16:01:46,996] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:01:46,999] {logging_mixin.py:112} INFO - [2022-02-17 16:01:46,998] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:01:47,423] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:01:47,471] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:01:47,478] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:01:47,483] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 16:02:00,239] {scheduler_job.py:155} INFO - Started process (PID=8564) to work on /airflow/dags/download_data.py
[2022-02-17 16:02:00,246] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:02:00,249] {logging_mixin.py:112} INFO - [2022-02-17 16:02:00,248] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:02:00,689] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:02:00,736] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:02:00,745] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:02:00,749] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 16:02:13,522] {scheduler_job.py:155} INFO - Started process (PID=8590) to work on /airflow/dags/download_data.py
[2022-02-17 16:02:13,526] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:02:13,528] {logging_mixin.py:112} INFO - [2022-02-17 16:02:13,528] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:02:13,968] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:02:14,016] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:02:14,026] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:02:14,030] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 16:02:27,027] {scheduler_job.py:155} INFO - Started process (PID=8618) to work on /airflow/dags/download_data.py
[2022-02-17 16:02:27,039] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:02:27,041] {logging_mixin.py:112} INFO - [2022-02-17 16:02:27,041] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:02:27,546] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:02:27,610] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:02:27,624] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:02:27,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 16:02:40,317] {scheduler_job.py:155} INFO - Started process (PID=8644) to work on /airflow/dags/download_data.py
[2022-02-17 16:02:40,321] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:02:40,324] {logging_mixin.py:112} INFO - [2022-02-17 16:02:40,323] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:02:40,758] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:02:40,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:02:40,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:02:40,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 16:02:53,554] {scheduler_job.py:155} INFO - Started process (PID=8670) to work on /airflow/dags/download_data.py
[2022-02-17 16:02:53,559] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:02:53,561] {logging_mixin.py:112} INFO - [2022-02-17 16:02:53,560] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:02:53,981] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:02:54,030] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:02:54,038] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:02:54,045] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 16:03:06,847] {scheduler_job.py:155} INFO - Started process (PID=8698) to work on /airflow/dags/download_data.py
[2022-02-17 16:03:06,853] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:03:06,854] {logging_mixin.py:112} INFO - [2022-02-17 16:03:06,854] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:03:07,279] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:03:07,330] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:03:07,338] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:03:07,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 16:03:20,103] {scheduler_job.py:155} INFO - Started process (PID=8724) to work on /airflow/dags/download_data.py
[2022-02-17 16:03:20,116] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:03:20,118] {logging_mixin.py:112} INFO - [2022-02-17 16:03:20,118] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:03:20,691] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:03:20,752] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:03:20,759] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:03:20,769] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-17 16:03:33,349] {scheduler_job.py:155} INFO - Started process (PID=8752) to work on /airflow/dags/download_data.py
[2022-02-17 16:03:33,354] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:03:33,356] {logging_mixin.py:112} INFO - [2022-02-17 16:03:33,356] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:03:33,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:03:33,876] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:03:33,884] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:03:33,887] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 16:03:46,664] {scheduler_job.py:155} INFO - Started process (PID=8778) to work on /airflow/dags/download_data.py
[2022-02-17 16:03:46,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:03:46,671] {logging_mixin.py:112} INFO - [2022-02-17 16:03:46,671] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:03:47,119] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:03:47,168] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:03:47,177] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:03:47,181] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 16:03:59,970] {scheduler_job.py:155} INFO - Started process (PID=8806) to work on /airflow/dags/download_data.py
[2022-02-17 16:03:59,977] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:03:59,979] {logging_mixin.py:112} INFO - [2022-02-17 16:03:59,979] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:04:00,425] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:04:00,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:04:00,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:04:00,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 16:04:13,249] {scheduler_job.py:155} INFO - Started process (PID=8832) to work on /airflow/dags/download_data.py
[2022-02-17 16:04:13,257] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:04:13,259] {logging_mixin.py:112} INFO - [2022-02-17 16:04:13,259] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:04:13,688] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:04:13,737] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:04:13,744] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:04:13,748] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 16:04:26,526] {scheduler_job.py:155} INFO - Started process (PID=8858) to work on /airflow/dags/download_data.py
[2022-02-17 16:04:26,530] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:04:26,536] {logging_mixin.py:112} INFO - [2022-02-17 16:04:26,536] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:04:27,165] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:04:27,221] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:04:27,232] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:04:27,237] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.711 seconds
[2022-02-17 16:04:39,819] {scheduler_job.py:155} INFO - Started process (PID=8886) to work on /airflow/dags/download_data.py
[2022-02-17 16:04:39,826] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:04:39,829] {logging_mixin.py:112} INFO - [2022-02-17 16:04:39,828] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:04:40,285] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:04:40,332] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:04:40,340] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:04:40,345] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 16:04:53,054] {scheduler_job.py:155} INFO - Started process (PID=8912) to work on /airflow/dags/download_data.py
[2022-02-17 16:04:53,059] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:04:53,061] {logging_mixin.py:112} INFO - [2022-02-17 16:04:53,061] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:04:53,503] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:04:53,557] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:04:53,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:04:53,566] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 16:05:06,328] {scheduler_job.py:155} INFO - Started process (PID=8940) to work on /airflow/dags/download_data.py
[2022-02-17 16:05:06,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:05:06,333] {logging_mixin.py:112} INFO - [2022-02-17 16:05:06,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:05:06,772] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:05:06,820] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:05:06,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:05:06,831] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 16:05:19,669] {scheduler_job.py:155} INFO - Started process (PID=8966) to work on /airflow/dags/download_data.py
[2022-02-17 16:05:19,679] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:05:19,681] {logging_mixin.py:112} INFO - [2022-02-17 16:05:19,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:05:20,108] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:05:20,163] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:05:20,168] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:05:20,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 16:05:32,974] {scheduler_job.py:155} INFO - Started process (PID=8994) to work on /airflow/dags/download_data.py
[2022-02-17 16:05:32,979] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:05:32,981] {logging_mixin.py:112} INFO - [2022-02-17 16:05:32,981] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:05:33,419] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:05:33,483] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:05:33,498] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:05:33,504] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 16:05:46,259] {scheduler_job.py:155} INFO - Started process (PID=9020) to work on /airflow/dags/download_data.py
[2022-02-17 16:05:46,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:05:46,268] {logging_mixin.py:112} INFO - [2022-02-17 16:05:46,267] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:05:46,709] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:05:46,751] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:05:46,757] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:05:46,761] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 16:05:59,554] {scheduler_job.py:155} INFO - Started process (PID=9048) to work on /airflow/dags/download_data.py
[2022-02-17 16:05:59,566] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:05:59,570] {logging_mixin.py:112} INFO - [2022-02-17 16:05:59,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:06:00,101] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:06:00,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:06:00,179] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:06:00,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.631 seconds
[2022-02-17 16:06:12,907] {scheduler_job.py:155} INFO - Started process (PID=9074) to work on /airflow/dags/download_data.py
[2022-02-17 16:06:12,912] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:06:12,914] {logging_mixin.py:112} INFO - [2022-02-17 16:06:12,914] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:06:13,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:06:13,397] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:06:13,406] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:06:13,411] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 16:06:26,192] {scheduler_job.py:155} INFO - Started process (PID=9100) to work on /airflow/dags/download_data.py
[2022-02-17 16:06:26,202] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:06:26,205] {logging_mixin.py:112} INFO - [2022-02-17 16:06:26,204] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:06:26,649] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:06:26,708] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:06:26,719] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:06:26,724] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 16:06:39,522] {scheduler_job.py:155} INFO - Started process (PID=9128) to work on /airflow/dags/download_data.py
[2022-02-17 16:06:39,530] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:06:39,532] {logging_mixin.py:112} INFO - [2022-02-17 16:06:39,531] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:06:39,996] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:06:40,034] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:06:40,040] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:06:40,044] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 16:06:52,758] {scheduler_job.py:155} INFO - Started process (PID=9154) to work on /airflow/dags/download_data.py
[2022-02-17 16:06:52,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:06:52,764] {logging_mixin.py:112} INFO - [2022-02-17 16:06:52,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:06:53,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:06:53,255] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:06:53,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:06:53,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 16:07:06,093] {scheduler_job.py:155} INFO - Started process (PID=9182) to work on /airflow/dags/download_data.py
[2022-02-17 16:07:06,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:07:06,101] {logging_mixin.py:112} INFO - [2022-02-17 16:07:06,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:07:06,530] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:07:06,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:07:06,597] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:07:06,602] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 16:07:19,352] {scheduler_job.py:155} INFO - Started process (PID=9208) to work on /airflow/dags/download_data.py
[2022-02-17 16:07:19,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:07:19,359] {logging_mixin.py:112} INFO - [2022-02-17 16:07:19,359] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:07:19,794] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:07:19,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:07:19,851] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:07:19,857] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 16:07:32,651] {scheduler_job.py:155} INFO - Started process (PID=9236) to work on /airflow/dags/download_data.py
[2022-02-17 16:07:32,655] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:07:32,657] {logging_mixin.py:112} INFO - [2022-02-17 16:07:32,657] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:07:33,126] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:07:33,176] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:07:33,186] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:07:33,191] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 16:07:45,956] {scheduler_job.py:155} INFO - Started process (PID=9262) to work on /airflow/dags/download_data.py
[2022-02-17 16:07:45,962] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:07:45,964] {logging_mixin.py:112} INFO - [2022-02-17 16:07:45,964] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:07:46,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:07:46,451] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:07:46,460] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:07:46,464] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 16:07:59,221] {scheduler_job.py:155} INFO - Started process (PID=9288) to work on /airflow/dags/download_data.py
[2022-02-17 16:07:59,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:07:59,228] {logging_mixin.py:112} INFO - [2022-02-17 16:07:59,228] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:07:59,702] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:07:59,745] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:07:59,759] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:07:59,764] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 16:08:12,558] {scheduler_job.py:155} INFO - Started process (PID=9316) to work on /airflow/dags/download_data.py
[2022-02-17 16:08:12,563] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:08:12,564] {logging_mixin.py:112} INFO - [2022-02-17 16:08:12,564] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:08:13,007] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:08:13,041] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:08:13,048] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:08:13,052] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 16:08:25,793] {scheduler_job.py:155} INFO - Started process (PID=9342) to work on /airflow/dags/download_data.py
[2022-02-17 16:08:25,799] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:08:25,801] {logging_mixin.py:112} INFO - [2022-02-17 16:08:25,800] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:08:26,260] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:08:26,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:08:26,326] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:08:26,332] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 16:08:39,109] {scheduler_job.py:155} INFO - Started process (PID=9370) to work on /airflow/dags/download_data.py
[2022-02-17 16:08:39,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:08:39,115] {logging_mixin.py:112} INFO - [2022-02-17 16:08:39,115] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:08:39,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:08:39,608] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:08:39,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:08:39,619] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 16:08:52,427] {scheduler_job.py:155} INFO - Started process (PID=9396) to work on /airflow/dags/download_data.py
[2022-02-17 16:08:52,434] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:08:52,437] {logging_mixin.py:112} INFO - [2022-02-17 16:08:52,436] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:08:52,880] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:08:52,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:08:52,943] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:08:52,952] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 16:09:05,742] {scheduler_job.py:155} INFO - Started process (PID=9424) to work on /airflow/dags/download_data.py
[2022-02-17 16:09:05,757] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:09:05,760] {logging_mixin.py:112} INFO - [2022-02-17 16:09:05,760] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:09:06,210] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:09:06,257] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:09:06,265] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:09:06,270] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 16:09:19,016] {scheduler_job.py:155} INFO - Started process (PID=9450) to work on /airflow/dags/download_data.py
[2022-02-17 16:09:19,020] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:09:19,022] {logging_mixin.py:112} INFO - [2022-02-17 16:09:19,021] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:09:19,447] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:09:19,499] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:09:19,507] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:09:19,512] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 16:09:32,270] {scheduler_job.py:155} INFO - Started process (PID=9476) to work on /airflow/dags/download_data.py
[2022-02-17 16:09:32,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:09:32,280] {logging_mixin.py:112} INFO - [2022-02-17 16:09:32,280] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:09:32,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:09:32,771] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:09:32,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:09:32,788] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 16:09:45,544] {scheduler_job.py:155} INFO - Started process (PID=9504) to work on /airflow/dags/download_data.py
[2022-02-17 16:09:45,548] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:09:45,550] {logging_mixin.py:112} INFO - [2022-02-17 16:09:45,550] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:09:45,995] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:09:46,044] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:09:46,054] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:09:46,060] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 16:09:58,798] {scheduler_job.py:155} INFO - Started process (PID=9530) to work on /airflow/dags/download_data.py
[2022-02-17 16:09:58,808] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:09:58,809] {logging_mixin.py:112} INFO - [2022-02-17 16:09:58,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:09:59,273] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:09:59,321] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:09:59,332] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:09:59,338] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 16:10:12,078] {scheduler_job.py:155} INFO - Started process (PID=9558) to work on /airflow/dags/download_data.py
[2022-02-17 16:10:12,081] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:10:12,083] {logging_mixin.py:112} INFO - [2022-02-17 16:10:12,082] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:10:12,521] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:10:12,563] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:10:12,573] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:10:12,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 16:10:25,379] {scheduler_job.py:155} INFO - Started process (PID=9584) to work on /airflow/dags/download_data.py
[2022-02-17 16:10:25,388] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:10:25,391] {logging_mixin.py:112} INFO - [2022-02-17 16:10:25,390] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:10:25,846] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:10:25,902] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:10:25,911] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:10:25,915] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 16:10:38,662] {scheduler_job.py:155} INFO - Started process (PID=9612) to work on /airflow/dags/download_data.py
[2022-02-17 16:10:38,670] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:10:38,673] {logging_mixin.py:112} INFO - [2022-02-17 16:10:38,672] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:10:39,122] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:10:39,174] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:10:39,180] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:10:39,184] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 16:10:51,919] {scheduler_job.py:155} INFO - Started process (PID=9638) to work on /airflow/dags/download_data.py
[2022-02-17 16:10:51,926] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:10:51,928] {logging_mixin.py:112} INFO - [2022-02-17 16:10:51,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:10:52,356] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:10:52,404] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:10:52,410] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:10:52,416] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 16:11:05,214] {scheduler_job.py:155} INFO - Started process (PID=9666) to work on /airflow/dags/download_data.py
[2022-02-17 16:11:05,224] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:11:05,228] {logging_mixin.py:112} INFO - [2022-02-17 16:11:05,228] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:11:05,724] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:11:05,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:11:05,766] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:11:05,770] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 16:11:18,497] {scheduler_job.py:155} INFO - Started process (PID=9692) to work on /airflow/dags/download_data.py
[2022-02-17 16:11:18,504] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:11:18,505] {logging_mixin.py:112} INFO - [2022-02-17 16:11:18,505] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:11:18,950] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:11:18,998] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:11:19,004] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:11:19,007] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 16:11:31,737] {scheduler_job.py:155} INFO - Started process (PID=9718) to work on /airflow/dags/download_data.py
[2022-02-17 16:11:31,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:11:31,748] {logging_mixin.py:112} INFO - [2022-02-17 16:11:31,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:11:32,226] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:11:32,269] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:11:32,277] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:11:32,280] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 16:11:45,026] {scheduler_job.py:155} INFO - Started process (PID=9746) to work on /airflow/dags/download_data.py
[2022-02-17 16:11:45,030] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:11:45,031] {logging_mixin.py:112} INFO - [2022-02-17 16:11:45,031] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:11:45,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:11:45,499] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:11:45,506] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:11:45,509] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.483 seconds
[2022-02-17 16:11:58,260] {scheduler_job.py:155} INFO - Started process (PID=9772) to work on /airflow/dags/download_data.py
[2022-02-17 16:11:58,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:11:58,266] {logging_mixin.py:112} INFO - [2022-02-17 16:11:58,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:11:58,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:11:58,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:11:58,816] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:11:58,823] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 16:12:11,605] {scheduler_job.py:155} INFO - Started process (PID=9800) to work on /airflow/dags/download_data.py
[2022-02-17 16:12:11,615] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:12:11,617] {logging_mixin.py:112} INFO - [2022-02-17 16:12:11,617] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:12:12,073] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:12:12,116] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:12:12,126] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:12:12,130] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 16:12:24,861] {scheduler_job.py:155} INFO - Started process (PID=9826) to work on /airflow/dags/download_data.py
[2022-02-17 16:12:24,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:12:24,870] {logging_mixin.py:112} INFO - [2022-02-17 16:12:24,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:12:25,390] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:12:25,445] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:12:25,454] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:12:25,465] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-17 16:12:38,203] {scheduler_job.py:155} INFO - Started process (PID=9854) to work on /airflow/dags/download_data.py
[2022-02-17 16:12:38,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:12:38,219] {logging_mixin.py:112} INFO - [2022-02-17 16:12:38,218] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:12:38,668] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:12:38,718] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:12:38,730] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:12:38,735] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 16:12:51,477] {scheduler_job.py:155} INFO - Started process (PID=9880) to work on /airflow/dags/download_data.py
[2022-02-17 16:12:51,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:12:51,489] {logging_mixin.py:112} INFO - [2022-02-17 16:12:51,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:12:51,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:12:51,975] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:12:51,983] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:12:51,987] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 16:13:04,752] {scheduler_job.py:155} INFO - Started process (PID=9906) to work on /airflow/dags/download_data.py
[2022-02-17 16:13:04,758] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:13:04,760] {logging_mixin.py:112} INFO - [2022-02-17 16:13:04,759] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:13:05,184] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:13:05,233] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:13:05,242] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:13:05,248] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 16:13:18,039] {scheduler_job.py:155} INFO - Started process (PID=9934) to work on /airflow/dags/download_data.py
[2022-02-17 16:13:18,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:13:18,046] {logging_mixin.py:112} INFO - [2022-02-17 16:13:18,045] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:13:18,500] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:13:18,548] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:13:18,558] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:13:18,564] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 16:13:31,295] {scheduler_job.py:155} INFO - Started process (PID=9960) to work on /airflow/dags/download_data.py
[2022-02-17 16:13:31,303] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:13:31,305] {logging_mixin.py:112} INFO - [2022-02-17 16:13:31,305] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:13:31,765] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:13:31,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:13:31,826] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:13:31,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 16:13:44,622] {scheduler_job.py:155} INFO - Started process (PID=9988) to work on /airflow/dags/download_data.py
[2022-02-17 16:13:44,631] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:13:44,633] {logging_mixin.py:112} INFO - [2022-02-17 16:13:44,633] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:13:45,065] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:13:45,105] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:13:45,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:13:45,118] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 16:13:57,880] {scheduler_job.py:155} INFO - Started process (PID=10014) to work on /airflow/dags/download_data.py
[2022-02-17 16:13:57,885] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:13:57,887] {logging_mixin.py:112} INFO - [2022-02-17 16:13:57,887] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:13:58,358] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:13:58,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:13:58,426] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:13:58,434] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 16:14:11,206] {scheduler_job.py:155} INFO - Started process (PID=10042) to work on /airflow/dags/download_data.py
[2022-02-17 16:14:11,209] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:14:11,211] {logging_mixin.py:112} INFO - [2022-02-17 16:14:11,211] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:14:11,663] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:14:11,723] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:14:11,732] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:14:11,738] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 16:14:24,489] {scheduler_job.py:155} INFO - Started process (PID=10068) to work on /airflow/dags/download_data.py
[2022-02-17 16:14:24,500] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:14:24,503] {logging_mixin.py:112} INFO - [2022-02-17 16:14:24,503] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:14:24,994] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:14:25,052] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:14:25,065] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:14:25,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 16:14:37,785] {scheduler_job.py:155} INFO - Started process (PID=10094) to work on /airflow/dags/download_data.py
[2022-02-17 16:14:37,790] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:14:37,792] {logging_mixin.py:112} INFO - [2022-02-17 16:14:37,791] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:14:38,210] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:14:38,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:14:38,254] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:14:38,257] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.473 seconds
[2022-02-17 16:14:51,065] {scheduler_job.py:155} INFO - Started process (PID=10122) to work on /airflow/dags/download_data.py
[2022-02-17 16:14:51,071] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:14:51,072] {logging_mixin.py:112} INFO - [2022-02-17 16:14:51,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:14:51,552] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:14:51,598] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:14:51,606] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:14:51,611] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 16:15:04,380] {scheduler_job.py:155} INFO - Started process (PID=10148) to work on /airflow/dags/download_data.py
[2022-02-17 16:15:04,387] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:15:04,388] {logging_mixin.py:112} INFO - [2022-02-17 16:15:04,388] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:15:04,822] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:15:04,862] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:15:04,868] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:15:04,872] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 16:15:17,693] {scheduler_job.py:155} INFO - Started process (PID=10176) to work on /airflow/dags/download_data.py
[2022-02-17 16:15:17,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:15:17,703] {logging_mixin.py:112} INFO - [2022-02-17 16:15:17,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:15:18,178] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:15:18,221] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:15:18,228] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:15:18,233] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 16:15:31,022] {scheduler_job.py:155} INFO - Started process (PID=10202) to work on /airflow/dags/download_data.py
[2022-02-17 16:15:31,034] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:15:31,037] {logging_mixin.py:112} INFO - [2022-02-17 16:15:31,036] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:15:31,496] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:15:31,558] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:15:31,570] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:15:31,575] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 16:15:44,311] {scheduler_job.py:155} INFO - Started process (PID=10230) to work on /airflow/dags/download_data.py
[2022-02-17 16:15:44,324] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:15:44,326] {logging_mixin.py:112} INFO - [2022-02-17 16:15:44,326] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:15:44,786] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:15:44,827] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:15:44,833] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:15:44,836] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 16:15:57,557] {scheduler_job.py:155} INFO - Started process (PID=10256) to work on /airflow/dags/download_data.py
[2022-02-17 16:15:57,563] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:15:57,565] {logging_mixin.py:112} INFO - [2022-02-17 16:15:57,565] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:15:58,032] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:15:58,079] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:15:58,089] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:15:58,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 16:16:10,853] {scheduler_job.py:155} INFO - Started process (PID=10282) to work on /airflow/dags/download_data.py
[2022-02-17 16:16:10,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:16:10,863] {logging_mixin.py:112} INFO - [2022-02-17 16:16:10,862] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:16:11,294] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:16:11,339] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:16:11,346] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:16:11,367] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 16:16:24,117] {scheduler_job.py:155} INFO - Started process (PID=10310) to work on /airflow/dags/download_data.py
[2022-02-17 16:16:24,124] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:16:24,127] {logging_mixin.py:112} INFO - [2022-02-17 16:16:24,126] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:16:24,566] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:16:24,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:16:24,625] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:16:24,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 16:16:37,430] {scheduler_job.py:155} INFO - Started process (PID=10336) to work on /airflow/dags/download_data.py
[2022-02-17 16:16:37,437] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:16:37,439] {logging_mixin.py:112} INFO - [2022-02-17 16:16:37,439] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:16:37,862] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:16:37,911] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:16:37,919] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:16:37,923] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 16:16:50,680] {scheduler_job.py:155} INFO - Started process (PID=10364) to work on /airflow/dags/download_data.py
[2022-02-17 16:16:50,685] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:16:50,687] {logging_mixin.py:112} INFO - [2022-02-17 16:16:50,686] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:16:51,115] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:16:51,168] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:16:51,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:16:51,176] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 16:17:03,976] {scheduler_job.py:155} INFO - Started process (PID=10390) to work on /airflow/dags/download_data.py
[2022-02-17 16:17:03,980] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:17:03,982] {logging_mixin.py:112} INFO - [2022-02-17 16:17:03,982] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:17:04,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:17:04,478] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:17:04,486] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:17:04,490] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 16:17:17,313] {scheduler_job.py:155} INFO - Started process (PID=10418) to work on /airflow/dags/download_data.py
[2022-02-17 16:17:17,319] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:17:17,321] {logging_mixin.py:112} INFO - [2022-02-17 16:17:17,321] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:17:17,740] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:17:17,786] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:17:17,793] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:17:17,797] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-17 16:17:30,549] {scheduler_job.py:155} INFO - Started process (PID=10444) to work on /airflow/dags/download_data.py
[2022-02-17 16:17:30,553] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:17:30,555] {logging_mixin.py:112} INFO - [2022-02-17 16:17:30,555] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:17:31,017] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:17:31,067] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:17:31,077] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:17:31,083] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 16:17:43,874] {scheduler_job.py:155} INFO - Started process (PID=10472) to work on /airflow/dags/download_data.py
[2022-02-17 16:17:43,884] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:17:43,886] {logging_mixin.py:112} INFO - [2022-02-17 16:17:43,886] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:17:44,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:17:44,606] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:17:44,620] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:17:44,640] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.765 seconds
[2022-02-17 16:17:57,168] {scheduler_job.py:155} INFO - Started process (PID=10498) to work on /airflow/dags/download_data.py
[2022-02-17 16:17:57,173] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:17:57,174] {logging_mixin.py:112} INFO - [2022-02-17 16:17:57,174] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:17:57,649] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:17:57,691] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:17:57,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:17:57,701] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 16:18:10,523] {scheduler_job.py:155} INFO - Started process (PID=10524) to work on /airflow/dags/download_data.py
[2022-02-17 16:18:10,528] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:18:10,531] {logging_mixin.py:112} INFO - [2022-02-17 16:18:10,530] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:18:10,962] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:18:11,014] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:18:11,024] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:18:11,028] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 16:18:23,734] {scheduler_job.py:155} INFO - Started process (PID=10552) to work on /airflow/dags/download_data.py
[2022-02-17 16:18:23,740] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:18:23,741] {logging_mixin.py:112} INFO - [2022-02-17 16:18:23,741] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:18:24,261] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:18:24,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:18:24,313] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:18:24,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 16:18:37,066] {scheduler_job.py:155} INFO - Started process (PID=10578) to work on /airflow/dags/download_data.py
[2022-02-17 16:18:37,072] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:18:37,074] {logging_mixin.py:112} INFO - [2022-02-17 16:18:37,074] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:18:37,511] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:18:37,550] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:18:37,559] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:18:37,565] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 16:18:50,307] {scheduler_job.py:155} INFO - Started process (PID=10606) to work on /airflow/dags/download_data.py
[2022-02-17 16:18:50,313] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:18:50,315] {logging_mixin.py:112} INFO - [2022-02-17 16:18:50,315] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:18:50,752] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:18:50,791] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:18:50,797] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:18:50,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 16:19:03,571] {scheduler_job.py:155} INFO - Started process (PID=10632) to work on /airflow/dags/download_data.py
[2022-02-17 16:19:03,576] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:19:03,578] {logging_mixin.py:112} INFO - [2022-02-17 16:19:03,578] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:19:04,022] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:19:04,070] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:19:04,077] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:19:04,082] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 16:19:16,895] {scheduler_job.py:155} INFO - Started process (PID=10660) to work on /airflow/dags/download_data.py
[2022-02-17 16:19:16,903] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:19:16,905] {logging_mixin.py:112} INFO - [2022-02-17 16:19:16,905] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:19:17,348] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:19:17,399] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:19:17,407] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:19:17,410] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 16:19:30,164] {scheduler_job.py:155} INFO - Started process (PID=10686) to work on /airflow/dags/download_data.py
[2022-02-17 16:19:30,171] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:19:30,173] {logging_mixin.py:112} INFO - [2022-02-17 16:19:30,173] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:19:30,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:19:30,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:19:30,684] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:19:30,690] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 16:19:43,447] {scheduler_job.py:155} INFO - Started process (PID=10712) to work on /airflow/dags/download_data.py
[2022-02-17 16:19:43,452] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:19:43,453] {logging_mixin.py:112} INFO - [2022-02-17 16:19:43,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:19:43,894] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:19:43,947] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:19:43,955] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:19:43,960] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 16:19:56,709] {scheduler_job.py:155} INFO - Started process (PID=10740) to work on /airflow/dags/download_data.py
[2022-02-17 16:19:56,715] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:19:56,716] {logging_mixin.py:112} INFO - [2022-02-17 16:19:56,716] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:19:57,178] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:19:57,235] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:19:57,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:19:57,253] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 16:20:10,070] {scheduler_job.py:155} INFO - Started process (PID=10766) to work on /airflow/dags/download_data.py
[2022-02-17 16:20:10,075] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:20:10,077] {logging_mixin.py:112} INFO - [2022-02-17 16:20:10,077] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:20:10,559] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:20:10,610] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:20:10,620] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:20:10,626] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 16:20:23,320] {scheduler_job.py:155} INFO - Started process (PID=10794) to work on /airflow/dags/download_data.py
[2022-02-17 16:20:23,326] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:20:23,328] {logging_mixin.py:112} INFO - [2022-02-17 16:20:23,327] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:20:23,756] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:20:23,805] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:20:23,812] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:20:23,817] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 16:20:36,625] {scheduler_job.py:155} INFO - Started process (PID=10820) to work on /airflow/dags/download_data.py
[2022-02-17 16:20:36,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:20:36,635] {logging_mixin.py:112} INFO - [2022-02-17 16:20:36,634] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:20:37,065] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:20:37,114] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:20:37,121] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:20:37,126] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 16:20:49,863] {scheduler_job.py:155} INFO - Started process (PID=10848) to work on /airflow/dags/download_data.py
[2022-02-17 16:20:49,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:20:49,869] {logging_mixin.py:112} INFO - [2022-02-17 16:20:49,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:20:50,298] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:20:50,338] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:20:50,344] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:20:50,347] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-17 16:21:03,184] {scheduler_job.py:155} INFO - Started process (PID=10874) to work on /airflow/dags/download_data.py
[2022-02-17 16:21:03,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:21:03,194] {logging_mixin.py:112} INFO - [2022-02-17 16:21:03,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:21:03,616] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:21:03,657] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:21:03,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:21:03,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.481 seconds
[2022-02-17 16:21:16,455] {scheduler_job.py:155} INFO - Started process (PID=10900) to work on /airflow/dags/download_data.py
[2022-02-17 16:21:16,459] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:21:16,461] {logging_mixin.py:112} INFO - [2022-02-17 16:21:16,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:21:16,894] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:21:16,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:21:16,945] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:21:16,950] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 16:21:29,702] {scheduler_job.py:155} INFO - Started process (PID=10928) to work on /airflow/dags/download_data.py
[2022-02-17 16:21:29,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:21:29,709] {logging_mixin.py:112} INFO - [2022-02-17 16:21:29,708] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:21:30,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:21:30,216] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:21:30,227] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:21:30,232] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 16:21:43,036] {scheduler_job.py:155} INFO - Started process (PID=10954) to work on /airflow/dags/download_data.py
[2022-02-17 16:21:43,045] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:21:43,048] {logging_mixin.py:112} INFO - [2022-02-17 16:21:43,047] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:21:43,486] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:21:43,523] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:21:43,529] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:21:43,532] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 16:21:56,280] {scheduler_job.py:155} INFO - Started process (PID=10982) to work on /airflow/dags/download_data.py
[2022-02-17 16:21:56,291] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:21:56,294] {logging_mixin.py:112} INFO - [2022-02-17 16:21:56,293] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:21:56,754] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:21:56,797] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:21:56,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:21:56,811] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 16:22:09,565] {scheduler_job.py:155} INFO - Started process (PID=11008) to work on /airflow/dags/download_data.py
[2022-02-17 16:22:09,569] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:22:09,570] {logging_mixin.py:112} INFO - [2022-02-17 16:22:09,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:22:10,095] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:22:10,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:22:10,159] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:22:10,168] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 16:22:22,819] {scheduler_job.py:155} INFO - Started process (PID=11036) to work on /airflow/dags/download_data.py
[2022-02-17 16:22:22,833] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:22:22,836] {logging_mixin.py:112} INFO - [2022-02-17 16:22:22,835] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:22:23,296] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:22:23,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:22:23,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:22:23,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 16:22:36,111] {scheduler_job.py:155} INFO - Started process (PID=11062) to work on /airflow/dags/download_data.py
[2022-02-17 16:22:36,118] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:22:36,120] {logging_mixin.py:112} INFO - [2022-02-17 16:22:36,120] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:22:36,554] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:22:36,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:22:36,606] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:22:36,611] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 16:22:49,368] {scheduler_job.py:155} INFO - Started process (PID=11088) to work on /airflow/dags/download_data.py
[2022-02-17 16:22:49,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:22:49,377] {logging_mixin.py:112} INFO - [2022-02-17 16:22:49,376] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:22:49,777] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:22:49,830] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:22:49,840] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:22:49,847] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.479 seconds
[2022-02-17 16:23:02,664] {scheduler_job.py:155} INFO - Started process (PID=11116) to work on /airflow/dags/download_data.py
[2022-02-17 16:23:02,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:23:02,671] {logging_mixin.py:112} INFO - [2022-02-17 16:23:02,670] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:23:03,096] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:23:03,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:23:03,155] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:23:03,161] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 16:23:15,954] {scheduler_job.py:155} INFO - Started process (PID=11142) to work on /airflow/dags/download_data.py
[2022-02-17 16:23:15,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:23:15,960] {logging_mixin.py:112} INFO - [2022-02-17 16:23:15,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:23:16,410] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:23:16,460] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:23:16,469] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:23:16,475] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 16:23:29,216] {scheduler_job.py:155} INFO - Started process (PID=11170) to work on /airflow/dags/download_data.py
[2022-02-17 16:23:29,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:23:29,229] {logging_mixin.py:112} INFO - [2022-02-17 16:23:29,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:23:29,687] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:23:29,745] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:23:29,755] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:23:29,761] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 16:23:42,512] {scheduler_job.py:155} INFO - Started process (PID=11196) to work on /airflow/dags/download_data.py
[2022-02-17 16:23:42,517] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:23:42,518] {logging_mixin.py:112} INFO - [2022-02-17 16:23:42,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:23:42,968] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:23:43,015] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:23:43,022] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:23:43,028] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 16:23:55,800] {scheduler_job.py:155} INFO - Started process (PID=11224) to work on /airflow/dags/download_data.py
[2022-02-17 16:23:55,812] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:23:55,814] {logging_mixin.py:112} INFO - [2022-02-17 16:23:55,814] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:23:56,316] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:23:56,360] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:23:56,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:23:56,373] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 16:24:09,102] {scheduler_job.py:155} INFO - Started process (PID=11250) to work on /airflow/dags/download_data.py
[2022-02-17 16:24:09,106] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:24:09,108] {logging_mixin.py:112} INFO - [2022-02-17 16:24:09,107] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:24:09,539] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:24:09,592] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:24:09,602] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:24:09,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 16:24:22,384] {scheduler_job.py:155} INFO - Started process (PID=11277) to work on /airflow/dags/download_data.py
[2022-02-17 16:24:22,397] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:24:22,401] {logging_mixin.py:112} INFO - [2022-02-17 16:24:22,400] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:24:22,921] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:24:22,978] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:24:22,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:24:22,988] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 16:24:35,663] {scheduler_job.py:155} INFO - Started process (PID=11304) to work on /airflow/dags/download_data.py
[2022-02-17 16:24:35,672] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:24:35,674] {logging_mixin.py:112} INFO - [2022-02-17 16:24:35,674] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:24:36,128] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:24:36,170] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:24:36,177] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:24:36,182] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 16:24:48,956] {scheduler_job.py:155} INFO - Started process (PID=11330) to work on /airflow/dags/download_data.py
[2022-02-17 16:24:48,960] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:24:48,965] {logging_mixin.py:112} INFO - [2022-02-17 16:24:48,965] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:24:49,402] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:24:49,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:24:49,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:24:49,453] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 16:25:02,221] {scheduler_job.py:155} INFO - Started process (PID=11358) to work on /airflow/dags/download_data.py
[2022-02-17 16:25:02,228] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:25:02,230] {logging_mixin.py:112} INFO - [2022-02-17 16:25:02,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:25:02,668] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:25:02,716] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:25:02,722] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:25:02,726] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 16:25:15,501] {scheduler_job.py:155} INFO - Started process (PID=11384) to work on /airflow/dags/download_data.py
[2022-02-17 16:25:15,505] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:25:15,507] {logging_mixin.py:112} INFO - [2022-02-17 16:25:15,507] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:25:15,959] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:25:16,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:25:16,018] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:25:16,023] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 16:25:28,853] {scheduler_job.py:155} INFO - Started process (PID=11412) to work on /airflow/dags/download_data.py
[2022-02-17 16:25:28,858] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:25:28,860] {logging_mixin.py:112} INFO - [2022-02-17 16:25:28,860] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:25:29,339] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:25:29,393] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:25:29,407] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:25:29,412] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 16:25:42,155] {scheduler_job.py:155} INFO - Started process (PID=11438) to work on /airflow/dags/download_data.py
[2022-02-17 16:25:42,164] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:25:42,166] {logging_mixin.py:112} INFO - [2022-02-17 16:25:42,166] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:25:42,608] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:25:42,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:25:42,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:25:42,678] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 16:25:55,424] {scheduler_job.py:155} INFO - Started process (PID=11466) to work on /airflow/dags/download_data.py
[2022-02-17 16:25:55,432] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:25:55,434] {logging_mixin.py:112} INFO - [2022-02-17 16:25:55,434] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:25:55,910] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:25:55,973] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:25:55,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:25:55,986] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 16:26:08,763] {scheduler_job.py:155} INFO - Started process (PID=11492) to work on /airflow/dags/download_data.py
[2022-02-17 16:26:08,770] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:26:08,773] {logging_mixin.py:112} INFO - [2022-02-17 16:26:08,773] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:26:09,217] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:26:09,274] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:26:09,280] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:26:09,285] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 16:26:22,009] {scheduler_job.py:155} INFO - Started process (PID=11518) to work on /airflow/dags/download_data.py
[2022-02-17 16:26:22,017] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:26:22,020] {logging_mixin.py:112} INFO - [2022-02-17 16:26:22,020] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:26:22,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:26:22,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:26:22,513] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:26:22,519] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 16:26:35,307] {scheduler_job.py:155} INFO - Started process (PID=11546) to work on /airflow/dags/download_data.py
[2022-02-17 16:26:35,317] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:26:35,319] {logging_mixin.py:112} INFO - [2022-02-17 16:26:35,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:26:35,775] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:26:35,829] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:26:35,837] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:26:35,842] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 16:26:48,606] {scheduler_job.py:155} INFO - Started process (PID=11572) to work on /airflow/dags/download_data.py
[2022-02-17 16:26:48,612] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:26:48,615] {logging_mixin.py:112} INFO - [2022-02-17 16:26:48,614] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:26:49,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:26:49,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:26:49,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:26:49,127] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 16:27:01,865] {scheduler_job.py:155} INFO - Started process (PID=11600) to work on /airflow/dags/download_data.py
[2022-02-17 16:27:01,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:27:01,871] {logging_mixin.py:112} INFO - [2022-02-17 16:27:01,871] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:27:02,297] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:27:02,336] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:27:02,344] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:27:02,348] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.483 seconds
[2022-02-17 16:27:15,188] {scheduler_job.py:155} INFO - Started process (PID=11626) to work on /airflow/dags/download_data.py
[2022-02-17 16:27:15,196] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:27:15,198] {logging_mixin.py:112} INFO - [2022-02-17 16:27:15,198] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:27:15,634] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:27:15,690] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:27:15,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:27:15,702] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 16:27:28,479] {scheduler_job.py:155} INFO - Started process (PID=11654) to work on /airflow/dags/download_data.py
[2022-02-17 16:27:28,492] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:27:28,494] {logging_mixin.py:112} INFO - [2022-02-17 16:27:28,494] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:27:28,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:27:28,972] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:27:28,980] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:27:28,985] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 16:27:41,789] {scheduler_job.py:155} INFO - Started process (PID=11680) to work on /airflow/dags/download_data.py
[2022-02-17 16:27:41,793] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:27:41,795] {logging_mixin.py:112} INFO - [2022-02-17 16:27:41,795] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:27:42,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:27:42,294] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:27:42,301] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:27:42,306] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 16:27:55,050] {scheduler_job.py:155} INFO - Started process (PID=11706) to work on /airflow/dags/download_data.py
[2022-02-17 16:27:55,057] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:27:55,060] {logging_mixin.py:112} INFO - [2022-02-17 16:27:55,059] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:27:55,510] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:27:55,574] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:27:55,582] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:27:55,588] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 16:28:08,331] {scheduler_job.py:155} INFO - Started process (PID=11734) to work on /airflow/dags/download_data.py
[2022-02-17 16:28:08,340] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:28:08,342] {logging_mixin.py:112} INFO - [2022-02-17 16:28:08,342] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:28:08,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:28:08,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:28:08,821] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:28:08,826] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 16:28:21,593] {scheduler_job.py:155} INFO - Started process (PID=11760) to work on /airflow/dags/download_data.py
[2022-02-17 16:28:21,600] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:28:21,602] {logging_mixin.py:112} INFO - [2022-02-17 16:28:21,602] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:28:22,027] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:28:22,068] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:28:22,079] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:28:22,084] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 16:28:34,903] {scheduler_job.py:155} INFO - Started process (PID=11788) to work on /airflow/dags/download_data.py
[2022-02-17 16:28:34,907] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:28:34,908] {logging_mixin.py:112} INFO - [2022-02-17 16:28:34,908] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:28:35,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:28:35,393] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:28:35,402] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:28:35,405] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 16:28:48,185] {scheduler_job.py:155} INFO - Started process (PID=11814) to work on /airflow/dags/download_data.py
[2022-02-17 16:28:48,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:28:48,190] {logging_mixin.py:112} INFO - [2022-02-17 16:28:48,190] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:28:48,606] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:28:48,659] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:28:48,666] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:28:48,669] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-17 16:29:01,516] {scheduler_job.py:155} INFO - Started process (PID=11842) to work on /airflow/dags/download_data.py
[2022-02-17 16:29:01,531] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:29:01,534] {logging_mixin.py:112} INFO - [2022-02-17 16:29:01,533] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:29:01,984] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:29:02,025] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:29:02,030] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:29:02,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 16:29:14,799] {scheduler_job.py:155} INFO - Started process (PID=11868) to work on /airflow/dags/download_data.py
[2022-02-17 16:29:14,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:29:14,807] {logging_mixin.py:112} INFO - [2022-02-17 16:29:14,807] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:29:15,241] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:29:15,282] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:29:15,289] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:29:15,292] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 16:29:28,052] {scheduler_job.py:155} INFO - Started process (PID=11894) to work on /airflow/dags/download_data.py
[2022-02-17 16:29:28,061] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:29:28,067] {logging_mixin.py:112} INFO - [2022-02-17 16:29:28,066] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:29:28,526] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:29:28,580] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:29:28,589] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:29:28,593] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 16:29:41,453] {scheduler_job.py:155} INFO - Started process (PID=11922) to work on /airflow/dags/download_data.py
[2022-02-17 16:29:41,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:29:41,480] {logging_mixin.py:112} INFO - [2022-02-17 16:29:41,480] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:29:42,149] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:29:42,194] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:29:42,203] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:29:42,209] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.756 seconds
[2022-02-17 16:29:54,655] {scheduler_job.py:155} INFO - Started process (PID=11948) to work on /airflow/dags/download_data.py
[2022-02-17 16:29:54,662] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:29:54,664] {logging_mixin.py:112} INFO - [2022-02-17 16:29:54,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:29:55,126] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:29:55,181] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:29:55,190] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:29:55,195] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 16:30:07,991] {scheduler_job.py:155} INFO - Started process (PID=11976) to work on /airflow/dags/download_data.py
[2022-02-17 16:30:07,996] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:30:07,998] {logging_mixin.py:112} INFO - [2022-02-17 16:30:07,998] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:30:08,424] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:30:08,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:30:08,484] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:30:08,489] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 16:30:21,233] {scheduler_job.py:155} INFO - Started process (PID=12002) to work on /airflow/dags/download_data.py
[2022-02-17 16:30:21,237] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:30:21,239] {logging_mixin.py:112} INFO - [2022-02-17 16:30:21,239] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:30:21,694] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:30:21,745] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:30:21,752] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:30:21,756] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 16:30:34,542] {scheduler_job.py:155} INFO - Started process (PID=12030) to work on /airflow/dags/download_data.py
[2022-02-17 16:30:34,549] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:30:34,552] {logging_mixin.py:112} INFO - [2022-02-17 16:30:34,551] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:30:35,004] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:30:35,044] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:30:35,051] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:30:35,055] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 16:30:47,863] {scheduler_job.py:155} INFO - Started process (PID=12056) to work on /airflow/dags/download_data.py
[2022-02-17 16:30:47,871] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:30:47,873] {logging_mixin.py:112} INFO - [2022-02-17 16:30:47,872] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:30:48,302] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:30:48,353] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:30:48,363] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:30:48,368] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 16:31:01,138] {scheduler_job.py:155} INFO - Started process (PID=12084) to work on /airflow/dags/download_data.py
[2022-02-17 16:31:01,148] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:31:01,150] {logging_mixin.py:112} INFO - [2022-02-17 16:31:01,150] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:31:01,638] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:31:01,695] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:31:01,708] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:31:01,711] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 16:31:14,431] {scheduler_job.py:155} INFO - Started process (PID=12110) to work on /airflow/dags/download_data.py
[2022-02-17 16:31:14,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:31:14,437] {logging_mixin.py:112} INFO - [2022-02-17 16:31:14,436] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:31:14,870] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:31:14,911] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:31:14,918] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:31:14,921] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 16:31:27,702] {scheduler_job.py:155} INFO - Started process (PID=12136) to work on /airflow/dags/download_data.py
[2022-02-17 16:31:27,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:31:27,711] {logging_mixin.py:112} INFO - [2022-02-17 16:31:27,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:31:28,177] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:31:28,234] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:31:28,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:31:28,254] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 16:31:41,002] {scheduler_job.py:155} INFO - Started process (PID=12164) to work on /airflow/dags/download_data.py
[2022-02-17 16:31:41,005] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:31:41,007] {logging_mixin.py:112} INFO - [2022-02-17 16:31:41,007] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:31:41,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:31:41,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:31:41,516] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:31:41,520] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 16:31:54,276] {scheduler_job.py:155} INFO - Started process (PID=12190) to work on /airflow/dags/download_data.py
[2022-02-17 16:31:54,284] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:31:54,287] {logging_mixin.py:112} INFO - [2022-02-17 16:31:54,287] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:31:54,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:31:54,796] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:31:54,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:31:54,814] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 16:32:07,555] {scheduler_job.py:155} INFO - Started process (PID=12218) to work on /airflow/dags/download_data.py
[2022-02-17 16:32:07,559] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:32:07,561] {logging_mixin.py:112} INFO - [2022-02-17 16:32:07,561] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:32:08,005] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:32:08,051] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:32:08,056] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:32:08,060] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 16:32:20,826] {scheduler_job.py:155} INFO - Started process (PID=12244) to work on /airflow/dags/download_data.py
[2022-02-17 16:32:20,830] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:32:20,832] {logging_mixin.py:112} INFO - [2022-02-17 16:32:20,832] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:32:21,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:32:21,312] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:32:21,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:32:21,323] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 16:32:34,146] {scheduler_job.py:155} INFO - Started process (PID=12272) to work on /airflow/dags/download_data.py
[2022-02-17 16:32:34,150] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:32:34,152] {logging_mixin.py:112} INFO - [2022-02-17 16:32:34,152] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:32:34,588] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:32:34,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:32:34,674] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:32:34,683] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 16:32:47,473] {scheduler_job.py:155} INFO - Started process (PID=12298) to work on /airflow/dags/download_data.py
[2022-02-17 16:32:47,480] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:32:47,482] {logging_mixin.py:112} INFO - [2022-02-17 16:32:47,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:32:47,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:32:47,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:32:47,983] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:32:47,990] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 16:33:00,742] {scheduler_job.py:155} INFO - Started process (PID=12324) to work on /airflow/dags/download_data.py
[2022-02-17 16:33:00,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:33:00,748] {logging_mixin.py:112} INFO - [2022-02-17 16:33:00,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:33:01,192] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:33:01,235] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:33:01,243] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:33:01,247] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 16:33:14,048] {scheduler_job.py:155} INFO - Started process (PID=12352) to work on /airflow/dags/download_data.py
[2022-02-17 16:33:14,052] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:33:14,054] {logging_mixin.py:112} INFO - [2022-02-17 16:33:14,053] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:33:14,500] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:33:14,544] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:33:14,554] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:33:14,558] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 16:33:27,382] {scheduler_job.py:155} INFO - Started process (PID=12378) to work on /airflow/dags/download_data.py
[2022-02-17 16:33:27,387] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:33:27,389] {logging_mixin.py:112} INFO - [2022-02-17 16:33:27,389] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:33:27,837] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:33:27,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:33:27,911] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:33:27,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 16:33:40,732] {scheduler_job.py:155} INFO - Started process (PID=12406) to work on /airflow/dags/download_data.py
[2022-02-17 16:33:40,739] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:33:40,741] {logging_mixin.py:112} INFO - [2022-02-17 16:33:40,741] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:33:41,183] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:33:41,229] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:33:41,236] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:33:41,240] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 16:33:53,984] {scheduler_job.py:155} INFO - Started process (PID=12432) to work on /airflow/dags/download_data.py
[2022-02-17 16:33:53,996] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:33:53,998] {logging_mixin.py:112} INFO - [2022-02-17 16:33:53,998] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:33:54,470] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:33:54,532] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:33:54,544] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:33:54,548] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 16:34:07,292] {scheduler_job.py:155} INFO - Started process (PID=12460) to work on /airflow/dags/download_data.py
[2022-02-17 16:34:07,300] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:34:07,303] {logging_mixin.py:112} INFO - [2022-02-17 16:34:07,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:34:07,765] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:34:07,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:34:07,814] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:34:07,819] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 16:34:20,561] {scheduler_job.py:155} INFO - Started process (PID=12486) to work on /airflow/dags/download_data.py
[2022-02-17 16:34:20,565] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:34:20,567] {logging_mixin.py:112} INFO - [2022-02-17 16:34:20,567] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:34:21,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:34:21,073] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:34:21,080] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:34:21,085] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 16:34:33,906] {scheduler_job.py:155} INFO - Started process (PID=12512) to work on /airflow/dags/download_data.py
[2022-02-17 16:34:33,914] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:34:33,916] {logging_mixin.py:112} INFO - [2022-02-17 16:34:33,916] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:34:34,384] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:34:34,441] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:34:34,451] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:34:34,458] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 16:34:47,192] {scheduler_job.py:155} INFO - Started process (PID=12540) to work on /airflow/dags/download_data.py
[2022-02-17 16:34:47,196] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:34:47,197] {logging_mixin.py:112} INFO - [2022-02-17 16:34:47,197] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:34:47,630] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:34:47,674] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:34:47,684] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:34:47,690] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 16:35:00,423] {scheduler_job.py:155} INFO - Started process (PID=12566) to work on /airflow/dags/download_data.py
[2022-02-17 16:35:00,429] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:35:00,431] {logging_mixin.py:112} INFO - [2022-02-17 16:35:00,430] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:35:00,863] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:35:00,912] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:35:00,919] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:35:00,925] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 16:35:13,727] {scheduler_job.py:155} INFO - Started process (PID=12594) to work on /airflow/dags/download_data.py
[2022-02-17 16:35:13,735] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:35:13,737] {logging_mixin.py:112} INFO - [2022-02-17 16:35:13,737] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:35:14,164] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:35:14,214] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:35:14,222] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:35:14,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 16:35:27,010] {scheduler_job.py:155} INFO - Started process (PID=12620) to work on /airflow/dags/download_data.py
[2022-02-17 16:35:27,016] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:35:27,019] {logging_mixin.py:112} INFO - [2022-02-17 16:35:27,018] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:35:27,501] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:35:27,559] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:35:27,569] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:35:27,574] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 16:35:40,328] {scheduler_job.py:155} INFO - Started process (PID=12648) to work on /airflow/dags/download_data.py
[2022-02-17 16:35:40,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:35:40,334] {logging_mixin.py:112} INFO - [2022-02-17 16:35:40,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:35:40,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:35:40,870] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:35:40,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:35:40,878] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 16:35:53,617] {scheduler_job.py:155} INFO - Started process (PID=12674) to work on /airflow/dags/download_data.py
[2022-02-17 16:35:53,621] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:35:53,623] {logging_mixin.py:112} INFO - [2022-02-17 16:35:53,622] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:35:54,102] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:35:54,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:35:54,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:35:54,162] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 16:36:06,913] {scheduler_job.py:155} INFO - Started process (PID=12701) to work on /airflow/dags/download_data.py
[2022-02-17 16:36:06,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:36:06,921] {logging_mixin.py:112} INFO - [2022-02-17 16:36:06,921] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:36:07,465] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:36:07,518] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:36:07,525] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:36:07,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 16:36:20,143] {scheduler_job.py:155} INFO - Started process (PID=12728) to work on /airflow/dags/download_data.py
[2022-02-17 16:36:20,149] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:36:20,152] {logging_mixin.py:112} INFO - [2022-02-17 16:36:20,151] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:36:20,605] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:36:20,649] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:36:20,656] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:36:20,662] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 16:36:33,429] {scheduler_job.py:155} INFO - Started process (PID=12754) to work on /airflow/dags/download_data.py
[2022-02-17 16:36:33,433] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:36:33,436] {logging_mixin.py:112} INFO - [2022-02-17 16:36:33,435] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:36:33,894] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:36:33,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:36:33,961] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:36:33,968] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 16:36:46,742] {scheduler_job.py:155} INFO - Started process (PID=12782) to work on /airflow/dags/download_data.py
[2022-02-17 16:36:46,746] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:36:46,748] {logging_mixin.py:112} INFO - [2022-02-17 16:36:46,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:36:47,202] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:36:47,253] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:36:47,259] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:36:47,262] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 16:37:00,018] {scheduler_job.py:155} INFO - Started process (PID=12808) to work on /airflow/dags/download_data.py
[2022-02-17 16:37:00,022] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:37:00,024] {logging_mixin.py:112} INFO - [2022-02-17 16:37:00,024] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:37:00,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:37:00,498] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:37:00,508] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:37:00,514] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 16:37:13,302] {scheduler_job.py:155} INFO - Started process (PID=12836) to work on /airflow/dags/download_data.py
[2022-02-17 16:37:13,308] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:37:13,310] {logging_mixin.py:112} INFO - [2022-02-17 16:37:13,310] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:37:13,743] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:37:13,795] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:37:13,801] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:37:13,805] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 16:37:26,567] {scheduler_job.py:155} INFO - Started process (PID=12862) to work on /airflow/dags/download_data.py
[2022-02-17 16:37:26,576] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:37:26,578] {logging_mixin.py:112} INFO - [2022-02-17 16:37:26,578] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:37:27,032] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:37:27,086] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:37:27,095] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:37:27,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 16:37:39,827] {scheduler_job.py:155} INFO - Started process (PID=12890) to work on /airflow/dags/download_data.py
[2022-02-17 16:37:39,839] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:37:39,843] {logging_mixin.py:112} INFO - [2022-02-17 16:37:39,843] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:37:40,318] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:37:40,351] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:37:40,358] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:37:40,362] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 16:37:53,055] {scheduler_job.py:155} INFO - Started process (PID=12916) to work on /airflow/dags/download_data.py
[2022-02-17 16:37:53,059] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:37:53,061] {logging_mixin.py:112} INFO - [2022-02-17 16:37:53,061] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:37:53,496] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:37:53,541] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:37:53,548] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:37:53,554] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 16:38:06,380] {scheduler_job.py:155} INFO - Started process (PID=12942) to work on /airflow/dags/download_data.py
[2022-02-17 16:38:06,385] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:38:06,386] {logging_mixin.py:112} INFO - [2022-02-17 16:38:06,386] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:38:06,852] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:38:06,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:38:06,908] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:38:06,914] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 16:38:19,643] {scheduler_job.py:155} INFO - Started process (PID=12970) to work on /airflow/dags/download_data.py
[2022-02-17 16:38:19,650] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:38:19,652] {logging_mixin.py:112} INFO - [2022-02-17 16:38:19,652] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:38:20,107] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:38:20,150] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:38:20,155] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:38:20,159] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 16:38:32,964] {scheduler_job.py:155} INFO - Started process (PID=12996) to work on /airflow/dags/download_data.py
[2022-02-17 16:38:32,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:38:32,972] {logging_mixin.py:112} INFO - [2022-02-17 16:38:32,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:38:33,437] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:38:33,480] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:38:33,487] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:38:33,493] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 16:38:46,256] {scheduler_job.py:155} INFO - Started process (PID=13024) to work on /airflow/dags/download_data.py
[2022-02-17 16:38:46,260] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:38:46,262] {logging_mixin.py:112} INFO - [2022-02-17 16:38:46,262] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:38:46,697] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:38:46,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:38:46,746] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:38:46,750] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 16:38:59,519] {scheduler_job.py:155} INFO - Started process (PID=13050) to work on /airflow/dags/download_data.py
[2022-02-17 16:38:59,524] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:38:59,528] {logging_mixin.py:112} INFO - [2022-02-17 16:38:59,527] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:38:59,965] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:39:00,015] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:39:00,021] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:39:00,025] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 16:39:12,791] {scheduler_job.py:155} INFO - Started process (PID=13078) to work on /airflow/dags/download_data.py
[2022-02-17 16:39:12,795] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:39:12,797] {logging_mixin.py:112} INFO - [2022-02-17 16:39:12,797] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:39:13,234] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:39:13,275] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:39:13,284] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:39:13,289] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 16:39:26,088] {scheduler_job.py:155} INFO - Started process (PID=13104) to work on /airflow/dags/download_data.py
[2022-02-17 16:39:26,093] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:39:26,095] {logging_mixin.py:112} INFO - [2022-02-17 16:39:26,095] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:39:26,548] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:39:26,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:39:26,624] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:39:26,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 16:39:39,387] {scheduler_job.py:155} INFO - Started process (PID=13130) to work on /airflow/dags/download_data.py
[2022-02-17 16:39:39,391] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:39:39,393] {logging_mixin.py:112} INFO - [2022-02-17 16:39:39,393] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:39:39,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:39:39,958] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:39:39,975] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:39:39,983] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 16:39:52,624] {scheduler_job.py:155} INFO - Started process (PID=13158) to work on /airflow/dags/download_data.py
[2022-02-17 16:39:52,628] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:39:52,630] {logging_mixin.py:112} INFO - [2022-02-17 16:39:52,630] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:39:53,099] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:39:53,145] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:39:53,151] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:39:53,154] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 16:40:05,945] {scheduler_job.py:155} INFO - Started process (PID=13184) to work on /airflow/dags/download_data.py
[2022-02-17 16:40:05,955] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:40:05,957] {logging_mixin.py:112} INFO - [2022-02-17 16:40:05,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:40:06,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:40:06,454] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:40:06,463] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:40:06,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 16:40:19,190] {scheduler_job.py:155} INFO - Started process (PID=13212) to work on /airflow/dags/download_data.py
[2022-02-17 16:40:19,197] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:40:19,198] {logging_mixin.py:112} INFO - [2022-02-17 16:40:19,198] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:40:19,649] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:40:19,697] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:40:19,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:40:19,708] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 16:40:32,509] {scheduler_job.py:155} INFO - Started process (PID=13238) to work on /airflow/dags/download_data.py
[2022-02-17 16:40:32,514] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:40:32,515] {logging_mixin.py:112} INFO - [2022-02-17 16:40:32,515] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:40:32,977] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:40:33,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:40:33,050] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:40:33,055] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 16:40:45,807] {scheduler_job.py:155} INFO - Started process (PID=13266) to work on /airflow/dags/download_data.py
[2022-02-17 16:40:45,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:40:45,828] {logging_mixin.py:112} INFO - [2022-02-17 16:40:45,827] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:40:46,294] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:40:46,338] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:40:46,344] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:40:46,350] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 16:40:59,063] {scheduler_job.py:155} INFO - Started process (PID=13292) to work on /airflow/dags/download_data.py
[2022-02-17 16:40:59,070] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:40:59,074] {logging_mixin.py:112} INFO - [2022-02-17 16:40:59,074] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:40:59,502] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:40:59,554] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:40:59,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:40:59,567] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 16:41:12,370] {scheduler_job.py:155} INFO - Started process (PID=13318) to work on /airflow/dags/download_data.py
[2022-02-17 16:41:12,374] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:41:12,376] {logging_mixin.py:112} INFO - [2022-02-17 16:41:12,376] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:41:12,810] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:41:12,858] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:41:12,864] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:41:12,870] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 16:41:25,624] {scheduler_job.py:155} INFO - Started process (PID=13346) to work on /airflow/dags/download_data.py
[2022-02-17 16:41:25,629] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:41:25,631] {logging_mixin.py:112} INFO - [2022-02-17 16:41:25,630] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:41:26,079] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:41:26,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:41:26,146] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:41:26,151] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 16:41:38,906] {scheduler_job.py:155} INFO - Started process (PID=13372) to work on /airflow/dags/download_data.py
[2022-02-17 16:41:38,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:41:38,919] {logging_mixin.py:112} INFO - [2022-02-17 16:41:38,918] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:41:39,383] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:41:39,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:41:39,426] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:41:39,431] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 16:41:52,159] {scheduler_job.py:155} INFO - Started process (PID=13400) to work on /airflow/dags/download_data.py
[2022-02-17 16:41:52,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:41:52,165] {logging_mixin.py:112} INFO - [2022-02-17 16:41:52,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:41:52,611] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:41:52,665] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:41:52,671] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:41:52,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 16:42:05,478] {scheduler_job.py:155} INFO - Started process (PID=13426) to work on /airflow/dags/download_data.py
[2022-02-17 16:42:05,482] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:42:05,485] {logging_mixin.py:112} INFO - [2022-02-17 16:42:05,484] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:42:05,922] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:42:05,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:42:05,962] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:42:05,965] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.487 seconds
[2022-02-17 16:42:18,767] {scheduler_job.py:155} INFO - Started process (PID=13454) to work on /airflow/dags/download_data.py
[2022-02-17 16:42:18,780] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:42:18,784] {logging_mixin.py:112} INFO - [2022-02-17 16:42:18,783] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:42:19,225] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:42:19,273] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:42:19,281] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:42:19,285] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 16:42:32,040] {scheduler_job.py:155} INFO - Started process (PID=13480) to work on /airflow/dags/download_data.py
[2022-02-17 16:42:32,049] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:42:32,051] {logging_mixin.py:112} INFO - [2022-02-17 16:42:32,051] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:42:32,519] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:42:32,566] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:42:32,579] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:42:32,585] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 16:42:45,338] {scheduler_job.py:155} INFO - Started process (PID=13507) to work on /airflow/dags/download_data.py
[2022-02-17 16:42:45,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:42:45,352] {logging_mixin.py:112} INFO - [2022-02-17 16:42:45,352] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:42:45,939] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:42:45,992] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:42:46,000] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:42:46,005] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-17 16:42:58,639] {scheduler_job.py:155} INFO - Started process (PID=13534) to work on /airflow/dags/download_data.py
[2022-02-17 16:42:58,645] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:42:58,647] {logging_mixin.py:112} INFO - [2022-02-17 16:42:58,646] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:42:59,073] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:42:59,115] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:42:59,123] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:42:59,129] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 16:43:11,944] {scheduler_job.py:155} INFO - Started process (PID=13560) to work on /airflow/dags/download_data.py
[2022-02-17 16:43:11,948] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:43:11,955] {logging_mixin.py:112} INFO - [2022-02-17 16:43:11,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:43:12,423] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:43:12,471] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:43:12,480] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:43:12,485] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 16:43:25,171] {scheduler_job.py:155} INFO - Started process (PID=13588) to work on /airflow/dags/download_data.py
[2022-02-17 16:43:25,176] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:43:25,178] {logging_mixin.py:112} INFO - [2022-02-17 16:43:25,178] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:43:25,663] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:43:25,712] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:43:25,718] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:43:25,721] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 16:43:38,470] {scheduler_job.py:155} INFO - Started process (PID=13614) to work on /airflow/dags/download_data.py
[2022-02-17 16:43:38,474] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:43:38,475] {logging_mixin.py:112} INFO - [2022-02-17 16:43:38,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:43:38,923] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:43:38,973] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:43:38,978] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:43:38,982] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 16:43:51,756] {scheduler_job.py:155} INFO - Started process (PID=13642) to work on /airflow/dags/download_data.py
[2022-02-17 16:43:51,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:43:51,766] {logging_mixin.py:112} INFO - [2022-02-17 16:43:51,766] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:43:52,189] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:43:52,231] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:43:52,238] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:43:52,241] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-17 16:44:05,062] {scheduler_job.py:155} INFO - Started process (PID=13668) to work on /airflow/dags/download_data.py
[2022-02-17 16:44:05,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:44:05,070] {logging_mixin.py:112} INFO - [2022-02-17 16:44:05,070] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:44:05,504] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:44:05,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:44:05,564] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:44:05,569] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 16:44:18,329] {scheduler_job.py:155} INFO - Started process (PID=13696) to work on /airflow/dags/download_data.py
[2022-02-17 16:44:18,345] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:44:18,349] {logging_mixin.py:112} INFO - [2022-02-17 16:44:18,348] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:44:18,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:44:18,874] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:44:18,881] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:44:18,885] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 16:44:31,612] {scheduler_job.py:155} INFO - Started process (PID=13722) to work on /airflow/dags/download_data.py
[2022-02-17 16:44:31,616] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:44:31,618] {logging_mixin.py:112} INFO - [2022-02-17 16:44:31,618] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:44:32,084] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:44:32,143] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:44:32,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:44:32,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 16:44:44,904] {scheduler_job.py:155} INFO - Started process (PID=13748) to work on /airflow/dags/download_data.py
[2022-02-17 16:44:44,908] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:44:44,909] {logging_mixin.py:112} INFO - [2022-02-17 16:44:44,909] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:44:45,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:44:45,406] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:44:45,413] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:44:45,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 16:44:58,185] {scheduler_job.py:155} INFO - Started process (PID=13776) to work on /airflow/dags/download_data.py
[2022-02-17 16:44:58,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:44:58,194] {logging_mixin.py:112} INFO - [2022-02-17 16:44:58,193] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:44:58,623] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:44:58,673] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:44:58,683] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:44:58,689] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 16:45:11,481] {scheduler_job.py:155} INFO - Started process (PID=13802) to work on /airflow/dags/download_data.py
[2022-02-17 16:45:11,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:45:11,488] {logging_mixin.py:112} INFO - [2022-02-17 16:45:11,488] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:45:11,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:45:11,992] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:45:12,003] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:45:12,007] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 16:45:24,753] {scheduler_job.py:155} INFO - Started process (PID=13830) to work on /airflow/dags/download_data.py
[2022-02-17 16:45:24,758] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:45:24,760] {logging_mixin.py:112} INFO - [2022-02-17 16:45:24,760] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:45:25,215] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:45:25,279] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:45:25,290] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:45:25,294] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 16:45:38,078] {scheduler_job.py:155} INFO - Started process (PID=13856) to work on /airflow/dags/download_data.py
[2022-02-17 16:45:38,085] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:45:38,087] {logging_mixin.py:112} INFO - [2022-02-17 16:45:38,086] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:45:38,552] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:45:38,610] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:45:38,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:45:38,622] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 16:45:51,353] {scheduler_job.py:155} INFO - Started process (PID=13884) to work on /airflow/dags/download_data.py
[2022-02-17 16:45:51,361] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:45:51,364] {logging_mixin.py:112} INFO - [2022-02-17 16:45:51,363] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:45:51,805] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:45:51,851] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:45:51,860] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:45:51,867] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 16:46:04,632] {scheduler_job.py:155} INFO - Started process (PID=13910) to work on /airflow/dags/download_data.py
[2022-02-17 16:46:04,637] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:46:04,638] {logging_mixin.py:112} INFO - [2022-02-17 16:46:04,638] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:46:05,091] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:46:05,142] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:46:05,155] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:46:05,161] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 16:46:17,915] {scheduler_job.py:155} INFO - Started process (PID=13936) to work on /airflow/dags/download_data.py
[2022-02-17 16:46:17,920] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:46:17,922] {logging_mixin.py:112} INFO - [2022-02-17 16:46:17,921] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:46:18,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:46:18,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:46:18,390] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:46:18,394] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.479 seconds
[2022-02-17 16:46:31,203] {scheduler_job.py:155} INFO - Started process (PID=13964) to work on /airflow/dags/download_data.py
[2022-02-17 16:46:31,211] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:46:31,213] {logging_mixin.py:112} INFO - [2022-02-17 16:46:31,213] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:46:31,655] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:46:31,720] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:46:31,729] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:46:31,734] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 16:46:44,509] {scheduler_job.py:155} INFO - Started process (PID=13990) to work on /airflow/dags/download_data.py
[2022-02-17 16:46:44,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:46:44,518] {logging_mixin.py:112} INFO - [2022-02-17 16:46:44,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:46:44,945] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:46:44,988] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:46:44,995] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:46:45,000] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 16:46:57,791] {scheduler_job.py:155} INFO - Started process (PID=14018) to work on /airflow/dags/download_data.py
[2022-02-17 16:46:57,798] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:46:57,800] {logging_mixin.py:112} INFO - [2022-02-17 16:46:57,800] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:46:58,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:46:58,275] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:46:58,281] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:46:58,284] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 16:47:11,099] {scheduler_job.py:155} INFO - Started process (PID=14044) to work on /airflow/dags/download_data.py
[2022-02-17 16:47:11,105] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:47:11,108] {logging_mixin.py:112} INFO - [2022-02-17 16:47:11,108] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:47:11,700] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:47:11,758] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:47:11,768] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:47:11,776] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-17 16:47:24,361] {scheduler_job.py:155} INFO - Started process (PID=14072) to work on /airflow/dags/download_data.py
[2022-02-17 16:47:24,366] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:47:24,374] {logging_mixin.py:112} INFO - [2022-02-17 16:47:24,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:47:24,926] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:47:24,969] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:47:24,977] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:47:24,981] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 16:47:37,637] {scheduler_job.py:155} INFO - Started process (PID=14098) to work on /airflow/dags/download_data.py
[2022-02-17 16:47:37,642] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:47:37,644] {logging_mixin.py:112} INFO - [2022-02-17 16:47:37,644] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:47:38,102] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:47:38,158] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:47:38,172] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:47:38,177] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 16:47:50,914] {scheduler_job.py:155} INFO - Started process (PID=14124) to work on /airflow/dags/download_data.py
[2022-02-17 16:47:50,922] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:47:50,925] {logging_mixin.py:112} INFO - [2022-02-17 16:47:50,924] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:47:51,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:47:51,411] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:47:51,417] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:47:51,420] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 16:48:04,218] {scheduler_job.py:155} INFO - Started process (PID=14152) to work on /airflow/dags/download_data.py
[2022-02-17 16:48:04,222] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:48:04,223] {logging_mixin.py:112} INFO - [2022-02-17 16:48:04,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:48:04,669] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:48:04,709] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:48:04,717] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:48:04,722] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 16:48:17,541] {scheduler_job.py:155} INFO - Started process (PID=14178) to work on /airflow/dags/download_data.py
[2022-02-17 16:48:17,550] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:48:17,552] {logging_mixin.py:112} INFO - [2022-02-17 16:48:17,552] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:48:17,953] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:48:18,006] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:48:18,013] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:48:18,017] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.476 seconds
[2022-02-17 16:48:30,787] {scheduler_job.py:155} INFO - Started process (PID=14206) to work on /airflow/dags/download_data.py
[2022-02-17 16:48:30,792] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:48:30,793] {logging_mixin.py:112} INFO - [2022-02-17 16:48:30,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:48:31,251] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:48:31,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:48:31,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:48:31,325] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 16:48:44,085] {scheduler_job.py:155} INFO - Started process (PID=14232) to work on /airflow/dags/download_data.py
[2022-02-17 16:48:44,090] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:48:44,091] {logging_mixin.py:112} INFO - [2022-02-17 16:48:44,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:48:44,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:48:44,583] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:48:44,590] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:48:44,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 16:48:57,391] {scheduler_job.py:155} INFO - Started process (PID=14260) to work on /airflow/dags/download_data.py
[2022-02-17 16:48:57,398] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:48:57,401] {logging_mixin.py:112} INFO - [2022-02-17 16:48:57,400] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:48:57,841] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:48:57,894] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:48:57,904] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:48:57,910] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 16:49:10,670] {scheduler_job.py:155} INFO - Started process (PID=14286) to work on /airflow/dags/download_data.py
[2022-02-17 16:49:10,674] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:49:10,677] {logging_mixin.py:112} INFO - [2022-02-17 16:49:10,676] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:49:11,193] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:49:11,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:49:11,257] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:49:11,263] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 16:49:23,968] {scheduler_job.py:155} INFO - Started process (PID=14312) to work on /airflow/dags/download_data.py
[2022-02-17 16:49:23,975] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:49:23,980] {logging_mixin.py:112} INFO - [2022-02-17 16:49:23,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:49:24,576] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:49:24,625] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:49:24,637] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:49:24,646] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-17 16:49:37,273] {scheduler_job.py:155} INFO - Started process (PID=14340) to work on /airflow/dags/download_data.py
[2022-02-17 16:49:37,280] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:49:37,284] {logging_mixin.py:112} INFO - [2022-02-17 16:49:37,283] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:49:37,773] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:49:37,830] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:49:37,840] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:49:37,844] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 16:49:50,571] {scheduler_job.py:155} INFO - Started process (PID=14366) to work on /airflow/dags/download_data.py
[2022-02-17 16:49:50,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:49:50,579] {logging_mixin.py:112} INFO - [2022-02-17 16:49:50,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:49:51,015] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:49:51,066] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:49:51,076] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:49:51,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 16:50:03,878] {scheduler_job.py:155} INFO - Started process (PID=14394) to work on /airflow/dags/download_data.py
[2022-02-17 16:50:03,894] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:50:03,898] {logging_mixin.py:112} INFO - [2022-02-17 16:50:03,897] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:50:04,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:50:04,401] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:50:04,409] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:50:04,414] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 16:50:17,164] {scheduler_job.py:155} INFO - Started process (PID=14420) to work on /airflow/dags/download_data.py
[2022-02-17 16:50:17,170] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:50:17,172] {logging_mixin.py:112} INFO - [2022-02-17 16:50:17,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:50:17,637] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:50:17,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:50:17,692] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:50:17,695] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 16:50:30,473] {scheduler_job.py:155} INFO - Started process (PID=14448) to work on /airflow/dags/download_data.py
[2022-02-17 16:50:30,479] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:50:30,482] {logging_mixin.py:112} INFO - [2022-02-17 16:50:30,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:50:30,952] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:50:31,011] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:50:31,021] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:50:31,028] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 16:50:43,780] {scheduler_job.py:155} INFO - Started process (PID=14474) to work on /airflow/dags/download_data.py
[2022-02-17 16:50:43,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:50:43,788] {logging_mixin.py:112} INFO - [2022-02-17 16:50:43,788] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:50:44,239] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:50:44,290] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:50:44,297] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:50:44,303] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 16:50:57,019] {scheduler_job.py:155} INFO - Started process (PID=14502) to work on /airflow/dags/download_data.py
[2022-02-17 16:50:57,033] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:50:57,035] {logging_mixin.py:112} INFO - [2022-02-17 16:50:57,034] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:50:57,451] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:50:57,490] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:50:57,501] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:50:57,505] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-17 16:51:10,282] {scheduler_job.py:155} INFO - Started process (PID=14528) to work on /airflow/dags/download_data.py
[2022-02-17 16:51:10,286] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:51:10,288] {logging_mixin.py:112} INFO - [2022-02-17 16:51:10,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:51:10,753] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:51:10,794] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:51:10,803] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:51:10,809] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 16:51:23,521] {scheduler_job.py:155} INFO - Started process (PID=14554) to work on /airflow/dags/download_data.py
[2022-02-17 16:51:23,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:51:23,534] {logging_mixin.py:112} INFO - [2022-02-17 16:51:23,534] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:51:24,044] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:51:24,110] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:51:24,124] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:51:24,130] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-17 16:51:36,830] {scheduler_job.py:155} INFO - Started process (PID=14582) to work on /airflow/dags/download_data.py
[2022-02-17 16:51:36,834] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:51:36,836] {logging_mixin.py:112} INFO - [2022-02-17 16:51:36,836] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:51:37,284] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:51:37,330] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:51:37,339] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:51:37,345] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 16:51:50,096] {scheduler_job.py:155} INFO - Started process (PID=14608) to work on /airflow/dags/download_data.py
[2022-02-17 16:51:50,100] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:51:50,102] {logging_mixin.py:112} INFO - [2022-02-17 16:51:50,101] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:51:50,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:51:50,577] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:51:50,584] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:51:50,588] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-17 16:52:03,497] {scheduler_job.py:155} INFO - Started process (PID=14636) to work on /airflow/dags/download_data.py
[2022-02-17 16:52:03,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:52:03,505] {logging_mixin.py:112} INFO - [2022-02-17 16:52:03,505] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:52:03,934] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:52:03,983] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:52:03,993] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:52:04,000] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 16:52:16,775] {scheduler_job.py:155} INFO - Started process (PID=14662) to work on /airflow/dags/download_data.py
[2022-02-17 16:52:16,787] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:52:16,789] {logging_mixin.py:112} INFO - [2022-02-17 16:52:16,789] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:52:17,213] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:52:17,260] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:52:17,268] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:52:17,273] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 16:52:30,076] {scheduler_job.py:155} INFO - Started process (PID=14690) to work on /airflow/dags/download_data.py
[2022-02-17 16:52:30,086] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:52:30,087] {logging_mixin.py:112} INFO - [2022-02-17 16:52:30,087] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:52:30,530] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:52:30,584] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:52:30,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:52:30,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 16:52:43,391] {scheduler_job.py:155} INFO - Started process (PID=14716) to work on /airflow/dags/download_data.py
[2022-02-17 16:52:43,400] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:52:43,402] {logging_mixin.py:112} INFO - [2022-02-17 16:52:43,402] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:52:43,838] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:52:43,888] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:52:43,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:52:43,900] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 16:52:56,635] {scheduler_job.py:155} INFO - Started process (PID=14742) to work on /airflow/dags/download_data.py
[2022-02-17 16:52:56,645] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:52:56,647] {logging_mixin.py:112} INFO - [2022-02-17 16:52:56,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:52:57,075] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:52:57,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:52:57,135] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:52:57,139] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 16:53:09,942] {scheduler_job.py:155} INFO - Started process (PID=14770) to work on /airflow/dags/download_data.py
[2022-02-17 16:53:09,945] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:53:09,948] {logging_mixin.py:112} INFO - [2022-02-17 16:53:09,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:53:10,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:53:10,758] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:53:10,763] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:53:10,767] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.826 seconds
[2022-02-17 16:53:23,347] {scheduler_job.py:155} INFO - Started process (PID=14796) to work on /airflow/dags/download_data.py
[2022-02-17 16:53:23,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:53:23,359] {logging_mixin.py:112} INFO - [2022-02-17 16:53:23,359] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:53:23,793] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:53:23,842] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:53:23,850] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:53:23,855] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 16:53:36,638] {scheduler_job.py:155} INFO - Started process (PID=14824) to work on /airflow/dags/download_data.py
[2022-02-17 16:53:36,644] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:53:36,645] {logging_mixin.py:112} INFO - [2022-02-17 16:53:36,645] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:53:37,114] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:53:37,179] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:53:37,190] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:53:37,198] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 16:53:49,875] {scheduler_job.py:155} INFO - Started process (PID=14850) to work on /airflow/dags/download_data.py
[2022-02-17 16:53:49,879] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:53:49,881] {logging_mixin.py:112} INFO - [2022-02-17 16:53:49,881] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:53:50,299] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:53:50,350] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:53:50,357] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:53:50,361] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.486 seconds
[2022-02-17 16:54:03,207] {scheduler_job.py:155} INFO - Started process (PID=14878) to work on /airflow/dags/download_data.py
[2022-02-17 16:54:03,210] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:54:03,212] {logging_mixin.py:112} INFO - [2022-02-17 16:54:03,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:54:03,641] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:54:03,694] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:54:03,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:54:03,708] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 16:54:16,519] {scheduler_job.py:155} INFO - Started process (PID=14904) to work on /airflow/dags/download_data.py
[2022-02-17 16:54:16,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:54:16,529] {logging_mixin.py:112} INFO - [2022-02-17 16:54:16,529] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:54:16,982] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:54:17,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:54:17,036] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:54:17,041] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 16:54:29,801] {scheduler_job.py:155} INFO - Started process (PID=14930) to work on /airflow/dags/download_data.py
[2022-02-17 16:54:29,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:54:29,811] {logging_mixin.py:112} INFO - [2022-02-17 16:54:29,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:54:30,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:54:30,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:54:30,459] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:54:30,463] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.662 seconds
[2022-02-17 16:54:43,110] {scheduler_job.py:155} INFO - Started process (PID=14958) to work on /airflow/dags/download_data.py
[2022-02-17 16:54:43,115] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:54:43,117] {logging_mixin.py:112} INFO - [2022-02-17 16:54:43,116] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:54:43,568] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:54:43,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:54:43,622] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:54:43,627] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 16:54:56,405] {scheduler_job.py:155} INFO - Started process (PID=14984) to work on /airflow/dags/download_data.py
[2022-02-17 16:54:56,412] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:54:56,414] {logging_mixin.py:112} INFO - [2022-02-17 16:54:56,414] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:54:56,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:54:56,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:54:56,907] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:54:56,913] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 16:55:09,733] {scheduler_job.py:155} INFO - Started process (PID=15012) to work on /airflow/dags/download_data.py
[2022-02-17 16:55:09,745] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:55:09,747] {logging_mixin.py:112} INFO - [2022-02-17 16:55:09,747] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:55:10,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:55:10,307] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:55:10,317] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:55:10,323] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 16:55:22,961] {scheduler_job.py:155} INFO - Started process (PID=15038) to work on /airflow/dags/download_data.py
[2022-02-17 16:55:22,966] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:55:22,968] {logging_mixin.py:112} INFO - [2022-02-17 16:55:22,968] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:55:23,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:55:23,451] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:55:23,459] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:55:23,464] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 16:55:36,351] {scheduler_job.py:155} INFO - Started process (PID=15066) to work on /airflow/dags/download_data.py
[2022-02-17 16:55:36,356] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:55:36,359] {logging_mixin.py:112} INFO - [2022-02-17 16:55:36,358] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:55:36,814] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:55:36,881] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:55:36,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:55:36,898] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 16:55:49,589] {scheduler_job.py:155} INFO - Started process (PID=15092) to work on /airflow/dags/download_data.py
[2022-02-17 16:55:49,595] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:55:49,597] {logging_mixin.py:112} INFO - [2022-02-17 16:55:49,597] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:55:50,036] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:55:50,088] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:55:50,096] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:55:50,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 16:56:02,899] {scheduler_job.py:155} INFO - Started process (PID=15120) to work on /airflow/dags/download_data.py
[2022-02-17 16:56:02,907] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:56:02,909] {logging_mixin.py:112} INFO - [2022-02-17 16:56:02,909] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:56:03,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:56:03,426] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:56:03,436] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:56:03,443] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 16:56:16,232] {scheduler_job.py:155} INFO - Started process (PID=15146) to work on /airflow/dags/download_data.py
[2022-02-17 16:56:16,239] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:56:16,241] {logging_mixin.py:112} INFO - [2022-02-17 16:56:16,241] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:56:16,683] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:56:16,737] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:56:16,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:56:16,752] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 16:56:29,480] {scheduler_job.py:155} INFO - Started process (PID=15172) to work on /airflow/dags/download_data.py
[2022-02-17 16:56:29,484] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:56:29,486] {logging_mixin.py:112} INFO - [2022-02-17 16:56:29,486] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:56:29,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:56:29,998] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:56:30,012] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:56:30,021] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 16:56:42,811] {scheduler_job.py:155} INFO - Started process (PID=15200) to work on /airflow/dags/download_data.py
[2022-02-17 16:56:42,816] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:56:42,817] {logging_mixin.py:112} INFO - [2022-02-17 16:56:42,817] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:56:43,256] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:56:43,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:56:43,314] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:56:43,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 16:56:56,093] {scheduler_job.py:155} INFO - Started process (PID=15226) to work on /airflow/dags/download_data.py
[2022-02-17 16:56:56,098] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:56:56,100] {logging_mixin.py:112} INFO - [2022-02-17 16:56:56,099] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:56:56,549] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:56:56,592] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:56:56,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:56:56,607] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 16:57:09,379] {scheduler_job.py:155} INFO - Started process (PID=15254) to work on /airflow/dags/download_data.py
[2022-02-17 16:57:09,383] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:57:09,384] {logging_mixin.py:112} INFO - [2022-02-17 16:57:09,384] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:57:09,815] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:57:09,856] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:57:09,863] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:57:09,869] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 16:57:22,649] {scheduler_job.py:155} INFO - Started process (PID=15280) to work on /airflow/dags/download_data.py
[2022-02-17 16:57:22,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:57:22,656] {logging_mixin.py:112} INFO - [2022-02-17 16:57:22,656] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:57:23,096] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:57:23,147] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:57:23,152] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:57:23,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 16:57:35,974] {scheduler_job.py:155} INFO - Started process (PID=15308) to work on /airflow/dags/download_data.py
[2022-02-17 16:57:35,978] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:57:35,980] {logging_mixin.py:112} INFO - [2022-02-17 16:57:35,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:57:36,438] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:57:36,505] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:57:36,516] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:57:36,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 16:57:49,218] {scheduler_job.py:155} INFO - Started process (PID=15334) to work on /airflow/dags/download_data.py
[2022-02-17 16:57:49,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:57:49,229] {logging_mixin.py:112} INFO - [2022-02-17 16:57:49,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:57:49,683] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:57:49,737] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:57:49,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:57:49,755] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 16:58:02,493] {scheduler_job.py:155} INFO - Started process (PID=15360) to work on /airflow/dags/download_data.py
[2022-02-17 16:58:02,500] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:58:02,503] {logging_mixin.py:112} INFO - [2022-02-17 16:58:02,502] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:58:02,950] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:58:02,994] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:58:03,001] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:58:03,006] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 16:58:15,811] {scheduler_job.py:155} INFO - Started process (PID=15388) to work on /airflow/dags/download_data.py
[2022-02-17 16:58:15,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:58:15,822] {logging_mixin.py:112} INFO - [2022-02-17 16:58:15,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:58:16,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:58:16,317] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:58:16,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:58:16,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 16:58:29,098] {scheduler_job.py:155} INFO - Started process (PID=15414) to work on /airflow/dags/download_data.py
[2022-02-17 16:58:29,106] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:58:29,108] {logging_mixin.py:112} INFO - [2022-02-17 16:58:29,108] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:58:29,556] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:58:29,619] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:58:29,628] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:58:29,633] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 16:58:42,404] {scheduler_job.py:155} INFO - Started process (PID=15442) to work on /airflow/dags/download_data.py
[2022-02-17 16:58:42,410] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:58:42,413] {logging_mixin.py:112} INFO - [2022-02-17 16:58:42,412] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:58:42,848] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:58:42,895] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:58:42,901] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:58:42,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 16:58:55,657] {scheduler_job.py:155} INFO - Started process (PID=15468) to work on /airflow/dags/download_data.py
[2022-02-17 16:58:55,661] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:58:55,663] {logging_mixin.py:112} INFO - [2022-02-17 16:58:55,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:58:56,084] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:58:56,123] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:58:56,132] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:58:56,138] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.482 seconds
[2022-02-17 16:59:08,951] {scheduler_job.py:155} INFO - Started process (PID=15496) to work on /airflow/dags/download_data.py
[2022-02-17 16:59:08,955] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:59:08,956] {logging_mixin.py:112} INFO - [2022-02-17 16:59:08,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:59:09,390] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:59:09,501] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:59:09,513] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:59:09,523] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 16:59:22,222] {scheduler_job.py:155} INFO - Started process (PID=15522) to work on /airflow/dags/download_data.py
[2022-02-17 16:59:22,226] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:59:22,228] {logging_mixin.py:112} INFO - [2022-02-17 16:59:22,228] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:59:22,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:59:22,713] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:59:22,718] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:59:22,724] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 16:59:35,566] {scheduler_job.py:155} INFO - Started process (PID=15548) to work on /airflow/dags/download_data.py
[2022-02-17 16:59:35,571] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:59:35,573] {logging_mixin.py:112} INFO - [2022-02-17 16:59:35,573] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:59:36,049] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:59:36,109] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:59:36,117] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:59:36,122] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 16:59:48,889] {scheduler_job.py:155} INFO - Started process (PID=15576) to work on /airflow/dags/download_data.py
[2022-02-17 16:59:48,898] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 16:59:48,899] {logging_mixin.py:112} INFO - [2022-02-17 16:59:48,899] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 16:59:49,339] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 16:59:49,397] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 16:59:49,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 16:59:49,410] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 17:00:02,352] {scheduler_job.py:155} INFO - Started process (PID=15602) to work on /airflow/dags/download_data.py
[2022-02-17 17:00:02,359] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:00:02,362] {logging_mixin.py:112} INFO - [2022-02-17 17:00:02,361] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:00:02,807] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:00:02,859] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:00:02,868] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:00:02,874] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 17:00:16,318] {scheduler_job.py:155} INFO - Started process (PID=15630) to work on /airflow/dags/download_data.py
[2022-02-17 17:00:16,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:00:16,325] {logging_mixin.py:112} INFO - [2022-02-17 17:00:16,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:00:16,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:00:16,868] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:00:16,877] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:00:16,882] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 17:54:39,811] {scheduler_job.py:155} INFO - Started process (PID=15666) to work on /airflow/dags/download_data.py
[2022-02-17 17:54:39,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:54:39,821] {logging_mixin.py:112} INFO - [2022-02-17 17:54:39,820] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:54:40,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:54:40,322] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:54:40,330] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:54:40,335] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 17:54:53,060] {scheduler_job.py:155} INFO - Started process (PID=15694) to work on /airflow/dags/download_data.py
[2022-02-17 17:54:53,066] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:54:53,068] {logging_mixin.py:112} INFO - [2022-02-17 17:54:53,068] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:54:53,500] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:54:53,549] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:54:53,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:54:53,571] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 17:55:06,340] {scheduler_job.py:155} INFO - Started process (PID=15720) to work on /airflow/dags/download_data.py
[2022-02-17 17:55:06,344] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:55:06,346] {logging_mixin.py:112} INFO - [2022-02-17 17:55:06,345] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:55:06,788] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:55:06,836] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:55:06,846] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:55:06,851] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 17:55:19,588] {scheduler_job.py:155} INFO - Started process (PID=15746) to work on /airflow/dags/download_data.py
[2022-02-17 17:55:19,596] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:55:19,599] {logging_mixin.py:112} INFO - [2022-02-17 17:55:19,599] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:55:20,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:55:20,080] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:55:20,087] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:55:20,094] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 17:55:32,915] {scheduler_job.py:155} INFO - Started process (PID=15774) to work on /airflow/dags/download_data.py
[2022-02-17 17:55:32,922] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:55:32,924] {logging_mixin.py:112} INFO - [2022-02-17 17:55:32,924] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:55:33,392] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:55:33,437] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:55:33,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:55:33,459] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 17:55:46,218] {scheduler_job.py:155} INFO - Started process (PID=15800) to work on /airflow/dags/download_data.py
[2022-02-17 17:55:46,225] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:55:46,227] {logging_mixin.py:112} INFO - [2022-02-17 17:55:46,227] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:55:46,653] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:55:46,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:55:46,711] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:55:46,714] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 17:55:59,483] {scheduler_job.py:155} INFO - Started process (PID=15828) to work on /airflow/dags/download_data.py
[2022-02-17 17:55:59,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:55:59,489] {logging_mixin.py:112} INFO - [2022-02-17 17:55:59,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:55:59,934] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:55:59,991] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:56:00,001] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:56:00,007] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 17:56:12,804] {scheduler_job.py:155} INFO - Started process (PID=15854) to work on /airflow/dags/download_data.py
[2022-02-17 17:56:12,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:56:12,810] {logging_mixin.py:112} INFO - [2022-02-17 17:56:12,810] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:56:13,253] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:56:13,295] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:56:13,304] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:56:13,310] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 17:56:26,096] {scheduler_job.py:155} INFO - Started process (PID=15882) to work on /airflow/dags/download_data.py
[2022-02-17 17:56:26,102] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:56:26,104] {logging_mixin.py:112} INFO - [2022-02-17 17:56:26,104] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:56:26,562] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:56:26,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:56:26,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:56:26,627] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 17:56:39,413] {scheduler_job.py:155} INFO - Started process (PID=15908) to work on /airflow/dags/download_data.py
[2022-02-17 17:56:39,420] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:56:39,422] {logging_mixin.py:112} INFO - [2022-02-17 17:56:39,422] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:56:39,842] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:56:39,892] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:56:39,902] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:56:39,908] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 17:56:52,701] {scheduler_job.py:155} INFO - Started process (PID=15934) to work on /airflow/dags/download_data.py
[2022-02-17 17:56:52,706] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:56:52,708] {logging_mixin.py:112} INFO - [2022-02-17 17:56:52,707] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:56:53,167] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:56:53,221] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:56:53,232] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:56:53,236] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 17:57:06,016] {scheduler_job.py:155} INFO - Started process (PID=15962) to work on /airflow/dags/download_data.py
[2022-02-17 17:57:06,025] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:57:06,030] {logging_mixin.py:112} INFO - [2022-02-17 17:57:06,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:57:06,485] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:57:06,531] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:57:06,538] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:57:06,542] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 17:57:19,262] {scheduler_job.py:155} INFO - Started process (PID=15988) to work on /airflow/dags/download_data.py
[2022-02-17 17:57:19,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:57:19,268] {logging_mixin.py:112} INFO - [2022-02-17 17:57:19,268] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:57:19,707] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:57:19,756] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:57:19,766] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:57:19,772] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 17:57:32,579] {scheduler_job.py:155} INFO - Started process (PID=16016) to work on /airflow/dags/download_data.py
[2022-02-17 17:57:32,584] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:57:32,586] {logging_mixin.py:112} INFO - [2022-02-17 17:57:32,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:57:33,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:57:33,077] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:57:33,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:57:33,090] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 17:57:45,861] {scheduler_job.py:155} INFO - Started process (PID=16042) to work on /airflow/dags/download_data.py
[2022-02-17 17:57:45,867] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:57:45,869] {logging_mixin.py:112} INFO - [2022-02-17 17:57:45,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:57:46,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:57:46,359] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:57:46,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:57:46,373] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 17:57:59,141] {scheduler_job.py:155} INFO - Started process (PID=16070) to work on /airflow/dags/download_data.py
[2022-02-17 17:57:59,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:57:59,149] {logging_mixin.py:112} INFO - [2022-02-17 17:57:59,148] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:57:59,609] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:57:59,666] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:57:59,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:57:59,678] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 17:58:12,429] {scheduler_job.py:155} INFO - Started process (PID=16096) to work on /airflow/dags/download_data.py
[2022-02-17 17:58:12,434] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:58:12,436] {logging_mixin.py:112} INFO - [2022-02-17 17:58:12,436] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:58:12,868] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:58:12,963] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:58:12,969] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:58:12,974] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 17:58:25,734] {scheduler_job.py:155} INFO - Started process (PID=16124) to work on /airflow/dags/download_data.py
[2022-02-17 17:58:25,749] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:58:25,751] {logging_mixin.py:112} INFO - [2022-02-17 17:58:25,751] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:58:26,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:58:26,327] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:58:26,336] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:58:26,344] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-17 17:58:39,013] {scheduler_job.py:155} INFO - Started process (PID=16150) to work on /airflow/dags/download_data.py
[2022-02-17 17:58:39,020] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:58:39,024] {logging_mixin.py:112} INFO - [2022-02-17 17:58:39,024] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:58:39,466] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:58:39,520] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:58:39,526] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:58:39,529] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 17:58:52,281] {scheduler_job.py:155} INFO - Started process (PID=16176) to work on /airflow/dags/download_data.py
[2022-02-17 17:58:52,290] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:58:52,295] {logging_mixin.py:112} INFO - [2022-02-17 17:58:52,295] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:58:52,731] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:58:52,781] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:58:52,789] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:58:52,794] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 17:59:05,562] {scheduler_job.py:155} INFO - Started process (PID=16204) to work on /airflow/dags/download_data.py
[2022-02-17 17:59:05,569] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:59:05,589] {logging_mixin.py:112} INFO - [2022-02-17 17:59:05,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:59:06,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:59:06,208] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:59:06,218] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:59:06,225] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.663 seconds
[2022-02-17 17:59:18,872] {scheduler_job.py:155} INFO - Started process (PID=16230) to work on /airflow/dags/download_data.py
[2022-02-17 17:59:18,879] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:59:18,881] {logging_mixin.py:112} INFO - [2022-02-17 17:59:18,881] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:59:19,276] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:59:19,317] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:59:19,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:59:19,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.454 seconds
[2022-02-17 17:59:32,186] {scheduler_job.py:155} INFO - Started process (PID=16258) to work on /airflow/dags/download_data.py
[2022-02-17 17:59:32,198] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:59:32,201] {logging_mixin.py:112} INFO - [2022-02-17 17:59:32,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:59:32,646] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:59:32,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:59:32,713] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:59:32,722] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 17:59:45,471] {scheduler_job.py:155} INFO - Started process (PID=16284) to work on /airflow/dags/download_data.py
[2022-02-17 17:59:45,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:59:45,480] {logging_mixin.py:112} INFO - [2022-02-17 17:59:45,480] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:59:45,920] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:59:45,959] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:59:45,965] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:59:45,970] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 17:59:58,743] {scheduler_job.py:155} INFO - Started process (PID=16312) to work on /airflow/dags/download_data.py
[2022-02-17 17:59:58,748] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 17:59:58,750] {logging_mixin.py:112} INFO - [2022-02-17 17:59:58,750] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 17:59:59,205] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 17:59:59,261] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 17:59:59,271] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 17:59:59,277] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 18:00:12,052] {scheduler_job.py:155} INFO - Started process (PID=16338) to work on /airflow/dags/download_data.py
[2022-02-17 18:00:12,060] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:00:12,063] {logging_mixin.py:112} INFO - [2022-02-17 18:00:12,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:00:12,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:00:12,682] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:00:12,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:00:12,696] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-17 18:00:25,265] {scheduler_job.py:155} INFO - Started process (PID=16364) to work on /airflow/dags/download_data.py
[2022-02-17 18:00:25,272] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:00:25,274] {logging_mixin.py:112} INFO - [2022-02-17 18:00:25,273] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:00:25,705] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:00:25,755] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:00:25,763] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:00:25,767] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 18:00:38,554] {scheduler_job.py:155} INFO - Started process (PID=16392) to work on /airflow/dags/download_data.py
[2022-02-17 18:00:38,557] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:00:38,559] {logging_mixin.py:112} INFO - [2022-02-17 18:00:38,559] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:00:39,007] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:00:39,049] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:00:39,056] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:00:39,059] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 18:00:51,823] {scheduler_job.py:155} INFO - Started process (PID=16418) to work on /airflow/dags/download_data.py
[2022-02-17 18:00:51,827] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:00:51,828] {logging_mixin.py:112} INFO - [2022-02-17 18:00:51,828] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:00:52,270] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:00:52,310] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:00:52,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:00:52,320] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 18:01:05,113] {scheduler_job.py:155} INFO - Started process (PID=16446) to work on /airflow/dags/download_data.py
[2022-02-17 18:01:05,120] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:01:05,122] {logging_mixin.py:112} INFO - [2022-02-17 18:01:05,121] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:01:05,556] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:01:05,604] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:01:05,613] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:01:05,619] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 18:01:18,409] {scheduler_job.py:155} INFO - Started process (PID=16472) to work on /airflow/dags/download_data.py
[2022-02-17 18:01:18,413] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:01:18,415] {logging_mixin.py:112} INFO - [2022-02-17 18:01:18,414] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:01:18,906] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:01:18,951] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:01:18,957] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:01:18,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 18:01:31,697] {scheduler_job.py:155} INFO - Started process (PID=16500) to work on /airflow/dags/download_data.py
[2022-02-17 18:01:31,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:01:31,709] {logging_mixin.py:112} INFO - [2022-02-17 18:01:31,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:01:32,227] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:01:32,266] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:01:32,273] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:01:32,279] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 18:01:45,004] {scheduler_job.py:155} INFO - Started process (PID=16526) to work on /airflow/dags/download_data.py
[2022-02-17 18:01:45,015] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:01:45,018] {logging_mixin.py:112} INFO - [2022-02-17 18:01:45,017] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:01:45,443] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:01:45,496] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:01:45,502] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:01:45,506] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 18:01:58,309] {scheduler_job.py:155} INFO - Started process (PID=16552) to work on /airflow/dags/download_data.py
[2022-02-17 18:01:58,316] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:01:58,319] {logging_mixin.py:112} INFO - [2022-02-17 18:01:58,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:01:58,821] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:01:58,880] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:01:58,888] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:01:58,893] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 18:02:11,612] {scheduler_job.py:155} INFO - Started process (PID=16580) to work on /airflow/dags/download_data.py
[2022-02-17 18:02:11,618] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:02:11,619] {logging_mixin.py:112} INFO - [2022-02-17 18:02:11,619] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:02:12,096] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:02:12,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:02:12,170] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:02:12,177] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 18:02:24,871] {scheduler_job.py:155} INFO - Started process (PID=16606) to work on /airflow/dags/download_data.py
[2022-02-17 18:02:24,880] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:02:24,882] {logging_mixin.py:112} INFO - [2022-02-17 18:02:24,882] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:02:25,347] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:02:25,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:02:25,386] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:02:25,389] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 18:02:38,175] {scheduler_job.py:155} INFO - Started process (PID=16634) to work on /airflow/dags/download_data.py
[2022-02-17 18:02:38,180] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:02:38,182] {logging_mixin.py:112} INFO - [2022-02-17 18:02:38,181] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:02:38,652] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:02:38,708] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:02:38,720] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:02:38,729] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 18:02:51,456] {scheduler_job.py:155} INFO - Started process (PID=16660) to work on /airflow/dags/download_data.py
[2022-02-17 18:02:51,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:02:51,464] {logging_mixin.py:112} INFO - [2022-02-17 18:02:51,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:02:51,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:02:51,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:02:51,953] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:02:51,959] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 18:03:04,736] {scheduler_job.py:155} INFO - Started process (PID=16688) to work on /airflow/dags/download_data.py
[2022-02-17 18:03:04,740] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:03:04,742] {logging_mixin.py:112} INFO - [2022-02-17 18:03:04,742] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:03:05,182] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:03:05,235] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:03:05,242] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:03:05,247] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 18:03:18,007] {scheduler_job.py:155} INFO - Started process (PID=16714) to work on /airflow/dags/download_data.py
[2022-02-17 18:03:18,013] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:03:18,015] {logging_mixin.py:112} INFO - [2022-02-17 18:03:18,015] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:03:18,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:03:18,519] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:03:18,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:03:18,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 18:03:31,289] {scheduler_job.py:155} INFO - Started process (PID=16742) to work on /airflow/dags/download_data.py
[2022-02-17 18:03:31,304] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:03:31,307] {logging_mixin.py:112} INFO - [2022-02-17 18:03:31,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:03:31,872] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:03:31,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:03:31,935] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:03:31,941] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.652 seconds
[2022-02-17 18:03:44,626] {scheduler_job.py:155} INFO - Started process (PID=16768) to work on /airflow/dags/download_data.py
[2022-02-17 18:03:44,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:03:44,635] {logging_mixin.py:112} INFO - [2022-02-17 18:03:44,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:03:45,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:03:45,112] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:03:45,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:03:45,128] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 18:03:57,870] {scheduler_job.py:155} INFO - Started process (PID=16794) to work on /airflow/dags/download_data.py
[2022-02-17 18:03:57,876] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:03:57,878] {logging_mixin.py:112} INFO - [2022-02-17 18:03:57,877] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:03:58,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:03:58,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:03:58,417] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:03:58,423] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 18:04:11,178] {scheduler_job.py:155} INFO - Started process (PID=16822) to work on /airflow/dags/download_data.py
[2022-02-17 18:04:11,187] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:04:11,189] {logging_mixin.py:112} INFO - [2022-02-17 18:04:11,189] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:04:11,615] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:04:11,664] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:04:11,671] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:04:11,677] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 18:04:24,464] {scheduler_job.py:155} INFO - Started process (PID=16848) to work on /airflow/dags/download_data.py
[2022-02-17 18:04:24,468] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:04:24,469] {logging_mixin.py:112} INFO - [2022-02-17 18:04:24,469] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:04:24,904] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:04:24,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:04:24,961] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:04:24,966] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 18:04:37,781] {scheduler_job.py:155} INFO - Started process (PID=16876) to work on /airflow/dags/download_data.py
[2022-02-17 18:04:37,785] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:04:37,787] {logging_mixin.py:112} INFO - [2022-02-17 18:04:37,786] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:04:38,227] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:04:38,267] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:04:38,278] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:04:38,282] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 18:04:51,055] {scheduler_job.py:155} INFO - Started process (PID=16902) to work on /airflow/dags/download_data.py
[2022-02-17 18:04:51,060] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:04:51,062] {logging_mixin.py:112} INFO - [2022-02-17 18:04:51,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:04:51,510] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:04:51,551] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:04:51,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:04:51,565] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 18:05:04,389] {scheduler_job.py:155} INFO - Started process (PID=16930) to work on /airflow/dags/download_data.py
[2022-02-17 18:05:04,392] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:05:04,394] {logging_mixin.py:112} INFO - [2022-02-17 18:05:04,394] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:05:04,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:05:04,866] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:05:04,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:05:04,881] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 18:05:17,689] {scheduler_job.py:155} INFO - Started process (PID=16956) to work on /airflow/dags/download_data.py
[2022-02-17 18:05:17,693] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:05:17,695] {logging_mixin.py:112} INFO - [2022-02-17 18:05:17,695] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:05:18,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:05:18,184] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:05:18,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:05:18,197] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 18:05:30,943] {scheduler_job.py:155} INFO - Started process (PID=16982) to work on /airflow/dags/download_data.py
[2022-02-17 18:05:30,950] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:05:30,951] {logging_mixin.py:112} INFO - [2022-02-17 18:05:30,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:05:31,418] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:05:31,473] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:05:31,485] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:05:31,490] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 18:05:44,279] {scheduler_job.py:155} INFO - Started process (PID=17010) to work on /airflow/dags/download_data.py
[2022-02-17 18:05:44,288] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:05:44,290] {logging_mixin.py:112} INFO - [2022-02-17 18:05:44,290] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:05:44,743] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:05:44,790] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:05:44,801] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:05:44,805] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 18:05:57,517] {scheduler_job.py:155} INFO - Started process (PID=17036) to work on /airflow/dags/download_data.py
[2022-02-17 18:05:57,522] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:05:57,524] {logging_mixin.py:112} INFO - [2022-02-17 18:05:57,523] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:05:57,985] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:05:58,036] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:05:58,044] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:05:58,048] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 18:06:10,806] {scheduler_job.py:155} INFO - Started process (PID=17064) to work on /airflow/dags/download_data.py
[2022-02-17 18:06:10,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:06:10,820] {logging_mixin.py:112} INFO - [2022-02-17 18:06:10,820] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:06:11,264] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:06:11,310] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:06:11,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:06:11,325] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 18:06:24,051] {scheduler_job.py:155} INFO - Started process (PID=17090) to work on /airflow/dags/download_data.py
[2022-02-17 18:06:24,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:06:24,057] {logging_mixin.py:112} INFO - [2022-02-17 18:06:24,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:06:24,487] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:06:24,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:06:24,536] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:06:24,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 18:06:37,376] {scheduler_job.py:155} INFO - Started process (PID=17118) to work on /airflow/dags/download_data.py
[2022-02-17 18:06:37,382] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:06:37,384] {logging_mixin.py:112} INFO - [2022-02-17 18:06:37,384] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:06:37,802] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:06:37,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:06:37,860] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:06:37,865] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 18:06:50,598] {scheduler_job.py:155} INFO - Started process (PID=17144) to work on /airflow/dags/download_data.py
[2022-02-17 18:06:50,602] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:06:50,604] {logging_mixin.py:112} INFO - [2022-02-17 18:06:50,604] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:06:51,049] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:06:51,099] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:06:51,105] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:06:51,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 18:07:03,883] {scheduler_job.py:155} INFO - Started process (PID=17170) to work on /airflow/dags/download_data.py
[2022-02-17 18:07:03,887] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:07:03,889] {logging_mixin.py:112} INFO - [2022-02-17 18:07:03,889] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:07:04,319] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:07:04,371] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:07:04,378] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:07:04,383] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 18:07:17,179] {scheduler_job.py:155} INFO - Started process (PID=17198) to work on /airflow/dags/download_data.py
[2022-02-17 18:07:17,184] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:07:17,185] {logging_mixin.py:112} INFO - [2022-02-17 18:07:17,185] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:07:17,630] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:07:17,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:07:17,681] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:07:17,685] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 18:07:30,456] {scheduler_job.py:155} INFO - Started process (PID=17224) to work on /airflow/dags/download_data.py
[2022-02-17 18:07:30,468] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:07:30,470] {logging_mixin.py:112} INFO - [2022-02-17 18:07:30,470] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:07:30,929] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:07:30,982] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:07:30,991] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:07:30,997] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 18:07:43,735] {scheduler_job.py:155} INFO - Started process (PID=17252) to work on /airflow/dags/download_data.py
[2022-02-17 18:07:43,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:07:43,744] {logging_mixin.py:112} INFO - [2022-02-17 18:07:43,743] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:07:44,193] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:07:44,242] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:07:44,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:07:44,253] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 18:07:56,993] {scheduler_job.py:155} INFO - Started process (PID=17278) to work on /airflow/dags/download_data.py
[2022-02-17 18:07:56,997] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:07:57,000] {logging_mixin.py:112} INFO - [2022-02-17 18:07:56,999] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:07:57,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:07:57,500] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:07:57,506] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:07:57,509] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 18:08:10,306] {scheduler_job.py:155} INFO - Started process (PID=17306) to work on /airflow/dags/download_data.py
[2022-02-17 18:08:10,320] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:08:10,324] {logging_mixin.py:112} INFO - [2022-02-17 18:08:10,323] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:08:10,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:08:10,829] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:08:10,837] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:08:10,842] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 18:08:23,523] {scheduler_job.py:155} INFO - Started process (PID=17332) to work on /airflow/dags/download_data.py
[2022-02-17 18:08:23,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:08:23,528] {logging_mixin.py:112} INFO - [2022-02-17 18:08:23,528] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:08:23,993] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:08:24,044] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:08:24,054] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:08:24,061] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 18:08:36,799] {scheduler_job.py:155} INFO - Started process (PID=17358) to work on /airflow/dags/download_data.py
[2022-02-17 18:08:36,806] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:08:36,808] {logging_mixin.py:112} INFO - [2022-02-17 18:08:36,808] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:08:37,247] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:08:37,293] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:08:37,306] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:08:37,313] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 18:08:50,037] {scheduler_job.py:155} INFO - Started process (PID=17386) to work on /airflow/dags/download_data.py
[2022-02-17 18:08:50,043] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:08:50,046] {logging_mixin.py:112} INFO - [2022-02-17 18:08:50,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:08:50,481] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:08:50,532] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:08:50,543] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:08:50,550] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 18:09:03,290] {scheduler_job.py:155} INFO - Started process (PID=17412) to work on /airflow/dags/download_data.py
[2022-02-17 18:09:03,295] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:09:03,296] {logging_mixin.py:112} INFO - [2022-02-17 18:09:03,296] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:09:03,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:09:03,794] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:09:03,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:09:03,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 18:09:16,609] {scheduler_job.py:155} INFO - Started process (PID=17440) to work on /airflow/dags/download_data.py
[2022-02-17 18:09:16,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:09:16,616] {logging_mixin.py:112} INFO - [2022-02-17 18:09:16,616] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:09:17,098] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:09:17,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:09:17,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:09:17,166] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 18:09:29,888] {scheduler_job.py:155} INFO - Started process (PID=17466) to work on /airflow/dags/download_data.py
[2022-02-17 18:09:29,893] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:09:29,895] {logging_mixin.py:112} INFO - [2022-02-17 18:09:29,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:09:30,360] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:09:30,415] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:09:30,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:09:30,427] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 18:09:43,168] {scheduler_job.py:155} INFO - Started process (PID=17494) to work on /airflow/dags/download_data.py
[2022-02-17 18:09:43,173] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:09:43,174] {logging_mixin.py:112} INFO - [2022-02-17 18:09:43,174] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:09:43,605] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:09:43,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:09:43,682] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:09:43,688] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 18:09:56,491] {scheduler_job.py:155} INFO - Started process (PID=17520) to work on /airflow/dags/download_data.py
[2022-02-17 18:09:56,504] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:09:56,507] {logging_mixin.py:112} INFO - [2022-02-17 18:09:56,506] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:09:56,962] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:09:57,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:09:57,030] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:09:57,036] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 18:10:09,963] {scheduler_job.py:155} INFO - Started process (PID=17547) to work on /airflow/dags/download_data.py
[2022-02-17 18:10:09,975] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:10:09,978] {logging_mixin.py:112} INFO - [2022-02-17 18:10:09,977] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:10:10,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:10:10,547] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:10:10,557] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:10:10,564] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-17 18:10:23,209] {scheduler_job.py:155} INFO - Started process (PID=17574) to work on /airflow/dags/download_data.py
[2022-02-17 18:10:23,217] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:10:23,219] {logging_mixin.py:112} INFO - [2022-02-17 18:10:23,218] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:10:23,664] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:10:23,714] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:10:23,724] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:10:23,730] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 18:10:36,492] {scheduler_job.py:155} INFO - Started process (PID=17600) to work on /airflow/dags/download_data.py
[2022-02-17 18:10:36,498] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:10:36,500] {logging_mixin.py:112} INFO - [2022-02-17 18:10:36,500] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:10:36,968] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:10:37,005] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:10:37,012] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:10:37,016] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 18:10:49,754] {scheduler_job.py:155} INFO - Started process (PID=17628) to work on /airflow/dags/download_data.py
[2022-02-17 18:10:49,760] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:10:49,765] {logging_mixin.py:112} INFO - [2022-02-17 18:10:49,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:10:50,210] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:10:50,260] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:10:50,268] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:10:50,273] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-17 18:11:03,051] {scheduler_job.py:155} INFO - Started process (PID=17654) to work on /airflow/dags/download_data.py
[2022-02-17 18:11:03,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:11:03,057] {logging_mixin.py:112} INFO - [2022-02-17 18:11:03,056] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:11:03,501] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:11:03,549] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:11:03,556] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:11:03,561] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 18:11:16,358] {scheduler_job.py:155} INFO - Started process (PID=17682) to work on /airflow/dags/download_data.py
[2022-02-17 18:11:16,362] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:11:16,364] {logging_mixin.py:112} INFO - [2022-02-17 18:11:16,364] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:11:16,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:11:16,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:11:16,826] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:11:16,831] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.474 seconds
[2022-02-17 18:11:29,614] {scheduler_job.py:155} INFO - Started process (PID=17708) to work on /airflow/dags/download_data.py
[2022-02-17 18:11:29,622] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:11:29,624] {logging_mixin.py:112} INFO - [2022-02-17 18:11:29,624] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:11:30,109] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:11:30,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:11:30,163] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:11:30,169] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 18:11:42,914] {scheduler_job.py:155} INFO - Started process (PID=17736) to work on /airflow/dags/download_data.py
[2022-02-17 18:11:42,920] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:11:42,922] {logging_mixin.py:112} INFO - [2022-02-17 18:11:42,922] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:11:43,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:11:43,393] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:11:43,399] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:11:43,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 18:11:56,136] {scheduler_job.py:155} INFO - Started process (PID=17762) to work on /airflow/dags/download_data.py
[2022-02-17 18:11:56,141] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:11:56,143] {logging_mixin.py:112} INFO - [2022-02-17 18:11:56,142] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:11:56,603] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:11:56,650] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:11:56,657] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:11:56,661] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 18:12:09,428] {scheduler_job.py:155} INFO - Started process (PID=17788) to work on /airflow/dags/download_data.py
[2022-02-17 18:12:09,434] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:12:09,436] {logging_mixin.py:112} INFO - [2022-02-17 18:12:09,436] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:12:09,863] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:12:09,913] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:12:09,921] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:12:09,926] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 18:12:22,706] {scheduler_job.py:155} INFO - Started process (PID=17816) to work on /airflow/dags/download_data.py
[2022-02-17 18:12:22,715] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:12:22,717] {logging_mixin.py:112} INFO - [2022-02-17 18:12:22,716] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:12:23,143] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:12:23,186] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:12:23,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:12:23,195] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-17 18:12:36,006] {scheduler_job.py:155} INFO - Started process (PID=17842) to work on /airflow/dags/download_data.py
[2022-02-17 18:12:36,010] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:12:36,012] {logging_mixin.py:112} INFO - [2022-02-17 18:12:36,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:12:36,473] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:12:36,526] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:12:36,533] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:12:36,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 18:12:49,285] {scheduler_job.py:155} INFO - Started process (PID=17870) to work on /airflow/dags/download_data.py
[2022-02-17 18:12:49,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:12:49,298] {logging_mixin.py:112} INFO - [2022-02-17 18:12:49,298] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:12:49,756] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:12:49,810] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:12:49,819] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:12:49,825] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 18:13:02,542] {scheduler_job.py:155} INFO - Started process (PID=17896) to work on /airflow/dags/download_data.py
[2022-02-17 18:13:02,547] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:13:02,549] {logging_mixin.py:112} INFO - [2022-02-17 18:13:02,549] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:13:02,986] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:13:03,039] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:13:03,049] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:13:03,053] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 18:13:15,819] {scheduler_job.py:155} INFO - Started process (PID=17924) to work on /airflow/dags/download_data.py
[2022-02-17 18:13:15,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:13:15,824] {logging_mixin.py:112} INFO - [2022-02-17 18:13:15,824] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:13:16,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:13:16,297] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:13:16,304] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:13:16,309] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-17 18:13:29,075] {scheduler_job.py:155} INFO - Started process (PID=17950) to work on /airflow/dags/download_data.py
[2022-02-17 18:13:29,080] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:13:29,082] {logging_mixin.py:112} INFO - [2022-02-17 18:13:29,082] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:13:29,544] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:13:29,594] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:13:29,603] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:13:29,607] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 18:13:42,376] {scheduler_job.py:155} INFO - Started process (PID=17976) to work on /airflow/dags/download_data.py
[2022-02-17 18:13:42,383] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:13:42,385] {logging_mixin.py:112} INFO - [2022-02-17 18:13:42,384] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:13:42,815] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:13:42,868] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:13:42,876] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:13:42,882] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 18:13:55,633] {scheduler_job.py:155} INFO - Started process (PID=18004) to work on /airflow/dags/download_data.py
[2022-02-17 18:13:55,641] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:13:55,642] {logging_mixin.py:112} INFO - [2022-02-17 18:13:55,642] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:13:56,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:13:56,192] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:13:56,201] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:13:56,206] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 18:14:08,931] {scheduler_job.py:155} INFO - Started process (PID=18030) to work on /airflow/dags/download_data.py
[2022-02-17 18:14:08,955] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:14:08,960] {logging_mixin.py:112} INFO - [2022-02-17 18:14:08,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:14:09,408] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:14:09,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:14:09,476] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:14:09,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 18:14:22,241] {scheduler_job.py:155} INFO - Started process (PID=18058) to work on /airflow/dags/download_data.py
[2022-02-17 18:14:22,249] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:14:22,251] {logging_mixin.py:112} INFO - [2022-02-17 18:14:22,250] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:14:22,681] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:14:22,731] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:14:22,741] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:14:22,744] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 18:14:35,551] {scheduler_job.py:155} INFO - Started process (PID=18084) to work on /airflow/dags/download_data.py
[2022-02-17 18:14:35,560] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:14:35,562] {logging_mixin.py:112} INFO - [2022-02-17 18:14:35,562] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:14:36,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:14:36,080] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:14:36,088] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:14:36,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 18:14:48,802] {scheduler_job.py:155} INFO - Started process (PID=18112) to work on /airflow/dags/download_data.py
[2022-02-17 18:14:48,811] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:14:48,816] {logging_mixin.py:112} INFO - [2022-02-17 18:14:48,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:14:49,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:14:49,336] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:14:49,343] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:14:49,349] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 18:15:02,098] {scheduler_job.py:155} INFO - Started process (PID=18138) to work on /airflow/dags/download_data.py
[2022-02-17 18:15:02,103] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:15:02,105] {logging_mixin.py:112} INFO - [2022-02-17 18:15:02,105] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:15:02,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:15:02,572] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:15:02,580] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:15:02,586] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-17 18:15:15,347] {scheduler_job.py:155} INFO - Started process (PID=18164) to work on /airflow/dags/download_data.py
[2022-02-17 18:15:15,351] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:15:15,353] {logging_mixin.py:112} INFO - [2022-02-17 18:15:15,353] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:15:15,786] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:15:15,834] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:15:15,841] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:15:15,845] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 18:15:28,609] {scheduler_job.py:155} INFO - Started process (PID=18192) to work on /airflow/dags/download_data.py
[2022-02-17 18:15:28,618] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:15:28,620] {logging_mixin.py:112} INFO - [2022-02-17 18:15:28,620] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:15:29,097] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:15:29,152] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:15:29,159] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:15:29,163] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 18:15:41,903] {scheduler_job.py:155} INFO - Started process (PID=18218) to work on /airflow/dags/download_data.py
[2022-02-17 18:15:41,909] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:15:41,910] {logging_mixin.py:112} INFO - [2022-02-17 18:15:41,910] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:15:42,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:15:42,389] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:15:42,399] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:15:42,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 18:15:55,195] {scheduler_job.py:155} INFO - Started process (PID=18246) to work on /airflow/dags/download_data.py
[2022-02-17 18:15:55,201] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:15:55,204] {logging_mixin.py:112} INFO - [2022-02-17 18:15:55,203] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:15:55,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:15:55,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:15:55,710] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:15:55,717] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 18:16:08,491] {scheduler_job.py:155} INFO - Started process (PID=18272) to work on /airflow/dags/download_data.py
[2022-02-17 18:16:08,496] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:16:08,497] {logging_mixin.py:112} INFO - [2022-02-17 18:16:08,497] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:16:08,935] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:16:08,975] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:16:08,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:16:08,987] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 18:16:21,777] {scheduler_job.py:155} INFO - Started process (PID=18300) to work on /airflow/dags/download_data.py
[2022-02-17 18:16:21,782] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:16:21,785] {logging_mixin.py:112} INFO - [2022-02-17 18:16:21,784] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:16:22,216] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:16:22,282] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:16:22,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:16:22,294] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 18:16:35,069] {scheduler_job.py:155} INFO - Started process (PID=18326) to work on /airflow/dags/download_data.py
[2022-02-17 18:16:35,074] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:16:35,075] {logging_mixin.py:112} INFO - [2022-02-17 18:16:35,075] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:16:35,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:16:35,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:16:35,578] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:16:35,586] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 18:16:48,311] {scheduler_job.py:155} INFO - Started process (PID=18353) to work on /airflow/dags/download_data.py
[2022-02-17 18:16:48,318] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:16:48,320] {logging_mixin.py:112} INFO - [2022-02-17 18:16:48,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:16:48,830] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:16:48,870] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:16:48,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:16:48,878] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 18:17:01,606] {scheduler_job.py:155} INFO - Started process (PID=18380) to work on /airflow/dags/download_data.py
[2022-02-17 18:17:01,610] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:17:01,611] {logging_mixin.py:112} INFO - [2022-02-17 18:17:01,611] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:17:02,041] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:17:02,090] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:17:02,097] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:17:02,102] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 18:17:14,883] {scheduler_job.py:155} INFO - Started process (PID=18406) to work on /airflow/dags/download_data.py
[2022-02-17 18:17:14,890] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:17:14,892] {logging_mixin.py:112} INFO - [2022-02-17 18:17:14,891] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:17:15,336] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:17:15,376] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:17:15,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:17:15,385] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 18:17:28,147] {scheduler_job.py:155} INFO - Started process (PID=18434) to work on /airflow/dags/download_data.py
[2022-02-17 18:17:28,154] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:17:28,155] {logging_mixin.py:112} INFO - [2022-02-17 18:17:28,155] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:17:28,628] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:17:28,690] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:17:28,704] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:17:28,708] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 18:17:41,477] {scheduler_job.py:155} INFO - Started process (PID=18460) to work on /airflow/dags/download_data.py
[2022-02-17 18:17:41,484] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:17:41,486] {logging_mixin.py:112} INFO - [2022-02-17 18:17:41,486] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:17:41,938] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:17:41,994] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:17:42,002] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:17:42,007] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 18:17:54,691] {scheduler_job.py:155} INFO - Started process (PID=18488) to work on /airflow/dags/download_data.py
[2022-02-17 18:17:54,695] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:17:54,696] {logging_mixin.py:112} INFO - [2022-02-17 18:17:54,696] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:17:55,131] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:17:55,179] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:17:55,188] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:17:55,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 18:18:07,977] {scheduler_job.py:155} INFO - Started process (PID=18514) to work on /airflow/dags/download_data.py
[2022-02-17 18:18:07,983] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:18:07,985] {logging_mixin.py:112} INFO - [2022-02-17 18:18:07,985] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:18:08,417] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:18:08,472] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:18:08,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:18:08,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 18:18:21,249] {scheduler_job.py:155} INFO - Started process (PID=18542) to work on /airflow/dags/download_data.py
[2022-02-17 18:18:21,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:18:21,254] {logging_mixin.py:112} INFO - [2022-02-17 18:18:21,254] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:18:21,679] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:18:21,721] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:18:21,727] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:18:21,733] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-17 18:18:34,552] {scheduler_job.py:155} INFO - Started process (PID=18568) to work on /airflow/dags/download_data.py
[2022-02-17 18:18:34,557] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:18:34,565] {logging_mixin.py:112} INFO - [2022-02-17 18:18:34,565] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:18:35,018] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:18:35,078] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:18:35,089] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:18:35,095] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 18:18:47,833] {scheduler_job.py:155} INFO - Started process (PID=18594) to work on /airflow/dags/download_data.py
[2022-02-17 18:18:47,838] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:18:47,839] {logging_mixin.py:112} INFO - [2022-02-17 18:18:47,839] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:18:48,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:18:48,315] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:18:48,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:18:48,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 18:19:01,114] {scheduler_job.py:155} INFO - Started process (PID=18622) to work on /airflow/dags/download_data.py
[2022-02-17 18:19:01,122] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:19:01,125] {logging_mixin.py:112} INFO - [2022-02-17 18:19:01,125] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:19:01,556] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:19:01,610] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:19:01,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:19:01,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 18:19:14,419] {scheduler_job.py:155} INFO - Started process (PID=18648) to work on /airflow/dags/download_data.py
[2022-02-17 18:19:14,424] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:19:14,426] {logging_mixin.py:112} INFO - [2022-02-17 18:19:14,426] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:19:14,875] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:19:14,926] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:19:14,935] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:19:14,941] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 18:19:27,752] {scheduler_job.py:155} INFO - Started process (PID=18676) to work on /airflow/dags/download_data.py
[2022-02-17 18:19:27,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:19:27,766] {logging_mixin.py:112} INFO - [2022-02-17 18:19:27,766] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:19:28,205] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:19:28,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:19:28,276] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:19:28,281] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 18:19:41,041] {scheduler_job.py:155} INFO - Started process (PID=18702) to work on /airflow/dags/download_data.py
[2022-02-17 18:19:41,049] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:19:41,052] {logging_mixin.py:112} INFO - [2022-02-17 18:19:41,051] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:19:41,493] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:19:41,543] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:19:41,550] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:19:41,556] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 18:19:54,304] {scheduler_job.py:155} INFO - Started process (PID=18730) to work on /airflow/dags/download_data.py
[2022-02-17 18:19:54,308] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:19:54,310] {logging_mixin.py:112} INFO - [2022-02-17 18:19:54,310] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:19:54,755] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:19:54,794] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:19:54,799] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:19:54,805] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 18:20:07,619] {scheduler_job.py:155} INFO - Started process (PID=18756) to work on /airflow/dags/download_data.py
[2022-02-17 18:20:07,625] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:20:07,627] {logging_mixin.py:112} INFO - [2022-02-17 18:20:07,627] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:20:08,072] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:20:08,123] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:20:08,130] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:20:08,135] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 18:20:20,882] {scheduler_job.py:155} INFO - Started process (PID=18782) to work on /airflow/dags/download_data.py
[2022-02-17 18:20:20,890] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:20:20,892] {logging_mixin.py:112} INFO - [2022-02-17 18:20:20,891] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:20:21,326] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:20:21,376] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:20:21,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:20:21,388] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 18:20:34,211] {scheduler_job.py:155} INFO - Started process (PID=18810) to work on /airflow/dags/download_data.py
[2022-02-17 18:20:34,217] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:20:34,218] {logging_mixin.py:112} INFO - [2022-02-17 18:20:34,218] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:20:34,667] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:20:34,737] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:20:34,752] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:20:34,758] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 18:20:47,501] {scheduler_job.py:155} INFO - Started process (PID=18836) to work on /airflow/dags/download_data.py
[2022-02-17 18:20:47,505] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:20:47,507] {logging_mixin.py:112} INFO - [2022-02-17 18:20:47,506] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:20:47,912] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:20:47,964] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:20:47,973] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:20:47,979] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.478 seconds
[2022-02-17 18:21:00,787] {scheduler_job.py:155} INFO - Started process (PID=18864) to work on /airflow/dags/download_data.py
[2022-02-17 18:21:00,794] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:21:00,797] {logging_mixin.py:112} INFO - [2022-02-17 18:21:00,796] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:21:01,237] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:21:01,277] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:21:01,283] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:21:01,288] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 18:21:14,054] {scheduler_job.py:155} INFO - Started process (PID=18890) to work on /airflow/dags/download_data.py
[2022-02-17 18:21:14,059] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:21:14,061] {logging_mixin.py:112} INFO - [2022-02-17 18:21:14,061] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:21:14,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:21:14,546] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:21:14,555] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:21:14,560] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 18:21:27,356] {scheduler_job.py:155} INFO - Started process (PID=18918) to work on /airflow/dags/download_data.py
[2022-02-17 18:21:27,364] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:21:27,367] {logging_mixin.py:112} INFO - [2022-02-17 18:21:27,367] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:21:27,811] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:21:27,863] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:21:27,874] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:21:27,879] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 18:21:40,664] {scheduler_job.py:155} INFO - Started process (PID=18944) to work on /airflow/dags/download_data.py
[2022-02-17 18:21:40,670] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:21:40,673] {logging_mixin.py:112} INFO - [2022-02-17 18:21:40,672] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:21:41,130] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:21:41,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:21:41,190] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:21:41,195] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 18:21:53,906] {scheduler_job.py:155} INFO - Started process (PID=18971) to work on /airflow/dags/download_data.py
[2022-02-17 18:21:53,918] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:21:53,922] {logging_mixin.py:112} INFO - [2022-02-17 18:21:53,921] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:21:54,441] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:21:54,484] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:21:54,490] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:21:54,493] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-17 18:22:07,242] {scheduler_job.py:155} INFO - Started process (PID=18998) to work on /airflow/dags/download_data.py
[2022-02-17 18:22:07,246] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:22:07,248] {logging_mixin.py:112} INFO - [2022-02-17 18:22:07,248] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:22:07,686] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:22:07,727] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:22:07,733] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:22:07,740] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-17 18:22:20,501] {scheduler_job.py:155} INFO - Started process (PID=19024) to work on /airflow/dags/download_data.py
[2022-02-17 18:22:20,505] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:22:20,506] {logging_mixin.py:112} INFO - [2022-02-17 18:22:20,506] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:22:20,933] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:22:20,981] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:22:20,989] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:22:20,994] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-17 18:22:33,850] {scheduler_job.py:155} INFO - Started process (PID=19052) to work on /airflow/dags/download_data.py
[2022-02-17 18:22:33,857] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:22:33,859] {logging_mixin.py:112} INFO - [2022-02-17 18:22:33,859] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:22:34,301] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:22:34,359] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:22:34,372] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:22:34,379] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 18:22:47,097] {scheduler_job.py:155} INFO - Started process (PID=19078) to work on /airflow/dags/download_data.py
[2022-02-17 18:22:47,101] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:22:47,103] {logging_mixin.py:112} INFO - [2022-02-17 18:22:47,103] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:22:47,554] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:22:47,605] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:22:47,613] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:22:47,619] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 18:23:00,417] {scheduler_job.py:155} INFO - Started process (PID=19106) to work on /airflow/dags/download_data.py
[2022-02-17 18:23:00,422] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:23:00,424] {logging_mixin.py:112} INFO - [2022-02-17 18:23:00,424] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:23:00,888] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:23:00,933] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:23:00,939] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:23:00,944] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 18:23:13,697] {scheduler_job.py:155} INFO - Started process (PID=19132) to work on /airflow/dags/download_data.py
[2022-02-17 18:23:13,704] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:23:13,707] {logging_mixin.py:112} INFO - [2022-02-17 18:23:13,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:23:14,145] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:23:14,189] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:23:14,199] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:23:14,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 18:23:26,950] {scheduler_job.py:155} INFO - Started process (PID=19160) to work on /airflow/dags/download_data.py
[2022-02-17 18:23:26,956] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:23:26,960] {logging_mixin.py:112} INFO - [2022-02-17 18:23:26,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:23:27,542] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:23:27,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:23:27,597] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:23:27,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.658 seconds
[2022-02-17 18:23:40,274] {scheduler_job.py:155} INFO - Started process (PID=19186) to work on /airflow/dags/download_data.py
[2022-02-17 18:23:40,281] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:23:40,283] {logging_mixin.py:112} INFO - [2022-02-17 18:23:40,283] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:23:40,734] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:23:40,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:23:40,801] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:23:40,808] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 18:23:53,508] {scheduler_job.py:155} INFO - Started process (PID=19212) to work on /airflow/dags/download_data.py
[2022-02-17 18:23:53,513] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:23:53,516] {logging_mixin.py:112} INFO - [2022-02-17 18:23:53,516] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:23:53,975] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:23:54,026] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:23:54,032] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:23:54,036] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 18:24:06,820] {scheduler_job.py:155} INFO - Started process (PID=19240) to work on /airflow/dags/download_data.py
[2022-02-17 18:24:06,828] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:24:06,830] {logging_mixin.py:112} INFO - [2022-02-17 18:24:06,830] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:24:07,258] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:24:07,308] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:24:07,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:24:07,324] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 18:24:21,193] {scheduler_job.py:155} INFO - Started process (PID=19266) to work on /airflow/dags/download_data.py
[2022-02-17 18:24:21,203] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:24:21,206] {logging_mixin.py:112} INFO - [2022-02-17 18:24:21,205] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:24:21,682] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:24:21,727] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:24:21,737] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:24:21,746] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 18:24:41,873] {scheduler_job.py:155} INFO - Started process (PID=19294) to work on /airflow/dags/download_data.py
[2022-02-17 18:24:41,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 18:24:41,890] {logging_mixin.py:112} INFO - [2022-02-17 18:24:41,890] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 18:24:42,497] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 18:24:42,584] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 18:24:42,607] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 18:24:42,617] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.746 seconds
[2022-02-17 19:24:47,638] {scheduler_job.py:155} INFO - Started process (PID=19330) to work on /airflow/dags/download_data.py
[2022-02-17 19:24:47,665] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:24:47,671] {logging_mixin.py:112} INFO - [2022-02-17 19:24:47,670] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:24:49,433] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:24:49,542] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:24:49,566] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:24:49,577] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.938 seconds
[2022-02-17 19:25:01,958] {scheduler_job.py:155} INFO - Started process (PID=19357) to work on /airflow/dags/download_data.py
[2022-02-17 19:25:01,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:25:01,969] {logging_mixin.py:112} INFO - [2022-02-17 19:25:01,968] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:25:02,406] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:25:02,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:25:02,463] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:25:02,468] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 19:25:14,179] {scheduler_job.py:155} INFO - Started process (PID=19382) to work on /airflow/dags/download_data.py
[2022-02-17 19:25:14,183] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:25:14,185] {logging_mixin.py:112} INFO - [2022-02-17 19:25:14,185] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:25:14,602] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:25:14,651] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:25:14,660] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:25:14,663] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-17 19:25:27,466] {scheduler_job.py:155} INFO - Started process (PID=19410) to work on /airflow/dags/download_data.py
[2022-02-17 19:25:27,471] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:25:27,472] {logging_mixin.py:112} INFO - [2022-02-17 19:25:27,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:25:27,948] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:25:28,006] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:25:28,018] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:25:28,023] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 19:25:40,765] {scheduler_job.py:155} INFO - Started process (PID=19436) to work on /airflow/dags/download_data.py
[2022-02-17 19:25:40,769] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:25:40,772] {logging_mixin.py:112} INFO - [2022-02-17 19:25:40,772] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:25:41,225] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:25:41,264] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:25:41,269] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:25:41,272] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 19:25:53,965] {scheduler_job.py:155} INFO - Started process (PID=19464) to work on /airflow/dags/download_data.py
[2022-02-17 19:25:53,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:25:53,972] {logging_mixin.py:112} INFO - [2022-02-17 19:25:53,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:25:54,451] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:25:54,495] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:25:54,502] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:25:54,506] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 19:26:07,280] {scheduler_job.py:155} INFO - Started process (PID=19490) to work on /airflow/dags/download_data.py
[2022-02-17 19:26:07,289] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:26:07,291] {logging_mixin.py:112} INFO - [2022-02-17 19:26:07,291] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:26:07,713] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:26:07,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:26:07,765] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:26:07,769] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-17 19:26:20,544] {scheduler_job.py:155} INFO - Started process (PID=19518) to work on /airflow/dags/download_data.py
[2022-02-17 19:26:20,551] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:26:20,553] {logging_mixin.py:112} INFO - [2022-02-17 19:26:20,553] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:26:20,982] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:26:21,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:26:21,035] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:26:21,040] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-17 19:26:33,830] {scheduler_job.py:155} INFO - Started process (PID=19544) to work on /airflow/dags/download_data.py
[2022-02-17 19:26:33,835] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:26:33,837] {logging_mixin.py:112} INFO - [2022-02-17 19:26:33,836] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:26:34,294] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:26:34,356] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:26:34,366] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:26:34,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 19:26:47,103] {scheduler_job.py:155} INFO - Started process (PID=19570) to work on /airflow/dags/download_data.py
[2022-02-17 19:26:47,107] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:26:47,109] {logging_mixin.py:112} INFO - [2022-02-17 19:26:47,108] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:26:47,568] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:26:47,621] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:26:47,630] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:26:47,634] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 19:27:00,406] {scheduler_job.py:155} INFO - Started process (PID=19598) to work on /airflow/dags/download_data.py
[2022-02-17 19:27:00,410] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:27:00,412] {logging_mixin.py:112} INFO - [2022-02-17 19:27:00,411] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:27:00,858] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:27:00,899] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:27:00,906] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:27:00,912] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 19:27:13,718] {scheduler_job.py:155} INFO - Started process (PID=19624) to work on /airflow/dags/download_data.py
[2022-02-17 19:27:13,723] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:27:13,724] {logging_mixin.py:112} INFO - [2022-02-17 19:27:13,724] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:27:14,191] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:27:14,210] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:27:14,217] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:27:14,223] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 19:27:26,986] {scheduler_job.py:155} INFO - Started process (PID=19652) to work on /airflow/dags/download_data.py
[2022-02-17 19:27:26,992] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:27:26,993] {logging_mixin.py:112} INFO - [2022-02-17 19:27:26,993] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:27:27,460] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:27:27,504] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:27:27,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:27:27,519] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 19:27:40,295] {scheduler_job.py:155} INFO - Started process (PID=19678) to work on /airflow/dags/download_data.py
[2022-02-17 19:27:40,301] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:27:40,304] {logging_mixin.py:112} INFO - [2022-02-17 19:27:40,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:27:40,764] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:27:40,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:27:40,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:27:40,829] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 19:27:53,566] {scheduler_job.py:155} INFO - Started process (PID=19706) to work on /airflow/dags/download_data.py
[2022-02-17 19:27:53,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:27:53,580] {logging_mixin.py:112} INFO - [2022-02-17 19:27:53,580] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:27:54,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:27:54,090] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:27:54,104] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:27:54,109] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 19:28:06,827] {scheduler_job.py:155} INFO - Started process (PID=19732) to work on /airflow/dags/download_data.py
[2022-02-17 19:28:06,832] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:28:06,835] {logging_mixin.py:112} INFO - [2022-02-17 19:28:06,834] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:28:07,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:28:07,312] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:28:07,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:28:07,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-17 19:28:20,091] {scheduler_job.py:155} INFO - Started process (PID=19760) to work on /airflow/dags/download_data.py
[2022-02-17 19:28:20,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:28:20,101] {logging_mixin.py:112} INFO - [2022-02-17 19:28:20,101] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:28:20,603] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:28:20,650] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:28:20,658] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:28:20,663] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 19:28:33,370] {scheduler_job.py:155} INFO - Started process (PID=19786) to work on /airflow/dags/download_data.py
[2022-02-17 19:28:33,376] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:28:33,378] {logging_mixin.py:112} INFO - [2022-02-17 19:28:33,378] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:28:33,866] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:28:33,909] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:28:33,917] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:28:33,921] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 19:28:46,640] {scheduler_job.py:155} INFO - Started process (PID=19812) to work on /airflow/dags/download_data.py
[2022-02-17 19:28:46,649] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:28:46,651] {logging_mixin.py:112} INFO - [2022-02-17 19:28:46,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:28:47,078] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:28:47,131] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:28:47,137] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:28:47,141] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 19:28:59,933] {scheduler_job.py:155} INFO - Started process (PID=19840) to work on /airflow/dags/download_data.py
[2022-02-17 19:28:59,937] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:28:59,939] {logging_mixin.py:112} INFO - [2022-02-17 19:28:59,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:29:00,371] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:29:00,412] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:29:00,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:29:00,422] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-17 19:29:13,166] {scheduler_job.py:155} INFO - Started process (PID=19866) to work on /airflow/dags/download_data.py
[2022-02-17 19:29:13,171] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:29:13,172] {logging_mixin.py:112} INFO - [2022-02-17 19:29:13,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:29:13,622] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:29:13,674] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:29:13,684] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:29:13,692] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 19:29:26,401] {scheduler_job.py:155} INFO - Started process (PID=19894) to work on /airflow/dags/download_data.py
[2022-02-17 19:29:26,409] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:29:26,411] {logging_mixin.py:112} INFO - [2022-02-17 19:29:26,410] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:29:26,885] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:29:26,933] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:29:26,941] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:29:26,946] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 19:29:39,681] {scheduler_job.py:155} INFO - Started process (PID=19920) to work on /airflow/dags/download_data.py
[2022-02-17 19:29:39,687] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:29:39,688] {logging_mixin.py:112} INFO - [2022-02-17 19:29:39,688] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:29:40,336] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:29:40,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:29:40,391] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:29:40,397] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.716 seconds
[2022-02-17 19:29:53,017] {scheduler_job.py:155} INFO - Started process (PID=19948) to work on /airflow/dags/download_data.py
[2022-02-17 19:29:53,026] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:29:53,030] {logging_mixin.py:112} INFO - [2022-02-17 19:29:53,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:29:53,494] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:29:53,555] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:29:53,578] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:29:53,598] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 19:30:06,248] {scheduler_job.py:155} INFO - Started process (PID=19974) to work on /airflow/dags/download_data.py
[2022-02-17 19:30:06,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:30:06,254] {logging_mixin.py:112} INFO - [2022-02-17 19:30:06,254] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:30:06,701] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:30:06,754] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:30:06,763] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:30:06,769] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 19:30:19,502] {scheduler_job.py:155} INFO - Started process (PID=20000) to work on /airflow/dags/download_data.py
[2022-02-17 19:30:19,506] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:30:19,509] {logging_mixin.py:112} INFO - [2022-02-17 19:30:19,509] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:30:19,961] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:30:20,000] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:30:20,005] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:30:20,009] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 19:30:32,764] {scheduler_job.py:155} INFO - Started process (PID=20028) to work on /airflow/dags/download_data.py
[2022-02-17 19:30:32,770] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:30:32,771] {logging_mixin.py:112} INFO - [2022-02-17 19:30:32,771] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:30:33,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:30:33,302] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:30:33,313] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:30:33,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 19:30:46,000] {scheduler_job.py:155} INFO - Started process (PID=20054) to work on /airflow/dags/download_data.py
[2022-02-17 19:30:46,004] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:30:46,007] {logging_mixin.py:112} INFO - [2022-02-17 19:30:46,006] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:30:46,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:30:46,511] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:30:46,523] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:30:46,527] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 19:30:59,318] {scheduler_job.py:155} INFO - Started process (PID=20082) to work on /airflow/dags/download_data.py
[2022-02-17 19:30:59,324] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:30:59,326] {logging_mixin.py:112} INFO - [2022-02-17 19:30:59,326] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:30:59,752] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:30:59,803] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:30:59,812] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:30:59,817] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-17 19:31:12,624] {scheduler_job.py:155} INFO - Started process (PID=20108) to work on /airflow/dags/download_data.py
[2022-02-17 19:31:12,628] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:31:12,630] {logging_mixin.py:112} INFO - [2022-02-17 19:31:12,630] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:31:13,069] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:31:13,120] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:31:13,131] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:31:13,135] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 19:31:25,950] {scheduler_job.py:155} INFO - Started process (PID=20136) to work on /airflow/dags/download_data.py
[2022-02-17 19:31:25,955] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:31:25,958] {logging_mixin.py:112} INFO - [2022-02-17 19:31:25,958] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:31:26,399] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:31:26,471] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:31:26,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:31:26,490] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 19:31:39,246] {scheduler_job.py:155} INFO - Started process (PID=20162) to work on /airflow/dags/download_data.py
[2022-02-17 19:31:39,251] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:31:39,252] {logging_mixin.py:112} INFO - [2022-02-17 19:31:39,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:31:39,709] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:31:39,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:31:39,767] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:31:39,772] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 19:31:52,505] {scheduler_job.py:155} INFO - Started process (PID=20188) to work on /airflow/dags/download_data.py
[2022-02-17 19:31:52,510] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:31:52,511] {logging_mixin.py:112} INFO - [2022-02-17 19:31:52,511] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:31:52,999] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:31:53,059] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:31:53,070] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:31:53,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 19:32:05,803] {scheduler_job.py:155} INFO - Started process (PID=20216) to work on /airflow/dags/download_data.py
[2022-02-17 19:32:05,813] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:32:05,815] {logging_mixin.py:112} INFO - [2022-02-17 19:32:05,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:32:06,253] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:32:06,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:32:06,317] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:32:06,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 19:32:19,076] {scheduler_job.py:155} INFO - Started process (PID=20242) to work on /airflow/dags/download_data.py
[2022-02-17 19:32:19,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:32:19,083] {logging_mixin.py:112} INFO - [2022-02-17 19:32:19,083] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:32:19,515] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:32:19,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:32:19,575] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:32:19,578] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 19:32:32,368] {scheduler_job.py:155} INFO - Started process (PID=20270) to work on /airflow/dags/download_data.py
[2022-02-17 19:32:32,374] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:32:32,376] {logging_mixin.py:112} INFO - [2022-02-17 19:32:32,376] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:32:32,836] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:32:32,900] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:32:32,914] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:32:32,925] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 19:32:45,629] {scheduler_job.py:155} INFO - Started process (PID=20296) to work on /airflow/dags/download_data.py
[2022-02-17 19:32:45,636] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:32:45,639] {logging_mixin.py:112} INFO - [2022-02-17 19:32:45,639] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:32:46,073] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:32:46,125] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:32:46,130] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:32:46,133] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-17 19:32:58,918] {scheduler_job.py:155} INFO - Started process (PID=20324) to work on /airflow/dags/download_data.py
[2022-02-17 19:32:58,926] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:32:58,928] {logging_mixin.py:112} INFO - [2022-02-17 19:32:58,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:32:59,379] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:32:59,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:32:59,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:32:59,434] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 19:33:12,205] {scheduler_job.py:155} INFO - Started process (PID=20350) to work on /airflow/dags/download_data.py
[2022-02-17 19:33:12,212] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:33:12,214] {logging_mixin.py:112} INFO - [2022-02-17 19:33:12,214] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:33:12,655] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:33:12,702] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:33:12,710] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:33:12,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 19:33:25,471] {scheduler_job.py:155} INFO - Started process (PID=20376) to work on /airflow/dags/download_data.py
[2022-02-17 19:33:25,477] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:33:25,478] {logging_mixin.py:112} INFO - [2022-02-17 19:33:25,478] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:33:25,959] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:33:26,019] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:33:26,030] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:33:26,035] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 19:33:38,799] {scheduler_job.py:155} INFO - Started process (PID=20404) to work on /airflow/dags/download_data.py
[2022-02-17 19:33:38,804] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:33:38,806] {logging_mixin.py:112} INFO - [2022-02-17 19:33:38,805] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:33:39,245] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:33:39,296] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:33:39,302] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:33:39,305] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 19:33:52,066] {scheduler_job.py:155} INFO - Started process (PID=20430) to work on /airflow/dags/download_data.py
[2022-02-17 19:33:52,070] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:33:52,072] {logging_mixin.py:112} INFO - [2022-02-17 19:33:52,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:33:52,495] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:33:52,548] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:33:52,559] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:33:52,562] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-17 19:34:05,377] {scheduler_job.py:155} INFO - Started process (PID=20458) to work on /airflow/dags/download_data.py
[2022-02-17 19:34:05,384] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:34:05,386] {logging_mixin.py:112} INFO - [2022-02-17 19:34:05,385] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:34:05,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:34:05,866] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:34:05,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:34:05,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 19:34:18,672] {scheduler_job.py:155} INFO - Started process (PID=20484) to work on /airflow/dags/download_data.py
[2022-02-17 19:34:18,676] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:34:18,677] {logging_mixin.py:112} INFO - [2022-02-17 19:34:18,677] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:34:19,134] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:34:19,186] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:34:19,195] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:34:19,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 19:34:31,954] {scheduler_job.py:155} INFO - Started process (PID=20512) to work on /airflow/dags/download_data.py
[2022-02-17 19:34:31,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:34:31,961] {logging_mixin.py:112} INFO - [2022-02-17 19:34:31,961] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:34:32,410] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:34:32,466] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:34:32,472] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:34:32,477] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 19:34:45,211] {scheduler_job.py:155} INFO - Started process (PID=20538) to work on /airflow/dags/download_data.py
[2022-02-17 19:34:45,221] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:34:45,224] {logging_mixin.py:112} INFO - [2022-02-17 19:34:45,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:34:45,658] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:34:45,707] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:34:45,714] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:34:45,720] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 19:34:58,549] {scheduler_job.py:155} INFO - Started process (PID=20566) to work on /airflow/dags/download_data.py
[2022-02-17 19:34:58,557] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:34:58,559] {logging_mixin.py:112} INFO - [2022-02-17 19:34:58,558] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:34:59,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:34:59,082] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:34:59,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:34:59,097] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 19:35:11,816] {scheduler_job.py:155} INFO - Started process (PID=20592) to work on /airflow/dags/download_data.py
[2022-02-17 19:35:11,820] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:35:11,822] {logging_mixin.py:112} INFO - [2022-02-17 19:35:11,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:35:12,279] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:35:12,326] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:35:12,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:35:12,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 19:35:25,114] {scheduler_job.py:155} INFO - Started process (PID=20618) to work on /airflow/dags/download_data.py
[2022-02-17 19:35:25,121] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:35:25,125] {logging_mixin.py:112} INFO - [2022-02-17 19:35:25,124] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:35:25,590] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:35:25,633] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:35:25,644] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:35:25,649] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-17 19:35:38,413] {scheduler_job.py:155} INFO - Started process (PID=20646) to work on /airflow/dags/download_data.py
[2022-02-17 19:35:38,417] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:35:38,418] {logging_mixin.py:112} INFO - [2022-02-17 19:35:38,418] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:35:38,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:35:38,906] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:35:38,912] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:35:38,916] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 19:35:51,673] {scheduler_job.py:155} INFO - Started process (PID=20672) to work on /airflow/dags/download_data.py
[2022-02-17 19:35:51,677] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:35:51,679] {logging_mixin.py:112} INFO - [2022-02-17 19:35:51,678] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:35:52,137] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:35:52,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:35:52,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:35:52,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 19:36:04,964] {scheduler_job.py:155} INFO - Started process (PID=20700) to work on /airflow/dags/download_data.py
[2022-02-17 19:36:04,968] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:36:04,970] {logging_mixin.py:112} INFO - [2022-02-17 19:36:04,970] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:36:05,420] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:36:05,455] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:36:05,462] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:36:05,467] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 19:36:18,196] {scheduler_job.py:155} INFO - Started process (PID=20726) to work on /airflow/dags/download_data.py
[2022-02-17 19:36:18,200] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:36:18,202] {logging_mixin.py:112} INFO - [2022-02-17 19:36:18,201] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:36:18,646] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:36:18,696] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:36:18,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:36:18,708] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 19:36:31,522] {scheduler_job.py:155} INFO - Started process (PID=20754) to work on /airflow/dags/download_data.py
[2022-02-17 19:36:31,529] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:36:31,532] {logging_mixin.py:112} INFO - [2022-02-17 19:36:31,532] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:36:31,971] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:36:32,031] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:36:32,039] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:36:32,044] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 19:36:44,782] {scheduler_job.py:155} INFO - Started process (PID=20780) to work on /airflow/dags/download_data.py
[2022-02-17 19:36:44,789] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:36:44,791] {logging_mixin.py:112} INFO - [2022-02-17 19:36:44,791] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:36:45,231] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:36:45,284] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:36:45,291] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:36:45,296] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 19:36:58,082] {scheduler_job.py:155} INFO - Started process (PID=20806) to work on /airflow/dags/download_data.py
[2022-02-17 19:36:58,089] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:36:58,091] {logging_mixin.py:112} INFO - [2022-02-17 19:36:58,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:36:58,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:36:58,583] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:36:58,591] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:36:58,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-17 19:37:11,385] {scheduler_job.py:155} INFO - Started process (PID=20834) to work on /airflow/dags/download_data.py
[2022-02-17 19:37:11,394] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:37:11,396] {logging_mixin.py:112} INFO - [2022-02-17 19:37:11,396] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:37:11,827] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:37:11,870] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:37:11,881] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:37:11,885] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-17 19:37:24,647] {scheduler_job.py:155} INFO - Started process (PID=20860) to work on /airflow/dags/download_data.py
[2022-02-17 19:37:24,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:37:24,655] {logging_mixin.py:112} INFO - [2022-02-17 19:37:24,655] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:37:25,104] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:37:25,160] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:37:25,178] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:37:25,183] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 19:37:37,963] {scheduler_job.py:155} INFO - Started process (PID=20888) to work on /airflow/dags/download_data.py
[2022-02-17 19:37:37,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:37:37,978] {logging_mixin.py:112} INFO - [2022-02-17 19:37:37,978] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:37:38,469] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:37:38,515] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:37:38,524] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:37:38,531] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 19:37:51,252] {scheduler_job.py:155} INFO - Started process (PID=20914) to work on /airflow/dags/download_data.py
[2022-02-17 19:37:51,262] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:37:51,264] {logging_mixin.py:112} INFO - [2022-02-17 19:37:51,263] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:37:51,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:37:51,754] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:37:51,763] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:37:51,768] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 19:38:04,549] {scheduler_job.py:155} INFO - Started process (PID=20942) to work on /airflow/dags/download_data.py
[2022-02-17 19:38:04,558] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:38:04,560] {logging_mixin.py:112} INFO - [2022-02-17 19:38:04,560] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:38:04,981] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:38:05,020] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:38:05,027] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:38:05,033] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-17 19:38:17,824] {scheduler_job.py:155} INFO - Started process (PID=20968) to work on /airflow/dags/download_data.py
[2022-02-17 19:38:17,830] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:38:17,831] {logging_mixin.py:112} INFO - [2022-02-17 19:38:17,831] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:38:18,275] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:38:18,327] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:38:18,335] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:38:18,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 19:38:31,097] {scheduler_job.py:155} INFO - Started process (PID=20994) to work on /airflow/dags/download_data.py
[2022-02-17 19:38:31,106] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:38:31,108] {logging_mixin.py:112} INFO - [2022-02-17 19:38:31,108] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:38:31,551] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:38:31,606] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:38:31,617] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:38:31,622] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 19:38:44,384] {scheduler_job.py:155} INFO - Started process (PID=21022) to work on /airflow/dags/download_data.py
[2022-02-17 19:38:44,391] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:38:44,393] {logging_mixin.py:112} INFO - [2022-02-17 19:38:44,393] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:38:44,818] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:38:44,865] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:38:44,874] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:38:44,879] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-17 19:38:57,674] {scheduler_job.py:155} INFO - Started process (PID=21048) to work on /airflow/dags/download_data.py
[2022-02-17 19:38:57,684] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:38:57,686] {logging_mixin.py:112} INFO - [2022-02-17 19:38:57,686] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:38:58,115] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:38:58,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:38:58,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:38:58,179] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 19:39:10,967] {scheduler_job.py:155} INFO - Started process (PID=21076) to work on /airflow/dags/download_data.py
[2022-02-17 19:39:10,971] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:39:10,972] {logging_mixin.py:112} INFO - [2022-02-17 19:39:10,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:39:11,409] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:39:11,458] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:39:11,466] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:39:11,471] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-17 19:39:24,258] {scheduler_job.py:155} INFO - Started process (PID=21102) to work on /airflow/dags/download_data.py
[2022-02-17 19:39:24,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:39:24,269] {logging_mixin.py:112} INFO - [2022-02-17 19:39:24,269] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:39:24,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:39:24,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:39:24,811] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:39:24,818] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 19:39:37,650] {scheduler_job.py:155} INFO - Started process (PID=21130) to work on /airflow/dags/download_data.py
[2022-02-17 19:39:37,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:39:37,672] {logging_mixin.py:112} INFO - [2022-02-17 19:39:37,672] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:39:38,255] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:39:38,315] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:39:38,321] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:39:38,325] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.674 seconds
[2022-02-17 19:39:50,913] {scheduler_job.py:155} INFO - Started process (PID=21156) to work on /airflow/dags/download_data.py
[2022-02-17 19:39:50,918] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:39:50,920] {logging_mixin.py:112} INFO - [2022-02-17 19:39:50,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:39:51,384] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:39:51,423] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:39:51,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:39:51,435] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 19:40:04,226] {scheduler_job.py:155} INFO - Started process (PID=21182) to work on /airflow/dags/download_data.py
[2022-02-17 19:40:04,230] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:40:04,231] {logging_mixin.py:112} INFO - [2022-02-17 19:40:04,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:40:04,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:40:04,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:40:04,724] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:40:04,728] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-17 19:40:17,484] {scheduler_job.py:155} INFO - Started process (PID=21210) to work on /airflow/dags/download_data.py
[2022-02-17 19:40:17,488] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:40:17,490] {logging_mixin.py:112} INFO - [2022-02-17 19:40:17,490] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:40:17,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:40:17,980] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:40:17,987] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:40:17,992] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 19:40:30,785] {scheduler_job.py:155} INFO - Started process (PID=21236) to work on /airflow/dags/download_data.py
[2022-02-17 19:40:30,789] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:40:30,791] {logging_mixin.py:112} INFO - [2022-02-17 19:40:30,791] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:40:31,255] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:40:31,315] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:40:31,327] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:40:31,333] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 19:40:44,004] {scheduler_job.py:155} INFO - Started process (PID=21264) to work on /airflow/dags/download_data.py
[2022-02-17 19:40:44,013] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:40:44,015] {logging_mixin.py:112} INFO - [2022-02-17 19:40:44,015] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:40:44,447] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:40:44,496] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:40:44,505] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:40:44,508] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 19:40:57,373] {scheduler_job.py:155} INFO - Started process (PID=21290) to work on /airflow/dags/download_data.py
[2022-02-17 19:40:57,387] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:40:57,393] {logging_mixin.py:112} INFO - [2022-02-17 19:40:57,393] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:40:58,716] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:40:58,767] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:40:58,778] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:40:58,783] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.410 seconds
[2022-02-17 19:41:11,689] {scheduler_job.py:155} INFO - Started process (PID=21318) to work on /airflow/dags/download_data.py
[2022-02-17 19:41:11,695] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:41:11,696] {logging_mixin.py:112} INFO - [2022-02-17 19:41:11,696] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:41:12,285] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:41:12,444] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:41:12,455] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:41:12,460] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.770 seconds
[2022-02-17 19:41:23,948] {scheduler_job.py:155} INFO - Started process (PID=21343) to work on /airflow/dags/download_data.py
[2022-02-17 19:41:23,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:41:23,956] {logging_mixin.py:112} INFO - [2022-02-17 19:41:23,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:41:24,472] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:41:24,547] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:41:24,559] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:41:24,567] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 19:41:37,429] {scheduler_job.py:155} INFO - Started process (PID=21370) to work on /airflow/dags/download_data.py
[2022-02-17 19:41:37,443] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:41:37,445] {logging_mixin.py:112} INFO - [2022-02-17 19:41:37,445] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:41:37,982] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:41:38,024] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:41:38,031] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:41:38,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 19:41:50,679] {scheduler_job.py:155} INFO - Started process (PID=21397) to work on /airflow/dags/download_data.py
[2022-02-17 19:41:50,691] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:41:50,692] {logging_mixin.py:112} INFO - [2022-02-17 19:41:50,692] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:41:51,172] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:41:51,237] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:41:51,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:41:51,254] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-17 19:42:03,960] {scheduler_job.py:155} INFO - Started process (PID=21423) to work on /airflow/dags/download_data.py
[2022-02-17 19:42:03,971] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:42:03,973] {logging_mixin.py:112} INFO - [2022-02-17 19:42:03,973] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:42:04,423] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:42:04,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:42:04,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:42:04,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-17 19:42:17,231] {scheduler_job.py:155} INFO - Started process (PID=21451) to work on /airflow/dags/download_data.py
[2022-02-17 19:42:17,242] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:42:17,244] {logging_mixin.py:112} INFO - [2022-02-17 19:42:17,244] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:42:17,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:42:17,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:42:17,785] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:42:17,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 19:42:30,528] {scheduler_job.py:155} INFO - Started process (PID=21477) to work on /airflow/dags/download_data.py
[2022-02-17 19:42:30,541] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:42:30,544] {logging_mixin.py:112} INFO - [2022-02-17 19:42:30,544] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:42:30,993] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:42:31,036] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:42:31,044] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:42:31,050] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 19:42:43,799] {scheduler_job.py:155} INFO - Started process (PID=21505) to work on /airflow/dags/download_data.py
[2022-02-17 19:42:43,811] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:42:43,817] {logging_mixin.py:112} INFO - [2022-02-17 19:42:43,814] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:42:44,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:42:44,365] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:42:44,377] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:42:44,381] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 19:42:57,071] {scheduler_job.py:155} INFO - Started process (PID=21531) to work on /airflow/dags/download_data.py
[2022-02-17 19:42:57,075] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:42:57,077] {logging_mixin.py:112} INFO - [2022-02-17 19:42:57,077] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:42:57,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:42:57,597] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:42:57,611] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:42:57,619] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 19:43:10,391] {scheduler_job.py:155} INFO - Started process (PID=21559) to work on /airflow/dags/download_data.py
[2022-02-17 19:43:10,406] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:43:10,409] {logging_mixin.py:112} INFO - [2022-02-17 19:43:10,409] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:43:10,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:43:10,943] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:43:10,954] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:43:10,960] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 19:43:23,647] {scheduler_job.py:155} INFO - Started process (PID=21585) to work on /airflow/dags/download_data.py
[2022-02-17 19:43:23,656] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:43:23,661] {logging_mixin.py:112} INFO - [2022-02-17 19:43:23,661] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:43:24,228] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:43:24,271] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:43:24,277] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:43:24,282] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-17 19:43:36,957] {scheduler_job.py:155} INFO - Started process (PID=21611) to work on /airflow/dags/download_data.py
[2022-02-17 19:43:36,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:43:36,969] {logging_mixin.py:112} INFO - [2022-02-17 19:43:36,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:43:37,528] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:43:37,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:43:37,619] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:43:37,637] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.680 seconds
[2022-02-17 19:43:50,255] {scheduler_job.py:155} INFO - Started process (PID=21639) to work on /airflow/dags/download_data.py
[2022-02-17 19:43:50,262] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:43:50,265] {logging_mixin.py:112} INFO - [2022-02-17 19:43:50,264] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:43:50,735] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:43:50,790] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:43:50,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:43:50,806] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 19:44:03,533] {scheduler_job.py:155} INFO - Started process (PID=21665) to work on /airflow/dags/download_data.py
[2022-02-17 19:44:03,539] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:44:03,541] {logging_mixin.py:112} INFO - [2022-02-17 19:44:03,540] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:44:04,109] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:44:04,152] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:44:04,163] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:44:04,168] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-17 19:44:16,825] {scheduler_job.py:155} INFO - Started process (PID=21693) to work on /airflow/dags/download_data.py
[2022-02-17 19:44:16,832] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:44:16,834] {logging_mixin.py:112} INFO - [2022-02-17 19:44:16,834] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:44:17,374] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:44:17,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:44:17,435] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:44:17,441] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-17 19:44:30,144] {scheduler_job.py:155} INFO - Started process (PID=21719) to work on /airflow/dags/download_data.py
[2022-02-17 19:44:30,153] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:44:30,154] {logging_mixin.py:112} INFO - [2022-02-17 19:44:30,154] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:44:30,676] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:44:30,723] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:44:30,728] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:44:30,735] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 19:44:43,446] {scheduler_job.py:155} INFO - Started process (PID=21747) to work on /airflow/dags/download_data.py
[2022-02-17 19:44:43,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:44:43,452] {logging_mixin.py:112} INFO - [2022-02-17 19:44:43,452] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:44:43,981] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:44:44,048] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:44:44,057] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:44:44,060] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-17 19:44:56,778] {scheduler_job.py:155} INFO - Started process (PID=21773) to work on /airflow/dags/download_data.py
[2022-02-17 19:44:56,788] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:44:56,791] {logging_mixin.py:112} INFO - [2022-02-17 19:44:56,790] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:44:57,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:44:57,407] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:44:57,421] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:44:57,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-17 19:45:10,049] {scheduler_job.py:155} INFO - Started process (PID=21799) to work on /airflow/dags/download_data.py
[2022-02-17 19:45:10,056] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:45:10,058] {logging_mixin.py:112} INFO - [2022-02-17 19:45:10,058] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:45:10,563] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:45:10,615] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:45:10,623] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:45:10,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 19:45:23,393] {scheduler_job.py:155} INFO - Started process (PID=21827) to work on /airflow/dags/download_data.py
[2022-02-17 19:45:23,399] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:45:23,401] {logging_mixin.py:112} INFO - [2022-02-17 19:45:23,401] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:45:23,959] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:45:24,013] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:45:24,020] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:45:24,026] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-17 19:45:36,693] {scheduler_job.py:155} INFO - Started process (PID=21853) to work on /airflow/dags/download_data.py
[2022-02-17 19:45:36,699] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:45:36,702] {logging_mixin.py:112} INFO - [2022-02-17 19:45:36,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:45:37,238] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:45:37,297] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:45:37,307] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:45:37,312] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 19:45:49,956] {scheduler_job.py:155} INFO - Started process (PID=21881) to work on /airflow/dags/download_data.py
[2022-02-17 19:45:49,962] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:45:49,964] {logging_mixin.py:112} INFO - [2022-02-17 19:45:49,964] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:45:50,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:45:50,558] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:45:50,568] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:45:50,574] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 19:46:03,288] {scheduler_job.py:155} INFO - Started process (PID=21907) to work on /airflow/dags/download_data.py
[2022-02-17 19:46:03,294] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:46:03,296] {logging_mixin.py:112} INFO - [2022-02-17 19:46:03,296] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:46:03,893] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:46:03,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:46:03,971] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:46:03,976] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.688 seconds
[2022-02-17 19:46:16,597] {scheduler_job.py:155} INFO - Started process (PID=21935) to work on /airflow/dags/download_data.py
[2022-02-17 19:46:16,609] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:46:16,611] {logging_mixin.py:112} INFO - [2022-02-17 19:46:16,611] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:46:17,119] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:46:17,170] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:46:17,175] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:46:17,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 19:46:29,922] {scheduler_job.py:155} INFO - Started process (PID=21961) to work on /airflow/dags/download_data.py
[2022-02-17 19:46:29,933] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:46:29,935] {logging_mixin.py:112} INFO - [2022-02-17 19:46:29,935] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:46:30,476] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:46:30,524] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:46:30,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:46:30,536] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-17 19:46:43,232] {scheduler_job.py:155} INFO - Started process (PID=21987) to work on /airflow/dags/download_data.py
[2022-02-17 19:46:43,243] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:46:43,246] {logging_mixin.py:112} INFO - [2022-02-17 19:46:43,245] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:46:43,768] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:46:43,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:46:43,841] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:46:43,852] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-17 19:46:56,543] {scheduler_job.py:155} INFO - Started process (PID=22015) to work on /airflow/dags/download_data.py
[2022-02-17 19:46:56,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:46:56,557] {logging_mixin.py:112} INFO - [2022-02-17 19:46:56,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:46:57,079] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:46:57,138] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:46:57,147] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:46:57,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-17 19:47:09,856] {scheduler_job.py:155} INFO - Started process (PID=22041) to work on /airflow/dags/download_data.py
[2022-02-17 19:47:09,864] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:47:09,867] {logging_mixin.py:112} INFO - [2022-02-17 19:47:09,866] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:47:10,409] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:47:10,475] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:47:10,487] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:47:10,492] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.636 seconds
[2022-02-17 19:47:23,104] {scheduler_job.py:155} INFO - Started process (PID=22069) to work on /airflow/dags/download_data.py
[2022-02-17 19:47:23,109] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:47:23,110] {logging_mixin.py:112} INFO - [2022-02-17 19:47:23,110] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:47:23,575] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:47:23,625] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:47:23,637] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:47:23,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 19:47:36,436] {scheduler_job.py:155} INFO - Started process (PID=22095) to work on /airflow/dags/download_data.py
[2022-02-17 19:47:36,447] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:47:36,450] {logging_mixin.py:112} INFO - [2022-02-17 19:47:36,449] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:47:36,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:47:37,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:47:37,016] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:47:37,019] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 19:47:49,713] {scheduler_job.py:155} INFO - Started process (PID=22123) to work on /airflow/dags/download_data.py
[2022-02-17 19:47:49,720] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:47:49,723] {logging_mixin.py:112} INFO - [2022-02-17 19:47:49,722] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:47:50,226] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:47:50,286] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:47:50,299] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:47:50,307] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 19:48:03,007] {scheduler_job.py:155} INFO - Started process (PID=22149) to work on /airflow/dags/download_data.py
[2022-02-17 19:48:03,011] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:48:03,013] {logging_mixin.py:112} INFO - [2022-02-17 19:48:03,013] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:48:03,507] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:48:03,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:48:03,577] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:48:03,583] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 19:48:16,274] {scheduler_job.py:155} INFO - Started process (PID=22177) to work on /airflow/dags/download_data.py
[2022-02-17 19:48:16,286] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:48:16,290] {logging_mixin.py:112} INFO - [2022-02-17 19:48:16,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:48:16,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:48:16,821] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:48:16,826] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:48:16,829] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 19:48:29,532] {scheduler_job.py:155} INFO - Started process (PID=22203) to work on /airflow/dags/download_data.py
[2022-02-17 19:48:29,539] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:48:29,541] {logging_mixin.py:112} INFO - [2022-02-17 19:48:29,541] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:48:30,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:48:30,054] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:48:30,065] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:48:30,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 19:48:42,830] {scheduler_job.py:155} INFO - Started process (PID=22229) to work on /airflow/dags/download_data.py
[2022-02-17 19:48:42,834] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:48:42,836] {logging_mixin.py:112} INFO - [2022-02-17 19:48:42,836] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:48:43,243] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:48:43,285] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:48:43,295] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:48:43,299] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.469 seconds
[2022-02-17 19:48:56,062] {scheduler_job.py:155} INFO - Started process (PID=22257) to work on /airflow/dags/download_data.py
[2022-02-17 19:48:56,065] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:48:56,067] {logging_mixin.py:112} INFO - [2022-02-17 19:48:56,067] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:48:56,503] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:48:56,545] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:48:56,550] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:48:56,554] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-17 19:49:09,359] {scheduler_job.py:155} INFO - Started process (PID=22283) to work on /airflow/dags/download_data.py
[2022-02-17 19:49:09,364] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:49:09,368] {logging_mixin.py:112} INFO - [2022-02-17 19:49:09,368] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:49:09,816] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:49:09,871] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:49:09,883] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:49:09,889] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 19:49:22,632] {scheduler_job.py:155} INFO - Started process (PID=22311) to work on /airflow/dags/download_data.py
[2022-02-17 19:49:22,637] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:49:22,638] {logging_mixin.py:112} INFO - [2022-02-17 19:49:22,638] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:49:23,346] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:49:23,393] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:49:23,400] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:49:23,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.772 seconds
[2022-02-17 19:49:35,946] {scheduler_job.py:155} INFO - Started process (PID=22337) to work on /airflow/dags/download_data.py
[2022-02-17 19:49:35,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:49:35,956] {logging_mixin.py:112} INFO - [2022-02-17 19:49:35,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:49:36,409] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:49:36,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:49:36,465] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:49:36,468] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 19:49:49,255] {scheduler_job.py:155} INFO - Started process (PID=22365) to work on /airflow/dags/download_data.py
[2022-02-17 19:49:49,272] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:49:49,275] {logging_mixin.py:112} INFO - [2022-02-17 19:49:49,274] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:49:49,752] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:49:49,792] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:49:49,797] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:49:49,801] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 19:50:02,587] {scheduler_job.py:155} INFO - Started process (PID=22391) to work on /airflow/dags/download_data.py
[2022-02-17 19:50:02,596] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:50:02,599] {logging_mixin.py:112} INFO - [2022-02-17 19:50:02,598] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:50:03,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:50:03,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:50:03,168] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:50:03,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-17 19:50:15,852] {scheduler_job.py:155} INFO - Started process (PID=22417) to work on /airflow/dags/download_data.py
[2022-02-17 19:50:15,857] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:50:15,859] {logging_mixin.py:112} INFO - [2022-02-17 19:50:15,859] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:50:16,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:50:16,432] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:50:16,440] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:50:16,445] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 19:50:29,183] {scheduler_job.py:155} INFO - Started process (PID=22445) to work on /airflow/dags/download_data.py
[2022-02-17 19:50:29,193] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:50:29,195] {logging_mixin.py:112} INFO - [2022-02-17 19:50:29,195] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:50:29,874] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:50:29,930] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:50:29,943] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:50:29,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.768 seconds
[2022-02-17 19:50:42,493] {scheduler_job.py:155} INFO - Started process (PID=22471) to work on /airflow/dags/download_data.py
[2022-02-17 19:50:42,498] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:50:42,500] {logging_mixin.py:112} INFO - [2022-02-17 19:50:42,500] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:50:43,056] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:50:43,114] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:50:43,124] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:50:43,129] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.636 seconds
[2022-02-17 19:50:55,832] {scheduler_job.py:155} INFO - Started process (PID=22499) to work on /airflow/dags/download_data.py
[2022-02-17 19:50:55,848] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:50:55,851] {logging_mixin.py:112} INFO - [2022-02-17 19:50:55,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:50:56,395] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:50:56,431] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:50:56,437] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:50:56,440] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-17 19:51:09,149] {scheduler_job.py:155} INFO - Started process (PID=22525) to work on /airflow/dags/download_data.py
[2022-02-17 19:51:09,156] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:51:09,157] {logging_mixin.py:112} INFO - [2022-02-17 19:51:09,157] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:51:10,001] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:51:10,058] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:51:10,069] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:51:10,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.928 seconds
[2022-02-17 19:51:22,454] {scheduler_job.py:155} INFO - Started process (PID=22553) to work on /airflow/dags/download_data.py
[2022-02-17 19:51:22,469] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:51:22,472] {logging_mixin.py:112} INFO - [2022-02-17 19:51:22,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:51:23,156] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:51:23,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:51:23,228] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:51:23,234] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.780 seconds
[2022-02-17 19:51:35,764] {scheduler_job.py:155} INFO - Started process (PID=22579) to work on /airflow/dags/download_data.py
[2022-02-17 19:51:35,772] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:51:35,774] {logging_mixin.py:112} INFO - [2022-02-17 19:51:35,773] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:51:36,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:51:36,444] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:51:36,452] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:51:36,461] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-17 19:51:49,089] {scheduler_job.py:155} INFO - Started process (PID=22605) to work on /airflow/dags/download_data.py
[2022-02-17 19:51:49,102] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:51:49,105] {logging_mixin.py:112} INFO - [2022-02-17 19:51:49,104] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:51:49,669] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:51:49,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:51:49,746] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:51:49,755] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.665 seconds
[2022-02-17 19:52:02,455] {scheduler_job.py:155} INFO - Started process (PID=22633) to work on /airflow/dags/download_data.py
[2022-02-17 19:52:02,461] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:52:02,462] {logging_mixin.py:112} INFO - [2022-02-17 19:52:02,462] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:52:02,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:52:02,992] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:52:02,998] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:52:03,003] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 19:52:15,735] {scheduler_job.py:155} INFO - Started process (PID=22659) to work on /airflow/dags/download_data.py
[2022-02-17 19:52:15,748] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:52:15,750] {logging_mixin.py:112} INFO - [2022-02-17 19:52:15,749] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:52:16,329] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:52:16,389] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:52:16,397] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:52:16,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.669 seconds
[2022-02-17 19:52:29,075] {scheduler_job.py:155} INFO - Started process (PID=22687) to work on /airflow/dags/download_data.py
[2022-02-17 19:52:29,085] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:52:29,088] {logging_mixin.py:112} INFO - [2022-02-17 19:52:29,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:52:29,719] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:52:29,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:52:29,791] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:52:29,801] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.725 seconds
[2022-02-17 19:52:42,397] {scheduler_job.py:155} INFO - Started process (PID=22713) to work on /airflow/dags/download_data.py
[2022-02-17 19:52:42,411] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:52:42,414] {logging_mixin.py:112} INFO - [2022-02-17 19:52:42,413] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:52:42,886] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:52:42,945] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:52:42,957] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:52:42,964] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 19:52:55,694] {scheduler_job.py:155} INFO - Started process (PID=22741) to work on /airflow/dags/download_data.py
[2022-02-17 19:52:55,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:52:55,710] {logging_mixin.py:112} INFO - [2022-02-17 19:52:55,710] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:52:56,171] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:52:56,234] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:52:56,245] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:52:56,250] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 19:53:09,039] {scheduler_job.py:155} INFO - Started process (PID=22767) to work on /airflow/dags/download_data.py
[2022-02-17 19:53:09,045] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:53:09,048] {logging_mixin.py:112} INFO - [2022-02-17 19:53:09,047] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:53:09,600] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:53:09,662] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:53:09,672] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:53:09,678] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.639 seconds
[2022-02-17 19:53:22,330] {scheduler_job.py:155} INFO - Started process (PID=22795) to work on /airflow/dags/download_data.py
[2022-02-17 19:53:22,345] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:53:22,347] {logging_mixin.py:112} INFO - [2022-02-17 19:53:22,346] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:53:22,986] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:53:23,054] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:53:23,063] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:53:23,069] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.739 seconds
[2022-02-17 19:53:35,633] {scheduler_job.py:155} INFO - Started process (PID=22821) to work on /airflow/dags/download_data.py
[2022-02-17 19:53:35,646] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:53:35,648] {logging_mixin.py:112} INFO - [2022-02-17 19:53:35,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:53:36,217] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:53:36,282] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:53:36,292] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:53:36,300] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-17 19:53:48,924] {scheduler_job.py:155} INFO - Started process (PID=22847) to work on /airflow/dags/download_data.py
[2022-02-17 19:53:48,932] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:53:48,934] {logging_mixin.py:112} INFO - [2022-02-17 19:53:48,934] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:53:49,456] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:53:49,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:53:49,524] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:53:49,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 19:54:02,245] {scheduler_job.py:155} INFO - Started process (PID=22875) to work on /airflow/dags/download_data.py
[2022-02-17 19:54:02,251] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:54:02,252] {logging_mixin.py:112} INFO - [2022-02-17 19:54:02,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:54:02,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:54:02,840] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:54:02,853] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:54:02,857] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-17 19:54:15,510] {scheduler_job.py:155} INFO - Started process (PID=22901) to work on /airflow/dags/download_data.py
[2022-02-17 19:54:15,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:54:15,518] {logging_mixin.py:112} INFO - [2022-02-17 19:54:15,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:54:16,006] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:54:16,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:54:16,072] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:54:16,079] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 19:54:28,850] {scheduler_job.py:155} INFO - Started process (PID=22929) to work on /airflow/dags/download_data.py
[2022-02-17 19:54:28,855] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:54:28,857] {logging_mixin.py:112} INFO - [2022-02-17 19:54:28,856] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:54:29,368] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:54:29,438] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:54:29,445] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:54:29,450] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 19:54:42,173] {scheduler_job.py:155} INFO - Started process (PID=22955) to work on /airflow/dags/download_data.py
[2022-02-17 19:54:42,179] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:54:42,180] {logging_mixin.py:112} INFO - [2022-02-17 19:54:42,180] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:54:42,684] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:54:42,732] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:54:42,739] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:54:42,743] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 19:54:55,570] {scheduler_job.py:155} INFO - Started process (PID=22983) to work on /airflow/dags/download_data.py
[2022-02-17 19:54:55,589] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:54:55,591] {logging_mixin.py:112} INFO - [2022-02-17 19:54:55,591] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:54:56,101] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:54:56,145] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:54:56,153] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:54:56,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 19:55:08,830] {scheduler_job.py:155} INFO - Started process (PID=23009) to work on /airflow/dags/download_data.py
[2022-02-17 19:55:08,834] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:55:08,836] {logging_mixin.py:112} INFO - [2022-02-17 19:55:08,836] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:55:09,368] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:55:09,409] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:55:09,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:55:09,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 19:55:22,619] {scheduler_job.py:155} INFO - Started process (PID=23035) to work on /airflow/dags/download_data.py
[2022-02-17 19:55:22,623] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:55:22,625] {logging_mixin.py:112} INFO - [2022-02-17 19:55:22,625] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:55:23,120] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:55:23,156] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:55:23,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:55:23,163] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 19:55:40,325] {scheduler_job.py:155} INFO - Started process (PID=23063) to work on /airflow/dags/download_data.py
[2022-02-17 19:55:40,331] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:55:40,334] {logging_mixin.py:112} INFO - [2022-02-17 19:55:40,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:55:40,787] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:55:40,837] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:55:40,845] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:55:40,850] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 19:56:45,950] {scheduler_job.py:155} INFO - Started process (PID=23091) to work on /airflow/dags/download_data.py
[2022-02-17 19:56:45,960] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:56:45,963] {logging_mixin.py:112} INFO - [2022-02-17 19:56:45,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:56:46,422] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:56:46,469] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:56:46,479] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:56:46,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 19:56:58,258] {scheduler_job.py:155} INFO - Started process (PID=23116) to work on /airflow/dags/download_data.py
[2022-02-17 19:56:58,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 19:56:58,266] {logging_mixin.py:112} INFO - [2022-02-17 19:56:58,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 19:56:58,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 19:56:58,869] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 19:56:58,878] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 19:56:58,883] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-17 20:25:21,379] {scheduler_job.py:155} INFO - Started process (PID=23143) to work on /airflow/dags/download_data.py
[2022-02-17 20:25:21,384] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:25:21,385] {logging_mixin.py:112} INFO - [2022-02-17 20:25:21,385] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:25:21,912] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:25:21,959] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:25:21,966] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:25:21,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 20:25:41,784] {scheduler_job.py:155} INFO - Started process (PID=23169) to work on /airflow/dags/download_data.py
[2022-02-17 20:25:41,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:25:41,793] {logging_mixin.py:112} INFO - [2022-02-17 20:25:41,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:25:42,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:25:42,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:25:42,324] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:25:42,328] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 20:25:50,766] {scheduler_job.py:155} INFO - Started process (PID=23195) to work on /airflow/dags/download_data.py
[2022-02-17 20:25:50,775] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:25:50,777] {logging_mixin.py:112} INFO - [2022-02-17 20:25:50,777] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:25:51,330] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:25:51,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:25:51,390] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:25:51,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.631 seconds
[2022-02-17 20:25:57,943] {scheduler_job.py:155} INFO - Started process (PID=23222) to work on /airflow/dags/download_data.py
[2022-02-17 20:25:57,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:25:57,955] {logging_mixin.py:112} INFO - [2022-02-17 20:25:57,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:25:58,478] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:25:58,534] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:25:58,544] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:25:58,550] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-17 20:26:06,152] {scheduler_job.py:155} INFO - Started process (PID=23249) to work on /airflow/dags/download_data.py
[2022-02-17 20:26:06,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:26:06,165] {logging_mixin.py:112} INFO - [2022-02-17 20:26:06,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:26:06,792] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:26:06,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:26:06,849] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:26:06,857] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.705 seconds
[2022-02-17 20:26:19,463] {scheduler_job.py:155} INFO - Started process (PID=23276) to work on /airflow/dags/download_data.py
[2022-02-17 20:26:19,471] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:26:19,473] {logging_mixin.py:112} INFO - [2022-02-17 20:26:19,473] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:26:20,000] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:26:20,053] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:26:20,062] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:26:20,066] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-17 20:26:32,815] {scheduler_job.py:155} INFO - Started process (PID=23302) to work on /airflow/dags/download_data.py
[2022-02-17 20:26:32,824] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:26:32,827] {logging_mixin.py:112} INFO - [2022-02-17 20:26:32,826] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:26:33,355] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:26:33,398] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:26:33,406] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:26:33,411] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 20:26:46,066] {scheduler_job.py:155} INFO - Started process (PID=23328) to work on /airflow/dags/download_data.py
[2022-02-17 20:26:46,072] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:26:46,074] {logging_mixin.py:112} INFO - [2022-02-17 20:26:46,074] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:26:46,573] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:26:46,632] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:26:46,644] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:26:46,651] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 20:26:59,387] {scheduler_job.py:155} INFO - Started process (PID=23354) to work on /airflow/dags/download_data.py
[2022-02-17 20:26:59,394] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:26:59,396] {logging_mixin.py:112} INFO - [2022-02-17 20:26:59,395] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:26:59,998] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:27:00,061] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:27:00,068] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:27:00,072] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.685 seconds
[2022-02-17 20:27:12,692] {scheduler_job.py:155} INFO - Started process (PID=23380) to work on /airflow/dags/download_data.py
[2022-02-17 20:27:12,697] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:27:12,700] {logging_mixin.py:112} INFO - [2022-02-17 20:27:12,699] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:27:13,181] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:27:13,253] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:27:13,265] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:27:13,272] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-17 20:27:26,001] {scheduler_job.py:155} INFO - Started process (PID=23406) to work on /airflow/dags/download_data.py
[2022-02-17 20:27:26,007] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:27:26,008] {logging_mixin.py:112} INFO - [2022-02-17 20:27:26,008] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:27:26,586] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:27:26,646] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:27:26,655] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:27:26,661] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.659 seconds
[2022-02-17 20:27:39,338] {scheduler_job.py:155} INFO - Started process (PID=23432) to work on /airflow/dags/download_data.py
[2022-02-17 20:27:39,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:27:39,351] {logging_mixin.py:112} INFO - [2022-02-17 20:27:39,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:27:39,858] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:27:39,920] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:27:39,928] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:27:39,933] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 20:27:52,614] {scheduler_job.py:155} INFO - Started process (PID=23458) to work on /airflow/dags/download_data.py
[2022-02-17 20:27:52,627] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:27:52,629] {logging_mixin.py:112} INFO - [2022-02-17 20:27:52,629] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:27:53,091] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:27:53,147] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:27:53,159] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:27:53,164] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 20:28:05,872] {scheduler_job.py:155} INFO - Started process (PID=23484) to work on /airflow/dags/download_data.py
[2022-02-17 20:28:05,878] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:28:05,879] {logging_mixin.py:112} INFO - [2022-02-17 20:28:05,879] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:28:06,424] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:28:06,477] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:28:06,485] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:28:06,490] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 20:28:19,160] {scheduler_job.py:155} INFO - Started process (PID=23510) to work on /airflow/dags/download_data.py
[2022-02-17 20:28:19,164] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:28:19,168] {logging_mixin.py:112} INFO - [2022-02-17 20:28:19,168] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:28:19,658] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:28:19,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:28:19,710] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:28:19,715] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 20:28:32,547] {scheduler_job.py:155} INFO - Started process (PID=23536) to work on /airflow/dags/download_data.py
[2022-02-17 20:28:32,552] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:28:32,554] {logging_mixin.py:112} INFO - [2022-02-17 20:28:32,554] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:28:33,147] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:28:33,218] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:28:33,229] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:28:33,235] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.688 seconds
[2022-02-17 20:28:45,885] {scheduler_job.py:155} INFO - Started process (PID=23562) to work on /airflow/dags/download_data.py
[2022-02-17 20:28:45,894] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:28:45,897] {logging_mixin.py:112} INFO - [2022-02-17 20:28:45,896] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:28:46,364] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:28:46,421] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:28:46,433] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:28:46,439] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 20:28:59,225] {scheduler_job.py:155} INFO - Started process (PID=23588) to work on /airflow/dags/download_data.py
[2022-02-17 20:28:59,237] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:28:59,239] {logging_mixin.py:112} INFO - [2022-02-17 20:28:59,239] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:28:59,766] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:28:59,822] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:28:59,839] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:28:59,846] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-17 20:29:12,515] {scheduler_job.py:155} INFO - Started process (PID=23614) to work on /airflow/dags/download_data.py
[2022-02-17 20:29:12,520] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:29:12,522] {logging_mixin.py:112} INFO - [2022-02-17 20:29:12,522] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:29:13,071] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:29:13,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:29:13,137] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:29:13,142] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.627 seconds
[2022-02-17 20:29:25,814] {scheduler_job.py:155} INFO - Started process (PID=23640) to work on /airflow/dags/download_data.py
[2022-02-17 20:29:25,824] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:29:25,826] {logging_mixin.py:112} INFO - [2022-02-17 20:29:25,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:29:26,332] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:29:26,394] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:29:26,409] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:29:26,415] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-17 20:29:39,148] {scheduler_job.py:155} INFO - Started process (PID=23666) to work on /airflow/dags/download_data.py
[2022-02-17 20:29:39,155] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:29:39,157] {logging_mixin.py:112} INFO - [2022-02-17 20:29:39,157] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:29:39,633] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:29:39,682] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:29:39,694] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:29:39,704] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 20:29:52,466] {scheduler_job.py:155} INFO - Started process (PID=23692) to work on /airflow/dags/download_data.py
[2022-02-17 20:29:52,477] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:29:52,480] {logging_mixin.py:112} INFO - [2022-02-17 20:29:52,479] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:29:52,983] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:29:53,035] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:29:53,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:29:53,051] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 20:30:05,811] {scheduler_job.py:155} INFO - Started process (PID=23718) to work on /airflow/dags/download_data.py
[2022-02-17 20:30:05,822] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:30:05,827] {logging_mixin.py:112} INFO - [2022-02-17 20:30:05,826] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:30:06,319] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:30:06,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:30:06,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:30:06,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 20:30:19,120] {scheduler_job.py:155} INFO - Started process (PID=23744) to work on /airflow/dags/download_data.py
[2022-02-17 20:30:19,128] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:30:19,130] {logging_mixin.py:112} INFO - [2022-02-17 20:30:19,130] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:30:19,617] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:30:19,662] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:30:19,668] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:30:19,672] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 20:30:32,442] {scheduler_job.py:155} INFO - Started process (PID=23770) to work on /airflow/dags/download_data.py
[2022-02-17 20:30:32,448] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:30:32,450] {logging_mixin.py:112} INFO - [2022-02-17 20:30:32,450] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:30:33,011] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:30:33,058] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:30:33,070] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:30:33,075] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-17 20:30:45,755] {scheduler_job.py:155} INFO - Started process (PID=23796) to work on /airflow/dags/download_data.py
[2022-02-17 20:30:45,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:30:45,765] {logging_mixin.py:112} INFO - [2022-02-17 20:30:45,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:30:46,278] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:30:46,323] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:30:46,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:30:46,341] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 20:30:59,059] {scheduler_job.py:155} INFO - Started process (PID=23822) to work on /airflow/dags/download_data.py
[2022-02-17 20:30:59,064] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:30:59,068] {logging_mixin.py:112} INFO - [2022-02-17 20:30:59,068] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:30:59,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:30:59,701] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:30:59,712] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:30:59,720] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.661 seconds
[2022-02-17 20:31:12,393] {scheduler_job.py:155} INFO - Started process (PID=23848) to work on /airflow/dags/download_data.py
[2022-02-17 20:31:12,399] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:31:12,401] {logging_mixin.py:112} INFO - [2022-02-17 20:31:12,401] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:31:12,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:31:12,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:31:12,965] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:31:12,972] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 20:31:25,700] {scheduler_job.py:155} INFO - Started process (PID=23874) to work on /airflow/dags/download_data.py
[2022-02-17 20:31:25,706] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:31:25,707] {logging_mixin.py:112} INFO - [2022-02-17 20:31:25,707] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:31:26,273] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:31:26,337] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:31:26,349] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:31:26,355] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-17 20:31:39,095] {scheduler_job.py:155} INFO - Started process (PID=23900) to work on /airflow/dags/download_data.py
[2022-02-17 20:31:39,102] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:31:39,104] {logging_mixin.py:112} INFO - [2022-02-17 20:31:39,104] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:31:39,607] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:31:39,670] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:31:39,680] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:31:39,685] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 20:31:52,347] {scheduler_job.py:155} INFO - Started process (PID=23926) to work on /airflow/dags/download_data.py
[2022-02-17 20:31:52,355] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:31:52,357] {logging_mixin.py:112} INFO - [2022-02-17 20:31:52,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:31:52,848] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:31:52,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:31:52,900] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:31:52,906] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 20:32:05,687] {scheduler_job.py:155} INFO - Started process (PID=23952) to work on /airflow/dags/download_data.py
[2022-02-17 20:32:05,695] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:32:05,697] {logging_mixin.py:112} INFO - [2022-02-17 20:32:05,697] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:32:06,185] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:32:06,227] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:32:06,232] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:32:06,236] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 20:32:18,961] {scheduler_job.py:155} INFO - Started process (PID=23978) to work on /airflow/dags/download_data.py
[2022-02-17 20:32:18,966] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:32:18,968] {logging_mixin.py:112} INFO - [2022-02-17 20:32:18,968] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:32:19,468] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:32:19,514] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:32:19,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:32:19,525] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 20:32:32,297] {scheduler_job.py:155} INFO - Started process (PID=24004) to work on /airflow/dags/download_data.py
[2022-02-17 20:32:32,303] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:32:32,305] {logging_mixin.py:112} INFO - [2022-02-17 20:32:32,305] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:32:32,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:32:32,947] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:32:32,957] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:32:32,961] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.664 seconds
[2022-02-17 20:32:45,572] {scheduler_job.py:155} INFO - Started process (PID=24030) to work on /airflow/dags/download_data.py
[2022-02-17 20:32:45,579] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:32:45,587] {logging_mixin.py:112} INFO - [2022-02-17 20:32:45,587] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:32:46,098] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:32:46,140] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:32:46,146] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:32:46,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 20:32:58,908] {scheduler_job.py:155} INFO - Started process (PID=24056) to work on /airflow/dags/download_data.py
[2022-02-17 20:32:58,924] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:32:58,926] {logging_mixin.py:112} INFO - [2022-02-17 20:32:58,925] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:32:59,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:32:59,566] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:32:59,578] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:32:59,584] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.676 seconds
[2022-02-17 20:33:12,214] {scheduler_job.py:155} INFO - Started process (PID=24082) to work on /airflow/dags/download_data.py
[2022-02-17 20:33:12,220] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:33:12,224] {logging_mixin.py:112} INFO - [2022-02-17 20:33:12,224] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:33:12,737] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:33:12,791] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:33:12,809] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:33:12,814] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 20:33:25,445] {scheduler_job.py:155} INFO - Started process (PID=24108) to work on /airflow/dags/download_data.py
[2022-02-17 20:33:25,456] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:33:25,461] {logging_mixin.py:112} INFO - [2022-02-17 20:33:25,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:33:26,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:33:26,083] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:33:26,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:33:26,103] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.658 seconds
[2022-02-17 20:33:38,814] {scheduler_job.py:155} INFO - Started process (PID=24134) to work on /airflow/dags/download_data.py
[2022-02-17 20:33:38,820] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:33:38,822] {logging_mixin.py:112} INFO - [2022-02-17 20:33:38,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:33:39,502] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:33:39,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:33:39,566] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:33:39,572] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.758 seconds
[2022-02-17 20:33:52,079] {scheduler_job.py:155} INFO - Started process (PID=24160) to work on /airflow/dags/download_data.py
[2022-02-17 20:33:52,084] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:33:52,086] {logging_mixin.py:112} INFO - [2022-02-17 20:33:52,086] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:33:52,604] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:33:52,659] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:33:52,674] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:33:52,679] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 20:34:05,390] {scheduler_job.py:155} INFO - Started process (PID=24186) to work on /airflow/dags/download_data.py
[2022-02-17 20:34:05,590] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:34:05,675] {logging_mixin.py:112} INFO - [2022-02-17 20:34:05,675] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:34:06,270] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:34:06,318] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:34:06,326] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:34:06,331] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.941 seconds
[2022-02-17 20:34:18,669] {scheduler_job.py:155} INFO - Started process (PID=24212) to work on /airflow/dags/download_data.py
[2022-02-17 20:34:18,678] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:34:18,680] {logging_mixin.py:112} INFO - [2022-02-17 20:34:18,680] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:34:19,152] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:34:19,194] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:34:19,204] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:34:19,210] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 20:34:31,965] {scheduler_job.py:155} INFO - Started process (PID=24238) to work on /airflow/dags/download_data.py
[2022-02-17 20:34:31,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:34:31,973] {logging_mixin.py:112} INFO - [2022-02-17 20:34:31,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:34:32,572] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:34:32,634] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:34:32,647] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:34:32,652] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.688 seconds
[2022-02-17 20:34:45,255] {scheduler_job.py:155} INFO - Started process (PID=24264) to work on /airflow/dags/download_data.py
[2022-02-17 20:34:45,263] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:34:45,267] {logging_mixin.py:112} INFO - [2022-02-17 20:34:45,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:34:45,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:34:45,833] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:34:45,842] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:34:45,846] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 20:34:58,579] {scheduler_job.py:155} INFO - Started process (PID=24290) to work on /airflow/dags/download_data.py
[2022-02-17 20:34:58,590] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:34:58,594] {logging_mixin.py:112} INFO - [2022-02-17 20:34:58,593] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:34:59,122] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:34:59,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:34:59,191] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:34:59,198] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 20:35:11,887] {scheduler_job.py:155} INFO - Started process (PID=24316) to work on /airflow/dags/download_data.py
[2022-02-17 20:35:11,895] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:35:11,898] {logging_mixin.py:112} INFO - [2022-02-17 20:35:11,897] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:35:12,403] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:35:12,459] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:35:12,465] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:35:12,477] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 20:35:25,205] {scheduler_job.py:155} INFO - Started process (PID=24342) to work on /airflow/dags/download_data.py
[2022-02-17 20:35:25,209] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:35:25,211] {logging_mixin.py:112} INFO - [2022-02-17 20:35:25,211] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:35:25,827] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:35:25,881] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:35:25,892] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:35:25,897] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.693 seconds
[2022-02-17 20:35:38,558] {scheduler_job.py:155} INFO - Started process (PID=24368) to work on /airflow/dags/download_data.py
[2022-02-17 20:35:38,570] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:35:38,573] {logging_mixin.py:112} INFO - [2022-02-17 20:35:38,572] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:35:39,055] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:35:39,098] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:35:39,104] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:35:39,107] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 20:35:51,809] {scheduler_job.py:155} INFO - Started process (PID=24394) to work on /airflow/dags/download_data.py
[2022-02-17 20:35:51,813] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:35:51,815] {logging_mixin.py:112} INFO - [2022-02-17 20:35:51,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:35:52,321] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:35:52,376] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:35:52,389] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:35:52,395] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 20:36:05,148] {scheduler_job.py:155} INFO - Started process (PID=24420) to work on /airflow/dags/download_data.py
[2022-02-17 20:36:05,161] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:36:05,164] {logging_mixin.py:112} INFO - [2022-02-17 20:36:05,163] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:36:05,616] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:36:05,666] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:36:05,675] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:36:05,680] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 20:36:18,403] {scheduler_job.py:155} INFO - Started process (PID=24446) to work on /airflow/dags/download_data.py
[2022-02-17 20:36:18,408] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:36:18,410] {logging_mixin.py:112} INFO - [2022-02-17 20:36:18,410] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:36:18,926] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:36:18,975] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:36:18,989] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:36:18,998] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 20:36:31,709] {scheduler_job.py:155} INFO - Started process (PID=24472) to work on /airflow/dags/download_data.py
[2022-02-17 20:36:31,723] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:36:31,725] {logging_mixin.py:112} INFO - [2022-02-17 20:36:31,725] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:36:32,280] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:36:32,333] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:36:32,344] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:36:32,349] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-17 20:36:45,045] {scheduler_job.py:155} INFO - Started process (PID=24498) to work on /airflow/dags/download_data.py
[2022-02-17 20:36:45,054] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:36:45,056] {logging_mixin.py:112} INFO - [2022-02-17 20:36:45,056] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:36:45,566] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:36:45,619] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:36:45,629] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:36:45,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 20:36:58,391] {scheduler_job.py:155} INFO - Started process (PID=24524) to work on /airflow/dags/download_data.py
[2022-02-17 20:36:58,400] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:36:58,403] {logging_mixin.py:112} INFO - [2022-02-17 20:36:58,403] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:36:58,953] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:36:59,022] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:36:59,033] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:36:59,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-17 20:37:11,693] {scheduler_job.py:155} INFO - Started process (PID=24550) to work on /airflow/dags/download_data.py
[2022-02-17 20:37:11,698] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:37:11,700] {logging_mixin.py:112} INFO - [2022-02-17 20:37:11,699] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:37:12,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:37:12,272] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:37:12,285] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:37:12,291] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-17 20:37:24,947] {scheduler_job.py:155} INFO - Started process (PID=24576) to work on /airflow/dags/download_data.py
[2022-02-17 20:37:24,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:37:24,955] {logging_mixin.py:112} INFO - [2022-02-17 20:37:24,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:37:25,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:37:25,609] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:37:25,616] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:37:25,621] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.675 seconds
[2022-02-17 20:37:38,279] {scheduler_job.py:155} INFO - Started process (PID=24602) to work on /airflow/dags/download_data.py
[2022-02-17 20:37:38,291] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:37:38,293] {logging_mixin.py:112} INFO - [2022-02-17 20:37:38,292] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:37:38,743] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:37:38,791] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:37:38,798] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:37:38,802] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 20:37:51,573] {scheduler_job.py:155} INFO - Started process (PID=24628) to work on /airflow/dags/download_data.py
[2022-02-17 20:37:51,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:37:51,579] {logging_mixin.py:112} INFO - [2022-02-17 20:37:51,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:37:52,102] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:37:52,167] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:37:52,179] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:37:52,187] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-17 20:38:04,899] {scheduler_job.py:155} INFO - Started process (PID=24654) to work on /airflow/dags/download_data.py
[2022-02-17 20:38:04,904] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:38:04,905] {logging_mixin.py:112} INFO - [2022-02-17 20:38:04,905] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:38:05,382] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:38:05,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:38:05,450] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:38:05,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 20:38:18,178] {scheduler_job.py:155} INFO - Started process (PID=24680) to work on /airflow/dags/download_data.py
[2022-02-17 20:38:18,196] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:38:18,197] {logging_mixin.py:112} INFO - [2022-02-17 20:38:18,197] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:38:18,710] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:38:18,751] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:38:18,757] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:38:18,760] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 20:38:31,511] {scheduler_job.py:155} INFO - Started process (PID=24706) to work on /airflow/dags/download_data.py
[2022-02-17 20:38:31,517] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:38:31,519] {logging_mixin.py:112} INFO - [2022-02-17 20:38:31,519] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:38:32,099] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:38:32,179] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:38:32,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:38:32,196] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.685 seconds
[2022-02-17 20:38:44,844] {scheduler_job.py:155} INFO - Started process (PID=24732) to work on /airflow/dags/download_data.py
[2022-02-17 20:38:44,851] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:38:44,852] {logging_mixin.py:112} INFO - [2022-02-17 20:38:44,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:38:45,371] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:38:45,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:38:45,438] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:38:45,446] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-17 20:38:58,176] {scheduler_job.py:155} INFO - Started process (PID=24758) to work on /airflow/dags/download_data.py
[2022-02-17 20:38:58,182] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:38:58,183] {logging_mixin.py:112} INFO - [2022-02-17 20:38:58,183] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:38:58,703] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:38:58,768] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:38:58,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:38:58,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.620 seconds
[2022-02-17 20:39:11,468] {scheduler_job.py:155} INFO - Started process (PID=24784) to work on /airflow/dags/download_data.py
[2022-02-17 20:39:11,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:39:11,481] {logging_mixin.py:112} INFO - [2022-02-17 20:39:11,481] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:39:12,091] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:39:12,150] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:39:12,158] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:39:12,162] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.694 seconds
[2022-02-17 20:39:24,729] {scheduler_job.py:155} INFO - Started process (PID=24810) to work on /airflow/dags/download_data.py
[2022-02-17 20:39:24,737] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:39:24,739] {logging_mixin.py:112} INFO - [2022-02-17 20:39:24,738] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:39:25,205] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:39:25,262] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:39:25,277] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:39:25,285] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 20:39:38,084] {scheduler_job.py:155} INFO - Started process (PID=24836) to work on /airflow/dags/download_data.py
[2022-02-17 20:39:38,089] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:39:38,091] {logging_mixin.py:112} INFO - [2022-02-17 20:39:38,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:39:38,597] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:39:38,640] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:39:38,649] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:39:38,654] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-17 20:39:51,375] {scheduler_job.py:155} INFO - Started process (PID=24862) to work on /airflow/dags/download_data.py
[2022-02-17 20:39:51,382] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:39:51,383] {logging_mixin.py:112} INFO - [2022-02-17 20:39:51,383] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:39:51,859] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:39:51,904] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:39:51,912] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:39:51,916] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 20:40:03,646] {scheduler_job.py:155} INFO - Started process (PID=24886) to work on /airflow/dags/download_data.py
[2022-02-17 20:40:03,652] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:40:03,654] {logging_mixin.py:112} INFO - [2022-02-17 20:40:03,654] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:40:04,118] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:40:04,174] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:40:04,185] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:40:04,193] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 20:40:16,919] {scheduler_job.py:155} INFO - Started process (PID=24912) to work on /airflow/dags/download_data.py
[2022-02-17 20:40:16,927] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:40:16,928] {logging_mixin.py:112} INFO - [2022-02-17 20:40:16,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:40:17,451] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:40:17,496] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:40:17,505] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:40:17,511] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 20:40:30,282] {scheduler_job.py:155} INFO - Started process (PID=24938) to work on /airflow/dags/download_data.py
[2022-02-17 20:40:30,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:40:30,289] {logging_mixin.py:112} INFO - [2022-02-17 20:40:30,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:40:30,884] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:40:30,935] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:40:30,944] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:40:30,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-17 20:40:43,657] {scheduler_job.py:155} INFO - Started process (PID=24964) to work on /airflow/dags/download_data.py
[2022-02-17 20:40:43,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:40:43,671] {logging_mixin.py:112} INFO - [2022-02-17 20:40:43,671] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:40:44,156] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:40:44,196] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:40:44,206] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:40:44,211] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 20:40:56,971] {scheduler_job.py:155} INFO - Started process (PID=24990) to work on /airflow/dags/download_data.py
[2022-02-17 20:40:56,977] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:40:56,979] {logging_mixin.py:112} INFO - [2022-02-17 20:40:56,979] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:40:57,575] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:40:57,634] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:40:57,641] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:40:57,647] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.676 seconds
[2022-02-17 20:41:10,288] {scheduler_job.py:155} INFO - Started process (PID=25016) to work on /airflow/dags/download_data.py
[2022-02-17 20:41:10,300] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:41:10,302] {logging_mixin.py:112} INFO - [2022-02-17 20:41:10,302] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:41:10,799] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:41:10,860] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:41:10,868] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:41:10,873] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 20:41:23,576] {scheduler_job.py:155} INFO - Started process (PID=25042) to work on /airflow/dags/download_data.py
[2022-02-17 20:41:23,581] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:41:23,583] {logging_mixin.py:112} INFO - [2022-02-17 20:41:23,583] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:41:24,041] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:41:24,090] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:41:24,096] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:41:24,100] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 20:41:36,930] {scheduler_job.py:155} INFO - Started process (PID=25068) to work on /airflow/dags/download_data.py
[2022-02-17 20:41:36,937] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:41:36,939] {logging_mixin.py:112} INFO - [2022-02-17 20:41:36,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:41:37,475] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:41:37,519] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:41:37,529] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:41:37,537] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-17 20:41:50,247] {scheduler_job.py:155} INFO - Started process (PID=25094) to work on /airflow/dags/download_data.py
[2022-02-17 20:41:50,254] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:41:50,256] {logging_mixin.py:112} INFO - [2022-02-17 20:41:50,256] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:41:50,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:41:50,796] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:41:50,808] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:41:50,812] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 20:42:03,556] {scheduler_job.py:155} INFO - Started process (PID=25120) to work on /airflow/dags/download_data.py
[2022-02-17 20:42:03,561] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:42:03,563] {logging_mixin.py:112} INFO - [2022-02-17 20:42:03,563] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:42:04,023] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:42:04,080] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:42:04,090] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:42:04,095] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 20:42:16,844] {scheduler_job.py:155} INFO - Started process (PID=25146) to work on /airflow/dags/download_data.py
[2022-02-17 20:42:16,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:42:16,852] {logging_mixin.py:112} INFO - [2022-02-17 20:42:16,851] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:42:17,377] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:42:17,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:42:17,435] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:42:17,442] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-17 20:42:30,208] {scheduler_job.py:155} INFO - Started process (PID=25172) to work on /airflow/dags/download_data.py
[2022-02-17 20:42:30,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:42:30,215] {logging_mixin.py:112} INFO - [2022-02-17 20:42:30,215] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:42:30,693] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:42:30,756] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:42:30,767] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:42:30,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 20:42:43,555] {scheduler_job.py:155} INFO - Started process (PID=25198) to work on /airflow/dags/download_data.py
[2022-02-17 20:42:43,560] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:42:43,562] {logging_mixin.py:112} INFO - [2022-02-17 20:42:43,561] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:42:44,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:42:44,144] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:42:44,159] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:42:44,168] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-17 20:42:56,837] {scheduler_job.py:155} INFO - Started process (PID=25224) to work on /airflow/dags/download_data.py
[2022-02-17 20:42:56,844] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:42:56,845] {logging_mixin.py:112} INFO - [2022-02-17 20:42:56,845] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:42:57,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:42:57,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:42:57,467] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:42:57,474] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-17 20:43:10,158] {scheduler_job.py:155} INFO - Started process (PID=25250) to work on /airflow/dags/download_data.py
[2022-02-17 20:43:10,166] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:43:10,169] {logging_mixin.py:112} INFO - [2022-02-17 20:43:10,168] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:43:10,649] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:43:10,705] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:43:10,716] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:43:10,720] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 20:43:23,434] {scheduler_job.py:155} INFO - Started process (PID=25276) to work on /airflow/dags/download_data.py
[2022-02-17 20:43:23,440] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:43:23,442] {logging_mixin.py:112} INFO - [2022-02-17 20:43:23,442] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:43:23,968] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:43:24,027] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:43:24,037] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:43:24,045] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-17 20:43:36,800] {scheduler_job.py:155} INFO - Started process (PID=25302) to work on /airflow/dags/download_data.py
[2022-02-17 20:43:36,808] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:43:36,811] {logging_mixin.py:112} INFO - [2022-02-17 20:43:36,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:43:37,304] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:43:37,353] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:43:37,362] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:43:37,368] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 20:43:50,069] {scheduler_job.py:155} INFO - Started process (PID=25328) to work on /airflow/dags/download_data.py
[2022-02-17 20:43:50,073] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:43:50,075] {logging_mixin.py:112} INFO - [2022-02-17 20:43:50,075] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:43:50,578] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:43:50,637] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:43:50,651] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:43:50,656] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 20:44:03,397] {scheduler_job.py:155} INFO - Started process (PID=25354) to work on /airflow/dags/download_data.py
[2022-02-17 20:44:03,404] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:44:03,406] {logging_mixin.py:112} INFO - [2022-02-17 20:44:03,406] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:44:03,866] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:44:03,936] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:44:03,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:44:03,955] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 20:44:16,696] {scheduler_job.py:155} INFO - Started process (PID=25380) to work on /airflow/dags/download_data.py
[2022-02-17 20:44:16,704] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:44:16,707] {logging_mixin.py:112} INFO - [2022-02-17 20:44:16,707] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:44:17,181] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:44:17,230] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:44:17,240] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:44:17,245] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 20:44:30,002] {scheduler_job.py:155} INFO - Started process (PID=25406) to work on /airflow/dags/download_data.py
[2022-02-17 20:44:30,010] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:44:30,013] {logging_mixin.py:112} INFO - [2022-02-17 20:44:30,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:44:30,530] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:44:30,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:44:30,597] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:44:30,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-17 20:44:43,320] {scheduler_job.py:155} INFO - Started process (PID=25432) to work on /airflow/dags/download_data.py
[2022-02-17 20:44:43,344] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:44:43,351] {logging_mixin.py:112} INFO - [2022-02-17 20:44:43,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:44:43,883] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:44:43,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:44:43,950] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:44:43,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-17 20:44:56,634] {scheduler_job.py:155} INFO - Started process (PID=25458) to work on /airflow/dags/download_data.py
[2022-02-17 20:44:56,640] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:44:56,642] {logging_mixin.py:112} INFO - [2022-02-17 20:44:56,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:44:57,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:44:57,254] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:44:57,267] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:44:57,275] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-17 20:45:09,950] {scheduler_job.py:155} INFO - Started process (PID=25484) to work on /airflow/dags/download_data.py
[2022-02-17 20:45:09,964] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:45:09,967] {logging_mixin.py:112} INFO - [2022-02-17 20:45:09,967] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:45:10,439] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:45:10,490] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:45:10,499] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:45:10,505] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 20:45:23,284] {scheduler_job.py:155} INFO - Started process (PID=25510) to work on /airflow/dags/download_data.py
[2022-02-17 20:45:23,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:45:23,301] {logging_mixin.py:112} INFO - [2022-02-17 20:45:23,300] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:45:23,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:45:23,805] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:45:23,811] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:45:23,815] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 20:45:36,569] {scheduler_job.py:155} INFO - Started process (PID=25536) to work on /airflow/dags/download_data.py
[2022-02-17 20:45:36,574] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:45:36,576] {logging_mixin.py:112} INFO - [2022-02-17 20:45:36,576] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:45:37,084] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:45:37,138] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:45:37,147] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:45:37,156] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 20:45:49,862] {scheduler_job.py:155} INFO - Started process (PID=25562) to work on /airflow/dags/download_data.py
[2022-02-17 20:45:49,866] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:45:49,868] {logging_mixin.py:112} INFO - [2022-02-17 20:45:49,868] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:45:50,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:45:50,373] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:45:50,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:45:50,388] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 20:46:03,204] {scheduler_job.py:155} INFO - Started process (PID=25588) to work on /airflow/dags/download_data.py
[2022-02-17 20:46:03,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:46:03,216] {logging_mixin.py:112} INFO - [2022-02-17 20:46:03,216] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:46:03,668] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:46:03,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:46:03,727] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:46:03,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 20:46:16,476] {scheduler_job.py:155} INFO - Started process (PID=25614) to work on /airflow/dags/download_data.py
[2022-02-17 20:46:16,491] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:46:16,494] {logging_mixin.py:112} INFO - [2022-02-17 20:46:16,494] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:46:16,949] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:46:17,008] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:46:17,016] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:46:17,021] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-17 20:46:29,772] {scheduler_job.py:155} INFO - Started process (PID=25640) to work on /airflow/dags/download_data.py
[2022-02-17 20:46:29,778] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:46:29,779] {logging_mixin.py:112} INFO - [2022-02-17 20:46:29,779] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:46:30,291] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:46:30,350] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:46:30,363] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:46:30,369] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-17 20:46:43,066] {scheduler_job.py:155} INFO - Started process (PID=25666) to work on /airflow/dags/download_data.py
[2022-02-17 20:46:43,083] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:46:43,086] {logging_mixin.py:112} INFO - [2022-02-17 20:46:43,085] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:46:43,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:46:43,611] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:46:43,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:46:43,622] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 20:46:56,351] {scheduler_job.py:155} INFO - Started process (PID=25692) to work on /airflow/dags/download_data.py
[2022-02-17 20:46:56,356] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:46:56,358] {logging_mixin.py:112} INFO - [2022-02-17 20:46:56,358] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:46:56,905] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:46:56,968] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:46:56,977] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:46:56,981] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-17 20:47:09,689] {scheduler_job.py:155} INFO - Started process (PID=25718) to work on /airflow/dags/download_data.py
[2022-02-17 20:47:09,696] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:47:09,698] {logging_mixin.py:112} INFO - [2022-02-17 20:47:09,698] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:47:10,143] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:47:10,184] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:47:10,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:47:10,198] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 20:47:22,976] {scheduler_job.py:155} INFO - Started process (PID=25744) to work on /airflow/dags/download_data.py
[2022-02-17 20:47:22,982] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:47:22,983] {logging_mixin.py:112} INFO - [2022-02-17 20:47:22,983] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:47:23,473] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:47:23,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:47:23,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:47:23,527] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 20:47:36,265] {scheduler_job.py:155} INFO - Started process (PID=25770) to work on /airflow/dags/download_data.py
[2022-02-17 20:47:36,270] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:47:36,272] {logging_mixin.py:112} INFO - [2022-02-17 20:47:36,271] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:47:36,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:47:36,839] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:47:36,846] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:47:36,852] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 20:47:49,530] {scheduler_job.py:155} INFO - Started process (PID=25796) to work on /airflow/dags/download_data.py
[2022-02-17 20:47:49,534] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:47:49,536] {logging_mixin.py:112} INFO - [2022-02-17 20:47:49,536] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:47:50,026] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:47:50,076] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:47:50,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:47:50,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 20:48:02,854] {scheduler_job.py:155} INFO - Started process (PID=25822) to work on /airflow/dags/download_data.py
[2022-02-17 20:48:02,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:48:02,863] {logging_mixin.py:112} INFO - [2022-02-17 20:48:02,863] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:48:03,323] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:48:03,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:48:03,391] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:48:03,397] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 20:48:16,079] {scheduler_job.py:155} INFO - Started process (PID=25848) to work on /airflow/dags/download_data.py
[2022-02-17 20:48:16,088] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:48:16,091] {logging_mixin.py:112} INFO - [2022-02-17 20:48:16,090] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:48:16,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:48:16,615] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:48:16,629] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:48:16,635] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 20:48:29,386] {scheduler_job.py:155} INFO - Started process (PID=25874) to work on /airflow/dags/download_data.py
[2022-02-17 20:48:29,392] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:48:29,395] {logging_mixin.py:112} INFO - [2022-02-17 20:48:29,395] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:48:29,923] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:48:29,971] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:48:29,979] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:48:29,982] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 20:48:42,745] {scheduler_job.py:155} INFO - Started process (PID=25900) to work on /airflow/dags/download_data.py
[2022-02-17 20:48:42,755] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:48:42,759] {logging_mixin.py:112} INFO - [2022-02-17 20:48:42,758] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:48:43,313] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:48:43,379] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:48:43,393] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:48:43,399] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-17 20:48:56,013] {scheduler_job.py:155} INFO - Started process (PID=25926) to work on /airflow/dags/download_data.py
[2022-02-17 20:48:56,020] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:48:56,022] {logging_mixin.py:112} INFO - [2022-02-17 20:48:56,021] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:48:56,553] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:48:56,614] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:48:56,630] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:48:56,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-17 20:49:09,349] {scheduler_job.py:155} INFO - Started process (PID=25952) to work on /airflow/dags/download_data.py
[2022-02-17 20:49:09,359] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:49:09,361] {logging_mixin.py:112} INFO - [2022-02-17 20:49:09,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:49:09,800] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:49:09,845] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:49:09,860] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:49:09,866] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-17 20:49:22,650] {scheduler_job.py:155} INFO - Started process (PID=25978) to work on /airflow/dags/download_data.py
[2022-02-17 20:49:22,655] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:49:22,656] {logging_mixin.py:112} INFO - [2022-02-17 20:49:22,656] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:49:23,122] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:49:23,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:49:23,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:49:23,204] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 20:49:35,957] {scheduler_job.py:155} INFO - Started process (PID=26004) to work on /airflow/dags/download_data.py
[2022-02-17 20:49:35,962] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:49:35,964] {logging_mixin.py:112} INFO - [2022-02-17 20:49:35,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:49:36,489] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:49:36,534] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:49:36,544] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:49:36,550] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 20:49:49,248] {scheduler_job.py:155} INFO - Started process (PID=26030) to work on /airflow/dags/download_data.py
[2022-02-17 20:49:49,262] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:49:49,264] {logging_mixin.py:112} INFO - [2022-02-17 20:49:49,264] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:49:49,734] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:49:49,786] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:49:49,796] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:49:49,802] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 20:50:02,522] {scheduler_job.py:155} INFO - Started process (PID=26056) to work on /airflow/dags/download_data.py
[2022-02-17 20:50:02,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:50:02,534] {logging_mixin.py:112} INFO - [2022-02-17 20:50:02,534] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:50:03,011] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:50:03,068] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:50:03,079] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:50:03,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 20:50:15,798] {scheduler_job.py:155} INFO - Started process (PID=26082) to work on /airflow/dags/download_data.py
[2022-02-17 20:50:15,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:50:15,807] {logging_mixin.py:112} INFO - [2022-02-17 20:50:15,807] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:50:16,251] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:50:16,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:50:16,309] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:50:16,315] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 20:50:29,192] {scheduler_job.py:155} INFO - Started process (PID=26108) to work on /airflow/dags/download_data.py
[2022-02-17 20:50:29,202] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:50:29,205] {logging_mixin.py:112} INFO - [2022-02-17 20:50:29,205] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:50:29,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:50:29,789] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:50:29,802] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:50:29,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 20:50:42,479] {scheduler_job.py:155} INFO - Started process (PID=26134) to work on /airflow/dags/download_data.py
[2022-02-17 20:50:42,484] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:50:42,486] {logging_mixin.py:112} INFO - [2022-02-17 20:50:42,486] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:50:43,001] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:50:43,060] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:50:43,071] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:50:43,076] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-17 20:50:55,746] {scheduler_job.py:155} INFO - Started process (PID=26160) to work on /airflow/dags/download_data.py
[2022-02-17 20:50:55,753] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:50:55,755] {logging_mixin.py:112} INFO - [2022-02-17 20:50:55,755] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:50:56,255] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:50:56,310] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:50:56,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:50:56,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-17 20:51:09,067] {scheduler_job.py:155} INFO - Started process (PID=26186) to work on /airflow/dags/download_data.py
[2022-02-17 20:51:09,073] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:51:09,074] {logging_mixin.py:112} INFO - [2022-02-17 20:51:09,074] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:51:09,547] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:51:09,585] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:51:09,590] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:51:09,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 20:51:22,348] {scheduler_job.py:155} INFO - Started process (PID=26212) to work on /airflow/dags/download_data.py
[2022-02-17 20:51:22,356] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:51:22,359] {logging_mixin.py:112} INFO - [2022-02-17 20:51:22,359] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:51:22,809] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:51:22,865] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:51:22,873] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:51:22,878] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 20:51:35,725] {scheduler_job.py:155} INFO - Started process (PID=26238) to work on /airflow/dags/download_data.py
[2022-02-17 20:51:35,737] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:51:35,739] {logging_mixin.py:112} INFO - [2022-02-17 20:51:35,739] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:51:36,254] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:51:36,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:51:36,327] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:51:36,334] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-17 20:51:48,991] {scheduler_job.py:155} INFO - Started process (PID=26264) to work on /airflow/dags/download_data.py
[2022-02-17 20:51:48,996] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:51:48,998] {logging_mixin.py:112} INFO - [2022-02-17 20:51:48,997] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:51:49,445] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:51:49,501] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:51:49,510] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:51:49,515] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 20:52:02,301] {scheduler_job.py:155} INFO - Started process (PID=26290) to work on /airflow/dags/download_data.py
[2022-02-17 20:52:02,306] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:52:02,307] {logging_mixin.py:112} INFO - [2022-02-17 20:52:02,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:52:02,770] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:52:02,807] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:52:02,814] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:52:02,818] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 20:52:15,578] {scheduler_job.py:155} INFO - Started process (PID=26316) to work on /airflow/dags/download_data.py
[2022-02-17 20:52:15,583] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:52:15,585] {logging_mixin.py:112} INFO - [2022-02-17 20:52:15,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:52:16,044] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:52:16,105] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:52:16,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:52:16,116] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 20:52:28,922] {scheduler_job.py:155} INFO - Started process (PID=26342) to work on /airflow/dags/download_data.py
[2022-02-17 20:52:28,932] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:52:28,934] {logging_mixin.py:112} INFO - [2022-02-17 20:52:28,934] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:52:29,453] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:52:29,506] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:52:29,518] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:52:29,527] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 20:52:42,244] {scheduler_job.py:155} INFO - Started process (PID=26368) to work on /airflow/dags/download_data.py
[2022-02-17 20:52:42,248] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:52:42,250] {logging_mixin.py:112} INFO - [2022-02-17 20:52:42,250] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:52:42,739] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:52:42,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:52:42,804] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:52:42,816] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 20:52:55,512] {scheduler_job.py:155} INFO - Started process (PID=26394) to work on /airflow/dags/download_data.py
[2022-02-17 20:52:55,520] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:52:55,522] {logging_mixin.py:112} INFO - [2022-02-17 20:52:55,522] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:52:56,041] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:52:56,098] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:52:56,109] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:52:56,115] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-17 20:53:08,839] {scheduler_job.py:155} INFO - Started process (PID=26420) to work on /airflow/dags/download_data.py
[2022-02-17 20:53:08,844] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:53:08,845] {logging_mixin.py:112} INFO - [2022-02-17 20:53:08,845] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:53:09,299] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:53:09,341] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:53:09,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:53:09,361] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 20:53:22,102] {scheduler_job.py:155} INFO - Started process (PID=26446) to work on /airflow/dags/download_data.py
[2022-02-17 20:53:22,108] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:53:22,110] {logging_mixin.py:112} INFO - [2022-02-17 20:53:22,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:53:22,589] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:53:22,633] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:53:22,640] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:53:22,645] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 20:53:35,430] {scheduler_job.py:155} INFO - Started process (PID=26472) to work on /airflow/dags/download_data.py
[2022-02-17 20:53:35,442] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:53:35,451] {logging_mixin.py:112} INFO - [2022-02-17 20:53:35,445] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:53:35,953] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:53:36,010] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:53:36,017] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:53:36,022] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 20:53:48,704] {scheduler_job.py:155} INFO - Started process (PID=26498) to work on /airflow/dags/download_data.py
[2022-02-17 20:53:48,712] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:53:48,717] {logging_mixin.py:112} INFO - [2022-02-17 20:53:48,717] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:53:49,180] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:53:49,221] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:53:49,228] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:53:49,233] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-17 20:54:02,015] {scheduler_job.py:155} INFO - Started process (PID=26524) to work on /airflow/dags/download_data.py
[2022-02-17 20:54:02,026] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:54:02,029] {logging_mixin.py:112} INFO - [2022-02-17 20:54:02,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:54:02,482] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:54:02,532] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:54:02,541] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:54:02,547] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 20:54:15,290] {scheduler_job.py:155} INFO - Started process (PID=26550) to work on /airflow/dags/download_data.py
[2022-02-17 20:54:15,295] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:54:15,297] {logging_mixin.py:112} INFO - [2022-02-17 20:54:15,297] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:54:15,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:54:15,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:54:15,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:54:15,829] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 20:54:28,808] {scheduler_job.py:155} INFO - Started process (PID=26576) to work on /airflow/dags/download_data.py
[2022-02-17 20:54:28,822] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:54:28,824] {logging_mixin.py:112} INFO - [2022-02-17 20:54:28,824] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:54:29,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:54:29,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:54:29,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:54:29,429] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.620 seconds
[2022-02-17 20:54:42,124] {scheduler_job.py:155} INFO - Started process (PID=26602) to work on /airflow/dags/download_data.py
[2022-02-17 20:54:42,129] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:54:42,131] {logging_mixin.py:112} INFO - [2022-02-17 20:54:42,131] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:54:42,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:54:42,681] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:54:42,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:54:42,697] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 20:54:55,427] {scheduler_job.py:155} INFO - Started process (PID=26628) to work on /airflow/dags/download_data.py
[2022-02-17 20:54:55,433] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:54:55,435] {logging_mixin.py:112} INFO - [2022-02-17 20:54:55,435] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:54:55,955] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:54:55,999] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:54:56,008] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:54:56,013] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 20:55:08,762] {scheduler_job.py:155} INFO - Started process (PID=26654) to work on /airflow/dags/download_data.py
[2022-02-17 20:55:08,773] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:55:08,775] {logging_mixin.py:112} INFO - [2022-02-17 20:55:08,775] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:55:09,256] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:55:09,297] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:55:09,306] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:55:09,310] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 20:55:22,072] {scheduler_job.py:155} INFO - Started process (PID=26680) to work on /airflow/dags/download_data.py
[2022-02-17 20:55:22,076] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:55:22,079] {logging_mixin.py:112} INFO - [2022-02-17 20:55:22,079] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:55:22,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:55:22,568] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:55:22,574] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:55:22,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 20:55:35,392] {scheduler_job.py:155} INFO - Started process (PID=26706) to work on /airflow/dags/download_data.py
[2022-02-17 20:55:35,401] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:55:35,404] {logging_mixin.py:112} INFO - [2022-02-17 20:55:35,404] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:55:35,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:55:35,988] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:55:35,997] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:55:36,002] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-17 20:55:48,679] {scheduler_job.py:155} INFO - Started process (PID=26732) to work on /airflow/dags/download_data.py
[2022-02-17 20:55:48,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:55:48,693] {logging_mixin.py:112} INFO - [2022-02-17 20:55:48,692] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:55:49,197] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:55:49,252] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:55:49,262] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:55:49,269] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 20:56:02,015] {scheduler_job.py:155} INFO - Started process (PID=26758) to work on /airflow/dags/download_data.py
[2022-02-17 20:56:02,021] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:56:02,022] {logging_mixin.py:112} INFO - [2022-02-17 20:56:02,022] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:56:02,502] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:56:02,548] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:56:02,560] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:56:02,567] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 20:56:15,842] {scheduler_job.py:155} INFO - Started process (PID=26784) to work on /airflow/dags/download_data.py
[2022-02-17 20:56:15,847] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:56:15,848] {logging_mixin.py:112} INFO - [2022-02-17 20:56:15,848] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:56:16,343] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:56:16,389] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:56:16,400] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:56:16,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 20:56:29,181] {scheduler_job.py:155} INFO - Started process (PID=26810) to work on /airflow/dags/download_data.py
[2022-02-17 20:56:29,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:56:29,191] {logging_mixin.py:112} INFO - [2022-02-17 20:56:29,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:56:29,692] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:56:29,739] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:56:29,747] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:56:29,752] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 20:56:42,478] {scheduler_job.py:155} INFO - Started process (PID=26836) to work on /airflow/dags/download_data.py
[2022-02-17 20:56:42,485] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:56:42,488] {logging_mixin.py:112} INFO - [2022-02-17 20:56:42,487] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:56:42,987] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:56:43,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:56:43,157] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:56:43,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.682 seconds
[2022-02-17 20:56:55,769] {scheduler_job.py:155} INFO - Started process (PID=26862) to work on /airflow/dags/download_data.py
[2022-02-17 20:56:55,778] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:56:55,780] {logging_mixin.py:112} INFO - [2022-02-17 20:56:55,780] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:56:56,263] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:56:56,302] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:56:56,309] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:56:56,313] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 20:57:09,104] {scheduler_job.py:155} INFO - Started process (PID=26888) to work on /airflow/dags/download_data.py
[2022-02-17 20:57:09,108] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:57:09,110] {logging_mixin.py:112} INFO - [2022-02-17 20:57:09,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:57:09,602] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:57:09,660] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:57:09,668] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:57:09,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 20:57:22,403] {scheduler_job.py:155} INFO - Started process (PID=26914) to work on /airflow/dags/download_data.py
[2022-02-17 20:57:22,413] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:57:22,416] {logging_mixin.py:112} INFO - [2022-02-17 20:57:22,416] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:57:22,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:57:22,936] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:57:22,943] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:57:22,953] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 20:57:35,737] {scheduler_job.py:155} INFO - Started process (PID=26940) to work on /airflow/dags/download_data.py
[2022-02-17 20:57:35,744] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:57:35,746] {logging_mixin.py:112} INFO - [2022-02-17 20:57:35,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:57:36,252] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:57:36,290] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:57:36,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:57:36,300] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 20:57:48,982] {scheduler_job.py:155} INFO - Started process (PID=26966) to work on /airflow/dags/download_data.py
[2022-02-17 20:57:48,987] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:57:48,989] {logging_mixin.py:112} INFO - [2022-02-17 20:57:48,989] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:57:49,495] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:57:49,541] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:57:49,548] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:57:49,556] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-17 20:58:02,278] {scheduler_job.py:155} INFO - Started process (PID=26992) to work on /airflow/dags/download_data.py
[2022-02-17 20:58:02,286] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:58:02,288] {logging_mixin.py:112} INFO - [2022-02-17 20:58:02,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:58:02,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:58:02,794] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:58:02,801] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:58:02,806] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 20:58:15,561] {scheduler_job.py:155} INFO - Started process (PID=27018) to work on /airflow/dags/download_data.py
[2022-02-17 20:58:15,572] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:58:15,575] {logging_mixin.py:112} INFO - [2022-02-17 20:58:15,574] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:58:16,056] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:58:16,095] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:58:16,103] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:58:16,108] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 20:58:28,862] {scheduler_job.py:155} INFO - Started process (PID=27044) to work on /airflow/dags/download_data.py
[2022-02-17 20:58:28,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:58:28,877] {logging_mixin.py:112} INFO - [2022-02-17 20:58:28,877] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:58:29,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:58:29,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:58:29,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:58:29,436] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-17 20:58:42,152] {scheduler_job.py:155} INFO - Started process (PID=27070) to work on /airflow/dags/download_data.py
[2022-02-17 20:58:42,160] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:58:42,162] {logging_mixin.py:112} INFO - [2022-02-17 20:58:42,162] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:58:42,672] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:58:42,709] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:58:42,716] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:58:42,721] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 20:58:55,432] {scheduler_job.py:155} INFO - Started process (PID=27096) to work on /airflow/dags/download_data.py
[2022-02-17 20:58:55,439] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:58:55,441] {logging_mixin.py:112} INFO - [2022-02-17 20:58:55,441] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:58:55,937] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:58:55,977] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:58:55,985] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:58:55,989] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 20:59:08,801] {scheduler_job.py:155} INFO - Started process (PID=27122) to work on /airflow/dags/download_data.py
[2022-02-17 20:59:08,808] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:59:08,810] {logging_mixin.py:112} INFO - [2022-02-17 20:59:08,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:59:09,304] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:59:09,360] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:59:09,365] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:59:09,370] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 20:59:22,043] {scheduler_job.py:155} INFO - Started process (PID=27148) to work on /airflow/dags/download_data.py
[2022-02-17 20:59:22,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:59:22,058] {logging_mixin.py:112} INFO - [2022-02-17 20:59:22,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:59:22,500] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:59:22,551] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:59:22,559] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:59:22,563] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-17 20:59:36,533] {scheduler_job.py:155} INFO - Started process (PID=27174) to work on /airflow/dags/download_data.py
[2022-02-17 20:59:36,542] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 20:59:36,546] {logging_mixin.py:112} INFO - [2022-02-17 20:59:36,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 20:59:37,041] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 20:59:37,098] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 20:59:37,109] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 20:59:37,114] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 21:08:25,054] {scheduler_job.py:155} INFO - Started process (PID=27200) to work on /airflow/dags/download_data.py
[2022-02-17 21:08:25,061] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:08:25,063] {logging_mixin.py:112} INFO - [2022-02-17 21:08:25,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:08:25,511] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:08:25,554] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:08:25,564] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:08:25,571] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 21:08:38,328] {scheduler_job.py:155} INFO - Started process (PID=27226) to work on /airflow/dags/download_data.py
[2022-02-17 21:08:38,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:08:38,333] {logging_mixin.py:112} INFO - [2022-02-17 21:08:38,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:08:38,790] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:08:38,845] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:08:38,851] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:08:38,856] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 21:08:51,619] {scheduler_job.py:155} INFO - Started process (PID=27252) to work on /airflow/dags/download_data.py
[2022-02-17 21:08:51,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:08:51,628] {logging_mixin.py:112} INFO - [2022-02-17 21:08:51,627] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:08:52,128] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:08:52,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:08:52,187] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:08:52,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 21:09:05,676] {scheduler_job.py:155} INFO - Started process (PID=27278) to work on /airflow/dags/download_data.py
[2022-02-17 21:09:05,687] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:09:05,689] {logging_mixin.py:112} INFO - [2022-02-17 21:09:05,689] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:09:06,150] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:09:06,203] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:09:06,212] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:09:06,221] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 21:09:18,951] {scheduler_job.py:155} INFO - Started process (PID=27304) to work on /airflow/dags/download_data.py
[2022-02-17 21:09:18,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:09:18,961] {logging_mixin.py:112} INFO - [2022-02-17 21:09:18,961] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:09:19,391] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:09:19,438] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:09:19,448] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:09:19,454] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-17 21:09:32,226] {scheduler_job.py:155} INFO - Started process (PID=27330) to work on /airflow/dags/download_data.py
[2022-02-17 21:09:32,230] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:09:32,232] {logging_mixin.py:112} INFO - [2022-02-17 21:09:32,232] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:09:32,694] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:09:32,745] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:09:32,757] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:09:32,764] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 21:09:45,524] {scheduler_job.py:155} INFO - Started process (PID=27356) to work on /airflow/dags/download_data.py
[2022-02-17 21:09:45,530] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:09:45,532] {logging_mixin.py:112} INFO - [2022-02-17 21:09:45,532] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:09:45,981] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:09:46,031] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:09:46,040] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:09:46,045] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 21:09:59,462] {scheduler_job.py:155} INFO - Started process (PID=27382) to work on /airflow/dags/download_data.py
[2022-02-17 21:09:59,466] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:09:59,468] {logging_mixin.py:112} INFO - [2022-02-17 21:09:59,468] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:09:59,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:09:59,970] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:09:59,980] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:09:59,987] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 21:19:19,232] {scheduler_job.py:155} INFO - Started process (PID=27408) to work on /airflow/dags/download_data.py
[2022-02-17 21:19:19,239] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:19:19,241] {logging_mixin.py:112} INFO - [2022-02-17 21:19:19,241] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:19:19,743] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:19:19,796] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:19:19,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:19:19,811] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-17 21:19:32,582] {scheduler_job.py:155} INFO - Started process (PID=27433) to work on /airflow/dags/download_data.py
[2022-02-17 21:19:32,591] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:19:32,593] {logging_mixin.py:112} INFO - [2022-02-17 21:19:32,593] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:19:33,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:19:33,081] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:19:33,089] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:19:33,094] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 21:19:45,975] {scheduler_job.py:155} INFO - Started process (PID=27458) to work on /airflow/dags/download_data.py
[2022-02-17 21:19:45,990] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:19:45,997] {logging_mixin.py:112} INFO - [2022-02-17 21:19:45,996] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:19:46,703] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:19:46,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:56:05,854] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:56:05,876] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2179.901 seconds
[2022-02-17 21:56:25,709] {scheduler_job.py:155} INFO - Started process (PID=27484) to work on /airflow/dags/download_data.py
[2022-02-17 21:56:25,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:56:25,719] {logging_mixin.py:112} INFO - [2022-02-17 21:56:25,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:56:26,455] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:56:26,519] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:56:26,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:56:26,534] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.825 seconds
[2022-02-17 21:56:39,034] {scheduler_job.py:155} INFO - Started process (PID=27510) to work on /airflow/dags/download_data.py
[2022-02-17 21:56:39,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:56:39,049] {logging_mixin.py:112} INFO - [2022-02-17 21:56:39,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:56:39,569] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:56:39,619] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:56:39,631] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:56:39,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-17 21:56:52,358] {scheduler_job.py:155} INFO - Started process (PID=27536) to work on /airflow/dags/download_data.py
[2022-02-17 21:56:52,368] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:56:52,370] {logging_mixin.py:112} INFO - [2022-02-17 21:56:52,369] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:56:52,929] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:56:52,987] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:56:52,995] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:56:53,003] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-17 21:57:05,663] {scheduler_job.py:155} INFO - Started process (PID=27562) to work on /airflow/dags/download_data.py
[2022-02-17 21:57:05,668] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:57:05,671] {logging_mixin.py:112} INFO - [2022-02-17 21:57:05,670] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:57:06,149] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:57:06,227] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:57:06,235] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:57:06,241] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-17 21:57:18,949] {scheduler_job.py:155} INFO - Started process (PID=27588) to work on /airflow/dags/download_data.py
[2022-02-17 21:57:18,956] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:57:18,959] {logging_mixin.py:112} INFO - [2022-02-17 21:57:18,958] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:57:19,489] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:57:19,539] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:57:19,551] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:57:19,558] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-17 21:57:32,289] {scheduler_job.py:155} INFO - Started process (PID=27614) to work on /airflow/dags/download_data.py
[2022-02-17 21:57:32,293] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:57:32,295] {logging_mixin.py:112} INFO - [2022-02-17 21:57:32,295] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:57:32,759] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:57:32,805] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:57:32,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:57:32,823] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 21:57:45,582] {scheduler_job.py:155} INFO - Started process (PID=27640) to work on /airflow/dags/download_data.py
[2022-02-17 21:57:45,592] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:57:45,596] {logging_mixin.py:112} INFO - [2022-02-17 21:57:45,596] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:57:46,062] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:57:46,112] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:57:46,124] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:57:46,130] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 21:57:58,881] {scheduler_job.py:155} INFO - Started process (PID=27666) to work on /airflow/dags/download_data.py
[2022-02-17 21:57:58,886] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:57:58,887] {logging_mixin.py:112} INFO - [2022-02-17 21:57:58,887] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:57:59,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:57:59,420] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:57:59,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:57:59,432] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 21:58:12,165] {scheduler_job.py:155} INFO - Started process (PID=27692) to work on /airflow/dags/download_data.py
[2022-02-17 21:58:12,169] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:58:12,171] {logging_mixin.py:112} INFO - [2022-02-17 21:58:12,171] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:58:12,618] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:58:12,677] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:58:12,688] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:58:12,693] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 21:58:25,462] {scheduler_job.py:155} INFO - Started process (PID=27718) to work on /airflow/dags/download_data.py
[2022-02-17 21:58:25,476] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:58:25,478] {logging_mixin.py:112} INFO - [2022-02-17 21:58:25,477] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:58:26,018] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:58:26,062] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:58:26,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:58:26,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-17 21:58:38,735] {scheduler_job.py:155} INFO - Started process (PID=27744) to work on /airflow/dags/download_data.py
[2022-02-17 21:58:38,740] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:58:38,742] {logging_mixin.py:112} INFO - [2022-02-17 21:58:38,742] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:58:39,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:58:39,322] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:58:39,335] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:58:39,342] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-17 21:58:52,055] {scheduler_job.py:155} INFO - Started process (PID=27770) to work on /airflow/dags/download_data.py
[2022-02-17 21:58:52,064] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:58:52,067] {logging_mixin.py:112} INFO - [2022-02-17 21:58:52,067] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:58:52,562] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:58:52,621] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:58:52,636] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:58:52,642] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 21:59:05,384] {scheduler_job.py:155} INFO - Started process (PID=27796) to work on /airflow/dags/download_data.py
[2022-02-17 21:59:05,393] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:59:05,396] {logging_mixin.py:112} INFO - [2022-02-17 21:59:05,395] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:59:05,962] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:59:06,029] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:59:06,046] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:59:06,051] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-17 21:59:18,693] {scheduler_job.py:155} INFO - Started process (PID=27822) to work on /airflow/dags/download_data.py
[2022-02-17 21:59:18,699] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:59:18,700] {logging_mixin.py:112} INFO - [2022-02-17 21:59:18,700] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:59:19,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:59:19,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:59:19,325] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:59:19,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.636 seconds
[2022-02-17 21:59:32,016] {scheduler_job.py:155} INFO - Started process (PID=27848) to work on /airflow/dags/download_data.py
[2022-02-17 21:59:32,021] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:59:32,023] {logging_mixin.py:112} INFO - [2022-02-17 21:59:32,023] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:59:32,586] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:59:32,635] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:59:32,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:59:32,651] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-17 21:59:45,306] {scheduler_job.py:155} INFO - Started process (PID=27874) to work on /airflow/dags/download_data.py
[2022-02-17 21:59:45,316] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:59:45,319] {logging_mixin.py:112} INFO - [2022-02-17 21:59:45,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:59:45,838] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:59:45,879] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:59:45,884] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:59:45,889] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 21:59:58,607] {scheduler_job.py:155} INFO - Started process (PID=27900) to work on /airflow/dags/download_data.py
[2022-02-17 21:59:58,618] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 21:59:58,619] {logging_mixin.py:112} INFO - [2022-02-17 21:59:58,619] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 21:59:59,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 21:59:59,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 21:59:59,272] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 21:59:59,278] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-17 22:00:11,906] {scheduler_job.py:155} INFO - Started process (PID=27926) to work on /airflow/dags/download_data.py
[2022-02-17 22:00:11,911] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:00:11,913] {logging_mixin.py:112} INFO - [2022-02-17 22:00:11,912] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:00:12,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:00:12,430] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:00:12,437] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:00:12,442] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 22:00:25,266] {scheduler_job.py:155} INFO - Started process (PID=27952) to work on /airflow/dags/download_data.py
[2022-02-17 22:00:25,275] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:00:25,278] {logging_mixin.py:112} INFO - [2022-02-17 22:00:25,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:00:25,792] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:00:25,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:00:25,863] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:00:25,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-17 22:00:38,524] {scheduler_job.py:155} INFO - Started process (PID=27978) to work on /airflow/dags/download_data.py
[2022-02-17 22:00:38,529] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:00:38,531] {logging_mixin.py:112} INFO - [2022-02-17 22:00:38,531] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:00:39,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:00:39,077] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:00:39,087] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:00:39,093] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 22:00:51,813] {scheduler_job.py:155} INFO - Started process (PID=28004) to work on /airflow/dags/download_data.py
[2022-02-17 22:00:51,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:00:51,820] {logging_mixin.py:112} INFO - [2022-02-17 22:00:51,820] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:00:52,405] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:00:52,457] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:00:52,467] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:00:52,475] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.663 seconds
[2022-02-17 22:01:05,131] {scheduler_job.py:155} INFO - Started process (PID=28030) to work on /airflow/dags/download_data.py
[2022-02-17 22:01:05,149] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:01:05,156] {logging_mixin.py:112} INFO - [2022-02-17 22:01:05,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:01:05,680] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:01:05,735] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:01:05,745] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:01:05,750] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.620 seconds
[2022-02-17 22:01:18,481] {scheduler_job.py:155} INFO - Started process (PID=28056) to work on /airflow/dags/download_data.py
[2022-02-17 22:01:18,489] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:01:18,491] {logging_mixin.py:112} INFO - [2022-02-17 22:01:18,491] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:01:19,146] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:01:19,210] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:01:19,220] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:01:19,226] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.745 seconds
[2022-02-17 22:01:31,847] {scheduler_job.py:155} INFO - Started process (PID=28082) to work on /airflow/dags/download_data.py
[2022-02-17 22:01:31,857] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:01:31,859] {logging_mixin.py:112} INFO - [2022-02-17 22:01:31,859] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:01:32,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:01:32,446] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:01:32,455] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:01:32,462] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-17 22:01:45,130] {scheduler_job.py:155} INFO - Started process (PID=28108) to work on /airflow/dags/download_data.py
[2022-02-17 22:01:45,142] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:01:45,144] {logging_mixin.py:112} INFO - [2022-02-17 22:01:45,144] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:01:45,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:01:45,654] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:01:45,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:01:45,669] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 22:01:58,417] {scheduler_job.py:155} INFO - Started process (PID=28134) to work on /airflow/dags/download_data.py
[2022-02-17 22:01:58,427] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:01:58,429] {logging_mixin.py:112} INFO - [2022-02-17 22:01:58,429] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:01:58,868] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:01:58,918] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:01:58,927] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:01:58,932] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 22:02:11,643] {scheduler_job.py:155} INFO - Started process (PID=28160) to work on /airflow/dags/download_data.py
[2022-02-17 22:02:11,647] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:02:11,649] {logging_mixin.py:112} INFO - [2022-02-17 22:02:11,649] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:02:12,102] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:02:12,161] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:02:12,174] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:02:12,179] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 22:02:24,995] {scheduler_job.py:155} INFO - Started process (PID=28186) to work on /airflow/dags/download_data.py
[2022-02-17 22:02:25,002] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:02:25,005] {logging_mixin.py:112} INFO - [2022-02-17 22:02:25,004] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:02:25,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:02:25,584] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:02:25,595] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:02:25,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-17 22:02:38,275] {scheduler_job.py:155} INFO - Started process (PID=28212) to work on /airflow/dags/download_data.py
[2022-02-17 22:02:38,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:02:38,290] {logging_mixin.py:112} INFO - [2022-02-17 22:02:38,290] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:02:38,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:02:38,817] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:02:38,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:02:38,828] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 22:02:51,615] {scheduler_job.py:155} INFO - Started process (PID=28238) to work on /airflow/dags/download_data.py
[2022-02-17 22:02:51,622] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:02:51,624] {logging_mixin.py:112} INFO - [2022-02-17 22:02:51,624] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:02:52,141] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:02:52,200] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:02:52,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:02:52,219] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-17 22:03:04,956] {scheduler_job.py:155} INFO - Started process (PID=28264) to work on /airflow/dags/download_data.py
[2022-02-17 22:03:04,963] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:03:04,965] {logging_mixin.py:112} INFO - [2022-02-17 22:03:04,965] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:03:05,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:03:05,520] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:03:05,531] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:03:05,537] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 22:03:18,246] {scheduler_job.py:155} INFO - Started process (PID=28290) to work on /airflow/dags/download_data.py
[2022-02-17 22:03:18,251] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:03:18,253] {logging_mixin.py:112} INFO - [2022-02-17 22:03:18,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:03:18,869] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:03:18,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:03:18,945] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:03:18,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.704 seconds
[2022-02-17 22:03:31,599] {scheduler_job.py:155} INFO - Started process (PID=28316) to work on /airflow/dags/download_data.py
[2022-02-17 22:03:31,607] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:03:31,609] {logging_mixin.py:112} INFO - [2022-02-17 22:03:31,609] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:03:32,076] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:03:32,134] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:03:32,142] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:03:32,149] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 22:03:44,873] {scheduler_job.py:155} INFO - Started process (PID=28342) to work on /airflow/dags/download_data.py
[2022-02-17 22:03:44,880] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:03:44,883] {logging_mixin.py:112} INFO - [2022-02-17 22:03:44,882] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:03:45,364] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:03:45,415] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:03:45,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:03:45,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-17 22:03:58,228] {scheduler_job.py:155} INFO - Started process (PID=28368) to work on /airflow/dags/download_data.py
[2022-02-17 22:03:58,236] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:03:58,238] {logging_mixin.py:112} INFO - [2022-02-17 22:03:58,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:03:58,752] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:03:58,809] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:03:58,818] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:03:58,824] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 22:04:11,468] {scheduler_job.py:155} INFO - Started process (PID=28394) to work on /airflow/dags/download_data.py
[2022-02-17 22:04:11,472] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:04:11,474] {logging_mixin.py:112} INFO - [2022-02-17 22:04:11,474] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:04:11,983] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:04:12,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:04:12,036] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:04:12,043] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-17 22:04:24,797] {scheduler_job.py:155} INFO - Started process (PID=28420) to work on /airflow/dags/download_data.py
[2022-02-17 22:04:24,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:04:24,806] {logging_mixin.py:112} INFO - [2022-02-17 22:04:24,806] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:04:25,379] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:04:25,453] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:04:25,469] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:04:25,474] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-17 22:04:38,087] {scheduler_job.py:155} INFO - Started process (PID=28446) to work on /airflow/dags/download_data.py
[2022-02-17 22:04:38,094] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:04:38,096] {logging_mixin.py:112} INFO - [2022-02-17 22:04:38,096] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:04:38,689] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:04:38,747] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:04:38,756] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:04:38,764] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-17 22:04:51,455] {scheduler_job.py:155} INFO - Started process (PID=28472) to work on /airflow/dags/download_data.py
[2022-02-17 22:04:51,461] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:04:51,463] {logging_mixin.py:112} INFO - [2022-02-17 22:04:51,462] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:04:52,117] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:04:52,179] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:04:52,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:04:52,193] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.738 seconds
[2022-02-17 22:05:04,773] {scheduler_job.py:155} INFO - Started process (PID=28498) to work on /airflow/dags/download_data.py
[2022-02-17 22:05:04,779] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:05:04,782] {logging_mixin.py:112} INFO - [2022-02-17 22:05:04,781] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:05:05,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:05:05,584] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:05:05,594] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:05:05,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.827 seconds
[2022-02-17 22:05:18,084] {scheduler_job.py:155} INFO - Started process (PID=28524) to work on /airflow/dags/download_data.py
[2022-02-17 22:05:18,093] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:05:18,096] {logging_mixin.py:112} INFO - [2022-02-17 22:05:18,095] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:05:18,719] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:05:18,782] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:05:18,790] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:05:18,794] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.711 seconds
[2022-02-17 22:05:31,415] {scheduler_job.py:155} INFO - Started process (PID=28550) to work on /airflow/dags/download_data.py
[2022-02-17 22:05:31,420] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:05:31,422] {logging_mixin.py:112} INFO - [2022-02-17 22:05:31,422] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:05:31,937] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:05:31,984] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:05:31,997] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:05:32,003] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-17 22:05:44,718] {scheduler_job.py:155} INFO - Started process (PID=28576) to work on /airflow/dags/download_data.py
[2022-02-17 22:05:44,733] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:05:44,736] {logging_mixin.py:112} INFO - [2022-02-17 22:05:44,736] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:05:45,265] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:05:45,312] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:05:45,320] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:05:45,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-17 22:05:58,009] {scheduler_job.py:155} INFO - Started process (PID=28602) to work on /airflow/dags/download_data.py
[2022-02-17 22:05:58,015] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:05:58,017] {logging_mixin.py:112} INFO - [2022-02-17 22:05:58,016] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:05:58,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:05:58,568] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:05:58,574] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:05:58,580] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 22:06:11,347] {scheduler_job.py:155} INFO - Started process (PID=28628) to work on /airflow/dags/download_data.py
[2022-02-17 22:06:11,356] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:06:11,360] {logging_mixin.py:112} INFO - [2022-02-17 22:06:11,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:06:11,835] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:06:11,892] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:06:11,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:06:11,906] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 22:06:24,694] {scheduler_job.py:155} INFO - Started process (PID=28654) to work on /airflow/dags/download_data.py
[2022-02-17 22:06:24,706] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:06:24,709] {logging_mixin.py:112} INFO - [2022-02-17 22:06:24,708] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:06:25,295] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:06:25,348] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:06:25,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:06:25,359] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-17 22:06:37,967] {scheduler_job.py:155} INFO - Started process (PID=28680) to work on /airflow/dags/download_data.py
[2022-02-17 22:06:37,977] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:06:37,979] {logging_mixin.py:112} INFO - [2022-02-17 22:06:37,978] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:06:38,497] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:06:38,562] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:06:38,574] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:06:38,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-17 22:06:51,308] {scheduler_job.py:155} INFO - Started process (PID=28706) to work on /airflow/dags/download_data.py
[2022-02-17 22:06:51,315] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:06:51,316] {logging_mixin.py:112} INFO - [2022-02-17 22:06:51,316] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:06:51,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:06:51,873] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:06:51,884] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:06:51,892] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 22:07:04,751] {scheduler_job.py:155} INFO - Started process (PID=28732) to work on /airflow/dags/download_data.py
[2022-02-17 22:07:04,783] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:07:04,790] {logging_mixin.py:112} INFO - [2022-02-17 22:07:04,790] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:07:05,303] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:07:05,365] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:07:05,379] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:07:05,386] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-17 22:07:18,003] {scheduler_job.py:155} INFO - Started process (PID=28758) to work on /airflow/dags/download_data.py
[2022-02-17 22:07:18,014] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:07:18,018] {logging_mixin.py:112} INFO - [2022-02-17 22:07:18,017] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:07:18,585] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:07:18,637] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:07:18,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:07:18,650] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.647 seconds
[2022-02-17 22:07:31,358] {scheduler_job.py:155} INFO - Started process (PID=28784) to work on /airflow/dags/download_data.py
[2022-02-17 22:07:31,364] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:07:31,366] {logging_mixin.py:112} INFO - [2022-02-17 22:07:31,365] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:07:31,856] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:07:31,917] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:07:31,926] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:07:31,931] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 22:07:44,606] {scheduler_job.py:155} INFO - Started process (PID=28810) to work on /airflow/dags/download_data.py
[2022-02-17 22:07:44,611] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:07:44,613] {logging_mixin.py:112} INFO - [2022-02-17 22:07:44,612] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:07:45,062] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:07:45,110] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:07:45,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:07:45,122] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 22:07:57,947] {scheduler_job.py:155} INFO - Started process (PID=28836) to work on /airflow/dags/download_data.py
[2022-02-17 22:07:57,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:07:57,956] {logging_mixin.py:112} INFO - [2022-02-17 22:07:57,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:07:58,464] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:07:58,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:07:58,523] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:07:58,528] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 22:08:11,223] {scheduler_job.py:155} INFO - Started process (PID=28862) to work on /airflow/dags/download_data.py
[2022-02-17 22:08:11,228] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:08:11,230] {logging_mixin.py:112} INFO - [2022-02-17 22:08:11,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:08:11,763] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:08:11,822] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:08:11,831] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:08:11,836] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-17 22:08:24,563] {scheduler_job.py:155} INFO - Started process (PID=28888) to work on /airflow/dags/download_data.py
[2022-02-17 22:08:24,574] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:08:24,576] {logging_mixin.py:112} INFO - [2022-02-17 22:08:24,575] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:08:25,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:08:25,179] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:08:25,190] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:08:25,194] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-17 22:08:37,870] {scheduler_job.py:155} INFO - Started process (PID=28914) to work on /airflow/dags/download_data.py
[2022-02-17 22:08:37,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:08:37,876] {logging_mixin.py:112} INFO - [2022-02-17 22:08:37,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:08:38,388] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:08:38,440] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:08:38,450] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:08:38,456] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 22:08:51,192] {scheduler_job.py:155} INFO - Started process (PID=28940) to work on /airflow/dags/download_data.py
[2022-02-17 22:08:51,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:08:51,201] {logging_mixin.py:112} INFO - [2022-02-17 22:08:51,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:08:51,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:08:51,824] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:08:51,834] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:08:51,840] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-17 22:09:04,514] {scheduler_job.py:155} INFO - Started process (PID=28966) to work on /airflow/dags/download_data.py
[2022-02-17 22:09:04,519] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:09:04,521] {logging_mixin.py:112} INFO - [2022-02-17 22:09:04,520] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:09:05,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:09:05,142] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:09:05,150] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:09:05,154] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-17 22:09:17,780] {scheduler_job.py:155} INFO - Started process (PID=28992) to work on /airflow/dags/download_data.py
[2022-02-17 22:09:17,785] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:09:17,786] {logging_mixin.py:112} INFO - [2022-02-17 22:09:17,786] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:09:18,244] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:09:18,290] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:09:18,297] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:09:18,302] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-17 22:09:31,112] {scheduler_job.py:155} INFO - Started process (PID=29018) to work on /airflow/dags/download_data.py
[2022-02-17 22:09:31,117] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:09:31,119] {logging_mixin.py:112} INFO - [2022-02-17 22:09:31,119] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:09:31,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:09:31,715] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:09:31,726] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:09:31,733] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-17 22:09:44,359] {scheduler_job.py:155} INFO - Started process (PID=29044) to work on /airflow/dags/download_data.py
[2022-02-17 22:09:44,364] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:09:44,365] {logging_mixin.py:112} INFO - [2022-02-17 22:09:44,365] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:09:44,876] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:09:44,925] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:09:44,931] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:09:44,937] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-17 22:09:57,699] {scheduler_job.py:155} INFO - Started process (PID=29070) to work on /airflow/dags/download_data.py
[2022-02-17 22:09:57,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:09:57,709] {logging_mixin.py:112} INFO - [2022-02-17 22:09:57,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:09:58,182] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:09:58,229] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:09:58,238] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:09:58,243] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-17 22:10:11,010] {scheduler_job.py:155} INFO - Started process (PID=29096) to work on /airflow/dags/download_data.py
[2022-02-17 22:10:11,017] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:10:11,019] {logging_mixin.py:112} INFO - [2022-02-17 22:10:11,018] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:10:11,478] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:10:11,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:10:11,550] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:10:11,556] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 22:10:24,328] {scheduler_job.py:155} INFO - Started process (PID=29122) to work on /airflow/dags/download_data.py
[2022-02-17 22:10:24,337] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:10:24,339] {logging_mixin.py:112} INFO - [2022-02-17 22:10:24,339] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:10:24,889] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:10:24,954] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:10:24,965] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:10:24,975] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.647 seconds
[2022-02-17 22:10:37,639] {scheduler_job.py:155} INFO - Started process (PID=29148) to work on /airflow/dags/download_data.py
[2022-02-17 22:10:37,643] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:10:37,645] {logging_mixin.py:112} INFO - [2022-02-17 22:10:37,644] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:10:38,129] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:10:38,174] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:10:38,181] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:10:38,188] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 22:10:50,959] {scheduler_job.py:155} INFO - Started process (PID=29174) to work on /airflow/dags/download_data.py
[2022-02-17 22:10:50,964] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:10:50,966] {logging_mixin.py:112} INFO - [2022-02-17 22:10:50,966] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:10:51,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:10:51,575] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:10:51,588] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:10:51,593] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.634 seconds
[2022-02-17 22:11:04,282] {scheduler_job.py:155} INFO - Started process (PID=29200) to work on /airflow/dags/download_data.py
[2022-02-17 22:11:04,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:11:04,289] {logging_mixin.py:112} INFO - [2022-02-17 22:11:04,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:11:04,960] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:11:04,978] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:11:04,985] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:11:04,992] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.710 seconds
[2022-02-17 22:11:17,580] {scheduler_job.py:155} INFO - Started process (PID=29226) to work on /airflow/dags/download_data.py
[2022-02-17 22:11:17,591] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:11:17,608] {logging_mixin.py:112} INFO - [2022-02-17 22:11:17,607] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:11:18,118] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:11:18,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:11:18,175] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:11:18,179] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 22:11:30,908] {scheduler_job.py:155} INFO - Started process (PID=29252) to work on /airflow/dags/download_data.py
[2022-02-17 22:11:30,927] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:11:30,929] {logging_mixin.py:112} INFO - [2022-02-17 22:11:30,929] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:11:31,517] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:11:31,580] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:11:31,587] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:11:31,595] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.687 seconds
[2022-02-17 22:11:44,200] {scheduler_job.py:155} INFO - Started process (PID=29278) to work on /airflow/dags/download_data.py
[2022-02-17 22:11:44,211] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:11:44,214] {logging_mixin.py:112} INFO - [2022-02-17 22:11:44,214] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:11:44,733] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:11:44,785] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:11:44,792] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:11:44,796] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 22:11:57,493] {scheduler_job.py:155} INFO - Started process (PID=29304) to work on /airflow/dags/download_data.py
[2022-02-17 22:11:57,499] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:11:57,501] {logging_mixin.py:112} INFO - [2022-02-17 22:11:57,501] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:11:58,017] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:11:58,082] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:11:58,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:11:58,098] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 22:12:10,783] {scheduler_job.py:155} INFO - Started process (PID=29330) to work on /airflow/dags/download_data.py
[2022-02-17 22:12:10,788] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:12:10,790] {logging_mixin.py:112} INFO - [2022-02-17 22:12:10,790] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:12:11,273] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:12:11,335] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:12:11,344] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:12:11,350] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 22:12:24,077] {scheduler_job.py:155} INFO - Started process (PID=29356) to work on /airflow/dags/download_data.py
[2022-02-17 22:12:24,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:12:24,084] {logging_mixin.py:112} INFO - [2022-02-17 22:12:24,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:12:24,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:12:24,728] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:12:24,740] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:12:24,747] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.670 seconds
[2022-02-17 22:12:37,405] {scheduler_job.py:155} INFO - Started process (PID=29382) to work on /airflow/dags/download_data.py
[2022-02-17 22:12:37,410] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:12:37,412] {logging_mixin.py:112} INFO - [2022-02-17 22:12:37,412] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:12:37,909] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:12:37,964] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:12:37,970] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:12:37,973] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 22:12:50,676] {scheduler_job.py:155} INFO - Started process (PID=29408) to work on /airflow/dags/download_data.py
[2022-02-17 22:12:50,684] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:12:50,687] {logging_mixin.py:112} INFO - [2022-02-17 22:12:50,686] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:12:51,227] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:12:51,280] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:12:51,287] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:12:51,292] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 22:13:03,976] {scheduler_job.py:155} INFO - Started process (PID=29434) to work on /airflow/dags/download_data.py
[2022-02-17 22:13:03,987] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:13:03,989] {logging_mixin.py:112} INFO - [2022-02-17 22:13:03,989] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:13:04,442] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:13:04,497] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:13:04,507] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:13:04,514] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 22:13:17,235] {scheduler_job.py:155} INFO - Started process (PID=29460) to work on /airflow/dags/download_data.py
[2022-02-17 22:13:17,245] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:13:17,248] {logging_mixin.py:112} INFO - [2022-02-17 22:13:17,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:13:17,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:13:17,812] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:13:17,823] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:13:17,828] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 22:13:30,552] {scheduler_job.py:155} INFO - Started process (PID=29486) to work on /airflow/dags/download_data.py
[2022-02-17 22:13:30,558] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:13:30,560] {logging_mixin.py:112} INFO - [2022-02-17 22:13:30,559] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:13:31,154] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:13:31,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:13:31,205] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:13:31,209] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-17 22:13:43,807] {scheduler_job.py:155} INFO - Started process (PID=29512) to work on /airflow/dags/download_data.py
[2022-02-17 22:13:43,816] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:13:43,822] {logging_mixin.py:112} INFO - [2022-02-17 22:13:43,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:13:44,276] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:13:44,342] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:13:44,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:13:44,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 22:13:57,101] {scheduler_job.py:155} INFO - Started process (PID=29538) to work on /airflow/dags/download_data.py
[2022-02-17 22:13:57,107] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:13:57,108] {logging_mixin.py:112} INFO - [2022-02-17 22:13:57,108] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:13:57,598] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:13:57,651] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:13:57,658] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:13:57,664] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 22:14:10,422] {scheduler_job.py:155} INFO - Started process (PID=29564) to work on /airflow/dags/download_data.py
[2022-02-17 22:14:10,429] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:14:10,432] {logging_mixin.py:112} INFO - [2022-02-17 22:14:10,431] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:14:10,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:14:10,928] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:14:10,934] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:14:10,938] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 22:14:23,714] {scheduler_job.py:155} INFO - Started process (PID=29590) to work on /airflow/dags/download_data.py
[2022-02-17 22:14:23,720] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:14:23,721] {logging_mixin.py:112} INFO - [2022-02-17 22:14:23,721] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:14:24,273] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:14:24,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:14:24,327] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:14:24,331] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 22:14:37,028] {scheduler_job.py:155} INFO - Started process (PID=29616) to work on /airflow/dags/download_data.py
[2022-02-17 22:14:37,036] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:14:37,038] {logging_mixin.py:112} INFO - [2022-02-17 22:14:37,038] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:14:37,489] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:14:37,533] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:14:37,540] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:14:37,543] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-17 22:14:50,331] {scheduler_job.py:155} INFO - Started process (PID=29642) to work on /airflow/dags/download_data.py
[2022-02-17 22:14:50,337] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:14:50,339] {logging_mixin.py:112} INFO - [2022-02-17 22:14:50,338] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:14:50,904] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:14:50,955] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:14:50,968] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:14:50,976] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-17 22:15:03,655] {scheduler_job.py:155} INFO - Started process (PID=29668) to work on /airflow/dags/download_data.py
[2022-02-17 22:15:03,660] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:15:03,662] {logging_mixin.py:112} INFO - [2022-02-17 22:15:03,662] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:15:04,130] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:15:04,187] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:15:04,197] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:15:04,202] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 22:15:16,926] {scheduler_job.py:155} INFO - Started process (PID=29694) to work on /airflow/dags/download_data.py
[2022-02-17 22:15:16,932] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:15:16,934] {logging_mixin.py:112} INFO - [2022-02-17 22:15:16,934] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:15:17,393] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:15:17,427] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:15:17,433] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:15:17,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-17 22:15:30,232] {scheduler_job.py:155} INFO - Started process (PID=29720) to work on /airflow/dags/download_data.py
[2022-02-17 22:15:30,239] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:15:30,241] {logging_mixin.py:112} INFO - [2022-02-17 22:15:30,240] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:15:30,782] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:15:30,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:15:30,853] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:15:30,857] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-17 22:15:43,515] {scheduler_job.py:155} INFO - Started process (PID=29746) to work on /airflow/dags/download_data.py
[2022-02-17 22:15:43,522] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:15:43,524] {logging_mixin.py:112} INFO - [2022-02-17 22:15:43,524] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:15:44,006] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:15:44,061] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:15:44,075] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:15:44,082] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 22:15:56,821] {scheduler_job.py:155} INFO - Started process (PID=29772) to work on /airflow/dags/download_data.py
[2022-02-17 22:15:56,827] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:15:56,829] {logging_mixin.py:112} INFO - [2022-02-17 22:15:56,829] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:15:57,312] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:15:57,372] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:15:57,385] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:15:57,391] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 22:16:10,129] {scheduler_job.py:155} INFO - Started process (PID=29798) to work on /airflow/dags/download_data.py
[2022-02-17 22:16:10,135] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:16:10,137] {logging_mixin.py:112} INFO - [2022-02-17 22:16:10,136] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:16:10,624] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:16:10,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:16:10,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:16:10,695] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 22:16:23,436] {scheduler_job.py:155} INFO - Started process (PID=29824) to work on /airflow/dags/download_data.py
[2022-02-17 22:16:23,442] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:16:23,443] {logging_mixin.py:112} INFO - [2022-02-17 22:16:23,443] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:16:23,987] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:16:24,050] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:16:24,064] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:16:24,069] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-17 22:16:36,748] {scheduler_job.py:155} INFO - Started process (PID=29850) to work on /airflow/dags/download_data.py
[2022-02-17 22:16:36,753] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:16:36,755] {logging_mixin.py:112} INFO - [2022-02-17 22:16:36,755] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:16:37,234] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:16:37,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:16:37,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:16:37,292] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 22:16:50,090] {scheduler_job.py:155} INFO - Started process (PID=29876) to work on /airflow/dags/download_data.py
[2022-02-17 22:16:50,101] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:16:50,104] {logging_mixin.py:112} INFO - [2022-02-17 22:16:50,103] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:16:50,634] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:16:50,696] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:16:50,709] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:16:50,717] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.627 seconds
[2022-02-17 22:17:03,373] {scheduler_job.py:155} INFO - Started process (PID=29902) to work on /airflow/dags/download_data.py
[2022-02-17 22:17:03,378] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:17:03,380] {logging_mixin.py:112} INFO - [2022-02-17 22:17:03,379] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:17:03,873] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:17:03,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:17:03,935] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:17:03,939] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 22:17:16,651] {scheduler_job.py:155} INFO - Started process (PID=29928) to work on /airflow/dags/download_data.py
[2022-02-17 22:17:16,656] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:17:16,658] {logging_mixin.py:112} INFO - [2022-02-17 22:17:16,658] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:17:17,128] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:17:17,187] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:17:17,198] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:17:17,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 22:17:29,996] {scheduler_job.py:155} INFO - Started process (PID=29954) to work on /airflow/dags/download_data.py
[2022-02-17 22:17:30,005] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:17:30,007] {logging_mixin.py:112} INFO - [2022-02-17 22:17:30,007] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:17:30,574] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:17:30,616] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:17:30,629] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:17:30,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-17 22:17:43,267] {scheduler_job.py:155} INFO - Started process (PID=29980) to work on /airflow/dags/download_data.py
[2022-02-17 22:17:43,272] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:17:43,275] {logging_mixin.py:112} INFO - [2022-02-17 22:17:43,274] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:17:43,751] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:17:43,797] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:17:43,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:17:43,809] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 22:17:56,584] {scheduler_job.py:155} INFO - Started process (PID=30006) to work on /airflow/dags/download_data.py
[2022-02-17 22:17:56,590] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:17:56,592] {logging_mixin.py:112} INFO - [2022-02-17 22:17:56,592] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:17:57,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:17:57,113] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:17:57,120] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:17:57,127] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 22:18:09,913] {scheduler_job.py:155} INFO - Started process (PID=30032) to work on /airflow/dags/download_data.py
[2022-02-17 22:18:09,921] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:18:09,923] {logging_mixin.py:112} INFO - [2022-02-17 22:18:09,923] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:18:10,380] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:18:10,451] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:18:10,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:18:10,467] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 22:18:23,227] {scheduler_job.py:155} INFO - Started process (PID=30058) to work on /airflow/dags/download_data.py
[2022-02-17 22:18:23,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:18:23,238] {logging_mixin.py:112} INFO - [2022-02-17 22:18:23,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:18:23,811] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:18:23,871] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:18:23,880] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:18:23,888] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.661 seconds
[2022-02-17 22:18:36,482] {scheduler_job.py:155} INFO - Started process (PID=30084) to work on /airflow/dags/download_data.py
[2022-02-17 22:18:36,488] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:18:36,490] {logging_mixin.py:112} INFO - [2022-02-17 22:18:36,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:18:36,951] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:18:37,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:18:37,022] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:18:37,026] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 22:18:49,788] {scheduler_job.py:155} INFO - Started process (PID=30110) to work on /airflow/dags/download_data.py
[2022-02-17 22:18:49,793] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:18:49,795] {logging_mixin.py:112} INFO - [2022-02-17 22:18:49,795] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:18:50,316] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:18:50,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:18:50,389] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:18:50,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-17 22:19:03,118] {scheduler_job.py:155} INFO - Started process (PID=30136) to work on /airflow/dags/download_data.py
[2022-02-17 22:19:03,122] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:19:03,124] {logging_mixin.py:112} INFO - [2022-02-17 22:19:03,124] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:19:03,612] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:19:03,664] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:19:03,676] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:19:03,681] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 22:19:16,396] {scheduler_job.py:155} INFO - Started process (PID=30162) to work on /airflow/dags/download_data.py
[2022-02-17 22:19:16,403] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:19:16,405] {logging_mixin.py:112} INFO - [2022-02-17 22:19:16,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:19:16,861] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:19:16,921] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:19:16,934] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:19:16,939] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 22:19:29,703] {scheduler_job.py:155} INFO - Started process (PID=30188) to work on /airflow/dags/download_data.py
[2022-02-17 22:19:29,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:19:29,719] {logging_mixin.py:112} INFO - [2022-02-17 22:19:29,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:19:30,258] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:19:30,318] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:19:30,329] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:19:30,335] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-17 22:19:42,992] {scheduler_job.py:155} INFO - Started process (PID=30214) to work on /airflow/dags/download_data.py
[2022-02-17 22:19:43,001] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:19:43,005] {logging_mixin.py:112} INFO - [2022-02-17 22:19:43,004] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:19:43,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:19:43,585] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:19:43,592] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:19:43,597] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 22:19:56,284] {scheduler_job.py:155} INFO - Started process (PID=30240) to work on /airflow/dags/download_data.py
[2022-02-17 22:19:56,290] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:19:56,292] {logging_mixin.py:112} INFO - [2022-02-17 22:19:56,292] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:19:56,765] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:19:56,811] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:19:56,818] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:19:56,825] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 22:20:09,587] {scheduler_job.py:155} INFO - Started process (PID=30266) to work on /airflow/dags/download_data.py
[2022-02-17 22:20:09,593] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:20:09,595] {logging_mixin.py:112} INFO - [2022-02-17 22:20:09,595] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:20:10,056] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:20:10,102] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:20:10,108] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:20:10,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 22:20:22,881] {scheduler_job.py:155} INFO - Started process (PID=30292) to work on /airflow/dags/download_data.py
[2022-02-17 22:20:22,887] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:20:22,889] {logging_mixin.py:112} INFO - [2022-02-17 22:20:22,889] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:20:23,416] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:20:23,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:20:23,473] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:20:23,476] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 22:20:36,147] {scheduler_job.py:155} INFO - Started process (PID=30318) to work on /airflow/dags/download_data.py
[2022-02-17 22:20:36,154] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:20:36,156] {logging_mixin.py:112} INFO - [2022-02-17 22:20:36,155] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:20:36,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:20:36,694] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:20:36,707] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:20:36,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 22:20:49,468] {scheduler_job.py:155} INFO - Started process (PID=30344) to work on /airflow/dags/download_data.py
[2022-02-17 22:20:49,476] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:20:49,478] {logging_mixin.py:112} INFO - [2022-02-17 22:20:49,478] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:20:50,024] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:20:50,077] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:20:50,088] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:20:50,092] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-17 22:21:02,768] {scheduler_job.py:155} INFO - Started process (PID=30370) to work on /airflow/dags/download_data.py
[2022-02-17 22:21:02,780] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:21:02,782] {logging_mixin.py:112} INFO - [2022-02-17 22:21:02,782] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:21:03,254] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:21:03,307] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:21:03,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:21:03,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 22:21:16,117] {scheduler_job.py:155} INFO - Started process (PID=30396) to work on /airflow/dags/download_data.py
[2022-02-17 22:21:16,123] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:21:16,126] {logging_mixin.py:112} INFO - [2022-02-17 22:21:16,125] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:21:16,626] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:21:16,674] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:21:16,680] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:21:16,683] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 22:21:29,441] {scheduler_job.py:155} INFO - Started process (PID=30422) to work on /airflow/dags/download_data.py
[2022-02-17 22:21:29,449] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:21:29,451] {logging_mixin.py:112} INFO - [2022-02-17 22:21:29,451] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:21:29,989] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:21:30,048] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:21:30,059] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:21:30,065] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-17 22:21:42,727] {scheduler_job.py:155} INFO - Started process (PID=30448) to work on /airflow/dags/download_data.py
[2022-02-17 22:21:42,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:21:42,734] {logging_mixin.py:112} INFO - [2022-02-17 22:21:42,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:21:43,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:21:43,257] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:21:43,264] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:21:43,270] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-17 22:21:56,035] {scheduler_job.py:155} INFO - Started process (PID=30474) to work on /airflow/dags/download_data.py
[2022-02-17 22:21:56,043] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:21:56,044] {logging_mixin.py:112} INFO - [2022-02-17 22:21:56,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:21:56,634] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:21:56,682] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:21:56,694] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:21:56,699] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.664 seconds
[2022-02-17 22:22:09,281] {scheduler_job.py:155} INFO - Started process (PID=30500) to work on /airflow/dags/download_data.py
[2022-02-17 22:22:09,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:22:09,289] {logging_mixin.py:112} INFO - [2022-02-17 22:22:09,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:22:09,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:22:09,774] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:22:09,781] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:22:09,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 22:22:22,573] {scheduler_job.py:155} INFO - Started process (PID=30526) to work on /airflow/dags/download_data.py
[2022-02-17 22:22:22,582] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:22:22,584] {logging_mixin.py:112} INFO - [2022-02-17 22:22:22,583] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:22:23,061] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:22:23,105] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:22:23,116] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:22:23,120] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 22:22:35,834] {scheduler_job.py:155} INFO - Started process (PID=30552) to work on /airflow/dags/download_data.py
[2022-02-17 22:22:35,840] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:22:35,841] {logging_mixin.py:112} INFO - [2022-02-17 22:22:35,841] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:22:36,327] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:22:36,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:22:36,393] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:22:36,399] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-17 22:22:49,140] {scheduler_job.py:155} INFO - Started process (PID=30578) to work on /airflow/dags/download_data.py
[2022-02-17 22:22:49,145] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:22:49,146] {logging_mixin.py:112} INFO - [2022-02-17 22:22:49,146] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:22:49,629] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:22:49,674] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:22:49,683] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:22:49,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 22:23:02,433] {scheduler_job.py:155} INFO - Started process (PID=30604) to work on /airflow/dags/download_data.py
[2022-02-17 22:23:02,438] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:23:02,440] {logging_mixin.py:112} INFO - [2022-02-17 22:23:02,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:23:02,887] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:23:02,928] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:23:02,937] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:23:02,943] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 22:23:15,710] {scheduler_job.py:155} INFO - Started process (PID=30630) to work on /airflow/dags/download_data.py
[2022-02-17 22:23:15,715] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:23:15,721] {logging_mixin.py:112} INFO - [2022-02-17 22:23:15,720] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:23:16,166] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:23:16,216] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:23:16,222] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:23:16,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-17 22:23:29,031] {scheduler_job.py:155} INFO - Started process (PID=30656) to work on /airflow/dags/download_data.py
[2022-02-17 22:23:29,039] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:23:29,042] {logging_mixin.py:112} INFO - [2022-02-17 22:23:29,041] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:23:29,481] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:23:29,527] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:23:29,534] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:23:29,540] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-17 22:23:42,297] {scheduler_job.py:155} INFO - Started process (PID=30682) to work on /airflow/dags/download_data.py
[2022-02-17 22:23:42,302] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:23:42,304] {logging_mixin.py:112} INFO - [2022-02-17 22:23:42,304] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:23:42,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:23:42,798] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:23:42,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:23:42,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 22:23:55,593] {scheduler_job.py:155} INFO - Started process (PID=30708) to work on /airflow/dags/download_data.py
[2022-02-17 22:23:55,599] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:23:55,602] {logging_mixin.py:112} INFO - [2022-02-17 22:23:55,601] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:23:56,041] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:23:56,093] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:23:56,100] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:23:56,106] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 22:24:08,908] {scheduler_job.py:155} INFO - Started process (PID=30734) to work on /airflow/dags/download_data.py
[2022-02-17 22:24:08,916] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:24:08,918] {logging_mixin.py:112} INFO - [2022-02-17 22:24:08,917] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:24:09,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:24:09,401] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:24:09,410] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:24:09,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-17 22:24:22,221] {scheduler_job.py:155} INFO - Started process (PID=30760) to work on /airflow/dags/download_data.py
[2022-02-17 22:24:22,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:24:22,229] {logging_mixin.py:112} INFO - [2022-02-17 22:24:22,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:24:22,679] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:24:22,711] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:24:22,720] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:24:22,724] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 22:24:35,453] {scheduler_job.py:155} INFO - Started process (PID=30786) to work on /airflow/dags/download_data.py
[2022-02-17 22:24:35,460] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:24:35,462] {logging_mixin.py:112} INFO - [2022-02-17 22:24:35,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:24:35,970] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:24:36,024] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:24:36,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:24:36,038] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 22:24:48,776] {scheduler_job.py:155} INFO - Started process (PID=30812) to work on /airflow/dags/download_data.py
[2022-02-17 22:24:48,782] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:24:48,783] {logging_mixin.py:112} INFO - [2022-02-17 22:24:48,783] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:24:49,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:24:49,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:24:49,286] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:24:49,292] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-17 22:25:02,095] {scheduler_job.py:155} INFO - Started process (PID=30838) to work on /airflow/dags/download_data.py
[2022-02-17 22:25:02,100] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:25:02,101] {logging_mixin.py:112} INFO - [2022-02-17 22:25:02,101] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:25:02,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:25:02,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:25:02,587] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:25:02,595] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-17 22:25:15,344] {scheduler_job.py:155} INFO - Started process (PID=30864) to work on /airflow/dags/download_data.py
[2022-02-17 22:25:15,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:25:15,350] {logging_mixin.py:112} INFO - [2022-02-17 22:25:15,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:25:15,783] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:25:15,823] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:25:15,829] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:25:15,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-17 22:25:28,672] {scheduler_job.py:155} INFO - Started process (PID=30890) to work on /airflow/dags/download_data.py
[2022-02-17 22:25:28,678] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:25:28,680] {logging_mixin.py:112} INFO - [2022-02-17 22:25:28,680] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:25:29,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:25:29,186] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:25:29,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:25:29,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-17 22:25:41,940] {scheduler_job.py:155} INFO - Started process (PID=30916) to work on /airflow/dags/download_data.py
[2022-02-17 22:25:41,949] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:25:41,951] {logging_mixin.py:112} INFO - [2022-02-17 22:25:41,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:25:42,404] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:25:42,450] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:25:42,456] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:25:42,461] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-17 22:25:55,220] {scheduler_job.py:155} INFO - Started process (PID=30942) to work on /airflow/dags/download_data.py
[2022-02-17 22:25:55,231] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:25:55,233] {logging_mixin.py:112} INFO - [2022-02-17 22:25:55,232] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:25:55,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:25:55,707] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:25:55,718] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:25:55,724] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-17 22:26:08,494] {scheduler_job.py:155} INFO - Started process (PID=30968) to work on /airflow/dags/download_data.py
[2022-02-17 22:26:08,502] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:26:08,503] {logging_mixin.py:112} INFO - [2022-02-17 22:26:08,503] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:26:08,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:26:08,994] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:26:09,002] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:26:09,007] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-17 22:26:23,114] {scheduler_job.py:155} INFO - Started process (PID=30994) to work on /airflow/dags/download_data.py
[2022-02-17 22:26:23,119] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:26:23,121] {logging_mixin.py:112} INFO - [2022-02-17 22:26:23,120] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:26:26,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:26:28,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:26:29,234] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:26:29,369] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 6.243 seconds
[2022-02-17 22:33:27,122] {scheduler_job.py:155} INFO - Started process (PID=31020) to work on /airflow/dags/download_data.py
[2022-02-17 22:33:27,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:33:27,134] {logging_mixin.py:112} INFO - [2022-02-17 22:33:27,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:33:27,589] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:33:27,640] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:33:27,650] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:33:27,654] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 22:33:39,408] {scheduler_job.py:155} INFO - Started process (PID=31045) to work on /airflow/dags/download_data.py
[2022-02-17 22:33:39,415] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:33:39,417] {logging_mixin.py:112} INFO - [2022-02-17 22:33:39,417] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:33:39,883] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:33:39,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:33:39,930] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:33:39,936] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 22:33:53,921] {scheduler_job.py:155} INFO - Started process (PID=31071) to work on /airflow/dags/download_data.py
[2022-02-17 22:33:53,925] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:33:53,927] {logging_mixin.py:112} INFO - [2022-02-17 22:33:53,926] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:33:54,372] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:33:54,417] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:33:54,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:33:54,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-17 22:34:13,092] {scheduler_job.py:155} INFO - Started process (PID=31097) to work on /airflow/dags/download_data.py
[2022-02-17 22:34:13,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:34:13,101] {logging_mixin.py:112} INFO - [2022-02-17 22:34:13,101] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:34:13,633] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:34:13,698] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:34:13,708] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:34:13,714] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-17 22:38:00,564] {scheduler_job.py:155} INFO - Started process (PID=31123) to work on /airflow/dags/download_data.py
[2022-02-17 22:38:00,573] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:38:00,589] {logging_mixin.py:112} INFO - [2022-02-17 22:38:00,588] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:38:01,047] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:38:01,102] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:38:01,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:38:01,127] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-17 22:38:13,878] {scheduler_job.py:155} INFO - Started process (PID=31149) to work on /airflow/dags/download_data.py
[2022-02-17 22:38:13,884] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 22:38:13,886] {logging_mixin.py:112} INFO - [2022-02-17 22:38:13,886] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 22:38:14,329] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 22:38:14,377] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 22:38:14,385] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 22:38:14,390] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-17 23:15:51,517] {scheduler_job.py:155} INFO - Started process (PID=31175) to work on /airflow/dags/download_data.py
[2022-02-17 23:15:51,530] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:15:51,532] {logging_mixin.py:112} INFO - [2022-02-17 23:15:51,532] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:15:52,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:15:52,075] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:15:52,083] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:15:52,088] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 23:16:11,808] {scheduler_job.py:155} INFO - Started process (PID=31201) to work on /airflow/dags/download_data.py
[2022-02-17 23:16:11,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:16:11,820] {logging_mixin.py:112} INFO - [2022-02-17 23:16:11,820] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:16:12,303] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:16:12,347] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:16:12,358] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:16:12,364] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 23:16:25,131] {scheduler_job.py:155} INFO - Started process (PID=31227) to work on /airflow/dags/download_data.py
[2022-02-17 23:16:25,138] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:16:25,141] {logging_mixin.py:112} INFO - [2022-02-17 23:16:25,141] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:16:25,635] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:16:25,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:16:25,682] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:16:25,686] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 23:16:38,443] {scheduler_job.py:155} INFO - Started process (PID=31253) to work on /airflow/dags/download_data.py
[2022-02-17 23:16:38,450] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:16:38,451] {logging_mixin.py:112} INFO - [2022-02-17 23:16:38,451] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:16:38,968] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:16:39,017] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:16:39,027] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:16:39,032] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 23:16:51,734] {scheduler_job.py:155} INFO - Started process (PID=31279) to work on /airflow/dags/download_data.py
[2022-02-17 23:16:51,745] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:16:51,748] {logging_mixin.py:112} INFO - [2022-02-17 23:16:51,747] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:16:52,292] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:16:52,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:16:52,358] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:16:52,364] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-17 23:17:05,026] {scheduler_job.py:155} INFO - Started process (PID=31305) to work on /airflow/dags/download_data.py
[2022-02-17 23:17:05,032] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:17:05,033] {logging_mixin.py:112} INFO - [2022-02-17 23:17:05,033] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:17:05,635] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:17:05,683] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:17:05,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:17:05,872] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.847 seconds
[2022-02-17 23:17:18,345] {scheduler_job.py:155} INFO - Started process (PID=31331) to work on /airflow/dags/download_data.py
[2022-02-17 23:17:18,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:17:18,360] {logging_mixin.py:112} INFO - [2022-02-17 23:17:18,359] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:17:19,104] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:17:19,206] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:17:19,214] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:17:19,229] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.884 seconds
[2022-02-17 23:17:31,698] {scheduler_job.py:155} INFO - Started process (PID=31357) to work on /airflow/dags/download_data.py
[2022-02-17 23:17:31,702] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:17:31,709] {logging_mixin.py:112} INFO - [2022-02-17 23:17:31,704] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:17:32,169] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:17:32,220] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:17:32,230] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:17:32,235] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 23:17:44,980] {scheduler_job.py:155} INFO - Started process (PID=31383) to work on /airflow/dags/download_data.py
[2022-02-17 23:17:44,989] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:17:44,991] {logging_mixin.py:112} INFO - [2022-02-17 23:17:44,991] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:17:45,680] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:17:45,722] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:17:45,731] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:17:45,737] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.757 seconds
[2022-02-17 23:17:58,292] {scheduler_job.py:155} INFO - Started process (PID=31409) to work on /airflow/dags/download_data.py
[2022-02-17 23:17:58,305] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:17:58,307] {logging_mixin.py:112} INFO - [2022-02-17 23:17:58,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:17:58,841] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:17:58,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:17:58,904] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:17:58,911] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 23:18:11,638] {scheduler_job.py:155} INFO - Started process (PID=31435) to work on /airflow/dags/download_data.py
[2022-02-17 23:18:11,647] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:18:11,650] {logging_mixin.py:112} INFO - [2022-02-17 23:18:11,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:18:12,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:18:12,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:18:12,287] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:18:12,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.655 seconds
[2022-02-17 23:18:24,920] {scheduler_job.py:155} INFO - Started process (PID=31461) to work on /airflow/dags/download_data.py
[2022-02-17 23:18:24,925] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:18:24,926] {logging_mixin.py:112} INFO - [2022-02-17 23:18:24,926] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:18:25,444] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:18:25,491] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:18:25,498] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:18:25,503] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 23:18:38,259] {scheduler_job.py:155} INFO - Started process (PID=31487) to work on /airflow/dags/download_data.py
[2022-02-17 23:18:38,267] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:18:38,269] {logging_mixin.py:112} INFO - [2022-02-17 23:18:38,268] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:18:38,808] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:18:38,863] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:18:38,872] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:18:38,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 23:18:51,566] {scheduler_job.py:155} INFO - Started process (PID=31513) to work on /airflow/dags/download_data.py
[2022-02-17 23:18:51,574] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:18:51,576] {logging_mixin.py:112} INFO - [2022-02-17 23:18:51,576] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:18:52,072] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:18:52,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:18:52,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:18:52,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 23:19:04,869] {scheduler_job.py:155} INFO - Started process (PID=31539) to work on /airflow/dags/download_data.py
[2022-02-17 23:19:04,873] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:19:04,876] {logging_mixin.py:112} INFO - [2022-02-17 23:19:04,875] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:19:05,445] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:19:05,508] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:19:05,521] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:19:05,529] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.661 seconds
[2022-02-17 23:19:18,184] {scheduler_job.py:155} INFO - Started process (PID=31565) to work on /airflow/dags/download_data.py
[2022-02-17 23:19:18,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:19:18,195] {logging_mixin.py:112} INFO - [2022-02-17 23:19:18,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:19:18,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:19:18,711] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:19:18,719] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:19:18,725] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-17 23:19:31,533] {scheduler_job.py:155} INFO - Started process (PID=31591) to work on /airflow/dags/download_data.py
[2022-02-17 23:19:31,543] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:19:31,545] {logging_mixin.py:112} INFO - [2022-02-17 23:19:31,545] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:19:32,011] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:19:32,066] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:19:32,075] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:19:32,079] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 23:19:44,799] {scheduler_job.py:155} INFO - Started process (PID=31617) to work on /airflow/dags/download_data.py
[2022-02-17 23:19:44,804] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:19:44,806] {logging_mixin.py:112} INFO - [2022-02-17 23:19:44,806] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:19:45,287] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:19:45,332] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:19:45,340] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:19:45,344] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 23:19:58,126] {scheduler_job.py:155} INFO - Started process (PID=31643) to work on /airflow/dags/download_data.py
[2022-02-17 23:19:58,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:19:58,134] {logging_mixin.py:112} INFO - [2022-02-17 23:19:58,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:19:58,675] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:19:58,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:19:58,753] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:19:58,759] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-17 23:20:11,474] {scheduler_job.py:155} INFO - Started process (PID=31669) to work on /airflow/dags/download_data.py
[2022-02-17 23:20:11,489] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:20:11,491] {logging_mixin.py:112} INFO - [2022-02-17 23:20:11,491] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:20:12,045] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:20:12,101] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:20:12,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:20:12,116] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-17 23:20:24,768] {scheduler_job.py:155} INFO - Started process (PID=31695) to work on /airflow/dags/download_data.py
[2022-02-17 23:20:24,772] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:20:24,774] {logging_mixin.py:112} INFO - [2022-02-17 23:20:24,774] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:20:25,292] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:20:25,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:20:25,358] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:20:25,363] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 23:20:38,113] {scheduler_job.py:155} INFO - Started process (PID=31721) to work on /airflow/dags/download_data.py
[2022-02-17 23:20:38,118] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:20:38,121] {logging_mixin.py:112} INFO - [2022-02-17 23:20:38,120] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:20:38,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:20:38,691] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:20:38,699] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:20:38,704] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 23:20:51,441] {scheduler_job.py:155} INFO - Started process (PID=31747) to work on /airflow/dags/download_data.py
[2022-02-17 23:20:51,446] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:20:51,448] {logging_mixin.py:112} INFO - [2022-02-17 23:20:51,448] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:20:51,967] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:20:52,010] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:20:52,017] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:20:52,021] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 23:21:04,748] {scheduler_job.py:155} INFO - Started process (PID=31773) to work on /airflow/dags/download_data.py
[2022-02-17 23:21:04,757] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:21:04,759] {logging_mixin.py:112} INFO - [2022-02-17 23:21:04,759] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:21:05,273] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:21:05,334] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:21:05,342] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:21:05,347] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-17 23:21:17,998] {scheduler_job.py:155} INFO - Started process (PID=31799) to work on /airflow/dags/download_data.py
[2022-02-17 23:21:18,002] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:21:18,003] {logging_mixin.py:112} INFO - [2022-02-17 23:21:18,003] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:21:18,473] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:21:18,523] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:21:18,530] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:21:18,534] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 23:21:31,344] {scheduler_job.py:155} INFO - Started process (PID=31825) to work on /airflow/dags/download_data.py
[2022-02-17 23:21:31,353] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:21:31,357] {logging_mixin.py:112} INFO - [2022-02-17 23:21:31,356] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:21:31,860] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:21:31,917] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:21:31,924] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:21:31,929] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 23:21:44,653] {scheduler_job.py:155} INFO - Started process (PID=31851) to work on /airflow/dags/download_data.py
[2022-02-17 23:21:44,662] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:21:44,664] {logging_mixin.py:112} INFO - [2022-02-17 23:21:44,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:21:45,162] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:21:45,217] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:21:45,225] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:21:45,231] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 23:21:57,964] {scheduler_job.py:155} INFO - Started process (PID=31877) to work on /airflow/dags/download_data.py
[2022-02-17 23:21:57,974] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:21:57,978] {logging_mixin.py:112} INFO - [2022-02-17 23:21:57,978] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:21:58,553] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:21:58,621] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:21:58,628] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:21:58,633] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.669 seconds
[2022-02-17 23:22:11,272] {scheduler_job.py:155} INFO - Started process (PID=31903) to work on /airflow/dags/download_data.py
[2022-02-17 23:22:11,277] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:22:11,280] {logging_mixin.py:112} INFO - [2022-02-17 23:22:11,279] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:22:11,852] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:22:11,911] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:22:11,921] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:22:11,927] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-17 23:22:24,621] {scheduler_job.py:155} INFO - Started process (PID=31929) to work on /airflow/dags/download_data.py
[2022-02-17 23:22:24,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:22:24,628] {logging_mixin.py:112} INFO - [2022-02-17 23:22:24,628] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:22:25,128] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:22:25,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:22:25,195] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:22:25,202] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 23:22:37,930] {scheduler_job.py:155} INFO - Started process (PID=31955) to work on /airflow/dags/download_data.py
[2022-02-17 23:22:37,938] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:22:37,940] {logging_mixin.py:112} INFO - [2022-02-17 23:22:37,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:22:38,408] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:22:38,467] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:22:38,479] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:22:38,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-17 23:22:51,205] {scheduler_job.py:155} INFO - Started process (PID=31981) to work on /airflow/dags/download_data.py
[2022-02-17 23:22:51,210] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:22:51,212] {logging_mixin.py:112} INFO - [2022-02-17 23:22:51,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:22:51,691] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:22:51,744] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:22:51,753] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:22:51,756] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 23:23:04,549] {scheduler_job.py:155} INFO - Started process (PID=32007) to work on /airflow/dags/download_data.py
[2022-02-17 23:23:04,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:23:04,563] {logging_mixin.py:112} INFO - [2022-02-17 23:23:04,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:23:05,159] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:23:05,228] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:23:05,237] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:23:05,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.697 seconds
[2022-02-17 23:23:17,826] {scheduler_job.py:155} INFO - Started process (PID=32033) to work on /airflow/dags/download_data.py
[2022-02-17 23:23:17,833] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:23:17,835] {logging_mixin.py:112} INFO - [2022-02-17 23:23:17,835] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:23:18,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:23:18,419] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:23:18,426] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:23:18,430] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-17 23:23:31,143] {scheduler_job.py:155} INFO - Started process (PID=32059) to work on /airflow/dags/download_data.py
[2022-02-17 23:23:31,154] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:23:31,157] {logging_mixin.py:112} INFO - [2022-02-17 23:23:31,156] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:23:31,705] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:23:31,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:23:31,757] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:23:31,761] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 23:23:44,405] {scheduler_job.py:155} INFO - Started process (PID=32085) to work on /airflow/dags/download_data.py
[2022-02-17 23:23:44,410] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:23:44,412] {logging_mixin.py:112} INFO - [2022-02-17 23:23:44,412] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:23:44,958] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:23:45,006] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:23:45,014] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:23:45,018] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-17 23:23:57,725] {scheduler_job.py:155} INFO - Started process (PID=32111) to work on /airflow/dags/download_data.py
[2022-02-17 23:23:57,730] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:23:57,732] {logging_mixin.py:112} INFO - [2022-02-17 23:23:57,732] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:23:58,292] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:23:58,342] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:23:58,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:23:58,360] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.636 seconds
[2022-02-17 23:24:11,043] {scheduler_job.py:155} INFO - Started process (PID=32137) to work on /airflow/dags/download_data.py
[2022-02-17 23:24:11,048] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:24:11,050] {logging_mixin.py:112} INFO - [2022-02-17 23:24:11,050] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:24:11,635] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:24:11,681] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:24:11,689] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:24:11,693] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.651 seconds
[2022-02-17 23:24:24,333] {scheduler_job.py:155} INFO - Started process (PID=32163) to work on /airflow/dags/download_data.py
[2022-02-17 23:24:24,340] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:24:24,342] {logging_mixin.py:112} INFO - [2022-02-17 23:24:24,341] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:24:24,881] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:24:24,937] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:24:24,946] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:24:24,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-17 23:24:37,649] {scheduler_job.py:155} INFO - Started process (PID=32189) to work on /airflow/dags/download_data.py
[2022-02-17 23:24:37,654] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:24:37,655] {logging_mixin.py:112} INFO - [2022-02-17 23:24:37,655] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:24:38,152] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:24:38,207] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:24:38,216] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:24:38,221] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 23:24:50,900] {scheduler_job.py:155} INFO - Started process (PID=32215) to work on /airflow/dags/download_data.py
[2022-02-17 23:24:50,905] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:24:50,907] {logging_mixin.py:112} INFO - [2022-02-17 23:24:50,906] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:24:51,431] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:24:51,488] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:24:51,496] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:24:51,502] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-17 23:25:04,261] {scheduler_job.py:155} INFO - Started process (PID=32241) to work on /airflow/dags/download_data.py
[2022-02-17 23:25:04,272] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:25:04,276] {logging_mixin.py:112} INFO - [2022-02-17 23:25:04,276] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:25:04,821] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:25:04,889] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:25:04,897] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:25:04,903] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-17 23:25:17,539] {scheduler_job.py:155} INFO - Started process (PID=32267) to work on /airflow/dags/download_data.py
[2022-02-17 23:25:17,543] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:25:17,545] {logging_mixin.py:112} INFO - [2022-02-17 23:25:17,545] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:25:18,004] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:25:18,067] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:25:18,078] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:25:18,084] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-17 23:25:30,852] {scheduler_job.py:155} INFO - Started process (PID=32293) to work on /airflow/dags/download_data.py
[2022-02-17 23:25:30,857] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:25:30,858] {logging_mixin.py:112} INFO - [2022-02-17 23:25:30,858] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:25:31,315] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:25:31,378] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:25:31,388] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:25:31,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 23:25:44,149] {scheduler_job.py:155} INFO - Started process (PID=32319) to work on /airflow/dags/download_data.py
[2022-02-17 23:25:44,157] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:25:44,159] {logging_mixin.py:112} INFO - [2022-02-17 23:25:44,158] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:25:44,625] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:25:44,692] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:25:44,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:25:44,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 23:25:57,452] {scheduler_job.py:155} INFO - Started process (PID=32345) to work on /airflow/dags/download_data.py
[2022-02-17 23:25:57,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:25:57,464] {logging_mixin.py:112} INFO - [2022-02-17 23:25:57,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:25:57,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:25:58,030] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:25:58,044] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:25:58,055] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 23:26:10,787] {scheduler_job.py:155} INFO - Started process (PID=32371) to work on /airflow/dags/download_data.py
[2022-02-17 23:26:10,799] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:26:10,802] {logging_mixin.py:112} INFO - [2022-02-17 23:26:10,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:26:11,372] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:26:11,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:26:11,435] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:26:11,439] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.652 seconds
[2022-02-17 23:26:24,028] {scheduler_job.py:155} INFO - Started process (PID=32397) to work on /airflow/dags/download_data.py
[2022-02-17 23:26:24,034] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:26:24,036] {logging_mixin.py:112} INFO - [2022-02-17 23:26:24,036] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:26:24,546] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:26:24,609] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:26:24,623] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:26:24,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-17 23:26:37,394] {scheduler_job.py:155} INFO - Started process (PID=32423) to work on /airflow/dags/download_data.py
[2022-02-17 23:26:37,403] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:26:37,406] {logging_mixin.py:112} INFO - [2022-02-17 23:26:37,406] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:26:37,894] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:26:37,949] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:26:37,956] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:26:37,961] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 23:26:50,708] {scheduler_job.py:155} INFO - Started process (PID=32449) to work on /airflow/dags/download_data.py
[2022-02-17 23:26:50,717] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:26:50,720] {logging_mixin.py:112} INFO - [2022-02-17 23:26:50,719] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:26:51,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:26:51,273] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:26:51,286] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:26:51,290] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-17 23:27:04,016] {scheduler_job.py:155} INFO - Started process (PID=32475) to work on /airflow/dags/download_data.py
[2022-02-17 23:27:04,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:27:04,025] {logging_mixin.py:112} INFO - [2022-02-17 23:27:04,024] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:27:04,618] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:27:04,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:27:04,686] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:27:04,692] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.676 seconds
[2022-02-17 23:27:17,311] {scheduler_job.py:155} INFO - Started process (PID=32501) to work on /airflow/dags/download_data.py
[2022-02-17 23:27:17,318] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:27:17,319] {logging_mixin.py:112} INFO - [2022-02-17 23:27:17,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:27:17,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:27:17,887] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:27:17,900] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:27:17,905] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 23:27:30,659] {scheduler_job.py:155} INFO - Started process (PID=32527) to work on /airflow/dags/download_data.py
[2022-02-17 23:27:30,666] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:27:30,668] {logging_mixin.py:112} INFO - [2022-02-17 23:27:30,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:27:31,191] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:27:31,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:27:31,262] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:27:31,271] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-17 23:27:43,927] {scheduler_job.py:155} INFO - Started process (PID=32553) to work on /airflow/dags/download_data.py
[2022-02-17 23:27:43,936] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:27:43,939] {logging_mixin.py:112} INFO - [2022-02-17 23:27:43,938] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:27:44,495] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:27:44,551] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:27:44,566] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:27:44,574] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.646 seconds
[2022-02-17 23:27:57,243] {scheduler_job.py:155} INFO - Started process (PID=32579) to work on /airflow/dags/download_data.py
[2022-02-17 23:27:57,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:27:57,255] {logging_mixin.py:112} INFO - [2022-02-17 23:27:57,255] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:27:57,844] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:27:57,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:27:57,911] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:27:57,921] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-17 23:28:10,605] {scheduler_job.py:155} INFO - Started process (PID=32605) to work on /airflow/dags/download_data.py
[2022-02-17 23:28:10,619] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:28:10,621] {logging_mixin.py:112} INFO - [2022-02-17 23:28:10,621] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:28:11,212] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:28:11,269] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:28:11,278] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:28:11,290] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.685 seconds
[2022-02-17 23:28:23,897] {scheduler_job.py:155} INFO - Started process (PID=32631) to work on /airflow/dags/download_data.py
[2022-02-17 23:28:23,902] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:28:23,904] {logging_mixin.py:112} INFO - [2022-02-17 23:28:23,904] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:28:24,423] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:28:24,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:28:24,483] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:28:24,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 23:28:37,238] {scheduler_job.py:155} INFO - Started process (PID=32657) to work on /airflow/dags/download_data.py
[2022-02-17 23:28:37,245] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:28:37,248] {logging_mixin.py:112} INFO - [2022-02-17 23:28:37,247] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:28:37,764] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:28:37,813] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:28:37,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:28:37,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 23:28:50,519] {scheduler_job.py:155} INFO - Started process (PID=32683) to work on /airflow/dags/download_data.py
[2022-02-17 23:28:50,533] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:28:50,535] {logging_mixin.py:112} INFO - [2022-02-17 23:28:50,535] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:28:51,038] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:28:51,094] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:28:51,102] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:28:51,106] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 23:29:03,854] {scheduler_job.py:155} INFO - Started process (PID=32709) to work on /airflow/dags/download_data.py
[2022-02-17 23:29:03,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:29:03,870] {logging_mixin.py:112} INFO - [2022-02-17 23:29:03,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:29:04,473] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:29:04,526] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:29:04,538] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:29:04,544] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.690 seconds
[2022-02-17 23:29:17,181] {scheduler_job.py:155} INFO - Started process (PID=32735) to work on /airflow/dags/download_data.py
[2022-02-17 23:29:17,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:29:17,194] {logging_mixin.py:112} INFO - [2022-02-17 23:29:17,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:29:17,698] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:29:17,751] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:29:17,762] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:29:17,771] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-17 23:29:30,494] {scheduler_job.py:155} INFO - Started process (PID=32761) to work on /airflow/dags/download_data.py
[2022-02-17 23:29:30,502] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:29:30,505] {logging_mixin.py:112} INFO - [2022-02-17 23:29:30,505] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:29:31,024] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:29:31,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:29:31,072] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:29:31,078] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 23:29:43,780] {scheduler_job.py:155} INFO - Started process (PID=32787) to work on /airflow/dags/download_data.py
[2022-02-17 23:29:43,795] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:29:43,798] {logging_mixin.py:112} INFO - [2022-02-17 23:29:43,798] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:29:44,304] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:29:44,367] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:29:44,377] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:29:44,382] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-17 23:29:57,088] {scheduler_job.py:155} INFO - Started process (PID=32813) to work on /airflow/dags/download_data.py
[2022-02-17 23:29:57,096] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:29:57,098] {logging_mixin.py:112} INFO - [2022-02-17 23:29:57,098] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:29:57,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:29:57,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:29:57,768] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:29:57,775] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.686 seconds
[2022-02-17 23:30:10,411] {scheduler_job.py:155} INFO - Started process (PID=32839) to work on /airflow/dags/download_data.py
[2022-02-17 23:30:10,417] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:30:10,419] {logging_mixin.py:112} INFO - [2022-02-17 23:30:10,419] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:30:10,997] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:30:11,063] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:30:11,076] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:30:11,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.670 seconds
[2022-02-17 23:30:23,728] {scheduler_job.py:155} INFO - Started process (PID=32865) to work on /airflow/dags/download_data.py
[2022-02-17 23:30:23,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:30:23,745] {logging_mixin.py:112} INFO - [2022-02-17 23:30:23,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:30:24,215] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:30:24,271] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:30:24,283] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:30:24,289] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 23:30:37,062] {scheduler_job.py:155} INFO - Started process (PID=32891) to work on /airflow/dags/download_data.py
[2022-02-17 23:30:37,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:30:37,071] {logging_mixin.py:112} INFO - [2022-02-17 23:30:37,070] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:30:37,590] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:30:37,659] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:30:37,674] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:30:37,678] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-17 23:30:50,385] {scheduler_job.py:155} INFO - Started process (PID=32917) to work on /airflow/dags/download_data.py
[2022-02-17 23:30:50,391] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:30:50,393] {logging_mixin.py:112} INFO - [2022-02-17 23:30:50,392] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:30:50,916] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:30:50,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:30:50,983] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:30:50,989] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-17 23:31:03,719] {scheduler_job.py:155} INFO - Started process (PID=32943) to work on /airflow/dags/download_data.py
[2022-02-17 23:31:03,729] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:31:03,732] {logging_mixin.py:112} INFO - [2022-02-17 23:31:03,731] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:31:04,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:31:04,358] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:31:04,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:31:04,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.656 seconds
[2022-02-17 23:31:17,008] {scheduler_job.py:155} INFO - Started process (PID=32969) to work on /airflow/dags/download_data.py
[2022-02-17 23:31:17,014] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:31:17,017] {logging_mixin.py:112} INFO - [2022-02-17 23:31:17,016] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:31:17,536] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:31:17,594] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:31:17,608] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:31:17,618] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-17 23:31:30,314] {scheduler_job.py:155} INFO - Started process (PID=32995) to work on /airflow/dags/download_data.py
[2022-02-17 23:31:30,319] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:31:30,321] {logging_mixin.py:112} INFO - [2022-02-17 23:31:30,320] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:31:30,843] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:31:30,896] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:31:30,902] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:31:30,906] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 23:31:43,661] {scheduler_job.py:155} INFO - Started process (PID=33021) to work on /airflow/dags/download_data.py
[2022-02-17 23:31:43,670] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:31:43,674] {logging_mixin.py:112} INFO - [2022-02-17 23:31:43,674] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:31:44,187] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:31:44,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:31:44,246] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:31:44,249] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-17 23:31:57,002] {scheduler_job.py:155} INFO - Started process (PID=33047) to work on /airflow/dags/download_data.py
[2022-02-17 23:31:57,013] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:31:57,016] {logging_mixin.py:112} INFO - [2022-02-17 23:31:57,015] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:31:57,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:31:57,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:31:57,694] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:31:57,702] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.700 seconds
[2022-02-17 23:32:10,325] {scheduler_job.py:155} INFO - Started process (PID=33073) to work on /airflow/dags/download_data.py
[2022-02-17 23:32:10,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:32:10,334] {logging_mixin.py:112} INFO - [2022-02-17 23:32:10,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:32:10,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:32:10,994] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:32:11,008] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:32:11,015] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.690 seconds
[2022-02-17 23:32:23,588] {scheduler_job.py:155} INFO - Started process (PID=33099) to work on /airflow/dags/download_data.py
[2022-02-17 23:32:23,592] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:32:23,595] {logging_mixin.py:112} INFO - [2022-02-17 23:32:23,594] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:32:24,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:32:24,176] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:32:24,186] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:32:24,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 23:32:36,910] {scheduler_job.py:155} INFO - Started process (PID=33125) to work on /airflow/dags/download_data.py
[2022-02-17 23:32:36,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:32:36,919] {logging_mixin.py:112} INFO - [2022-02-17 23:32:36,919] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:32:37,430] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:32:37,488] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:32:37,496] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:32:37,504] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 23:32:50,226] {scheduler_job.py:155} INFO - Started process (PID=33151) to work on /airflow/dags/download_data.py
[2022-02-17 23:32:50,237] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:32:50,240] {logging_mixin.py:112} INFO - [2022-02-17 23:32:50,239] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:32:50,754] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:32:50,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:32:50,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:32:50,812] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-17 23:33:03,517] {scheduler_job.py:155} INFO - Started process (PID=33177) to work on /airflow/dags/download_data.py
[2022-02-17 23:33:03,522] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:33:03,524] {logging_mixin.py:112} INFO - [2022-02-17 23:33:03,524] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:33:04,104] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:33:04,171] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:33:04,183] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:33:04,188] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.671 seconds
[2022-02-17 23:33:16,843] {scheduler_job.py:155} INFO - Started process (PID=33203) to work on /airflow/dags/download_data.py
[2022-02-17 23:33:16,848] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:33:16,850] {logging_mixin.py:112} INFO - [2022-02-17 23:33:16,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:33:17,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:33:17,392] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:33:17,400] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:33:17,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-17 23:33:30,180] {scheduler_job.py:155} INFO - Started process (PID=33229) to work on /airflow/dags/download_data.py
[2022-02-17 23:33:30,190] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:33:30,201] {logging_mixin.py:112} INFO - [2022-02-17 23:33:30,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:33:30,674] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:33:30,709] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:33:30,715] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:33:30,720] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 23:33:43,503] {scheduler_job.py:155} INFO - Started process (PID=33255) to work on /airflow/dags/download_data.py
[2022-02-17 23:33:43,508] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:33:43,511] {logging_mixin.py:112} INFO - [2022-02-17 23:33:43,510] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:33:44,082] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:33:44,131] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:33:44,141] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:33:44,147] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.643 seconds
[2022-02-17 23:33:56,865] {scheduler_job.py:155} INFO - Started process (PID=33281) to work on /airflow/dags/download_data.py
[2022-02-17 23:33:56,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:33:56,878] {logging_mixin.py:112} INFO - [2022-02-17 23:33:56,878] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:33:57,512] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:33:57,579] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:33:57,587] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:33:57,594] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.729 seconds
[2022-02-17 23:34:10,184] {scheduler_job.py:155} INFO - Started process (PID=33307) to work on /airflow/dags/download_data.py
[2022-02-17 23:34:10,190] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:34:10,192] {logging_mixin.py:112} INFO - [2022-02-17 23:34:10,192] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:34:10,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:34:10,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:34:10,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:34:10,835] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.651 seconds
[2022-02-17 23:34:23,437] {scheduler_job.py:155} INFO - Started process (PID=33333) to work on /airflow/dags/download_data.py
[2022-02-17 23:34:23,442] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:34:23,444] {logging_mixin.py:112} INFO - [2022-02-17 23:34:23,443] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:34:23,967] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:34:24,025] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:34:24,036] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:34:24,041] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-17 23:34:36,753] {scheduler_job.py:155} INFO - Started process (PID=33359) to work on /airflow/dags/download_data.py
[2022-02-17 23:34:36,765] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:34:36,768] {logging_mixin.py:112} INFO - [2022-02-17 23:34:36,767] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:34:37,313] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:34:37,378] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:34:37,386] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:34:37,390] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-17 23:34:50,051] {scheduler_job.py:155} INFO - Started process (PID=33385) to work on /airflow/dags/download_data.py
[2022-02-17 23:34:50,056] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:34:50,057] {logging_mixin.py:112} INFO - [2022-02-17 23:34:50,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:34:50,590] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:34:50,649] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:34:50,658] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:34:50,665] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-17 23:35:03,377] {scheduler_job.py:155} INFO - Started process (PID=33411) to work on /airflow/dags/download_data.py
[2022-02-17 23:35:03,386] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:35:03,388] {logging_mixin.py:112} INFO - [2022-02-17 23:35:03,388] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:35:03,957] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:35:04,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:35:04,032] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:35:04,038] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.661 seconds
[2022-02-17 23:35:16,642] {scheduler_job.py:155} INFO - Started process (PID=33437) to work on /airflow/dags/download_data.py
[2022-02-17 23:35:16,648] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:35:16,650] {logging_mixin.py:112} INFO - [2022-02-17 23:35:16,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:35:17,132] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:35:17,190] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:35:17,199] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:35:17,204] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 23:35:29,970] {scheduler_job.py:155} INFO - Started process (PID=33463) to work on /airflow/dags/download_data.py
[2022-02-17 23:35:29,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:35:29,978] {logging_mixin.py:112} INFO - [2022-02-17 23:35:29,977] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:35:30,476] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:35:30,523] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:35:30,531] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:35:30,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 23:35:43,297] {scheduler_job.py:155} INFO - Started process (PID=33489) to work on /airflow/dags/download_data.py
[2022-02-17 23:35:43,315] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:35:43,321] {logging_mixin.py:112} INFO - [2022-02-17 23:35:43,320] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:35:43,871] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:35:43,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:35:43,943] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:35:43,947] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.651 seconds
[2022-02-17 23:35:56,621] {scheduler_job.py:155} INFO - Started process (PID=33515) to work on /airflow/dags/download_data.py
[2022-02-17 23:35:56,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:35:56,628] {logging_mixin.py:112} INFO - [2022-02-17 23:35:56,628] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:35:57,183] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:35:57,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:35:57,259] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:35:57,265] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-17 23:36:09,991] {scheduler_job.py:155} INFO - Started process (PID=33541) to work on /airflow/dags/download_data.py
[2022-02-17 23:36:09,997] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:36:10,001] {logging_mixin.py:112} INFO - [2022-02-17 23:36:10,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:36:10,517] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:36:10,572] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:36:10,585] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:36:10,597] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 23:36:23,254] {scheduler_job.py:155} INFO - Started process (PID=33567) to work on /airflow/dags/download_data.py
[2022-02-17 23:36:23,258] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:36:23,260] {logging_mixin.py:112} INFO - [2022-02-17 23:36:23,260] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:36:23,754] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:36:23,804] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:36:23,813] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:36:23,817] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 23:36:36,572] {scheduler_job.py:155} INFO - Started process (PID=33593) to work on /airflow/dags/download_data.py
[2022-02-17 23:36:36,579] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:36:36,580] {logging_mixin.py:112} INFO - [2022-02-17 23:36:36,580] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:36:37,129] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:36:37,176] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:36:37,184] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:36:37,188] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-17 23:36:49,847] {scheduler_job.py:155} INFO - Started process (PID=33619) to work on /airflow/dags/download_data.py
[2022-02-17 23:36:49,853] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:36:49,856] {logging_mixin.py:112} INFO - [2022-02-17 23:36:49,855] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:36:50,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:36:50,395] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:36:50,403] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:36:50,407] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-17 23:37:03,167] {scheduler_job.py:155} INFO - Started process (PID=33645) to work on /airflow/dags/download_data.py
[2022-02-17 23:37:03,172] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:37:03,173] {logging_mixin.py:112} INFO - [2022-02-17 23:37:03,173] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:37:03,704] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:37:03,776] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:37:03,792] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:37:03,798] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-17 23:37:16,514] {scheduler_job.py:155} INFO - Started process (PID=33671) to work on /airflow/dags/download_data.py
[2022-02-17 23:37:16,521] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:37:16,523] {logging_mixin.py:112} INFO - [2022-02-17 23:37:16,523] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:37:16,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:37:17,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:37:17,038] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:37:17,046] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 23:37:29,787] {scheduler_job.py:155} INFO - Started process (PID=33697) to work on /airflow/dags/download_data.py
[2022-02-17 23:37:29,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:37:29,793] {logging_mixin.py:112} INFO - [2022-02-17 23:37:29,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:37:30,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:37:30,325] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:37:30,332] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:37:30,337] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 23:37:43,075] {scheduler_job.py:155} INFO - Started process (PID=33723) to work on /airflow/dags/download_data.py
[2022-02-17 23:37:43,086] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:37:43,088] {logging_mixin.py:112} INFO - [2022-02-17 23:37:43,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:37:43,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:37:43,709] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:37:43,717] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:37:43,723] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-17 23:37:56,419] {scheduler_job.py:155} INFO - Started process (PID=33749) to work on /airflow/dags/download_data.py
[2022-02-17 23:37:56,425] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:37:56,428] {logging_mixin.py:112} INFO - [2022-02-17 23:37:56,428] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:37:56,914] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:37:56,978] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:37:56,986] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:37:56,991] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 23:38:09,713] {scheduler_job.py:155} INFO - Started process (PID=33775) to work on /airflow/dags/download_data.py
[2022-02-17 23:38:09,718] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:38:09,720] {logging_mixin.py:112} INFO - [2022-02-17 23:38:09,720] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:38:10,296] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:38:10,355] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:38:10,366] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:38:10,370] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-17 23:38:23,041] {scheduler_job.py:155} INFO - Started process (PID=33801) to work on /airflow/dags/download_data.py
[2022-02-17 23:38:23,052] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:38:23,054] {logging_mixin.py:112} INFO - [2022-02-17 23:38:23,054] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:38:23,548] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:38:23,596] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:38:23,604] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:38:23,607] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-17 23:38:36,372] {scheduler_job.py:155} INFO - Started process (PID=33827) to work on /airflow/dags/download_data.py
[2022-02-17 23:38:36,378] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:38:36,380] {logging_mixin.py:112} INFO - [2022-02-17 23:38:36,380] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:38:36,929] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:38:36,982] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:38:36,989] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:38:36,994] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-17 23:38:49,680] {scheduler_job.py:155} INFO - Started process (PID=33853) to work on /airflow/dags/download_data.py
[2022-02-17 23:38:49,685] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:38:49,686] {logging_mixin.py:112} INFO - [2022-02-17 23:38:49,686] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:38:50,158] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:38:50,202] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:38:50,207] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:38:50,212] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 23:39:02,998] {scheduler_job.py:155} INFO - Started process (PID=33879) to work on /airflow/dags/download_data.py
[2022-02-17 23:39:03,006] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:39:03,008] {logging_mixin.py:112} INFO - [2022-02-17 23:39:03,008] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:39:03,530] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:39:03,595] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:39:03,604] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:39:03,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-17 23:39:16,332] {scheduler_job.py:155} INFO - Started process (PID=33905) to work on /airflow/dags/download_data.py
[2022-02-17 23:39:16,340] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:39:16,342] {logging_mixin.py:112} INFO - [2022-02-17 23:39:16,341] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:39:16,818] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:39:16,869] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:39:16,880] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:39:16,886] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 23:39:29,660] {scheduler_job.py:155} INFO - Started process (PID=33931) to work on /airflow/dags/download_data.py
[2022-02-17 23:39:29,668] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:39:29,670] {logging_mixin.py:112} INFO - [2022-02-17 23:39:29,670] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:39:30,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:39:30,231] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:39:30,240] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:39:30,245] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-17 23:39:42,931] {scheduler_job.py:155} INFO - Started process (PID=33957) to work on /airflow/dags/download_data.py
[2022-02-17 23:39:42,936] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:39:42,937] {logging_mixin.py:112} INFO - [2022-02-17 23:39:42,937] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:39:43,469] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:39:43,525] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:39:43,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:39:43,536] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-17 23:39:56,237] {scheduler_job.py:155} INFO - Started process (PID=33983) to work on /airflow/dags/download_data.py
[2022-02-17 23:39:56,243] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:39:56,245] {logging_mixin.py:112} INFO - [2022-02-17 23:39:56,244] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:39:56,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:39:56,758] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:39:56,765] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:39:56,770] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 23:40:09,603] {scheduler_job.py:155} INFO - Started process (PID=34009) to work on /airflow/dags/download_data.py
[2022-02-17 23:40:09,613] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:40:09,615] {logging_mixin.py:112} INFO - [2022-02-17 23:40:09,614] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:40:10,169] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:40:10,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:40:10,232] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:40:10,242] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-17 23:40:22,882] {scheduler_job.py:155} INFO - Started process (PID=34035) to work on /airflow/dags/download_data.py
[2022-02-17 23:40:22,887] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:40:22,889] {logging_mixin.py:112} INFO - [2022-02-17 23:40:22,888] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:40:23,401] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:40:23,458] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:40:23,470] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:40:23,475] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 23:40:36,190] {scheduler_job.py:155} INFO - Started process (PID=34061) to work on /airflow/dags/download_data.py
[2022-02-17 23:40:36,197] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:40:36,200] {logging_mixin.py:112} INFO - [2022-02-17 23:40:36,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:40:36,734] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:40:36,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:40:36,813] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:40:36,818] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-17 23:40:49,549] {scheduler_job.py:155} INFO - Started process (PID=34087) to work on /airflow/dags/download_data.py
[2022-02-17 23:40:49,558] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:40:49,561] {logging_mixin.py:112} INFO - [2022-02-17 23:40:49,561] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:40:50,044] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:40:50,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:40:50,107] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:40:50,111] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 23:41:02,852] {scheduler_job.py:155} INFO - Started process (PID=34113) to work on /airflow/dags/download_data.py
[2022-02-17 23:41:02,856] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:41:02,857] {logging_mixin.py:112} INFO - [2022-02-17 23:41:02,857] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:41:03,406] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:41:03,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:41:03,463] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:41:03,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-17 23:41:16,104] {scheduler_job.py:155} INFO - Started process (PID=34139) to work on /airflow/dags/download_data.py
[2022-02-17 23:41:16,110] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:41:16,113] {logging_mixin.py:112} INFO - [2022-02-17 23:41:16,112] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:41:16,644] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:41:16,693] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:41:16,704] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:41:16,717] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-17 23:41:29,408] {scheduler_job.py:155} INFO - Started process (PID=34165) to work on /airflow/dags/download_data.py
[2022-02-17 23:41:29,414] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:41:29,415] {logging_mixin.py:112} INFO - [2022-02-17 23:41:29,415] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:41:29,940] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:41:29,983] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:41:29,991] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:41:29,996] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-17 23:41:42,686] {scheduler_job.py:155} INFO - Started process (PID=34191) to work on /airflow/dags/download_data.py
[2022-02-17 23:41:42,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:41:42,692] {logging_mixin.py:112} INFO - [2022-02-17 23:41:42,691] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:41:43,164] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:41:43,263] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:41:43,273] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:41:43,277] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 23:41:56,024] {scheduler_job.py:155} INFO - Started process (PID=34217) to work on /airflow/dags/download_data.py
[2022-02-17 23:41:56,028] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:41:56,031] {logging_mixin.py:112} INFO - [2022-02-17 23:41:56,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:41:56,481] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:41:56,533] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:41:56,548] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:41:56,555] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-17 23:42:09,363] {scheduler_job.py:155} INFO - Started process (PID=34243) to work on /airflow/dags/download_data.py
[2022-02-17 23:42:09,367] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:42:09,368] {logging_mixin.py:112} INFO - [2022-02-17 23:42:09,368] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:42:09,877] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:42:09,941] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:42:09,956] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:42:09,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-17 23:42:22,647] {scheduler_job.py:155} INFO - Started process (PID=34269) to work on /airflow/dags/download_data.py
[2022-02-17 23:42:22,651] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:42:22,653] {logging_mixin.py:112} INFO - [2022-02-17 23:42:22,653] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:42:23,157] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:42:23,209] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:42:23,215] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:42:23,220] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 23:42:35,988] {scheduler_job.py:155} INFO - Started process (PID=34295) to work on /airflow/dags/download_data.py
[2022-02-17 23:42:35,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:42:36,002] {logging_mixin.py:112} INFO - [2022-02-17 23:42:36,001] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:42:36,523] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:42:36,580] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:42:36,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:42:36,591] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-17 23:42:49,263] {scheduler_job.py:155} INFO - Started process (PID=34321) to work on /airflow/dags/download_data.py
[2022-02-17 23:42:49,273] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:42:49,275] {logging_mixin.py:112} INFO - [2022-02-17 23:42:49,275] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:42:49,774] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:42:49,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:42:49,836] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:42:49,841] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 23:43:02,644] {scheduler_job.py:155} INFO - Started process (PID=34347) to work on /airflow/dags/download_data.py
[2022-02-17 23:43:02,650] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:43:02,653] {logging_mixin.py:112} INFO - [2022-02-17 23:43:02,652] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:43:03,213] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:43:03,271] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:43:03,284] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:43:03,289] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-17 23:43:15,996] {scheduler_job.py:155} INFO - Started process (PID=34373) to work on /airflow/dags/download_data.py
[2022-02-17 23:43:16,005] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:43:16,008] {logging_mixin.py:112} INFO - [2022-02-17 23:43:16,008] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:43:16,509] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:43:16,565] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:43:16,575] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:43:16,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 23:43:29,307] {scheduler_job.py:155} INFO - Started process (PID=34399) to work on /airflow/dags/download_data.py
[2022-02-17 23:43:29,313] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:43:29,315] {logging_mixin.py:112} INFO - [2022-02-17 23:43:29,315] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:43:29,794] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:43:29,836] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:43:29,844] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:43:29,848] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-17 23:43:42,607] {scheduler_job.py:155} INFO - Started process (PID=34425) to work on /airflow/dags/download_data.py
[2022-02-17 23:43:42,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:43:42,616] {logging_mixin.py:112} INFO - [2022-02-17 23:43:42,616] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:43:43,049] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:43:43,097] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:43:43,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:43:43,116] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 23:43:55,941] {scheduler_job.py:155} INFO - Started process (PID=34451) to work on /airflow/dags/download_data.py
[2022-02-17 23:43:55,946] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:43:55,947] {logging_mixin.py:112} INFO - [2022-02-17 23:43:55,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:43:56,423] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:43:56,476] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:43:56,483] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:43:56,489] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-17 23:44:09,248] {scheduler_job.py:155} INFO - Started process (PID=34477) to work on /airflow/dags/download_data.py
[2022-02-17 23:44:09,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:44:09,254] {logging_mixin.py:112} INFO - [2022-02-17 23:44:09,254] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:44:09,775] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:44:09,825] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:44:09,833] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:44:09,840] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 23:44:22,499] {scheduler_job.py:155} INFO - Started process (PID=34503) to work on /airflow/dags/download_data.py
[2022-02-17 23:44:22,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:44:22,505] {logging_mixin.py:112} INFO - [2022-02-17 23:44:22,504] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:44:22,965] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:44:23,024] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:44:23,039] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:44:23,048] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 23:44:35,865] {scheduler_job.py:155} INFO - Started process (PID=34529) to work on /airflow/dags/download_data.py
[2022-02-17 23:44:35,874] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:44:35,876] {logging_mixin.py:112} INFO - [2022-02-17 23:44:35,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:44:36,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:44:36,451] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:44:36,464] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:44:36,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-17 23:44:49,140] {scheduler_job.py:155} INFO - Started process (PID=34555) to work on /airflow/dags/download_data.py
[2022-02-17 23:44:49,144] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:44:49,146] {logging_mixin.py:112} INFO - [2022-02-17 23:44:49,146] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:44:49,633] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:44:49,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:44:49,694] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:44:49,698] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 23:45:02,438] {scheduler_job.py:155} INFO - Started process (PID=34581) to work on /airflow/dags/download_data.py
[2022-02-17 23:45:02,447] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:45:02,450] {logging_mixin.py:112} INFO - [2022-02-17 23:45:02,449] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:45:02,962] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:45:03,012] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:45:03,022] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:45:03,029] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 23:45:15,710] {scheduler_job.py:155} INFO - Started process (PID=34607) to work on /airflow/dags/download_data.py
[2022-02-17 23:45:15,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:45:15,718] {logging_mixin.py:112} INFO - [2022-02-17 23:45:15,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:45:16,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:45:16,302] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:45:16,311] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:45:16,316] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-17 23:45:29,019] {scheduler_job.py:155} INFO - Started process (PID=34633) to work on /airflow/dags/download_data.py
[2022-02-17 23:45:29,032] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:45:29,036] {logging_mixin.py:112} INFO - [2022-02-17 23:45:29,035] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:45:29,473] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:45:29,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:45:29,544] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:45:29,552] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-17 23:45:42,287] {scheduler_job.py:155} INFO - Started process (PID=34659) to work on /airflow/dags/download_data.py
[2022-02-17 23:45:42,293] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:45:42,295] {logging_mixin.py:112} INFO - [2022-02-17 23:45:42,294] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:45:42,796] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:45:42,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:45:42,862] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:45:42,868] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-17 23:45:55,602] {scheduler_job.py:155} INFO - Started process (PID=34685) to work on /airflow/dags/download_data.py
[2022-02-17 23:45:55,608] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:45:55,609] {logging_mixin.py:112} INFO - [2022-02-17 23:45:55,609] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:45:56,077] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:45:56,115] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:45:56,124] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:45:56,128] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 23:46:08,954] {scheduler_job.py:155} INFO - Started process (PID=34711) to work on /airflow/dags/download_data.py
[2022-02-17 23:46:08,965] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:46:08,967] {logging_mixin.py:112} INFO - [2022-02-17 23:46:08,967] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:46:09,485] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:46:09,529] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:46:09,534] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:46:09,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-17 23:46:22,244] {scheduler_job.py:155} INFO - Started process (PID=34737) to work on /airflow/dags/download_data.py
[2022-02-17 23:46:22,249] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:46:22,250] {logging_mixin.py:112} INFO - [2022-02-17 23:46:22,250] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:46:22,735] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:46:22,773] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:46:22,780] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:46:22,784] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 23:46:35,572] {scheduler_job.py:155} INFO - Started process (PID=34763) to work on /airflow/dags/download_data.py
[2022-02-17 23:46:35,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:46:35,578] {logging_mixin.py:112} INFO - [2022-02-17 23:46:35,578] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:46:36,074] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:46:36,152] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:46:36,165] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:46:36,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-17 23:46:48,842] {scheduler_job.py:155} INFO - Started process (PID=34789) to work on /airflow/dags/download_data.py
[2022-02-17 23:46:48,847] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:46:48,848] {logging_mixin.py:112} INFO - [2022-02-17 23:46:48,848] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:46:49,309] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:46:49,356] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:46:49,362] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:46:49,367] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 23:47:02,211] {scheduler_job.py:155} INFO - Started process (PID=34815) to work on /airflow/dags/download_data.py
[2022-02-17 23:47:02,217] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:47:02,221] {logging_mixin.py:112} INFO - [2022-02-17 23:47:02,221] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:47:02,711] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:47:02,764] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:47:02,773] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:47:02,778] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-17 23:47:15,483] {scheduler_job.py:155} INFO - Started process (PID=34841) to work on /airflow/dags/download_data.py
[2022-02-17 23:47:15,495] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:47:15,497] {logging_mixin.py:112} INFO - [2022-02-17 23:47:15,497] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:47:15,999] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:47:16,040] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:47:16,049] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:47:16,053] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-17 23:47:28,780] {scheduler_job.py:155} INFO - Started process (PID=34867) to work on /airflow/dags/download_data.py
[2022-02-17 23:47:28,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:47:28,793] {logging_mixin.py:112} INFO - [2022-02-17 23:47:28,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:47:29,259] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:47:29,307] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:47:29,314] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:47:29,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 23:47:42,056] {scheduler_job.py:155} INFO - Started process (PID=34893) to work on /airflow/dags/download_data.py
[2022-02-17 23:47:42,060] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:47:42,063] {logging_mixin.py:112} INFO - [2022-02-17 23:47:42,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:47:42,516] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:47:42,564] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:47:42,573] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:47:42,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-17 23:47:55,330] {scheduler_job.py:155} INFO - Started process (PID=34919) to work on /airflow/dags/download_data.py
[2022-02-17 23:47:55,334] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:47:55,336] {logging_mixin.py:112} INFO - [2022-02-17 23:47:55,336] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:47:55,799] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:47:55,857] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:47:55,869] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:47:55,876] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 23:48:08,638] {scheduler_job.py:155} INFO - Started process (PID=34945) to work on /airflow/dags/download_data.py
[2022-02-17 23:48:08,642] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:48:08,644] {logging_mixin.py:112} INFO - [2022-02-17 23:48:08,644] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:48:09,162] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:48:09,209] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:48:09,225] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:48:09,230] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 23:48:21,915] {scheduler_job.py:155} INFO - Started process (PID=34971) to work on /airflow/dags/download_data.py
[2022-02-17 23:48:21,920] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:48:21,922] {logging_mixin.py:112} INFO - [2022-02-17 23:48:21,921] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:48:22,416] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:48:22,466] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:48:22,473] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:48:22,478] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-17 23:48:35,276] {scheduler_job.py:155} INFO - Started process (PID=34997) to work on /airflow/dags/download_data.py
[2022-02-17 23:48:35,282] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:48:35,284] {logging_mixin.py:112} INFO - [2022-02-17 23:48:35,284] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:48:35,758] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:48:35,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:48:35,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:48:35,812] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 23:48:48,562] {scheduler_job.py:155} INFO - Started process (PID=35023) to work on /airflow/dags/download_data.py
[2022-02-17 23:48:48,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:48:48,570] {logging_mixin.py:112} INFO - [2022-02-17 23:48:48,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:48:49,018] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:48:49,077] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:48:49,087] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:48:49,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 23:49:01,884] {scheduler_job.py:155} INFO - Started process (PID=35049) to work on /airflow/dags/download_data.py
[2022-02-17 23:49:01,891] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:49:01,894] {logging_mixin.py:112} INFO - [2022-02-17 23:49:01,893] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:49:02,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:49:02,434] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:49:02,445] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:49:02,451] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-17 23:49:15,158] {scheduler_job.py:155} INFO - Started process (PID=35075) to work on /airflow/dags/download_data.py
[2022-02-17 23:49:15,161] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:49:15,165] {logging_mixin.py:112} INFO - [2022-02-17 23:49:15,164] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:49:15,673] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:49:15,735] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:49:15,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:49:15,756] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-17 23:49:28,482] {scheduler_job.py:155} INFO - Started process (PID=35101) to work on /airflow/dags/download_data.py
[2022-02-17 23:49:28,491] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:49:28,493] {logging_mixin.py:112} INFO - [2022-02-17 23:49:28,493] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:49:28,937] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:49:28,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:49:29,003] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:49:29,010] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 23:49:41,765] {scheduler_job.py:155} INFO - Started process (PID=35127) to work on /airflow/dags/download_data.py
[2022-02-17 23:49:41,775] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:49:41,778] {logging_mixin.py:112} INFO - [2022-02-17 23:49:41,777] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:49:42,253] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:49:42,302] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:49:42,309] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:49:42,315] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-17 23:49:55,064] {scheduler_job.py:155} INFO - Started process (PID=35153) to work on /airflow/dags/download_data.py
[2022-02-17 23:49:55,074] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:49:55,077] {logging_mixin.py:112} INFO - [2022-02-17 23:49:55,076] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:49:55,552] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:49:55,606] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:49:55,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:49:55,619] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-17 23:50:08,416] {scheduler_job.py:155} INFO - Started process (PID=35179) to work on /airflow/dags/download_data.py
[2022-02-17 23:50:08,428] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:50:08,430] {logging_mixin.py:112} INFO - [2022-02-17 23:50:08,429] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:50:08,941] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:50:09,021] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:50:09,032] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:50:09,037] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-17 23:50:21,682] {scheduler_job.py:155} INFO - Started process (PID=35205) to work on /airflow/dags/download_data.py
[2022-02-17 23:50:21,688] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:50:21,690] {logging_mixin.py:112} INFO - [2022-02-17 23:50:21,689] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:50:22,196] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:50:22,246] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:50:22,260] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:50:22,264] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 23:50:35,018] {scheduler_job.py:155} INFO - Started process (PID=35231) to work on /airflow/dags/download_data.py
[2022-02-17 23:50:35,024] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:50:35,025] {logging_mixin.py:112} INFO - [2022-02-17 23:50:35,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:50:35,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:50:35,581] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:50:35,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:50:35,590] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 23:50:48,318] {scheduler_job.py:155} INFO - Started process (PID=35257) to work on /airflow/dags/download_data.py
[2022-02-17 23:50:48,324] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:50:48,327] {logging_mixin.py:112} INFO - [2022-02-17 23:50:48,326] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:50:48,770] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:50:48,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:50:48,837] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:50:48,842] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 23:51:01,612] {scheduler_job.py:155} INFO - Started process (PID=35283) to work on /airflow/dags/download_data.py
[2022-02-17 23:51:01,617] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:51:01,619] {logging_mixin.py:112} INFO - [2022-02-17 23:51:01,619] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:51:02,100] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:51:02,148] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:51:02,161] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:51:02,168] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-17 23:51:14,917] {scheduler_job.py:155} INFO - Started process (PID=35309) to work on /airflow/dags/download_data.py
[2022-02-17 23:51:14,927] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:51:14,928] {logging_mixin.py:112} INFO - [2022-02-17 23:51:14,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:51:15,418] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:51:15,465] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:51:15,474] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:51:15,480] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-17 23:51:28,255] {scheduler_job.py:155} INFO - Started process (PID=35335) to work on /airflow/dags/download_data.py
[2022-02-17 23:51:28,259] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:51:28,261] {logging_mixin.py:112} INFO - [2022-02-17 23:51:28,261] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:51:28,720] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:51:28,775] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:51:28,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:51:28,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-17 23:51:41,562] {scheduler_job.py:155} INFO - Started process (PID=35361) to work on /airflow/dags/download_data.py
[2022-02-17 23:51:41,566] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:51:41,568] {logging_mixin.py:112} INFO - [2022-02-17 23:51:41,568] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:51:42,020] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:51:42,067] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:51:42,077] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:51:42,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-17 23:51:54,900] {scheduler_job.py:155} INFO - Started process (PID=35387) to work on /airflow/dags/download_data.py
[2022-02-17 23:51:54,910] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:51:54,913] {logging_mixin.py:112} INFO - [2022-02-17 23:51:54,912] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:51:55,360] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:51:55,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:51:55,419] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:51:55,427] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 23:52:08,209] {scheduler_job.py:155} INFO - Started process (PID=35413) to work on /airflow/dags/download_data.py
[2022-02-17 23:52:08,216] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:52:08,218] {logging_mixin.py:112} INFO - [2022-02-17 23:52:08,218] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:52:08,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:52:08,781] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:52:08,789] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:52:08,794] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-17 23:52:21,509] {scheduler_job.py:155} INFO - Started process (PID=35439) to work on /airflow/dags/download_data.py
[2022-02-17 23:52:21,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:52:21,518] {logging_mixin.py:112} INFO - [2022-02-17 23:52:21,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:52:21,995] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:52:22,033] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:52:22,041] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:52:22,047] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 23:52:34,833] {scheduler_job.py:155} INFO - Started process (PID=35465) to work on /airflow/dags/download_data.py
[2022-02-17 23:52:34,839] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:52:34,841] {logging_mixin.py:112} INFO - [2022-02-17 23:52:34,840] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:52:35,346] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:52:35,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:52:35,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:52:35,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-17 23:52:48,133] {scheduler_job.py:155} INFO - Started process (PID=35491) to work on /airflow/dags/download_data.py
[2022-02-17 23:52:48,138] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:52:48,140] {logging_mixin.py:112} INFO - [2022-02-17 23:52:48,140] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:52:48,606] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:52:48,658] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:52:48,668] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:52:48,672] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-17 23:53:01,427] {scheduler_job.py:155} INFO - Started process (PID=35517) to work on /airflow/dags/download_data.py
[2022-02-17 23:53:01,432] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:53:01,433] {logging_mixin.py:112} INFO - [2022-02-17 23:53:01,433] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:53:01,936] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:53:01,998] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:53:02,011] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:53:02,024] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-17 23:53:14,766] {scheduler_job.py:155} INFO - Started process (PID=35543) to work on /airflow/dags/download_data.py
[2022-02-17 23:53:14,771] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:53:14,773] {logging_mixin.py:112} INFO - [2022-02-17 23:53:14,773] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:53:15,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:53:15,323] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:53:15,332] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:53:15,338] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-17 23:53:28,075] {scheduler_job.py:155} INFO - Started process (PID=35569) to work on /airflow/dags/download_data.py
[2022-02-17 23:53:28,079] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:53:28,081] {logging_mixin.py:112} INFO - [2022-02-17 23:53:28,081] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:53:28,546] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:53:28,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:53:28,595] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:53:28,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-17 23:53:41,320] {scheduler_job.py:155} INFO - Started process (PID=35595) to work on /airflow/dags/download_data.py
[2022-02-17 23:53:41,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:53:41,327] {logging_mixin.py:112} INFO - [2022-02-17 23:53:41,327] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:53:41,808] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:53:41,855] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:53:41,864] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:53:41,871] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-17 23:53:54,647] {scheduler_job.py:155} INFO - Started process (PID=35621) to work on /airflow/dags/download_data.py
[2022-02-17 23:53:54,652] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:53:54,661] {logging_mixin.py:112} INFO - [2022-02-17 23:53:54,654] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:53:55,130] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:53:55,193] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:53:55,201] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:53:55,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-17 23:54:07,946] {scheduler_job.py:155} INFO - Started process (PID=35647) to work on /airflow/dags/download_data.py
[2022-02-17 23:54:07,950] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:54:07,951] {logging_mixin.py:112} INFO - [2022-02-17 23:54:07,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:54:08,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:54:08,518] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:54:08,526] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:54:08,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 23:54:21,280] {scheduler_job.py:155} INFO - Started process (PID=35673) to work on /airflow/dags/download_data.py
[2022-02-17 23:54:21,285] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:54:21,288] {logging_mixin.py:112} INFO - [2022-02-17 23:54:21,287] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:54:21,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:54:21,838] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:54:21,851] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:54:21,858] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 23:54:34,598] {scheduler_job.py:155} INFO - Started process (PID=35699) to work on /airflow/dags/download_data.py
[2022-02-17 23:54:34,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:54:34,606] {logging_mixin.py:112} INFO - [2022-02-17 23:54:34,606] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:54:35,106] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:54:35,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:54:35,165] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:54:35,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-17 23:54:47,901] {scheduler_job.py:155} INFO - Started process (PID=35725) to work on /airflow/dags/download_data.py
[2022-02-17 23:54:47,911] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:54:47,913] {logging_mixin.py:112} INFO - [2022-02-17 23:54:47,913] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:54:48,376] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:54:48,425] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:54:48,435] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:54:48,442] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-17 23:55:01,213] {scheduler_job.py:155} INFO - Started process (PID=35751) to work on /airflow/dags/download_data.py
[2022-02-17 23:55:01,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:55:01,229] {logging_mixin.py:112} INFO - [2022-02-17 23:55:01,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:55:01,682] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:55:01,736] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:55:01,744] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:55:01,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-17 23:55:14,517] {scheduler_job.py:155} INFO - Started process (PID=35777) to work on /airflow/dags/download_data.py
[2022-02-17 23:55:14,522] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:55:14,524] {logging_mixin.py:112} INFO - [2022-02-17 23:55:14,524] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:55:15,053] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:55:15,090] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:55:15,102] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:55:15,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-17 23:55:27,842] {scheduler_job.py:155} INFO - Started process (PID=35803) to work on /airflow/dags/download_data.py
[2022-02-17 23:55:27,848] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:55:27,852] {logging_mixin.py:112} INFO - [2022-02-17 23:55:27,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:55:28,348] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:55:28,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:55:28,386] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:55:28,390] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-17 23:55:41,158] {scheduler_job.py:155} INFO - Started process (PID=35829) to work on /airflow/dags/download_data.py
[2022-02-17 23:55:41,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:55:41,164] {logging_mixin.py:112} INFO - [2022-02-17 23:55:41,164] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:55:41,644] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:55:41,697] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:55:41,705] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:55:41,710] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-17 23:55:54,494] {scheduler_job.py:155} INFO - Started process (PID=35855) to work on /airflow/dags/download_data.py
[2022-02-17 23:55:54,498] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:55:54,500] {logging_mixin.py:112} INFO - [2022-02-17 23:55:54,500] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:55:54,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:55:55,016] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:55:55,025] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:55:55,031] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-17 23:56:07,815] {scheduler_job.py:155} INFO - Started process (PID=35881) to work on /airflow/dags/download_data.py
[2022-02-17 23:56:07,824] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:56:07,827] {logging_mixin.py:112} INFO - [2022-02-17 23:56:07,826] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:56:08,334] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:56:08,383] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:56:08,392] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:56:08,397] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-17 23:56:21,134] {scheduler_job.py:155} INFO - Started process (PID=35907) to work on /airflow/dags/download_data.py
[2022-02-17 23:56:21,139] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:56:21,140] {logging_mixin.py:112} INFO - [2022-02-17 23:56:21,140] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:56:21,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:56:21,702] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:56:21,717] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:56:21,723] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-17 23:56:34,450] {scheduler_job.py:155} INFO - Started process (PID=35933) to work on /airflow/dags/download_data.py
[2022-02-17 23:56:34,454] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:56:34,456] {logging_mixin.py:112} INFO - [2022-02-17 23:56:34,456] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:56:34,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:56:35,007] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:56:35,020] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:56:35,028] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-17 23:56:47,751] {scheduler_job.py:155} INFO - Started process (PID=35959) to work on /airflow/dags/download_data.py
[2022-02-17 23:56:47,761] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:56:47,764] {logging_mixin.py:112} INFO - [2022-02-17 23:56:47,763] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:56:48,277] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:56:48,324] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:56:48,333] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:56:48,340] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-17 23:57:01,039] {scheduler_job.py:155} INFO - Started process (PID=35985) to work on /airflow/dags/download_data.py
[2022-02-17 23:57:01,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:57:01,046] {logging_mixin.py:112} INFO - [2022-02-17 23:57:01,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:57:01,550] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:57:01,595] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:57:01,602] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:57:01,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-17 23:57:14,343] {scheduler_job.py:155} INFO - Started process (PID=36011) to work on /airflow/dags/download_data.py
[2022-02-17 23:57:14,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:57:14,352] {logging_mixin.py:112} INFO - [2022-02-17 23:57:14,352] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:57:14,877] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:57:14,926] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:57:14,932] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:57:14,937] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-17 23:57:27,627] {scheduler_job.py:155} INFO - Started process (PID=36037) to work on /airflow/dags/download_data.py
[2022-02-17 23:57:27,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:57:27,635] {logging_mixin.py:112} INFO - [2022-02-17 23:57:27,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:57:28,076] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:57:28,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:57:28,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:57:28,135] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-17 23:57:40,885] {scheduler_job.py:155} INFO - Started process (PID=36063) to work on /airflow/dags/download_data.py
[2022-02-17 23:57:40,891] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:57:40,893] {logging_mixin.py:112} INFO - [2022-02-17 23:57:40,893] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:57:41,411] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:57:41,464] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:57:41,474] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:57:41,480] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-17 23:57:54,208] {scheduler_job.py:155} INFO - Started process (PID=36089) to work on /airflow/dags/download_data.py
[2022-02-17 23:57:54,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:57:54,215] {logging_mixin.py:112} INFO - [2022-02-17 23:57:54,215] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:57:54,683] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:57:54,727] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:57:54,736] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:57:54,742] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-17 23:58:07,519] {scheduler_job.py:155} INFO - Started process (PID=36115) to work on /airflow/dags/download_data.py
[2022-02-17 23:58:07,525] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:58:07,527] {logging_mixin.py:112} INFO - [2022-02-17 23:58:07,527] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:58:08,047] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:58:08,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:58:08,108] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:58:08,113] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-17 23:58:20,822] {scheduler_job.py:155} INFO - Started process (PID=36141) to work on /airflow/dags/download_data.py
[2022-02-17 23:58:20,828] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:58:20,830] {logging_mixin.py:112} INFO - [2022-02-17 23:58:20,830] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:58:21,318] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:58:21,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:58:21,372] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:58:21,375] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-17 23:58:34,130] {scheduler_job.py:155} INFO - Started process (PID=36167) to work on /airflow/dags/download_data.py
[2022-02-17 23:58:34,135] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:58:34,137] {logging_mixin.py:112} INFO - [2022-02-17 23:58:34,137] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:58:34,670] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:58:34,711] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:58:34,722] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:58:34,728] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-17 23:58:47,448] {scheduler_job.py:155} INFO - Started process (PID=36193) to work on /airflow/dags/download_data.py
[2022-02-17 23:58:47,453] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:58:47,457] {logging_mixin.py:112} INFO - [2022-02-17 23:58:47,456] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:58:47,941] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:58:47,989] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:58:47,995] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:58:48,006] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-17 23:59:00,782] {scheduler_job.py:155} INFO - Started process (PID=36219) to work on /airflow/dags/download_data.py
[2022-02-17 23:59:00,788] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:59:00,789] {logging_mixin.py:112} INFO - [2022-02-17 23:59:00,789] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:59:01,263] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:59:01,299] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:59:01,304] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:59:01,308] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-17 23:59:14,064] {scheduler_job.py:155} INFO - Started process (PID=36245) to work on /airflow/dags/download_data.py
[2022-02-17 23:59:14,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:59:14,070] {logging_mixin.py:112} INFO - [2022-02-17 23:59:14,070] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:59:14,551] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:59:14,590] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:59:14,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:59:14,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-17 23:59:27,378] {scheduler_job.py:155} INFO - Started process (PID=36271) to work on /airflow/dags/download_data.py
[2022-02-17 23:59:27,386] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:59:27,388] {logging_mixin.py:112} INFO - [2022-02-17 23:59:27,388] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:59:27,854] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:59:27,908] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:59:27,918] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:59:27,927] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-17 23:59:40,659] {scheduler_job.py:155} INFO - Started process (PID=36297) to work on /airflow/dags/download_data.py
[2022-02-17 23:59:40,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:59:40,671] {logging_mixin.py:112} INFO - [2022-02-17 23:59:40,671] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:59:41,125] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:59:41,175] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:59:41,182] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:59:41,187] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-17 23:59:53,954] {scheduler_job.py:155} INFO - Started process (PID=36323) to work on /airflow/dags/download_data.py
[2022-02-17 23:59:53,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-17 23:59:53,961] {logging_mixin.py:112} INFO - [2022-02-17 23:59:53,961] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-17 23:59:54,412] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-17 23:59:54,458] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-17 23:59:54,464] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-17 23:59:54,467] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
