[2022-02-18 00:00:07,315] {scheduler_job.py:155} INFO - Started process (PID=36349) to work on /airflow/dags/download_data.py
[2022-02-18 00:00:07,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:00:07,331] {logging_mixin.py:112} INFO - [2022-02-18 00:00:07,331] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:00:07,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:00:07,856] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:00:07,863] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:00:07,867] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 00:00:20,562] {scheduler_job.py:155} INFO - Started process (PID=36375) to work on /airflow/dags/download_data.py
[2022-02-18 00:00:20,569] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:00:20,571] {logging_mixin.py:112} INFO - [2022-02-18 00:00:20,571] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:00:21,076] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:00:21,120] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:00:21,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:00:21,134] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 00:00:33,886] {scheduler_job.py:155} INFO - Started process (PID=36401) to work on /airflow/dags/download_data.py
[2022-02-18 00:00:33,891] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:00:33,893] {logging_mixin.py:112} INFO - [2022-02-18 00:00:33,893] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:00:34,432] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:00:34,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:00:34,483] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:00:34,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 00:00:47,260] {scheduler_job.py:155} INFO - Started process (PID=36427) to work on /airflow/dags/download_data.py
[2022-02-18 00:00:47,268] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:00:47,271] {logging_mixin.py:112} INFO - [2022-02-18 00:00:47,270] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:00:47,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:00:47,782] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:00:47,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:00:47,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 00:00:59,547] {scheduler_job.py:155} INFO - Started process (PID=36451) to work on /airflow/dags/download_data.py
[2022-02-18 00:00:59,551] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:00:59,553] {logging_mixin.py:112} INFO - [2022-02-18 00:00:59,553] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:01:00,042] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:01:00,094] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:01:00,103] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:01:00,111] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 00:01:12,827] {scheduler_job.py:155} INFO - Started process (PID=36477) to work on /airflow/dags/download_data.py
[2022-02-18 00:01:12,831] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:01:12,832] {logging_mixin.py:112} INFO - [2022-02-18 00:01:12,832] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:01:13,320] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:01:13,371] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:01:13,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:01:13,388] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 00:01:26,128] {scheduler_job.py:155} INFO - Started process (PID=36503) to work on /airflow/dags/download_data.py
[2022-02-18 00:01:26,133] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:01:26,135] {logging_mixin.py:112} INFO - [2022-02-18 00:01:26,134] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:01:26,613] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:01:26,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:01:26,661] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:01:26,665] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 00:01:39,453] {scheduler_job.py:155} INFO - Started process (PID=36529) to work on /airflow/dags/download_data.py
[2022-02-18 00:01:39,457] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:01:39,462] {logging_mixin.py:112} INFO - [2022-02-18 00:01:39,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:01:39,935] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:01:39,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:01:39,965] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:01:39,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 00:01:52,710] {scheduler_job.py:155} INFO - Started process (PID=36555) to work on /airflow/dags/download_data.py
[2022-02-18 00:01:52,719] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:01:52,722] {logging_mixin.py:112} INFO - [2022-02-18 00:01:52,721] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:01:53,181] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:01:53,221] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:01:53,229] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:01:53,235] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 00:02:05,987] {scheduler_job.py:155} INFO - Started process (PID=36581) to work on /airflow/dags/download_data.py
[2022-02-18 00:02:05,992] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:02:05,999] {logging_mixin.py:112} INFO - [2022-02-18 00:02:05,998] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:02:06,488] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:02:06,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:02:06,546] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:02:06,555] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 00:02:19,280] {scheduler_job.py:155} INFO - Started process (PID=36607) to work on /airflow/dags/download_data.py
[2022-02-18 00:02:19,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:02:19,288] {logging_mixin.py:112} INFO - [2022-02-18 00:02:19,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:02:19,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:02:19,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:02:19,852] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:02:19,858] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 00:02:32,606] {scheduler_job.py:155} INFO - Started process (PID=36633) to work on /airflow/dags/download_data.py
[2022-02-18 00:02:32,610] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:02:32,612] {logging_mixin.py:112} INFO - [2022-02-18 00:02:32,612] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:02:33,099] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:02:33,148] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:02:33,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:02:33,161] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 00:02:45,884] {scheduler_job.py:155} INFO - Started process (PID=36659) to work on /airflow/dags/download_data.py
[2022-02-18 00:02:45,893] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:02:45,895] {logging_mixin.py:112} INFO - [2022-02-18 00:02:45,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:02:46,352] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:02:46,398] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:02:46,404] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:02:46,415] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 00:02:59,246] {scheduler_job.py:155} INFO - Started process (PID=36685) to work on /airflow/dags/download_data.py
[2022-02-18 00:02:59,254] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:02:59,256] {logging_mixin.py:112} INFO - [2022-02-18 00:02:59,256] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:02:59,720] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:02:59,764] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:02:59,770] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:02:59,777] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 00:03:12,549] {scheduler_job.py:155} INFO - Started process (PID=36711) to work on /airflow/dags/download_data.py
[2022-02-18 00:03:12,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:03:12,559] {logging_mixin.py:112} INFO - [2022-02-18 00:03:12,558] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:03:13,040] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:03:13,099] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:03:13,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:03:13,119] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 00:03:25,850] {scheduler_job.py:155} INFO - Started process (PID=36737) to work on /airflow/dags/download_data.py
[2022-02-18 00:03:25,859] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:03:25,861] {logging_mixin.py:112} INFO - [2022-02-18 00:03:25,861] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:03:26,370] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:03:26,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:03:26,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:03:26,422] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 00:03:39,143] {scheduler_job.py:155} INFO - Started process (PID=36763) to work on /airflow/dags/download_data.py
[2022-02-18 00:03:39,149] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:03:39,151] {logging_mixin.py:112} INFO - [2022-02-18 00:03:39,150] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:03:39,682] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:03:39,734] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:03:39,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:03:39,757] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 00:03:52,431] {scheduler_job.py:155} INFO - Started process (PID=36789) to work on /airflow/dags/download_data.py
[2022-02-18 00:03:52,436] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:03:52,438] {logging_mixin.py:112} INFO - [2022-02-18 00:03:52,438] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:03:52,986] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:03:53,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:03:53,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:03:53,050] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-18 00:04:05,763] {scheduler_job.py:155} INFO - Started process (PID=36815) to work on /airflow/dags/download_data.py
[2022-02-18 00:04:05,771] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:04:05,780] {logging_mixin.py:112} INFO - [2022-02-18 00:04:05,779] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:04:06,346] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:04:06,408] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:04:06,415] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:04:06,419] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.656 seconds
[2022-02-18 00:04:19,010] {scheduler_job.py:155} INFO - Started process (PID=36841) to work on /airflow/dags/download_data.py
[2022-02-18 00:04:19,025] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:04:19,031] {logging_mixin.py:112} INFO - [2022-02-18 00:04:19,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:04:19,642] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:04:19,697] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:04:19,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:04:19,707] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-18 00:04:32,544] {scheduler_job.py:155} INFO - Started process (PID=36867) to work on /airflow/dags/download_data.py
[2022-02-18 00:04:32,551] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:04:32,553] {logging_mixin.py:112} INFO - [2022-02-18 00:04:32,553] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:04:33,323] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:04:33,396] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:04:33,410] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:04:33,417] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.873 seconds
[2022-02-18 00:04:45,960] {scheduler_job.py:155} INFO - Started process (PID=36893) to work on /airflow/dags/download_data.py
[2022-02-18 00:04:45,974] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:04:45,977] {logging_mixin.py:112} INFO - [2022-02-18 00:04:45,977] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:04:46,845] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:04:46,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:04:46,971] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:04:46,997] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.036 seconds
[2022-02-18 00:05:00,396] {scheduler_job.py:155} INFO - Started process (PID=36919) to work on /airflow/dags/download_data.py
[2022-02-18 00:05:00,418] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:05:00,422] {logging_mixin.py:112} INFO - [2022-02-18 00:05:00,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:05:01,387] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:05:01,521] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:05:01,541] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:05:01,555] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.159 seconds
[2022-02-18 00:05:13,810] {scheduler_job.py:155} INFO - Started process (PID=36944) to work on /airflow/dags/download_data.py
[2022-02-18 00:05:13,839] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:05:13,842] {logging_mixin.py:112} INFO - [2022-02-18 00:05:13,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:05:14,903] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:05:14,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:05:15,007] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:05:15,014] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.207 seconds
[2022-02-18 00:05:27,252] {scheduler_job.py:155} INFO - Started process (PID=36969) to work on /airflow/dags/download_data.py
[2022-02-18 00:05:27,265] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:05:27,270] {logging_mixin.py:112} INFO - [2022-02-18 00:05:27,269] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:05:28,335] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:05:28,417] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:05:28,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:05:28,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.185 seconds
[2022-02-18 00:05:40,707] {scheduler_job.py:155} INFO - Started process (PID=36994) to work on /airflow/dags/download_data.py
[2022-02-18 00:05:40,726] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:05:40,729] {logging_mixin.py:112} INFO - [2022-02-18 00:05:40,729] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:05:41,934] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:05:42,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:05:42,055] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:05:42,072] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.364 seconds
[2022-02-18 00:05:54,406] {scheduler_job.py:155} INFO - Started process (PID=37019) to work on /airflow/dags/download_data.py
[2022-02-18 00:05:54,446] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:05:54,457] {logging_mixin.py:112} INFO - [2022-02-18 00:05:54,455] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:05:56,178] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:05:56,306] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:05:56,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:05:56,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.938 seconds
[2022-02-18 00:06:08,226] {scheduler_job.py:155} INFO - Started process (PID=37044) to work on /airflow/dags/download_data.py
[2022-02-18 00:06:08,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:06:08,282] {logging_mixin.py:112} INFO - [2022-02-18 00:06:08,278] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:06:10,822] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:06:11,003] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:06:11,032] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:06:11,052] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.827 seconds
[2022-02-18 00:06:21,901] {scheduler_job.py:155} INFO - Started process (PID=37069) to work on /airflow/dags/download_data.py
[2022-02-18 00:06:21,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:06:21,922] {logging_mixin.py:112} INFO - [2022-02-18 00:06:21,921] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:06:24,109] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:06:24,271] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:06:24,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:06:24,313] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.413 seconds
[2022-02-18 00:06:43,691] {scheduler_job.py:155} INFO - Started process (PID=37095) to work on /airflow/dags/download_data.py
[2022-02-18 00:06:43,717] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:06:43,729] {logging_mixin.py:112} INFO - [2022-02-18 00:06:43,728] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:06:46,130] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:06:46,309] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:06:46,345] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:06:46,373] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.682 seconds
[2022-02-18 00:07:06,837] {scheduler_job.py:155} INFO - Started process (PID=37120) to work on /airflow/dags/download_data.py
[2022-02-18 00:07:06,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:07:06,979] {logging_mixin.py:112} INFO - [2022-02-18 00:07:06,978] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:07:11,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:07:11,987] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:07:12,007] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:07:12,022] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 5.187 seconds
[2022-02-18 00:07:22,817] {scheduler_job.py:155} INFO - Started process (PID=37145) to work on /airflow/dags/download_data.py
[2022-02-18 00:07:22,842] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:07:22,859] {logging_mixin.py:112} INFO - [2022-02-18 00:07:22,857] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:07:28,567] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:07:29,616] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:07:29,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:07:29,815] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 6.998 seconds
[2022-02-18 00:07:46,054] {scheduler_job.py:155} INFO - Started process (PID=37171) to work on /airflow/dags/download_data.py
[2022-02-18 00:07:46,074] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:07:46,089] {logging_mixin.py:112} INFO - [2022-02-18 00:07:46,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:07:49,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:07:49,980] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:07:50,106] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:07:50,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 4.117 seconds
[2022-02-18 00:08:14,962] {scheduler_job.py:155} INFO - Started process (PID=37197) to work on /airflow/dags/download_data.py
[2022-02-18 00:08:15,058] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:08:15,104] {logging_mixin.py:112} INFO - [2022-02-18 00:08:15,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:08:26,264] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:08:26,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:08:26,433] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:08:26,447] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 11.485 seconds
[2022-02-18 00:08:34,077] {scheduler_job.py:155} INFO - Started process (PID=37222) to work on /airflow/dags/download_data.py
[2022-02-18 00:08:34,159] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:08:34,169] {logging_mixin.py:112} INFO - [2022-02-18 00:08:34,168] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:08:46,609] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:08:47,438] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:08:47,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:08:47,559] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 13.484 seconds
[2022-02-18 00:09:06,729] {scheduler_job.py:155} INFO - Started process (PID=37249) to work on /airflow/dags/download_data.py
[2022-02-18 00:09:06,842] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:09:06,877] {logging_mixin.py:112} INFO - [2022-02-18 00:09:06,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:09:17,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:09:18,653] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:09:18,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:09:18,937] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 12.208 seconds
[2022-02-18 00:09:34,848] {scheduler_job.py:155} INFO - Started process (PID=37274) to work on /airflow/dags/download_data.py
[2022-02-18 00:09:34,871] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:09:34,878] {logging_mixin.py:112} INFO - [2022-02-18 00:09:34,877] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:09:40,864] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:09:42,728] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:09:42,912] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:09:43,102] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 8.254 seconds
[2022-02-18 00:10:12,471] {scheduler_job.py:155} INFO - Started process (PID=37299) to work on /airflow/dags/download_data.py
[2022-02-18 00:10:12,499] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:10:12,505] {logging_mixin.py:112} INFO - [2022-02-18 00:10:12,504] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:10:14,829] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:10:15,054] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:10:15,084] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:10:15,102] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.632 seconds
[2022-02-18 00:10:36,795] {scheduler_job.py:155} INFO - Started process (PID=37324) to work on /airflow/dags/download_data.py
[2022-02-18 00:10:36,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:10:37,057] {logging_mixin.py:112} INFO - [2022-02-18 00:10:37,053] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:10:44,287] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:10:44,469] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:10:44,495] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:10:44,524] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 7.732 seconds
[2022-02-18 00:10:56,506] {scheduler_job.py:155} INFO - Started process (PID=37350) to work on /airflow/dags/download_data.py
[2022-02-18 00:10:56,524] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:10:56,528] {logging_mixin.py:112} INFO - [2022-02-18 00:10:56,528] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:10:58,605] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:10:58,836] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:10:58,863] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:10:58,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.372 seconds
[2022-02-18 00:11:10,544] {scheduler_job.py:155} INFO - Started process (PID=37375) to work on /airflow/dags/download_data.py
[2022-02-18 00:11:10,588] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:11:10,610] {logging_mixin.py:112} INFO - [2022-02-18 00:11:10,610] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:11:12,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:11:12,804] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:11:12,830] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:11:12,843] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.299 seconds
[2022-02-18 00:11:25,254] {scheduler_job.py:155} INFO - Started process (PID=37401) to work on /airflow/dags/download_data.py
[2022-02-18 00:11:25,277] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:11:25,282] {logging_mixin.py:112} INFO - [2022-02-18 00:11:25,282] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:11:27,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:11:27,482] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:11:27,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:11:27,528] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.274 seconds
[2022-02-18 00:11:40,129] {scheduler_job.py:155} INFO - Started process (PID=37427) to work on /airflow/dags/download_data.py
[2022-02-18 00:11:40,145] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:11:40,150] {logging_mixin.py:112} INFO - [2022-02-18 00:11:40,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:11:41,686] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:11:41,832] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:11:41,855] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:11:41,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.747 seconds
[2022-02-18 00:11:54,706] {scheduler_job.py:155} INFO - Started process (PID=37453) to work on /airflow/dags/download_data.py
[2022-02-18 00:11:54,725] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:11:54,734] {logging_mixin.py:112} INFO - [2022-02-18 00:11:54,732] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:11:55,964] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:11:56,069] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:11:56,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:11:56,095] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.389 seconds
[2022-02-18 00:12:08,257] {scheduler_job.py:155} INFO - Started process (PID=37478) to work on /airflow/dags/download_data.py
[2022-02-18 00:12:08,285] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:12:08,291] {logging_mixin.py:112} INFO - [2022-02-18 00:12:08,290] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:12:09,293] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:12:09,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:12:09,416] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:12:09,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.170 seconds
[2022-02-18 00:12:21,690] {scheduler_job.py:155} INFO - Started process (PID=37503) to work on /airflow/dags/download_data.py
[2022-02-18 00:12:21,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:12:21,720] {logging_mixin.py:112} INFO - [2022-02-18 00:12:21,719] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:12:22,560] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:12:22,651] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:12:22,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:12:22,669] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.980 seconds
[2022-02-18 00:12:34,057] {scheduler_job.py:155} INFO - Started process (PID=37528) to work on /airflow/dags/download_data.py
[2022-02-18 00:12:34,070] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:12:34,073] {logging_mixin.py:112} INFO - [2022-02-18 00:12:34,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:12:35,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:12:35,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:12:35,477] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:12:35,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.435 seconds
[2022-02-18 00:12:48,685] {scheduler_job.py:155} INFO - Started process (PID=37554) to work on /airflow/dags/download_data.py
[2022-02-18 00:12:48,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:12:48,704] {logging_mixin.py:112} INFO - [2022-02-18 00:12:48,704] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:12:50,256] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:12:50,394] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:12:50,414] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:12:50,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.741 seconds
[2022-02-18 00:13:02,317] {scheduler_job.py:155} INFO - Started process (PID=37579) to work on /airflow/dags/download_data.py
[2022-02-18 00:13:02,343] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:13:02,348] {logging_mixin.py:112} INFO - [2022-02-18 00:13:02,347] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:13:03,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:13:03,943] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:13:03,965] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:13:03,976] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.659 seconds
[2022-02-18 00:13:15,874] {scheduler_job.py:155} INFO - Started process (PID=37604) to work on /airflow/dags/download_data.py
[2022-02-18 00:13:15,915] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:13:15,921] {logging_mixin.py:112} INFO - [2022-02-18 00:13:15,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:13:17,325] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:13:17,444] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:13:17,459] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:13:17,475] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.601 seconds
[2022-02-18 00:13:29,404] {scheduler_job.py:155} INFO - Started process (PID=37629) to work on /airflow/dags/download_data.py
[2022-02-18 00:13:29,418] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:13:29,423] {logging_mixin.py:112} INFO - [2022-02-18 00:13:29,422] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:13:30,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:13:30,885] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:13:30,904] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:13:30,922] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.518 seconds
[2022-02-18 00:13:43,022] {scheduler_job.py:155} INFO - Started process (PID=37654) to work on /airflow/dags/download_data.py
[2022-02-18 00:13:43,038] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:13:43,042] {logging_mixin.py:112} INFO - [2022-02-18 00:13:43,042] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:13:45,000] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:13:45,207] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:13:45,230] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:13:45,263] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.241 seconds
[2022-02-18 00:13:56,520] {scheduler_job.py:155} INFO - Started process (PID=37679) to work on /airflow/dags/download_data.py
[2022-02-18 00:13:56,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:13:56,561] {logging_mixin.py:112} INFO - [2022-02-18 00:13:56,559] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:13:57,656] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:13:57,748] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:13:57,774] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:13:57,790] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.270 seconds
[2022-02-18 00:14:10,958] {scheduler_job.py:155} INFO - Started process (PID=37705) to work on /airflow/dags/download_data.py
[2022-02-18 00:14:10,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:14:10,980] {logging_mixin.py:112} INFO - [2022-02-18 00:14:10,979] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:14:12,065] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:14:12,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:14:12,219] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:14:12,229] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.271 seconds
[2022-02-18 00:14:24,380] {scheduler_job.py:155} INFO - Started process (PID=37730) to work on /airflow/dags/download_data.py
[2022-02-18 00:14:24,389] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:14:24,392] {logging_mixin.py:112} INFO - [2022-02-18 00:14:24,392] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:14:25,368] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:14:25,524] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:14:25,536] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:14:25,545] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.166 seconds
[2022-02-18 00:14:37,932] {scheduler_job.py:155} INFO - Started process (PID=37755) to work on /airflow/dags/download_data.py
[2022-02-18 00:14:37,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:14:37,960] {logging_mixin.py:112} INFO - [2022-02-18 00:14:37,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:14:38,837] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:14:38,914] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:14:38,928] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:14:38,935] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.004 seconds
[2022-02-18 00:14:51,214] {scheduler_job.py:155} INFO - Started process (PID=37780) to work on /airflow/dags/download_data.py
[2022-02-18 00:14:51,221] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:14:51,226] {logging_mixin.py:112} INFO - [2022-02-18 00:14:51,225] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:14:51,999] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:14:52,071] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:14:52,080] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:14:52,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.877 seconds
[2022-02-18 00:15:03,595] {scheduler_job.py:155} INFO - Started process (PID=37805) to work on /airflow/dags/download_data.py
[2022-02-18 00:15:03,613] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:15:03,616] {logging_mixin.py:112} INFO - [2022-02-18 00:15:03,616] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:15:04,242] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:15:04,306] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:15:04,314] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:15:04,319] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.724 seconds
[2022-02-18 00:15:16,903] {scheduler_job.py:155} INFO - Started process (PID=37831) to work on /airflow/dags/download_data.py
[2022-02-18 00:15:16,914] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:15:16,919] {logging_mixin.py:112} INFO - [2022-02-18 00:15:16,917] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:15:17,522] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:15:17,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:15:17,593] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:15:17,603] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.700 seconds
[2022-02-18 00:15:30,242] {scheduler_job.py:155} INFO - Started process (PID=37857) to work on /airflow/dags/download_data.py
[2022-02-18 00:15:30,249] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:15:30,252] {logging_mixin.py:112} INFO - [2022-02-18 00:15:30,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:15:30,813] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:15:30,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:15:30,888] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:15:30,899] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-18 00:15:43,555] {scheduler_job.py:155} INFO - Started process (PID=37883) to work on /airflow/dags/download_data.py
[2022-02-18 00:15:43,587] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:15:43,592] {logging_mixin.py:112} INFO - [2022-02-18 00:15:43,591] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:15:44,366] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:15:44,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:15:44,458] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:15:44,468] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.913 seconds
[2022-02-18 00:15:57,030] {scheduler_job.py:155} INFO - Started process (PID=37909) to work on /airflow/dags/download_data.py
[2022-02-18 00:15:57,039] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:15:57,041] {logging_mixin.py:112} INFO - [2022-02-18 00:15:57,041] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:15:57,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:15:57,847] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:15:57,863] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:15:57,874] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.843 seconds
[2022-02-18 00:16:10,381] {scheduler_job.py:155} INFO - Started process (PID=37935) to work on /airflow/dags/download_data.py
[2022-02-18 00:16:10,388] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:16:10,390] {logging_mixin.py:112} INFO - [2022-02-18 00:16:10,389] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:16:11,185] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:16:11,249] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:16:11,262] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:16:11,269] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.888 seconds
[2022-02-18 00:16:23,670] {scheduler_job.py:155} INFO - Started process (PID=37961) to work on /airflow/dags/download_data.py
[2022-02-18 00:16:23,676] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:16:23,677] {logging_mixin.py:112} INFO - [2022-02-18 00:16:23,677] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:16:24,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:16:24,277] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:16:24,285] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:16:24,292] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-18 00:16:37,013] {scheduler_job.py:155} INFO - Started process (PID=37987) to work on /airflow/dags/download_data.py
[2022-02-18 00:16:37,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:16:37,025] {logging_mixin.py:112} INFO - [2022-02-18 00:16:37,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:16:37,564] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:16:37,628] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:16:37,638] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:16:37,644] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.631 seconds
[2022-02-18 00:16:50,317] {scheduler_job.py:155} INFO - Started process (PID=38013) to work on /airflow/dags/download_data.py
[2022-02-18 00:16:50,331] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:16:50,334] {logging_mixin.py:112} INFO - [2022-02-18 00:16:50,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:16:50,929] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:16:50,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:16:51,009] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:16:51,014] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-18 00:17:03,633] {scheduler_job.py:155} INFO - Started process (PID=38039) to work on /airflow/dags/download_data.py
[2022-02-18 00:17:03,637] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:17:03,640] {logging_mixin.py:112} INFO - [2022-02-18 00:17:03,639] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:17:04,171] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:17:04,231] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:17:04,238] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:17:04,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 00:17:16,932] {scheduler_job.py:155} INFO - Started process (PID=38065) to work on /airflow/dags/download_data.py
[2022-02-18 00:17:16,945] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:17:16,947] {logging_mixin.py:112} INFO - [2022-02-18 00:17:16,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:17:17,517] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:17:17,573] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:17:17,581] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:17:17,586] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-18 00:17:30,209] {scheduler_job.py:155} INFO - Started process (PID=38091) to work on /airflow/dags/download_data.py
[2022-02-18 00:17:30,218] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:17:30,220] {logging_mixin.py:112} INFO - [2022-02-18 00:17:30,220] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:17:30,737] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:17:30,785] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:17:30,798] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:17:30,807] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 00:17:43,509] {scheduler_job.py:155} INFO - Started process (PID=38117) to work on /airflow/dags/download_data.py
[2022-02-18 00:17:43,523] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:17:43,527] {logging_mixin.py:112} INFO - [2022-02-18 00:17:43,527] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:17:44,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:17:44,121] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:17:44,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:17:44,137] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-18 00:17:56,848] {scheduler_job.py:155} INFO - Started process (PID=38143) to work on /airflow/dags/download_data.py
[2022-02-18 00:17:56,853] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:17:56,856] {logging_mixin.py:112} INFO - [2022-02-18 00:17:56,856] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:17:57,376] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:17:57,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:17:57,433] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:17:57,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 00:18:10,109] {scheduler_job.py:155} INFO - Started process (PID=38169) to work on /airflow/dags/download_data.py
[2022-02-18 00:18:10,115] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:18:10,118] {logging_mixin.py:112} INFO - [2022-02-18 00:18:10,118] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:18:10,674] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:18:10,721] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:18:10,732] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:18:10,737] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.627 seconds
[2022-02-18 00:18:23,447] {scheduler_job.py:155} INFO - Started process (PID=38195) to work on /airflow/dags/download_data.py
[2022-02-18 00:18:23,456] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:18:23,459] {logging_mixin.py:112} INFO - [2022-02-18 00:18:23,459] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:18:23,974] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:18:24,034] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:18:24,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:18:24,053] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 00:18:36,754] {scheduler_job.py:155} INFO - Started process (PID=38221) to work on /airflow/dags/download_data.py
[2022-02-18 00:18:36,761] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:18:36,763] {logging_mixin.py:112} INFO - [2022-02-18 00:18:36,763] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:18:37,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:18:37,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:18:37,546] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:18:37,557] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.803 seconds
[2022-02-18 00:18:50,094] {scheduler_job.py:155} INFO - Started process (PID=38247) to work on /airflow/dags/download_data.py
[2022-02-18 00:18:50,100] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:18:50,102] {logging_mixin.py:112} INFO - [2022-02-18 00:18:50,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:18:50,670] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:18:50,736] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:18:50,744] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:18:50,754] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.660 seconds
[2022-02-18 00:19:03,427] {scheduler_job.py:155} INFO - Started process (PID=38273) to work on /airflow/dags/download_data.py
[2022-02-18 00:19:03,436] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:19:03,438] {logging_mixin.py:112} INFO - [2022-02-18 00:19:03,438] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:19:03,989] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:19:04,030] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:19:04,037] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:19:04,041] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 00:19:16,712] {scheduler_job.py:155} INFO - Started process (PID=38299) to work on /airflow/dags/download_data.py
[2022-02-18 00:19:16,720] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:19:16,722] {logging_mixin.py:112} INFO - [2022-02-18 00:19:16,722] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:19:17,249] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:19:17,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:19:17,323] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:19:17,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-18 00:19:29,998] {scheduler_job.py:155} INFO - Started process (PID=38325) to work on /airflow/dags/download_data.py
[2022-02-18 00:19:30,006] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:19:30,008] {logging_mixin.py:112} INFO - [2022-02-18 00:19:30,008] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:19:30,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:19:30,577] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:19:30,583] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:19:30,587] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 00:19:43,382] {scheduler_job.py:155} INFO - Started process (PID=38351) to work on /airflow/dags/download_data.py
[2022-02-18 00:19:43,391] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:19:43,396] {logging_mixin.py:112} INFO - [2022-02-18 00:19:43,395] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:19:44,015] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:19:44,082] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:19:44,095] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:19:44,102] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.720 seconds
[2022-02-18 00:19:56,682] {scheduler_job.py:155} INFO - Started process (PID=38377) to work on /airflow/dags/download_data.py
[2022-02-18 00:19:56,687] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:19:56,689] {logging_mixin.py:112} INFO - [2022-02-18 00:19:56,689] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:19:57,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:19:57,284] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:19:57,290] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:19:57,295] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 00:20:09,974] {scheduler_job.py:155} INFO - Started process (PID=38403) to work on /airflow/dags/download_data.py
[2022-02-18 00:20:09,985] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:20:09,987] {logging_mixin.py:112} INFO - [2022-02-18 00:20:09,987] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:20:10,495] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:20:10,561] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:20:10,573] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:20:10,578] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 00:20:23,280] {scheduler_job.py:155} INFO - Started process (PID=38429) to work on /airflow/dags/download_data.py
[2022-02-18 00:20:23,286] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:20:23,289] {logging_mixin.py:112} INFO - [2022-02-18 00:20:23,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:20:23,808] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:20:23,874] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:20:23,881] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:20:23,885] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 00:20:36,609] {scheduler_job.py:155} INFO - Started process (PID=38455) to work on /airflow/dags/download_data.py
[2022-02-18 00:20:36,617] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:20:36,619] {logging_mixin.py:112} INFO - [2022-02-18 00:20:36,619] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:20:37,122] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:20:37,169] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:20:37,178] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:20:37,185] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 00:20:49,940] {scheduler_job.py:155} INFO - Started process (PID=38481) to work on /airflow/dags/download_data.py
[2022-02-18 00:20:49,949] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:20:49,951] {logging_mixin.py:112} INFO - [2022-02-18 00:20:49,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:20:50,523] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:20:50,587] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:20:50,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:20:50,605] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.665 seconds
[2022-02-18 00:21:03,237] {scheduler_job.py:155} INFO - Started process (PID=38507) to work on /airflow/dags/download_data.py
[2022-02-18 00:21:03,242] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:21:03,244] {logging_mixin.py:112} INFO - [2022-02-18 00:21:03,244] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:21:03,759] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:21:03,816] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:21:03,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:21:03,832] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 00:21:16,586] {scheduler_job.py:155} INFO - Started process (PID=38533) to work on /airflow/dags/download_data.py
[2022-02-18 00:21:16,600] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:21:16,603] {logging_mixin.py:112} INFO - [2022-02-18 00:21:16,602] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:21:17,246] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:21:17,315] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:21:17,324] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:21:17,330] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.744 seconds
[2022-02-18 00:21:29,936] {scheduler_job.py:155} INFO - Started process (PID=38559) to work on /airflow/dags/download_data.py
[2022-02-18 00:21:29,943] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:21:29,947] {logging_mixin.py:112} INFO - [2022-02-18 00:21:29,946] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:21:30,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:21:30,523] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:21:30,530] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:21:30,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 00:21:43,217] {scheduler_job.py:155} INFO - Started process (PID=38585) to work on /airflow/dags/download_data.py
[2022-02-18 00:21:43,223] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:21:43,225] {logging_mixin.py:112} INFO - [2022-02-18 00:21:43,224] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:21:43,799] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:21:43,863] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:21:43,874] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:21:43,882] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.664 seconds
[2022-02-18 00:21:56,540] {scheduler_job.py:155} INFO - Started process (PID=38611) to work on /airflow/dags/download_data.py
[2022-02-18 00:21:56,545] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:21:56,547] {logging_mixin.py:112} INFO - [2022-02-18 00:21:56,547] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:21:57,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:21:57,129] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:21:57,140] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:21:57,145] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 00:22:09,797] {scheduler_job.py:155} INFO - Started process (PID=38637) to work on /airflow/dags/download_data.py
[2022-02-18 00:22:09,802] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:22:09,806] {logging_mixin.py:112} INFO - [2022-02-18 00:22:09,806] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:22:10,293] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:22:10,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:22:10,360] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:22:10,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 00:22:23,132] {scheduler_job.py:155} INFO - Started process (PID=38663) to work on /airflow/dags/download_data.py
[2022-02-18 00:22:23,136] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:22:23,138] {logging_mixin.py:112} INFO - [2022-02-18 00:22:23,138] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:22:23,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:22:23,714] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:22:23,724] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:22:23,730] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 00:22:36,452] {scheduler_job.py:155} INFO - Started process (PID=38689) to work on /airflow/dags/download_data.py
[2022-02-18 00:22:36,463] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:22:36,466] {logging_mixin.py:112} INFO - [2022-02-18 00:22:36,466] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:22:36,975] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:22:37,035] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:22:37,044] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:22:37,050] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 00:22:49,726] {scheduler_job.py:155} INFO - Started process (PID=38715) to work on /airflow/dags/download_data.py
[2022-02-18 00:22:49,736] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:22:49,738] {logging_mixin.py:112} INFO - [2022-02-18 00:22:49,738] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:22:50,232] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:22:50,286] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:22:50,293] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:22:50,298] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 00:23:03,025] {scheduler_job.py:155} INFO - Started process (PID=38741) to work on /airflow/dags/download_data.py
[2022-02-18 00:23:03,033] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:23:03,035] {logging_mixin.py:112} INFO - [2022-02-18 00:23:03,035] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:23:03,526] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:23:03,590] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:23:03,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:23:03,606] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 00:23:16,303] {scheduler_job.py:155} INFO - Started process (PID=38767) to work on /airflow/dags/download_data.py
[2022-02-18 00:23:16,313] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:23:16,315] {logging_mixin.py:112} INFO - [2022-02-18 00:23:16,315] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:23:16,808] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:23:16,866] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:23:16,877] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:23:16,888] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 00:23:29,616] {scheduler_job.py:155} INFO - Started process (PID=38793) to work on /airflow/dags/download_data.py
[2022-02-18 00:23:29,623] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:23:29,625] {logging_mixin.py:112} INFO - [2022-02-18 00:23:29,624] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:23:30,205] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:23:30,258] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:23:30,269] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:23:30,278] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.662 seconds
[2022-02-18 00:23:42,927] {scheduler_job.py:155} INFO - Started process (PID=38819) to work on /airflow/dags/download_data.py
[2022-02-18 00:23:42,932] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:23:42,934] {logging_mixin.py:112} INFO - [2022-02-18 00:23:42,933] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:23:43,754] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:23:43,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:23:43,843] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:23:43,852] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.925 seconds
[2022-02-18 00:23:56,318] {scheduler_job.py:155} INFO - Started process (PID=38845) to work on /airflow/dags/download_data.py
[2022-02-18 00:23:56,329] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:23:56,331] {logging_mixin.py:112} INFO - [2022-02-18 00:23:56,331] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:23:56,900] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:23:56,967] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:23:56,979] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:23:56,985] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-18 00:24:09,621] {scheduler_job.py:155} INFO - Started process (PID=38871) to work on /airflow/dags/download_data.py
[2022-02-18 00:24:09,635] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:24:09,637] {logging_mixin.py:112} INFO - [2022-02-18 00:24:09,636] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:24:10,154] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:24:10,203] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:24:10,215] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:24:10,221] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 00:24:22,973] {scheduler_job.py:155} INFO - Started process (PID=38897) to work on /airflow/dags/download_data.py
[2022-02-18 00:24:22,986] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:24:22,988] {logging_mixin.py:112} INFO - [2022-02-18 00:24:22,988] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:24:23,505] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:24:23,557] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:24:23,569] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:24:23,573] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-18 00:24:36,257] {scheduler_job.py:155} INFO - Started process (PID=38923) to work on /airflow/dags/download_data.py
[2022-02-18 00:24:36,265] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:24:36,268] {logging_mixin.py:112} INFO - [2022-02-18 00:24:36,267] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:24:36,759] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:24:36,803] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:24:36,811] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:24:36,817] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 00:24:49,553] {scheduler_job.py:155} INFO - Started process (PID=38949) to work on /airflow/dags/download_data.py
[2022-02-18 00:24:49,566] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:24:49,571] {logging_mixin.py:112} INFO - [2022-02-18 00:24:49,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:24:50,132] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:24:50,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:24:50,191] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:24:50,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-18 00:25:02,858] {scheduler_job.py:155} INFO - Started process (PID=38975) to work on /airflow/dags/download_data.py
[2022-02-18 00:25:02,866] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:25:02,869] {logging_mixin.py:112} INFO - [2022-02-18 00:25:02,868] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:25:03,380] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:25:03,450] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:25:03,460] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:25:03,467] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-18 00:25:16,105] {scheduler_job.py:155} INFO - Started process (PID=39001) to work on /airflow/dags/download_data.py
[2022-02-18 00:25:16,114] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:25:16,116] {logging_mixin.py:112} INFO - [2022-02-18 00:25:16,116] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:25:16,615] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:25:16,672] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:25:16,679] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:25:16,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 00:25:29,401] {scheduler_job.py:155} INFO - Started process (PID=39027) to work on /airflow/dags/download_data.py
[2022-02-18 00:25:29,408] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:25:29,411] {logging_mixin.py:112} INFO - [2022-02-18 00:25:29,410] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:25:29,904] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:25:29,969] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:25:29,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:25:29,989] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 00:25:42,663] {scheduler_job.py:155} INFO - Started process (PID=39053) to work on /airflow/dags/download_data.py
[2022-02-18 00:25:42,675] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:25:42,677] {logging_mixin.py:112} INFO - [2022-02-18 00:25:42,677] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:25:43,176] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:25:43,233] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:25:43,242] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:25:43,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 00:25:56,017] {scheduler_job.py:155} INFO - Started process (PID=39079) to work on /airflow/dags/download_data.py
[2022-02-18 00:25:56,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:25:56,025] {logging_mixin.py:112} INFO - [2022-02-18 00:25:56,024] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:25:56,559] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:25:56,616] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:25:56,625] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:25:56,633] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-18 00:26:09,333] {scheduler_job.py:155} INFO - Started process (PID=39105) to work on /airflow/dags/download_data.py
[2022-02-18 00:26:09,343] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:26:09,346] {logging_mixin.py:112} INFO - [2022-02-18 00:26:09,346] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:26:09,842] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:26:09,895] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:26:09,905] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:26:09,912] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 00:26:22,604] {scheduler_job.py:155} INFO - Started process (PID=39131) to work on /airflow/dags/download_data.py
[2022-02-18 00:26:22,609] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:26:22,612] {logging_mixin.py:112} INFO - [2022-02-18 00:26:22,611] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:26:23,093] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:26:23,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:26:23,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:26:23,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 00:26:35,916] {scheduler_job.py:155} INFO - Started process (PID=39157) to work on /airflow/dags/download_data.py
[2022-02-18 00:26:35,929] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:26:35,931] {logging_mixin.py:112} INFO - [2022-02-18 00:26:35,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:26:36,555] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:26:36,624] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:26:36,637] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:26:36,644] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.728 seconds
[2022-02-18 00:26:49,170] {scheduler_job.py:155} INFO - Started process (PID=39183) to work on /airflow/dags/download_data.py
[2022-02-18 00:26:49,175] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:26:49,177] {logging_mixin.py:112} INFO - [2022-02-18 00:26:49,177] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:26:49,687] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:26:49,740] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:26:49,751] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:26:49,759] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 00:27:02,504] {scheduler_job.py:155} INFO - Started process (PID=39209) to work on /airflow/dags/download_data.py
[2022-02-18 00:27:02,509] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:27:02,511] {logging_mixin.py:112} INFO - [2022-02-18 00:27:02,511] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:27:03,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:27:03,066] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:27:03,075] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:27:03,085] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 00:27:15,782] {scheduler_job.py:155} INFO - Started process (PID=39235) to work on /airflow/dags/download_data.py
[2022-02-18 00:27:15,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:27:15,788] {logging_mixin.py:112} INFO - [2022-02-18 00:27:15,787] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:27:16,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:27:16,372] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:27:16,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:27:16,390] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 00:27:29,090] {scheduler_job.py:155} INFO - Started process (PID=39261) to work on /airflow/dags/download_data.py
[2022-02-18 00:27:29,094] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:27:29,096] {logging_mixin.py:112} INFO - [2022-02-18 00:27:29,096] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:27:29,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:27:29,644] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:27:29,656] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:27:29,665] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 00:27:42,349] {scheduler_job.py:155} INFO - Started process (PID=39287) to work on /airflow/dags/download_data.py
[2022-02-18 00:27:42,354] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:27:42,357] {logging_mixin.py:112} INFO - [2022-02-18 00:27:42,356] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:27:42,846] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:27:42,908] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:27:42,921] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:27:42,929] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 00:27:55,780] {scheduler_job.py:155} INFO - Started process (PID=39313) to work on /airflow/dags/download_data.py
[2022-02-18 00:27:55,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:27:55,788] {logging_mixin.py:112} INFO - [2022-02-18 00:27:55,787] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:27:56,293] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:27:56,351] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:27:56,363] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:27:56,368] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 00:28:09,114] {scheduler_job.py:155} INFO - Started process (PID=39339) to work on /airflow/dags/download_data.py
[2022-02-18 00:28:09,123] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:28:09,126] {logging_mixin.py:112} INFO - [2022-02-18 00:28:09,125] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:28:09,722] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:28:09,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:28:09,804] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:28:09,812] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-18 00:28:22,416] {scheduler_job.py:155} INFO - Started process (PID=39365) to work on /airflow/dags/download_data.py
[2022-02-18 00:28:22,425] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:28:22,427] {logging_mixin.py:112} INFO - [2022-02-18 00:28:22,426] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:28:22,936] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:28:22,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:28:23,009] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:28:23,017] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-18 00:28:35,737] {scheduler_job.py:155} INFO - Started process (PID=39391) to work on /airflow/dags/download_data.py
[2022-02-18 00:28:35,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:28:35,744] {logging_mixin.py:112} INFO - [2022-02-18 00:28:35,744] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:28:36,242] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:28:36,288] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:28:36,295] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:28:36,299] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 00:28:49,027] {scheduler_job.py:155} INFO - Started process (PID=39417) to work on /airflow/dags/download_data.py
[2022-02-18 00:28:49,031] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:28:49,034] {logging_mixin.py:112} INFO - [2022-02-18 00:28:49,033] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:28:49,525] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:28:49,576] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:28:49,588] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:28:49,594] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 00:29:02,344] {scheduler_job.py:155} INFO - Started process (PID=39443) to work on /airflow/dags/download_data.py
[2022-02-18 00:29:02,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:29:02,350] {logging_mixin.py:112} INFO - [2022-02-18 00:29:02,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:29:02,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:29:02,906] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:29:02,918] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:29:02,928] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 00:29:15,657] {scheduler_job.py:155} INFO - Started process (PID=39469) to work on /airflow/dags/download_data.py
[2022-02-18 00:29:15,666] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:29:15,668] {logging_mixin.py:112} INFO - [2022-02-18 00:29:15,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:29:16,278] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:29:16,340] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:29:16,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:29:16,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.708 seconds
[2022-02-18 00:29:29,078] {scheduler_job.py:155} INFO - Started process (PID=39495) to work on /airflow/dags/download_data.py
[2022-02-18 00:29:29,088] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:29:29,091] {logging_mixin.py:112} INFO - [2022-02-18 00:29:29,090] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:29:29,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:29:29,726] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:29:29,738] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:29:29,747] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.670 seconds
[2022-02-18 00:29:42,355] {scheduler_job.py:155} INFO - Started process (PID=39521) to work on /airflow/dags/download_data.py
[2022-02-18 00:29:42,361] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:29:42,364] {logging_mixin.py:112} INFO - [2022-02-18 00:29:42,364] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:29:43,069] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:29:43,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:29:43,144] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:29:43,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.795 seconds
[2022-02-18 00:29:55,797] {scheduler_job.py:155} INFO - Started process (PID=39547) to work on /airflow/dags/download_data.py
[2022-02-18 00:29:55,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:29:55,810] {logging_mixin.py:112} INFO - [2022-02-18 00:29:55,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:29:56,320] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:29:56,378] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:29:56,387] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:29:56,392] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 00:30:09,082] {scheduler_job.py:155} INFO - Started process (PID=39573) to work on /airflow/dags/download_data.py
[2022-02-18 00:30:09,092] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:30:09,094] {logging_mixin.py:112} INFO - [2022-02-18 00:30:09,094] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:30:09,554] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:30:09,603] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:30:09,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:30:09,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 00:30:22,351] {scheduler_job.py:155} INFO - Started process (PID=39599) to work on /airflow/dags/download_data.py
[2022-02-18 00:30:22,358] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:30:22,359] {logging_mixin.py:112} INFO - [2022-02-18 00:30:22,359] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:30:22,865] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:30:22,933] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:30:22,944] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:30:22,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-18 00:30:35,668] {scheduler_job.py:155} INFO - Started process (PID=39625) to work on /airflow/dags/download_data.py
[2022-02-18 00:30:35,679] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:30:35,681] {logging_mixin.py:112} INFO - [2022-02-18 00:30:35,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:30:36,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:30:36,310] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:30:36,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:30:36,320] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.653 seconds
[2022-02-18 00:30:48,970] {scheduler_job.py:155} INFO - Started process (PID=39651) to work on /airflow/dags/download_data.py
[2022-02-18 00:30:48,977] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:30:48,979] {logging_mixin.py:112} INFO - [2022-02-18 00:30:48,978] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:30:49,493] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:30:49,554] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:30:49,565] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:30:49,574] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 00:31:02,345] {scheduler_job.py:155} INFO - Started process (PID=39677) to work on /airflow/dags/download_data.py
[2022-02-18 00:31:02,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:31:02,353] {logging_mixin.py:112} INFO - [2022-02-18 00:31:02,352] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:31:02,857] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:31:02,905] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:31:02,914] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:31:02,919] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 00:31:15,596] {scheduler_job.py:155} INFO - Started process (PID=39703) to work on /airflow/dags/download_data.py
[2022-02-18 00:31:15,602] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:31:15,603] {logging_mixin.py:112} INFO - [2022-02-18 00:31:15,603] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:31:16,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:31:16,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:31:16,165] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:31:16,172] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 00:31:28,916] {scheduler_job.py:155} INFO - Started process (PID=39729) to work on /airflow/dags/download_data.py
[2022-02-18 00:31:28,923] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:31:28,926] {logging_mixin.py:112} INFO - [2022-02-18 00:31:28,926] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:31:29,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:31:29,493] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:31:29,503] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:31:29,513] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-18 00:31:42,187] {scheduler_job.py:155} INFO - Started process (PID=39755) to work on /airflow/dags/download_data.py
[2022-02-18 00:31:42,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:31:42,194] {logging_mixin.py:112} INFO - [2022-02-18 00:31:42,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:31:42,759] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:31:42,816] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:31:42,825] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:31:42,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.643 seconds
[2022-02-18 00:31:55,538] {scheduler_job.py:155} INFO - Started process (PID=39781) to work on /airflow/dags/download_data.py
[2022-02-18 00:31:55,544] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:31:55,546] {logging_mixin.py:112} INFO - [2022-02-18 00:31:55,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:31:56,036] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:31:56,094] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:31:56,103] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:31:56,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 00:32:08,854] {scheduler_job.py:155} INFO - Started process (PID=39807) to work on /airflow/dags/download_data.py
[2022-02-18 00:32:08,859] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:32:08,861] {logging_mixin.py:112} INFO - [2022-02-18 00:32:08,860] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:32:09,341] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:32:09,398] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:32:09,408] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:32:09,417] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 00:32:22,115] {scheduler_job.py:155} INFO - Started process (PID=39833) to work on /airflow/dags/download_data.py
[2022-02-18 00:32:22,120] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:32:22,123] {logging_mixin.py:112} INFO - [2022-02-18 00:32:22,122] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:32:22,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:32:22,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:32:22,674] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:32:22,681] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 00:32:35,439] {scheduler_job.py:155} INFO - Started process (PID=39859) to work on /airflow/dags/download_data.py
[2022-02-18 00:32:35,446] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:32:35,449] {logging_mixin.py:112} INFO - [2022-02-18 00:32:35,448] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:32:36,114] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:32:36,174] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:32:36,187] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:32:36,198] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.760 seconds
[2022-02-18 00:32:48,736] {scheduler_job.py:155} INFO - Started process (PID=39885) to work on /airflow/dags/download_data.py
[2022-02-18 00:32:48,741] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:32:48,742] {logging_mixin.py:112} INFO - [2022-02-18 00:32:48,742] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:32:49,274] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:32:49,336] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:32:49,348] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:32:49,353] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-18 00:33:02,099] {scheduler_job.py:155} INFO - Started process (PID=39911) to work on /airflow/dags/download_data.py
[2022-02-18 00:33:02,107] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:33:02,110] {logging_mixin.py:112} INFO - [2022-02-18 00:33:02,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:33:02,609] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:33:02,659] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:33:02,672] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:33:02,680] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 00:33:15,405] {scheduler_job.py:155} INFO - Started process (PID=39937) to work on /airflow/dags/download_data.py
[2022-02-18 00:33:15,420] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:33:15,424] {logging_mixin.py:112} INFO - [2022-02-18 00:33:15,424] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:33:15,902] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:33:15,948] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:33:15,958] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:33:15,964] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 00:33:28,700] {scheduler_job.py:155} INFO - Started process (PID=39963) to work on /airflow/dags/download_data.py
[2022-02-18 00:33:28,705] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:33:28,707] {logging_mixin.py:112} INFO - [2022-02-18 00:33:28,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:33:29,201] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:33:29,259] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:33:29,270] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:33:29,275] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 00:33:41,988] {scheduler_job.py:155} INFO - Started process (PID=39989) to work on /airflow/dags/download_data.py
[2022-02-18 00:33:41,992] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:33:41,994] {logging_mixin.py:112} INFO - [2022-02-18 00:33:41,994] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:33:42,482] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:33:42,537] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:33:42,544] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:33:42,549] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 00:33:55,325] {scheduler_job.py:155} INFO - Started process (PID=40015) to work on /airflow/dags/download_data.py
[2022-02-18 00:33:55,333] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:33:55,335] {logging_mixin.py:112} INFO - [2022-02-18 00:33:55,335] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:33:55,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:33:55,887] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:33:55,901] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:33:55,908] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 00:34:08,656] {scheduler_job.py:155} INFO - Started process (PID=40041) to work on /airflow/dags/download_data.py
[2022-02-18 00:34:08,660] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:34:08,662] {logging_mixin.py:112} INFO - [2022-02-18 00:34:08,662] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:34:09,116] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:34:09,163] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:34:09,170] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:34:09,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 00:34:21,907] {scheduler_job.py:155} INFO - Started process (PID=40067) to work on /airflow/dags/download_data.py
[2022-02-18 00:34:21,912] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:34:21,913] {logging_mixin.py:112} INFO - [2022-02-18 00:34:21,913] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:34:22,556] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:34:22,625] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:34:22,636] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:34:22,642] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.735 seconds
[2022-02-18 00:34:35,256] {scheduler_job.py:155} INFO - Started process (PID=40093) to work on /airflow/dags/download_data.py
[2022-02-18 00:34:35,268] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:34:35,271] {logging_mixin.py:112} INFO - [2022-02-18 00:34:35,270] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:34:35,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:34:35,913] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:34:35,925] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:34:35,932] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.676 seconds
[2022-02-18 00:34:48,614] {scheduler_job.py:155} INFO - Started process (PID=40119) to work on /airflow/dags/download_data.py
[2022-02-18 00:34:48,620] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:34:48,622] {logging_mixin.py:112} INFO - [2022-02-18 00:34:48,622] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:34:49,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:34:49,284] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:34:49,298] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:34:49,307] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.694 seconds
[2022-02-18 00:35:01,947] {scheduler_job.py:155} INFO - Started process (PID=40145) to work on /airflow/dags/download_data.py
[2022-02-18 00:35:01,952] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:35:01,954] {logging_mixin.py:112} INFO - [2022-02-18 00:35:01,954] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:35:02,471] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:35:02,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:35:02,538] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:35:02,549] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 00:35:15,232] {scheduler_job.py:155} INFO - Started process (PID=40171) to work on /airflow/dags/download_data.py
[2022-02-18 00:35:15,242] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:35:15,244] {logging_mixin.py:112} INFO - [2022-02-18 00:35:15,244] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:35:15,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:35:15,812] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:35:15,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:35:15,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 00:35:28,549] {scheduler_job.py:155} INFO - Started process (PID=40197) to work on /airflow/dags/download_data.py
[2022-02-18 00:35:28,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:35:28,555] {logging_mixin.py:112} INFO - [2022-02-18 00:35:28,555] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:35:29,047] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:35:29,085] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:35:29,096] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:35:29,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 00:35:41,859] {scheduler_job.py:155} INFO - Started process (PID=40223) to work on /airflow/dags/download_data.py
[2022-02-18 00:35:41,865] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:35:41,868] {logging_mixin.py:112} INFO - [2022-02-18 00:35:41,867] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:35:42,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:35:42,408] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:35:42,420] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:35:42,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 00:35:55,217] {scheduler_job.py:155} INFO - Started process (PID=40249) to work on /airflow/dags/download_data.py
[2022-02-18 00:35:55,229] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:35:55,233] {logging_mixin.py:112} INFO - [2022-02-18 00:35:55,232] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:35:55,818] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:35:55,874] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:35:55,888] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:35:55,896] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-18 00:36:08,555] {scheduler_job.py:155} INFO - Started process (PID=40275) to work on /airflow/dags/download_data.py
[2022-02-18 00:36:08,561] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:36:08,563] {logging_mixin.py:112} INFO - [2022-02-18 00:36:08,563] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:36:09,057] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:36:09,113] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:36:09,127] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:36:09,135] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 00:36:21,835] {scheduler_job.py:155} INFO - Started process (PID=40301) to work on /airflow/dags/download_data.py
[2022-02-18 00:36:21,843] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:36:21,845] {logging_mixin.py:112} INFO - [2022-02-18 00:36:21,845] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:36:22,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:36:22,407] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:36:22,417] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:36:22,422] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 00:36:35,162] {scheduler_job.py:155} INFO - Started process (PID=40327) to work on /airflow/dags/download_data.py
[2022-02-18 00:36:35,168] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:36:35,170] {logging_mixin.py:112} INFO - [2022-02-18 00:36:35,170] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:36:35,692] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:36:35,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:36:35,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:36:35,755] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 00:36:48,464] {scheduler_job.py:155} INFO - Started process (PID=40353) to work on /airflow/dags/download_data.py
[2022-02-18 00:36:48,471] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:36:48,473] {logging_mixin.py:112} INFO - [2022-02-18 00:36:48,473] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:36:49,140] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:36:49,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:36:49,205] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:36:49,210] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.746 seconds
[2022-02-18 00:37:01,808] {scheduler_job.py:155} INFO - Started process (PID=40379) to work on /airflow/dags/download_data.py
[2022-02-18 00:37:01,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:37:01,820] {logging_mixin.py:112} INFO - [2022-02-18 00:37:01,820] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:37:02,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:37:02,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:37:02,412] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:37:02,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 00:37:15,100] {scheduler_job.py:155} INFO - Started process (PID=40405) to work on /airflow/dags/download_data.py
[2022-02-18 00:37:15,108] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:37:15,109] {logging_mixin.py:112} INFO - [2022-02-18 00:37:15,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:37:15,626] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:37:15,688] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:37:15,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:37:15,703] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 00:37:28,428] {scheduler_job.py:155} INFO - Started process (PID=40431) to work on /airflow/dags/download_data.py
[2022-02-18 00:37:28,440] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:37:28,443] {logging_mixin.py:112} INFO - [2022-02-18 00:37:28,442] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:37:28,930] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:37:28,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:37:28,997] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:37:29,004] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 00:37:41,726] {scheduler_job.py:155} INFO - Started process (PID=40457) to work on /airflow/dags/download_data.py
[2022-02-18 00:37:41,734] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:37:41,737] {logging_mixin.py:112} INFO - [2022-02-18 00:37:41,736] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:37:42,227] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:37:42,282] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:37:42,293] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:37:42,297] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 00:37:55,030] {scheduler_job.py:155} INFO - Started process (PID=40483) to work on /airflow/dags/download_data.py
[2022-02-18 00:37:55,038] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:37:55,040] {logging_mixin.py:112} INFO - [2022-02-18 00:37:55,040] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:37:55,569] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:37:55,617] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:37:55,625] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:37:55,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 00:38:08,336] {scheduler_job.py:155} INFO - Started process (PID=40509) to work on /airflow/dags/download_data.py
[2022-02-18 00:38:08,342] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:38:08,344] {logging_mixin.py:112} INFO - [2022-02-18 00:38:08,344] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:38:08,818] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:38:08,874] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:38:08,884] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:38:08,889] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 00:38:21,613] {scheduler_job.py:155} INFO - Started process (PID=40535) to work on /airflow/dags/download_data.py
[2022-02-18 00:38:21,618] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:38:21,619] {logging_mixin.py:112} INFO - [2022-02-18 00:38:21,619] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:38:22,118] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:38:22,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:38:22,194] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:38:22,198] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 00:38:34,924] {scheduler_job.py:155} INFO - Started process (PID=40561) to work on /airflow/dags/download_data.py
[2022-02-18 00:38:34,933] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:38:34,935] {logging_mixin.py:112} INFO - [2022-02-18 00:38:34,934] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:38:35,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:38:35,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:38:35,518] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:38:35,525] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 00:38:48,261] {scheduler_job.py:155} INFO - Started process (PID=40587) to work on /airflow/dags/download_data.py
[2022-02-18 00:38:48,270] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:38:48,274] {logging_mixin.py:112} INFO - [2022-02-18 00:38:48,274] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:38:48,788] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:38:48,845] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:38:48,852] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:38:48,861] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 00:39:01,554] {scheduler_job.py:155} INFO - Started process (PID=40613) to work on /airflow/dags/download_data.py
[2022-02-18 00:39:01,560] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:39:01,564] {logging_mixin.py:112} INFO - [2022-02-18 00:39:01,563] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:39:02,116] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:39:02,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:39:02,181] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:39:02,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-18 00:39:14,835] {scheduler_job.py:155} INFO - Started process (PID=40639) to work on /airflow/dags/download_data.py
[2022-02-18 00:39:14,841] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:39:14,842] {logging_mixin.py:112} INFO - [2022-02-18 00:39:14,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:39:15,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:39:15,411] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:39:15,421] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:39:15,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 00:39:28,131] {scheduler_job.py:155} INFO - Started process (PID=40665) to work on /airflow/dags/download_data.py
[2022-02-18 00:39:28,136] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:39:28,138] {logging_mixin.py:112} INFO - [2022-02-18 00:39:28,138] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:39:28,654] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:39:28,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:39:28,711] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:39:28,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-18 00:39:41,458] {scheduler_job.py:155} INFO - Started process (PID=40691) to work on /airflow/dags/download_data.py
[2022-02-18 00:39:41,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:39:41,473] {logging_mixin.py:112} INFO - [2022-02-18 00:39:41,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:39:42,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:39:42,077] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:39:42,091] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:39:42,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.639 seconds
[2022-02-18 00:39:54,798] {scheduler_job.py:155} INFO - Started process (PID=40717) to work on /airflow/dags/download_data.py
[2022-02-18 00:39:54,807] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:39:54,809] {logging_mixin.py:112} INFO - [2022-02-18 00:39:54,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:39:55,324] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:39:55,373] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:39:55,380] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:39:55,386] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 00:40:08,105] {scheduler_job.py:155} INFO - Started process (PID=40743) to work on /airflow/dags/download_data.py
[2022-02-18 00:40:08,114] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:40:08,117] {logging_mixin.py:112} INFO - [2022-02-18 00:40:08,117] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:40:08,610] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:40:08,665] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:40:08,677] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:40:08,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 00:40:21,392] {scheduler_job.py:155} INFO - Started process (PID=40769) to work on /airflow/dags/download_data.py
[2022-02-18 00:40:21,397] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:40:21,399] {logging_mixin.py:112} INFO - [2022-02-18 00:40:21,399] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:40:21,896] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:40:21,959] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:40:21,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:40:21,973] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 00:40:34,703] {scheduler_job.py:155} INFO - Started process (PID=40795) to work on /airflow/dags/download_data.py
[2022-02-18 00:40:34,718] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:40:34,722] {logging_mixin.py:112} INFO - [2022-02-18 00:40:34,721] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:40:35,237] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:40:35,293] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:40:35,302] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:40:35,311] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-18 00:40:47,978] {scheduler_job.py:155} INFO - Started process (PID=40821) to work on /airflow/dags/download_data.py
[2022-02-18 00:40:47,990] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:40:47,993] {logging_mixin.py:112} INFO - [2022-02-18 00:40:47,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:40:48,564] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:40:48,633] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:40:48,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:40:48,650] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-18 00:41:01,319] {scheduler_job.py:155} INFO - Started process (PID=40847) to work on /airflow/dags/download_data.py
[2022-02-18 00:41:01,324] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:41:01,326] {logging_mixin.py:112} INFO - [2022-02-18 00:41:01,326] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:41:01,944] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:41:02,002] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:41:02,017] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:41:02,021] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.701 seconds
[2022-02-18 00:41:14,627] {scheduler_job.py:155} INFO - Started process (PID=40873) to work on /airflow/dags/download_data.py
[2022-02-18 00:41:14,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:41:14,635] {logging_mixin.py:112} INFO - [2022-02-18 00:41:14,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:41:15,246] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:41:15,328] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:41:15,343] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:41:15,351] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.725 seconds
[2022-02-18 00:41:27,965] {scheduler_job.py:155} INFO - Started process (PID=40899) to work on /airflow/dags/download_data.py
[2022-02-18 00:41:27,975] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:41:27,977] {logging_mixin.py:112} INFO - [2022-02-18 00:41:27,977] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:41:28,583] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:41:28,637] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:41:28,652] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:41:28,661] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.696 seconds
[2022-02-18 00:41:41,245] {scheduler_job.py:155} INFO - Started process (PID=40925) to work on /airflow/dags/download_data.py
[2022-02-18 00:41:41,250] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:41:41,255] {logging_mixin.py:112} INFO - [2022-02-18 00:41:41,254] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:41:41,757] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:41:41,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:41:41,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:41:41,834] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 00:41:54,554] {scheduler_job.py:155} INFO - Started process (PID=40951) to work on /airflow/dags/download_data.py
[2022-02-18 00:41:54,559] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:41:54,561] {logging_mixin.py:112} INFO - [2022-02-18 00:41:54,560] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:41:55,184] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:41:55,249] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:41:55,262] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:41:55,267] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.713 seconds
[2022-02-18 00:42:07,868] {scheduler_job.py:155} INFO - Started process (PID=40977) to work on /airflow/dags/download_data.py
[2022-02-18 00:42:07,872] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:42:07,874] {logging_mixin.py:112} INFO - [2022-02-18 00:42:07,874] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:42:08,412] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:42:08,472] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:42:08,478] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:42:08,482] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-18 00:42:21,191] {scheduler_job.py:155} INFO - Started process (PID=41003) to work on /airflow/dags/download_data.py
[2022-02-18 00:42:21,203] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:42:21,205] {logging_mixin.py:112} INFO - [2022-02-18 00:42:21,205] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:42:21,690] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:42:21,755] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:42:21,766] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:42:21,772] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 00:42:34,500] {scheduler_job.py:155} INFO - Started process (PID=41029) to work on /airflow/dags/download_data.py
[2022-02-18 00:42:34,504] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:42:34,506] {logging_mixin.py:112} INFO - [2022-02-18 00:42:34,506] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:42:35,016] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:42:35,081] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:42:35,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:42:35,099] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 00:42:47,819] {scheduler_job.py:155} INFO - Started process (PID=41055) to work on /airflow/dags/download_data.py
[2022-02-18 00:42:47,830] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:42:47,833] {logging_mixin.py:112} INFO - [2022-02-18 00:42:47,833] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:42:48,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:42:48,409] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:42:48,417] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:42:48,423] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 00:43:01,078] {scheduler_job.py:155} INFO - Started process (PID=41081) to work on /airflow/dags/download_data.py
[2022-02-18 00:43:01,084] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:43:01,087] {logging_mixin.py:112} INFO - [2022-02-18 00:43:01,086] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:43:01,595] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:43:01,657] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:43:01,668] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:43:01,673] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 00:43:14,388] {scheduler_job.py:155} INFO - Started process (PID=41107) to work on /airflow/dags/download_data.py
[2022-02-18 00:43:14,395] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:43:14,396] {logging_mixin.py:112} INFO - [2022-02-18 00:43:14,396] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:43:14,902] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:43:14,968] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:43:14,979] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:43:14,987] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 00:43:27,696] {scheduler_job.py:155} INFO - Started process (PID=41133) to work on /airflow/dags/download_data.py
[2022-02-18 00:43:27,702] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:43:27,706] {logging_mixin.py:112} INFO - [2022-02-18 00:43:27,704] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:43:28,217] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:43:28,259] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:43:28,268] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:43:28,273] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 00:43:40,979] {scheduler_job.py:155} INFO - Started process (PID=41159) to work on /airflow/dags/download_data.py
[2022-02-18 00:43:40,991] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:43:40,993] {logging_mixin.py:112} INFO - [2022-02-18 00:43:40,993] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:43:41,647] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:43:41,711] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:43:41,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:43:41,731] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.752 seconds
[2022-02-18 00:43:54,367] {scheduler_job.py:155} INFO - Started process (PID=41185) to work on /airflow/dags/download_data.py
[2022-02-18 00:43:54,372] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:43:54,374] {logging_mixin.py:112} INFO - [2022-02-18 00:43:54,373] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:43:54,885] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:43:54,946] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:43:54,963] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:43:54,968] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-18 00:44:07,699] {scheduler_job.py:155} INFO - Started process (PID=41211) to work on /airflow/dags/download_data.py
[2022-02-18 00:44:07,705] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:44:07,707] {logging_mixin.py:112} INFO - [2022-02-18 00:44:07,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:44:08,303] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:44:08,360] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:44:08,373] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:44:08,380] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.682 seconds
[2022-02-18 00:44:21,052] {scheduler_job.py:155} INFO - Started process (PID=41237) to work on /airflow/dags/download_data.py
[2022-02-18 00:44:21,061] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:44:21,064] {logging_mixin.py:112} INFO - [2022-02-18 00:44:21,064] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:44:21,581] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:44:21,639] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:44:21,652] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:44:21,661] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-18 00:44:34,371] {scheduler_job.py:155} INFO - Started process (PID=41263) to work on /airflow/dags/download_data.py
[2022-02-18 00:44:34,376] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:44:34,377] {logging_mixin.py:112} INFO - [2022-02-18 00:44:34,377] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:44:34,887] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:44:34,958] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:44:34,966] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:44:34,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 00:44:47,686] {scheduler_job.py:155} INFO - Started process (PID=41289) to work on /airflow/dags/download_data.py
[2022-02-18 00:44:47,691] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:44:47,694] {logging_mixin.py:112} INFO - [2022-02-18 00:44:47,693] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:44:48,238] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:44:48,287] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:44:48,295] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:44:48,302] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-18 00:45:00,979] {scheduler_job.py:155} INFO - Started process (PID=41315) to work on /airflow/dags/download_data.py
[2022-02-18 00:45:00,988] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:45:00,990] {logging_mixin.py:112} INFO - [2022-02-18 00:45:00,989] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:45:01,502] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:45:01,554] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:45:01,567] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:45:01,574] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 00:45:14,216] {scheduler_job.py:155} INFO - Started process (PID=41341) to work on /airflow/dags/download_data.py
[2022-02-18 00:45:14,222] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:45:14,223] {logging_mixin.py:112} INFO - [2022-02-18 00:45:14,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:45:14,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:45:14,785] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:45:14,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:45:14,801] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-18 00:45:27,525] {scheduler_job.py:155} INFO - Started process (PID=41367) to work on /airflow/dags/download_data.py
[2022-02-18 00:45:27,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:45:27,537] {logging_mixin.py:112} INFO - [2022-02-18 00:45:27,537] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:45:28,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:45:28,110] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:45:28,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:45:28,124] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 00:45:40,825] {scheduler_job.py:155} INFO - Started process (PID=41393) to work on /airflow/dags/download_data.py
[2022-02-18 00:45:40,844] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:45:40,846] {logging_mixin.py:112} INFO - [2022-02-18 00:45:40,846] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:45:41,408] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:45:41,469] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:45:41,482] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:45:41,490] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-18 00:45:54,224] {scheduler_job.py:155} INFO - Started process (PID=41419) to work on /airflow/dags/download_data.py
[2022-02-18 00:45:54,232] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:45:54,235] {logging_mixin.py:112} INFO - [2022-02-18 00:45:54,234] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:45:54,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:45:54,842] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:45:54,859] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:45:54,866] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-18 00:46:07,532] {scheduler_job.py:155} INFO - Started process (PID=41445) to work on /airflow/dags/download_data.py
[2022-02-18 00:46:07,541] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:46:07,544] {logging_mixin.py:112} INFO - [2022-02-18 00:46:07,543] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:46:08,046] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:46:08,104] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:46:08,114] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:46:08,118] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 00:46:20,851] {scheduler_job.py:155} INFO - Started process (PID=41471) to work on /airflow/dags/download_data.py
[2022-02-18 00:46:20,862] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:46:20,864] {logging_mixin.py:112} INFO - [2022-02-18 00:46:20,863] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:46:21,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:46:21,420] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:46:21,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:46:21,435] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 00:46:34,195] {scheduler_job.py:155} INFO - Started process (PID=41497) to work on /airflow/dags/download_data.py
[2022-02-18 00:46:34,200] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:46:34,202] {logging_mixin.py:112} INFO - [2022-02-18 00:46:34,202] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:46:34,692] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:46:34,742] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:46:34,752] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:46:34,758] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 00:46:47,462] {scheduler_job.py:155} INFO - Started process (PID=41523) to work on /airflow/dags/download_data.py
[2022-02-18 00:46:47,467] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:46:47,470] {logging_mixin.py:112} INFO - [2022-02-18 00:46:47,469] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:46:48,003] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:46:48,064] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:46:48,071] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:46:48,076] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-18 00:47:00,776] {scheduler_job.py:155} INFO - Started process (PID=41549) to work on /airflow/dags/download_data.py
[2022-02-18 00:47:00,780] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:47:00,782] {logging_mixin.py:112} INFO - [2022-02-18 00:47:00,781] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:47:01,274] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:47:01,322] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:47:01,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:47:01,333] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 00:47:14,061] {scheduler_job.py:155} INFO - Started process (PID=41575) to work on /airflow/dags/download_data.py
[2022-02-18 00:47:14,065] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:47:14,067] {logging_mixin.py:112} INFO - [2022-02-18 00:47:14,067] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:47:14,579] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:47:14,660] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:47:14,667] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:47:14,672] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 00:47:27,385] {scheduler_job.py:155} INFO - Started process (PID=41601) to work on /airflow/dags/download_data.py
[2022-02-18 00:47:27,390] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:47:27,392] {logging_mixin.py:112} INFO - [2022-02-18 00:47:27,392] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:47:27,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:47:27,959] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:47:27,974] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:47:27,981] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 00:47:40,703] {scheduler_job.py:155} INFO - Started process (PID=41627) to work on /airflow/dags/download_data.py
[2022-02-18 00:47:40,713] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:47:40,715] {logging_mixin.py:112} INFO - [2022-02-18 00:47:40,715] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:47:41,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:47:41,258] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:47:41,266] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:47:41,274] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 00:47:54,028] {scheduler_job.py:155} INFO - Started process (PID=41653) to work on /airflow/dags/download_data.py
[2022-02-18 00:47:54,034] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:47:54,036] {logging_mixin.py:112} INFO - [2022-02-18 00:47:54,035] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:47:54,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:47:54,605] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:47:54,619] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:47:54,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 00:48:07,405] {scheduler_job.py:155} INFO - Started process (PID=41679) to work on /airflow/dags/download_data.py
[2022-02-18 00:48:07,418] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:48:07,421] {logging_mixin.py:112} INFO - [2022-02-18 00:48:07,420] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:48:07,974] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:48:08,035] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:48:08,044] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:48:08,048] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.643 seconds
[2022-02-18 00:48:20,722] {scheduler_job.py:155} INFO - Started process (PID=41705) to work on /airflow/dags/download_data.py
[2022-02-18 00:48:20,730] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:48:20,733] {logging_mixin.py:112} INFO - [2022-02-18 00:48:20,733] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:48:21,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:48:21,285] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:48:21,292] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:48:21,299] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 00:48:34,063] {scheduler_job.py:155} INFO - Started process (PID=41731) to work on /airflow/dags/download_data.py
[2022-02-18 00:48:34,071] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:48:34,073] {logging_mixin.py:112} INFO - [2022-02-18 00:48:34,073] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:48:34,576] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:48:34,640] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:48:34,650] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:48:34,658] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 00:48:47,326] {scheduler_job.py:155} INFO - Started process (PID=41757) to work on /airflow/dags/download_data.py
[2022-02-18 00:48:47,334] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:48:47,337] {logging_mixin.py:112} INFO - [2022-02-18 00:48:47,337] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:48:47,869] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:48:47,921] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:48:47,931] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:48:47,936] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 00:49:00,688] {scheduler_job.py:155} INFO - Started process (PID=41783) to work on /airflow/dags/download_data.py
[2022-02-18 00:49:00,693] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:49:00,694] {logging_mixin.py:112} INFO - [2022-02-18 00:49:00,694] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:49:01,279] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:49:01,335] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:49:01,347] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:49:01,353] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-18 00:49:13,968] {scheduler_job.py:155} INFO - Started process (PID=41809) to work on /airflow/dags/download_data.py
[2022-02-18 00:49:13,988] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:49:13,991] {logging_mixin.py:112} INFO - [2022-02-18 00:49:13,990] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:49:14,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:49:14,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:49:14,651] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:49:14,656] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.688 seconds
[2022-02-18 00:49:27,349] {scheduler_job.py:155} INFO - Started process (PID=41835) to work on /airflow/dags/download_data.py
[2022-02-18 00:49:27,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:49:27,361] {logging_mixin.py:112} INFO - [2022-02-18 00:49:27,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:49:27,889] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:49:27,943] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:49:27,951] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:49:27,956] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 00:49:40,615] {scheduler_job.py:155} INFO - Started process (PID=41861) to work on /airflow/dags/download_data.py
[2022-02-18 00:49:40,630] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:49:40,633] {logging_mixin.py:112} INFO - [2022-02-18 00:49:40,633] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:49:41,349] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:49:41,447] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:49:41,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:49:41,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.855 seconds
[2022-02-18 00:49:53,969] {scheduler_job.py:155} INFO - Started process (PID=41887) to work on /airflow/dags/download_data.py
[2022-02-18 00:49:53,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:49:53,978] {logging_mixin.py:112} INFO - [2022-02-18 00:49:53,977] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:49:54,540] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:49:54,599] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:49:54,611] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:49:54,617] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-18 00:50:07,311] {scheduler_job.py:155} INFO - Started process (PID=41913) to work on /airflow/dags/download_data.py
[2022-02-18 00:50:07,317] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:50:07,319] {logging_mixin.py:112} INFO - [2022-02-18 00:50:07,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:50:07,837] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:50:07,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:50:07,910] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:50:07,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-18 00:50:20,578] {scheduler_job.py:155} INFO - Started process (PID=41939) to work on /airflow/dags/download_data.py
[2022-02-18 00:50:20,584] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:50:20,586] {logging_mixin.py:112} INFO - [2022-02-18 00:50:20,586] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:50:21,099] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:50:21,154] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:50:21,167] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:50:21,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 00:50:33,900] {scheduler_job.py:155} INFO - Started process (PID=41965) to work on /airflow/dags/download_data.py
[2022-02-18 00:50:33,905] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:50:33,908] {logging_mixin.py:112} INFO - [2022-02-18 00:50:33,908] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:50:34,496] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:50:34,571] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:50:34,581] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:50:34,589] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.689 seconds
[2022-02-18 00:50:47,196] {scheduler_job.py:155} INFO - Started process (PID=41991) to work on /airflow/dags/download_data.py
[2022-02-18 00:50:47,203] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:50:47,204] {logging_mixin.py:112} INFO - [2022-02-18 00:50:47,204] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 00:50:47,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 00:50:47,795] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 00:50:47,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 00:50:47,811] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-18 00:51:06,682] {scheduler_job.py:155} INFO - Started process (PID=42017) to work on /airflow/dags/download_data.py
[2022-02-18 00:51:06,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 00:51:06,825] {logging_mixin.py:112} INFO - [2022-02-18 00:51:06,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:23:23,575] {scheduler_job.py:155} INFO - Started process (PID=42043) to work on /airflow/dags/download_data.py
[2022-02-18 01:23:23,583] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:23:23,585] {logging_mixin.py:112} INFO - [2022-02-18 01:23:23,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:23:24,040] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:23:24,083] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:23:24,095] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:23:24,103] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 01:23:36,885] {scheduler_job.py:155} INFO - Started process (PID=42069) to work on /airflow/dags/download_data.py
[2022-02-18 01:23:36,891] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:23:36,892] {logging_mixin.py:112} INFO - [2022-02-18 01:23:36,892] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:23:37,367] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:23:37,417] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:23:37,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:23:37,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 01:23:51,055] {scheduler_job.py:155} INFO - Started process (PID=42095) to work on /airflow/dags/download_data.py
[2022-02-18 01:23:51,061] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:23:51,064] {logging_mixin.py:112} INFO - [2022-02-18 01:23:51,063] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:23:51,705] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:23:51,762] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:23:51,772] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:23:51,785] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.730 seconds
[2022-02-18 01:29:18,882] {scheduler_job.py:155} INFO - Started process (PID=42121) to work on /airflow/dags/download_data.py
[2022-02-18 01:29:18,908] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:29:18,915] {logging_mixin.py:112} INFO - [2022-02-18 01:29:18,914] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:29:19,847] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:29:19,971] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:29:19,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:29:19,990] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.108 seconds
[2022-02-18 01:29:32,187] {scheduler_job.py:155} INFO - Started process (PID=42146) to work on /airflow/dags/download_data.py
[2022-02-18 01:29:32,201] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:29:32,203] {logging_mixin.py:112} INFO - [2022-02-18 01:29:32,203] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:29:32,840] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:29:32,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:29:32,911] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:29:32,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.732 seconds
[2022-02-18 01:29:44,489] {scheduler_job.py:155} INFO - Started process (PID=42171) to work on /airflow/dags/download_data.py
[2022-02-18 01:29:44,502] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:29:44,505] {logging_mixin.py:112} INFO - [2022-02-18 01:29:44,505] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:29:45,062] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:29:45,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:29:45,142] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:29:45,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.661 seconds
[2022-02-18 01:29:57,889] {scheduler_job.py:155} INFO - Started process (PID=42197) to work on /airflow/dags/download_data.py
[2022-02-18 01:29:57,897] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:29:57,900] {logging_mixin.py:112} INFO - [2022-02-18 01:29:57,900] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:29:58,802] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:29:58,871] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:29:58,888] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:29:58,900] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.011 seconds
[2022-02-18 01:30:12,214] {scheduler_job.py:155} INFO - Started process (PID=42223) to work on /airflow/dags/download_data.py
[2022-02-18 01:30:12,224] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:30:12,226] {logging_mixin.py:112} INFO - [2022-02-18 01:30:12,226] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:30:12,831] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:30:12,877] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:30:12,887] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:30:12,894] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.681 seconds
[2022-02-18 01:30:24,443] {scheduler_job.py:155} INFO - Started process (PID=42248) to work on /airflow/dags/download_data.py
[2022-02-18 01:30:24,447] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:30:24,450] {logging_mixin.py:112} INFO - [2022-02-18 01:30:24,449] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:30:24,920] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:30:24,967] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:30:24,976] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:30:24,983] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 01:30:37,739] {scheduler_job.py:155} INFO - Started process (PID=42274) to work on /airflow/dags/download_data.py
[2022-02-18 01:30:37,746] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:30:37,749] {logging_mixin.py:112} INFO - [2022-02-18 01:30:37,749] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:30:38,200] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:30:38,244] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:30:38,253] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:30:38,257] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 01:30:50,972] {scheduler_job.py:155} INFO - Started process (PID=42300) to work on /airflow/dags/download_data.py
[2022-02-18 01:30:50,988] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:30:50,993] {logging_mixin.py:112} INFO - [2022-02-18 01:30:50,993] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:30:51,466] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:30:51,513] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:30:51,523] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:30:51,529] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 01:31:04,260] {scheduler_job.py:155} INFO - Started process (PID=42326) to work on /airflow/dags/download_data.py
[2022-02-18 01:31:04,270] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:31:04,272] {logging_mixin.py:112} INFO - [2022-02-18 01:31:04,272] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:31:04,755] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:31:04,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:31:04,809] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:31:04,813] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 01:31:17,519] {scheduler_job.py:155} INFO - Started process (PID=42352) to work on /airflow/dags/download_data.py
[2022-02-18 01:31:17,525] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:31:17,527] {logging_mixin.py:112} INFO - [2022-02-18 01:31:17,527] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:31:18,225] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:31:18,310] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:31:18,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:31:18,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.810 seconds
[2022-02-18 01:31:30,827] {scheduler_job.py:155} INFO - Started process (PID=42378) to work on /airflow/dags/download_data.py
[2022-02-18 01:31:30,833] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:31:30,834] {logging_mixin.py:112} INFO - [2022-02-18 01:31:30,834] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:31:31,397] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:31:31,460] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:31:31,474] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:31:31,485] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.658 seconds
[2022-02-18 01:31:44,117] {scheduler_job.py:155} INFO - Started process (PID=42404) to work on /airflow/dags/download_data.py
[2022-02-18 01:31:44,124] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:31:44,126] {logging_mixin.py:112} INFO - [2022-02-18 01:31:44,126] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:31:44,596] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:31:44,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:31:44,666] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:31:44,671] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 01:31:57,401] {scheduler_job.py:155} INFO - Started process (PID=42430) to work on /airflow/dags/download_data.py
[2022-02-18 01:31:57,408] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:31:57,411] {logging_mixin.py:112} INFO - [2022-02-18 01:31:57,411] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:31:57,938] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:31:58,003] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:31:58,016] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:31:58,022] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-18 01:32:10,702] {scheduler_job.py:155} INFO - Started process (PID=42456) to work on /airflow/dags/download_data.py
[2022-02-18 01:32:10,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:32:10,710] {logging_mixin.py:112} INFO - [2022-02-18 01:32:10,710] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:32:11,256] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:32:11,323] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:32:11,335] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:32:11,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 01:32:23,982] {scheduler_job.py:155} INFO - Started process (PID=42482) to work on /airflow/dags/download_data.py
[2022-02-18 01:32:23,992] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:32:23,994] {logging_mixin.py:112} INFO - [2022-02-18 01:32:23,994] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:32:24,542] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:32:24,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:32:24,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:32:24,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 01:32:37,290] {scheduler_job.py:155} INFO - Started process (PID=42508) to work on /airflow/dags/download_data.py
[2022-02-18 01:32:37,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:32:37,302] {logging_mixin.py:112} INFO - [2022-02-18 01:32:37,301] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:32:37,841] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:32:37,888] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:32:37,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:32:37,900] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 01:32:50,549] {scheduler_job.py:155} INFO - Started process (PID=42534) to work on /airflow/dags/download_data.py
[2022-02-18 01:32:50,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:32:50,557] {logging_mixin.py:112} INFO - [2022-02-18 01:32:50,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:32:51,039] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:32:51,085] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:32:51,096] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:32:51,102] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 01:33:03,919] {scheduler_job.py:155} INFO - Started process (PID=42560) to work on /airflow/dags/download_data.py
[2022-02-18 01:33:03,927] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:33:03,929] {logging_mixin.py:112} INFO - [2022-02-18 01:33:03,929] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:33:04,548] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:33:04,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:33:04,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:33:04,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.710 seconds
[2022-02-18 01:33:17,271] {scheduler_job.py:155} INFO - Started process (PID=42586) to work on /airflow/dags/download_data.py
[2022-02-18 01:33:17,275] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:33:17,277] {logging_mixin.py:112} INFO - [2022-02-18 01:33:17,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:33:17,801] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:33:17,856] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:33:17,866] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:33:17,873] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 01:33:30,568] {scheduler_job.py:155} INFO - Started process (PID=42612) to work on /airflow/dags/download_data.py
[2022-02-18 01:33:30,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:33:30,586] {logging_mixin.py:112} INFO - [2022-02-18 01:33:30,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:33:31,073] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:33:31,131] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:33:31,142] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:33:31,147] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 01:33:43,843] {scheduler_job.py:155} INFO - Started process (PID=42638) to work on /airflow/dags/download_data.py
[2022-02-18 01:33:43,862] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:33:43,865] {logging_mixin.py:112} INFO - [2022-02-18 01:33:43,864] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:33:44,392] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:33:44,453] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:33:44,464] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:33:44,471] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-18 01:33:57,162] {scheduler_job.py:155} INFO - Started process (PID=42664) to work on /airflow/dags/download_data.py
[2022-02-18 01:33:57,177] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:33:57,181] {logging_mixin.py:112} INFO - [2022-02-18 01:33:57,180] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:33:57,787] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:33:57,834] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:33:57,847] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:33:57,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.691 seconds
[2022-02-18 01:34:09,634] {scheduler_job.py:155} INFO - Started process (PID=42690) to work on /airflow/dags/download_data.py
[2022-02-18 01:34:09,639] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:34:09,641] {logging_mixin.py:112} INFO - [2022-02-18 01:34:09,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:34:10,392] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:34:10,440] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:34:10,447] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:34:10,452] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.818 seconds
[2022-02-18 01:34:17,682] {scheduler_job.py:155} INFO - Started process (PID=42716) to work on /airflow/dags/download_data.py
[2022-02-18 01:34:17,686] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:34:17,688] {logging_mixin.py:112} INFO - [2022-02-18 01:34:17,688] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:34:18,283] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:34:18,339] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:34:18,349] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:34:18,354] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-18 01:34:24,957] {scheduler_job.py:155} INFO - Started process (PID=42743) to work on /airflow/dags/download_data.py
[2022-02-18 01:34:24,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:34:24,969] {logging_mixin.py:112} INFO - [2022-02-18 01:34:24,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:34:25,475] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:34:25,610] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:34:25,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:34:25,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-18 01:34:34,030] {scheduler_job.py:155} INFO - Started process (PID=42770) to work on /airflow/dags/download_data.py
[2022-02-18 01:34:34,043] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:34:34,047] {logging_mixin.py:112} INFO - [2022-02-18 01:34:34,047] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:34:34,635] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:34:34,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:34:34,695] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:34:34,703] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.673 seconds
[2022-02-18 01:34:47,338] {scheduler_job.py:155} INFO - Started process (PID=42797) to work on /airflow/dags/download_data.py
[2022-02-18 01:34:47,347] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:34:47,348] {logging_mixin.py:112} INFO - [2022-02-18 01:34:47,348] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:34:47,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:34:47,883] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:34:47,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:34:47,899] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 01:34:59,601] {scheduler_job.py:155} INFO - Started process (PID=42822) to work on /airflow/dags/download_data.py
[2022-02-18 01:34:59,608] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:34:59,610] {logging_mixin.py:112} INFO - [2022-02-18 01:34:59,609] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:35:00,082] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:35:00,129] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:35:00,136] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:35:00,141] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 01:35:12,893] {scheduler_job.py:155} INFO - Started process (PID=42848) to work on /airflow/dags/download_data.py
[2022-02-18 01:35:12,899] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:35:12,901] {logging_mixin.py:112} INFO - [2022-02-18 01:35:12,901] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:35:13,349] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:35:13,406] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:35:13,419] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:35:13,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 01:35:26,165] {scheduler_job.py:155} INFO - Started process (PID=42874) to work on /airflow/dags/download_data.py
[2022-02-18 01:35:26,170] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:35:26,172] {logging_mixin.py:112} INFO - [2022-02-18 01:35:26,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:35:26,640] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:35:26,698] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:35:26,705] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:35:26,711] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 01:35:39,453] {scheduler_job.py:155} INFO - Started process (PID=42900) to work on /airflow/dags/download_data.py
[2022-02-18 01:35:39,460] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:35:39,462] {logging_mixin.py:112} INFO - [2022-02-18 01:35:39,462] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:35:39,915] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:35:39,958] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:35:39,968] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:35:39,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 01:35:52,712] {scheduler_job.py:155} INFO - Started process (PID=42926) to work on /airflow/dags/download_data.py
[2022-02-18 01:35:52,729] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:35:52,731] {logging_mixin.py:112} INFO - [2022-02-18 01:35:52,730] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:35:53,164] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:35:53,217] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:35:53,227] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:35:53,233] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 01:36:05,965] {scheduler_job.py:155} INFO - Started process (PID=42952) to work on /airflow/dags/download_data.py
[2022-02-18 01:36:05,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:36:05,978] {logging_mixin.py:112} INFO - [2022-02-18 01:36:05,978] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:36:06,486] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:36:06,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:36:06,543] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:36:06,548] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 01:36:19,249] {scheduler_job.py:155} INFO - Started process (PID=42978) to work on /airflow/dags/download_data.py
[2022-02-18 01:36:19,263] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:36:19,265] {logging_mixin.py:112} INFO - [2022-02-18 01:36:19,264] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:36:19,721] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:36:19,778] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:36:19,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:36:19,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 01:36:32,507] {scheduler_job.py:155} INFO - Started process (PID=43004) to work on /airflow/dags/download_data.py
[2022-02-18 01:36:32,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:36:32,513] {logging_mixin.py:112} INFO - [2022-02-18 01:36:32,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:36:32,959] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:36:33,003] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:36:33,011] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:36:33,015] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 01:36:45,813] {scheduler_job.py:155} INFO - Started process (PID=43030) to work on /airflow/dags/download_data.py
[2022-02-18 01:36:45,822] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:36:45,826] {logging_mixin.py:112} INFO - [2022-02-18 01:36:45,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:36:46,308] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:36:46,363] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:36:46,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:36:46,376] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 01:36:59,049] {scheduler_job.py:155} INFO - Started process (PID=43056) to work on /airflow/dags/download_data.py
[2022-02-18 01:36:59,054] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:36:59,055] {logging_mixin.py:112} INFO - [2022-02-18 01:36:59,055] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:36:59,501] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:36:59,554] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:36:59,565] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:36:59,569] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 01:37:12,360] {scheduler_job.py:155} INFO - Started process (PID=43082) to work on /airflow/dags/download_data.py
[2022-02-18 01:37:12,369] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:37:12,371] {logging_mixin.py:112} INFO - [2022-02-18 01:37:12,370] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:37:12,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:37:12,856] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:37:12,863] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:37:12,866] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 01:37:25,586] {scheduler_job.py:155} INFO - Started process (PID=43108) to work on /airflow/dags/download_data.py
[2022-02-18 01:37:25,591] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:37:25,592] {logging_mixin.py:112} INFO - [2022-02-18 01:37:25,592] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:37:26,052] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:37:26,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:37:26,106] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:37:26,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 01:37:38,883] {scheduler_job.py:155} INFO - Started process (PID=43134) to work on /airflow/dags/download_data.py
[2022-02-18 01:37:38,896] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:37:38,897] {logging_mixin.py:112} INFO - [2022-02-18 01:37:38,897] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:37:39,346] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:37:39,399] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:37:39,411] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:37:39,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 01:37:52,114] {scheduler_job.py:155} INFO - Started process (PID=43160) to work on /airflow/dags/download_data.py
[2022-02-18 01:37:52,118] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:37:52,120] {logging_mixin.py:112} INFO - [2022-02-18 01:37:52,120] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:37:52,573] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:37:52,617] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:37:52,627] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:37:52,632] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 01:38:05,402] {scheduler_job.py:155} INFO - Started process (PID=43186) to work on /airflow/dags/download_data.py
[2022-02-18 01:38:05,410] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:38:05,412] {logging_mixin.py:112} INFO - [2022-02-18 01:38:05,412] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:38:05,957] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:38:05,998] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:38:06,003] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:38:06,007] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 01:38:18,633] {scheduler_job.py:155} INFO - Started process (PID=43212) to work on /airflow/dags/download_data.py
[2022-02-18 01:38:18,639] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:38:18,642] {logging_mixin.py:112} INFO - [2022-02-18 01:38:18,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:38:19,116] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:38:19,178] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:38:19,190] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:38:19,198] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 01:38:31,946] {scheduler_job.py:155} INFO - Started process (PID=43238) to work on /airflow/dags/download_data.py
[2022-02-18 01:38:31,951] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:38:31,954] {logging_mixin.py:112} INFO - [2022-02-18 01:38:31,953] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:38:32,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:38:32,435] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:38:32,441] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:38:32,444] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 01:38:45,238] {scheduler_job.py:155} INFO - Started process (PID=43264) to work on /airflow/dags/download_data.py
[2022-02-18 01:38:45,243] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:38:45,245] {logging_mixin.py:112} INFO - [2022-02-18 01:38:45,245] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:38:45,743] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:38:45,795] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:38:45,805] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:38:45,809] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 01:38:58,466] {scheduler_job.py:155} INFO - Started process (PID=43290) to work on /airflow/dags/download_data.py
[2022-02-18 01:38:58,471] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:38:58,472] {logging_mixin.py:112} INFO - [2022-02-18 01:38:58,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:38:58,924] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:38:58,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:38:58,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:38:58,991] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 01:39:11,753] {scheduler_job.py:155} INFO - Started process (PID=43316) to work on /airflow/dags/download_data.py
[2022-02-18 01:39:11,757] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:39:11,759] {logging_mixin.py:112} INFO - [2022-02-18 01:39:11,759] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:39:12,202] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:39:12,251] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:39:12,257] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:39:12,262] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 01:39:25,021] {scheduler_job.py:155} INFO - Started process (PID=43342) to work on /airflow/dags/download_data.py
[2022-02-18 01:39:25,033] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:39:25,035] {logging_mixin.py:112} INFO - [2022-02-18 01:39:25,035] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:39:25,494] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:39:25,551] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:39:25,557] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:39:25,562] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 01:39:38,293] {scheduler_job.py:155} INFO - Started process (PID=43368) to work on /airflow/dags/download_data.py
[2022-02-18 01:39:38,303] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:39:38,305] {logging_mixin.py:112} INFO - [2022-02-18 01:39:38,305] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:39:38,772] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:39:38,832] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:39:38,839] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:39:38,845] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 01:39:51,526] {scheduler_job.py:155} INFO - Started process (PID=43394) to work on /airflow/dags/download_data.py
[2022-02-18 01:39:51,536] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:39:51,538] {logging_mixin.py:112} INFO - [2022-02-18 01:39:51,537] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:39:51,973] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:39:52,011] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:39:52,018] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:39:52,021] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 01:40:04,791] {scheduler_job.py:155} INFO - Started process (PID=43420) to work on /airflow/dags/download_data.py
[2022-02-18 01:40:04,796] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:40:04,799] {logging_mixin.py:112} INFO - [2022-02-18 01:40:04,799] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:40:05,261] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:40:05,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:40:05,307] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:40:05,310] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 01:40:18,082] {scheduler_job.py:155} INFO - Started process (PID=43446) to work on /airflow/dags/download_data.py
[2022-02-18 01:40:18,087] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:40:18,089] {logging_mixin.py:112} INFO - [2022-02-18 01:40:18,089] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:40:18,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:40:18,572] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:40:18,578] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:40:18,582] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 01:40:31,317] {scheduler_job.py:155} INFO - Started process (PID=43472) to work on /airflow/dags/download_data.py
[2022-02-18 01:40:31,322] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:40:31,323] {logging_mixin.py:112} INFO - [2022-02-18 01:40:31,323] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:40:31,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:40:31,817] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:40:31,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:40:31,832] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 01:40:44,613] {scheduler_job.py:155} INFO - Started process (PID=43498) to work on /airflow/dags/download_data.py
[2022-02-18 01:40:44,620] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:40:44,623] {logging_mixin.py:112} INFO - [2022-02-18 01:40:44,623] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:40:45,083] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:40:45,152] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:40:45,165] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:40:45,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 01:40:57,845] {scheduler_job.py:155} INFO - Started process (PID=43524) to work on /airflow/dags/download_data.py
[2022-02-18 01:40:57,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:40:57,851] {logging_mixin.py:112} INFO - [2022-02-18 01:40:57,851] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:40:58,290] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:40:58,329] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:40:58,336] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:40:58,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 01:41:11,163] {scheduler_job.py:155} INFO - Started process (PID=43550) to work on /airflow/dags/download_data.py
[2022-02-18 01:41:11,168] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:41:11,170] {logging_mixin.py:112} INFO - [2022-02-18 01:41:11,170] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:41:11,613] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:41:11,664] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:41:11,674] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:41:11,680] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 01:41:24,373] {scheduler_job.py:155} INFO - Started process (PID=43576) to work on /airflow/dags/download_data.py
[2022-02-18 01:41:24,378] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:41:24,380] {logging_mixin.py:112} INFO - [2022-02-18 01:41:24,380] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:41:24,833] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:41:24,884] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:41:24,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:41:24,901] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 01:41:37,642] {scheduler_job.py:155} INFO - Started process (PID=43602) to work on /airflow/dags/download_data.py
[2022-02-18 01:41:37,646] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:41:37,648] {logging_mixin.py:112} INFO - [2022-02-18 01:41:37,648] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:41:38,223] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:41:38,277] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:41:38,285] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:41:38,291] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.649 seconds
[2022-02-18 01:41:50,904] {scheduler_job.py:155} INFO - Started process (PID=43628) to work on /airflow/dags/download_data.py
[2022-02-18 01:41:50,908] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:41:50,912] {logging_mixin.py:112} INFO - [2022-02-18 01:41:50,911] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:41:51,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:41:51,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:41:51,388] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:41:51,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-18 01:42:04,164] {scheduler_job.py:155} INFO - Started process (PID=43654) to work on /airflow/dags/download_data.py
[2022-02-18 01:42:04,169] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:42:04,171] {logging_mixin.py:112} INFO - [2022-02-18 01:42:04,171] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:42:04,647] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:42:04,697] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:42:04,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:42:04,707] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 01:42:17,496] {scheduler_job.py:155} INFO - Started process (PID=43680) to work on /airflow/dags/download_data.py
[2022-02-18 01:42:17,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:42:17,506] {logging_mixin.py:112} INFO - [2022-02-18 01:42:17,506] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:42:17,995] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:42:18,049] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:42:18,060] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:42:18,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 01:42:30,713] {scheduler_job.py:155} INFO - Started process (PID=43706) to work on /airflow/dags/download_data.py
[2022-02-18 01:42:30,718] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:42:30,719] {logging_mixin.py:112} INFO - [2022-02-18 01:42:30,719] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:42:31,195] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:42:31,249] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:42:31,255] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:42:31,259] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 01:42:44,017] {scheduler_job.py:155} INFO - Started process (PID=43732) to work on /airflow/dags/download_data.py
[2022-02-18 01:42:44,025] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:42:44,027] {logging_mixin.py:112} INFO - [2022-02-18 01:42:44,027] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:42:44,491] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:42:44,534] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:42:44,542] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:42:44,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 01:42:57,256] {scheduler_job.py:155} INFO - Started process (PID=43758) to work on /airflow/dags/download_data.py
[2022-02-18 01:42:57,263] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:42:57,265] {logging_mixin.py:112} INFO - [2022-02-18 01:42:57,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:42:57,703] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:42:57,744] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:42:57,754] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:42:57,758] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 01:43:10,533] {scheduler_job.py:155} INFO - Started process (PID=43784) to work on /airflow/dags/download_data.py
[2022-02-18 01:43:10,542] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:43:10,544] {logging_mixin.py:112} INFO - [2022-02-18 01:43:10,544] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:43:10,992] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:43:11,044] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:43:11,054] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:43:11,059] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 01:43:23,782] {scheduler_job.py:155} INFO - Started process (PID=43810) to work on /airflow/dags/download_data.py
[2022-02-18 01:43:23,788] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:43:23,789] {logging_mixin.py:112} INFO - [2022-02-18 01:43:23,789] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:43:24,235] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:43:24,289] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:43:24,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:43:24,301] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 01:43:37,059] {scheduler_job.py:155} INFO - Started process (PID=43836) to work on /airflow/dags/download_data.py
[2022-02-18 01:43:37,063] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:43:37,065] {logging_mixin.py:112} INFO - [2022-02-18 01:43:37,064] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:43:37,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:43:37,557] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:43:37,568] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:43:37,575] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 01:43:50,337] {scheduler_job.py:155} INFO - Started process (PID=43862) to work on /airflow/dags/download_data.py
[2022-02-18 01:43:50,341] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:43:50,344] {logging_mixin.py:112} INFO - [2022-02-18 01:43:50,343] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:43:50,793] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:43:50,844] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:43:50,851] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:43:50,858] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 01:44:03,596] {scheduler_job.py:155} INFO - Started process (PID=43888) to work on /airflow/dags/download_data.py
[2022-02-18 01:44:03,599] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:44:03,601] {logging_mixin.py:112} INFO - [2022-02-18 01:44:03,601] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:44:04,051] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:44:04,095] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:44:04,101] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:44:04,104] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 01:44:16,879] {scheduler_job.py:155} INFO - Started process (PID=43914) to work on /airflow/dags/download_data.py
[2022-02-18 01:44:16,885] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:44:16,886] {logging_mixin.py:112} INFO - [2022-02-18 01:44:16,886] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:44:17,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:44:17,399] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:44:17,412] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:44:17,419] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 01:44:30,159] {scheduler_job.py:155} INFO - Started process (PID=43940) to work on /airflow/dags/download_data.py
[2022-02-18 01:44:30,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:44:30,165] {logging_mixin.py:112} INFO - [2022-02-18 01:44:30,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:44:30,603] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:44:30,654] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:44:30,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:44:30,667] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 01:44:43,451] {scheduler_job.py:155} INFO - Started process (PID=43966) to work on /airflow/dags/download_data.py
[2022-02-18 01:44:43,457] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:44:43,458] {logging_mixin.py:112} INFO - [2022-02-18 01:44:43,458] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:44:43,938] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:44:43,997] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:44:44,004] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:44:44,011] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 01:44:56,696] {scheduler_job.py:155} INFO - Started process (PID=43992) to work on /airflow/dags/download_data.py
[2022-02-18 01:44:56,706] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:44:56,708] {logging_mixin.py:112} INFO - [2022-02-18 01:44:56,707] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:44:57,151] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:44:57,199] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:44:57,209] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:44:57,215] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 01:45:09,969] {scheduler_job.py:155} INFO - Started process (PID=44018) to work on /airflow/dags/download_data.py
[2022-02-18 01:45:09,975] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:45:09,977] {logging_mixin.py:112} INFO - [2022-02-18 01:45:09,976] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:45:10,468] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:45:10,527] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:45:10,539] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:45:10,544] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 01:45:23,211] {scheduler_job.py:155} INFO - Started process (PID=44044) to work on /airflow/dags/download_data.py
[2022-02-18 01:45:23,220] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:45:23,222] {logging_mixin.py:112} INFO - [2022-02-18 01:45:23,222] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:45:23,657] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:45:23,702] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:45:23,712] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:45:23,718] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 01:45:36,459] {scheduler_job.py:155} INFO - Started process (PID=44070) to work on /airflow/dags/download_data.py
[2022-02-18 01:45:36,465] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:45:36,467] {logging_mixin.py:112} INFO - [2022-02-18 01:45:36,467] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:45:37,008] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:45:37,053] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:45:37,060] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:45:37,066] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-18 01:45:49,700] {scheduler_job.py:155} INFO - Started process (PID=44096) to work on /airflow/dags/download_data.py
[2022-02-18 01:45:49,704] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:45:49,706] {logging_mixin.py:112} INFO - [2022-02-18 01:45:49,705] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:45:50,165] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:45:50,217] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:45:50,225] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:45:50,229] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 01:46:02,966] {scheduler_job.py:155} INFO - Started process (PID=44122) to work on /airflow/dags/download_data.py
[2022-02-18 01:46:02,973] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:46:02,975] {logging_mixin.py:112} INFO - [2022-02-18 01:46:02,975] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:46:03,410] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:46:03,462] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:46:03,471] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:46:03,476] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 01:46:16,260] {scheduler_job.py:155} INFO - Started process (PID=44148) to work on /airflow/dags/download_data.py
[2022-02-18 01:46:16,271] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:46:16,273] {logging_mixin.py:112} INFO - [2022-02-18 01:46:16,273] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:46:16,738] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:46:16,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:46:16,810] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:46:16,815] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 01:46:29,472] {scheduler_job.py:155} INFO - Started process (PID=44174) to work on /airflow/dags/download_data.py
[2022-02-18 01:46:29,481] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:46:29,483] {logging_mixin.py:112} INFO - [2022-02-18 01:46:29,483] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:46:29,935] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:46:29,982] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:46:29,990] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:46:29,996] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 01:46:42,793] {scheduler_job.py:155} INFO - Started process (PID=44200) to work on /airflow/dags/download_data.py
[2022-02-18 01:46:42,799] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:46:42,801] {logging_mixin.py:112} INFO - [2022-02-18 01:46:42,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:46:43,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:46:43,332] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:46:43,343] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:46:43,347] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 01:46:56,026] {scheduler_job.py:155} INFO - Started process (PID=44226) to work on /airflow/dags/download_data.py
[2022-02-18 01:46:56,038] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:46:56,045] {logging_mixin.py:112} INFO - [2022-02-18 01:46:56,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:46:56,523] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:46:56,620] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:46:56,629] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:46:56,634] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 01:47:09,288] {scheduler_job.py:155} INFO - Started process (PID=44252) to work on /airflow/dags/download_data.py
[2022-02-18 01:47:09,292] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:47:09,294] {logging_mixin.py:112} INFO - [2022-02-18 01:47:09,294] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:47:09,790] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:47:09,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:47:09,835] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:47:09,839] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 01:47:22,595] {scheduler_job.py:155} INFO - Started process (PID=44278) to work on /airflow/dags/download_data.py
[2022-02-18 01:47:22,608] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:47:22,611] {logging_mixin.py:112} INFO - [2022-02-18 01:47:22,611] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:47:23,062] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:47:23,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:47:23,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:47:23,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 01:47:35,890] {scheduler_job.py:155} INFO - Started process (PID=44304) to work on /airflow/dags/download_data.py
[2022-02-18 01:47:35,895] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:47:35,898] {logging_mixin.py:112} INFO - [2022-02-18 01:47:35,897] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:47:36,330] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:47:36,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:47:36,385] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:47:36,389] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 01:47:49,203] {scheduler_job.py:155} INFO - Started process (PID=44330) to work on /airflow/dags/download_data.py
[2022-02-18 01:47:49,208] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:47:49,210] {logging_mixin.py:112} INFO - [2022-02-18 01:47:49,209] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:47:49,649] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:47:49,701] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:47:49,707] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:47:49,710] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 01:48:03,766] {scheduler_job.py:155} INFO - Started process (PID=44356) to work on /airflow/dags/download_data.py
[2022-02-18 01:48:03,773] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:48:03,792] {logging_mixin.py:112} INFO - [2022-02-18 01:48:03,791] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:48:04,309] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:48:04,362] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:48:04,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:48:04,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 01:48:17,165] {scheduler_job.py:155} INFO - Started process (PID=44382) to work on /airflow/dags/download_data.py
[2022-02-18 01:48:17,172] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:48:17,174] {logging_mixin.py:112} INFO - [2022-02-18 01:48:17,174] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:48:55,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:48:56,020] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:48:56,043] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:48:56,057] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 38.893 seconds
[2022-02-18 01:49:09,210] {scheduler_job.py:155} INFO - Started process (PID=44408) to work on /airflow/dags/download_data.py
[2022-02-18 01:49:09,214] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:49:09,216] {logging_mixin.py:112} INFO - [2022-02-18 01:49:09,216] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:49:09,738] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:49:09,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:49:09,784] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:49:09,790] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 01:49:21,511] {scheduler_job.py:155} INFO - Started process (PID=44433) to work on /airflow/dags/download_data.py
[2022-02-18 01:49:21,518] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:49:21,520] {logging_mixin.py:112} INFO - [2022-02-18 01:49:21,520] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:49:21,999] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:49:22,041] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:49:22,049] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:49:22,054] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 01:49:34,759] {scheduler_job.py:155} INFO - Started process (PID=44459) to work on /airflow/dags/download_data.py
[2022-02-18 01:49:34,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:49:34,765] {logging_mixin.py:112} INFO - [2022-02-18 01:49:34,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:49:35,251] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:49:35,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:49:35,324] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:49:35,330] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 01:49:48,057] {scheduler_job.py:155} INFO - Started process (PID=44485) to work on /airflow/dags/download_data.py
[2022-02-18 01:49:48,070] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:49:48,073] {logging_mixin.py:112} INFO - [2022-02-18 01:49:48,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:49:48,561] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:49:48,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:49:48,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:49:48,627] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 01:50:01,302] {scheduler_job.py:155} INFO - Started process (PID=44511) to work on /airflow/dags/download_data.py
[2022-02-18 01:50:01,309] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:50:01,311] {logging_mixin.py:112} INFO - [2022-02-18 01:50:01,311] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:50:01,775] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:50:01,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:50:01,834] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:50:01,838] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 01:50:14,619] {scheduler_job.py:155} INFO - Started process (PID=44537) to work on /airflow/dags/download_data.py
[2022-02-18 01:50:14,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:50:14,637] {logging_mixin.py:112} INFO - [2022-02-18 01:50:14,637] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:50:18,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:50:18,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:50:18,667] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:50:18,687] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 4.068 seconds
[2022-02-18 01:50:30,238] {scheduler_job.py:155} INFO - Started process (PID=44563) to work on /airflow/dags/download_data.py
[2022-02-18 01:50:30,249] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:50:30,251] {logging_mixin.py:112} INFO - [2022-02-18 01:50:30,250] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:50:30,704] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:50:30,752] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:50:30,759] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:50:30,763] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 01:50:42,512] {scheduler_job.py:155} INFO - Started process (PID=44588) to work on /airflow/dags/download_data.py
[2022-02-18 01:50:42,523] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:50:42,526] {logging_mixin.py:112} INFO - [2022-02-18 01:50:42,525] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:50:43,017] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:50:43,064] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:50:43,078] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:50:43,083] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 01:50:55,741] {scheduler_job.py:155} INFO - Started process (PID=44614) to work on /airflow/dags/download_data.py
[2022-02-18 01:50:55,745] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:50:55,749] {logging_mixin.py:112} INFO - [2022-02-18 01:50:55,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:50:56,209] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:50:56,260] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:50:56,272] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:50:56,278] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 01:51:09,092] {scheduler_job.py:155} INFO - Started process (PID=44640) to work on /airflow/dags/download_data.py
[2022-02-18 01:51:09,101] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:51:09,110] {logging_mixin.py:112} INFO - [2022-02-18 01:51:09,103] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:51:09,588] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:51:09,628] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:51:09,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:51:09,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 01:51:22,379] {scheduler_job.py:155} INFO - Started process (PID=44666) to work on /airflow/dags/download_data.py
[2022-02-18 01:51:22,384] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:51:22,386] {logging_mixin.py:112} INFO - [2022-02-18 01:51:22,386] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:51:22,852] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:51:22,893] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:51:22,899] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:51:22,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 01:51:35,619] {scheduler_job.py:155} INFO - Started process (PID=44692) to work on /airflow/dags/download_data.py
[2022-02-18 01:51:35,624] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:51:35,626] {logging_mixin.py:112} INFO - [2022-02-18 01:51:35,625] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:51:36,089] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:51:36,133] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:51:36,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:51:36,149] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 01:51:48,896] {scheduler_job.py:155} INFO - Started process (PID=44718) to work on /airflow/dags/download_data.py
[2022-02-18 01:51:48,902] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:51:48,904] {logging_mixin.py:112} INFO - [2022-02-18 01:51:48,904] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:51:49,368] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:51:49,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:51:49,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:51:49,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 01:52:02,127] {scheduler_job.py:155} INFO - Started process (PID=44744) to work on /airflow/dags/download_data.py
[2022-02-18 01:52:02,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:52:02,133] {logging_mixin.py:112} INFO - [2022-02-18 01:52:02,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:52:02,583] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:52:02,623] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:52:02,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:52:02,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 01:52:15,393] {scheduler_job.py:155} INFO - Started process (PID=44770) to work on /airflow/dags/download_data.py
[2022-02-18 01:52:15,400] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:52:15,402] {logging_mixin.py:112} INFO - [2022-02-18 01:52:15,401] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:52:15,927] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:52:15,987] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:52:16,001] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:52:16,006] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 01:52:28,652] {scheduler_job.py:155} INFO - Started process (PID=44796) to work on /airflow/dags/download_data.py
[2022-02-18 01:52:28,659] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:52:28,662] {logging_mixin.py:112} INFO - [2022-02-18 01:52:28,662] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:52:29,108] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:52:29,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:52:29,153] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:52:29,156] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 01:52:41,950] {scheduler_job.py:155} INFO - Started process (PID=44822) to work on /airflow/dags/download_data.py
[2022-02-18 01:52:41,960] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:52:41,962] {logging_mixin.py:112} INFO - [2022-02-18 01:52:41,962] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:52:42,405] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:52:42,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:52:42,464] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:52:42,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 01:52:55,202] {scheduler_job.py:155} INFO - Started process (PID=44848) to work on /airflow/dags/download_data.py
[2022-02-18 01:52:55,207] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:52:55,209] {logging_mixin.py:112} INFO - [2022-02-18 01:52:55,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:52:55,671] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:52:55,726] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:52:55,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:52:55,743] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 01:53:08,483] {scheduler_job.py:155} INFO - Started process (PID=44874) to work on /airflow/dags/download_data.py
[2022-02-18 01:53:08,488] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:53:08,489] {logging_mixin.py:112} INFO - [2022-02-18 01:53:08,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:53:08,921] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:53:08,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:53:08,983] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:53:08,989] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 01:53:22,592] {scheduler_job.py:155} INFO - Started process (PID=44900) to work on /airflow/dags/download_data.py
[2022-02-18 01:53:22,599] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:53:22,604] {logging_mixin.py:112} INFO - [2022-02-18 01:53:22,604] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:53:23,435] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:53:23,511] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:53:23,524] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:53:23,531] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.940 seconds
[2022-02-18 01:56:38,494] {scheduler_job.py:155} INFO - Started process (PID=44926) to work on /airflow/dags/download_data.py
[2022-02-18 01:56:38,507] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:56:38,509] {logging_mixin.py:112} INFO - [2022-02-18 01:56:38,509] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:56:39,322] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:56:39,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:56:39,422] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:56:39,429] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.936 seconds
[2022-02-18 01:56:51,781] {scheduler_job.py:155} INFO - Started process (PID=44952) to work on /airflow/dags/download_data.py
[2022-02-18 01:56:51,785] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:56:51,787] {logging_mixin.py:112} INFO - [2022-02-18 01:56:51,787] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:56:52,614] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:56:52,657] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:56:52,666] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:56:52,672] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.891 seconds
[2022-02-18 01:57:05,315] {scheduler_job.py:155} INFO - Started process (PID=44978) to work on /airflow/dags/download_data.py
[2022-02-18 01:57:05,322] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:57:05,325] {logging_mixin.py:112} INFO - [2022-02-18 01:57:05,324] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:57:05,838] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:57:05,888] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:57:05,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:57:05,901] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 01:57:18,599] {scheduler_job.py:155} INFO - Started process (PID=45004) to work on /airflow/dags/download_data.py
[2022-02-18 01:57:18,609] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:57:18,612] {logging_mixin.py:112} INFO - [2022-02-18 01:57:18,612] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:57:19,376] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:57:19,417] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:57:19,437] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:57:19,444] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.845 seconds
[2022-02-18 01:57:31,920] {scheduler_job.py:155} INFO - Started process (PID=45030) to work on /airflow/dags/download_data.py
[2022-02-18 01:57:31,934] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:57:31,937] {logging_mixin.py:112} INFO - [2022-02-18 01:57:31,937] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:57:32,795] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:57:32,882] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:57:32,908] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:57:32,928] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.008 seconds
[2022-02-18 01:57:46,190] {scheduler_job.py:155} INFO - Started process (PID=45056) to work on /airflow/dags/download_data.py
[2022-02-18 01:57:46,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:57:46,202] {logging_mixin.py:112} INFO - [2022-02-18 01:57:46,201] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:57:46,731] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:57:46,774] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:57:46,779] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:57:46,785] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 01:57:58,414] {scheduler_job.py:155} INFO - Started process (PID=45081) to work on /airflow/dags/download_data.py
[2022-02-18 01:57:58,420] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:57:58,422] {logging_mixin.py:112} INFO - [2022-02-18 01:57:58,422] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:57:58,933] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:57:58,978] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:57:58,985] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:57:58,991] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 01:58:11,722] {scheduler_job.py:155} INFO - Started process (PID=45107) to work on /airflow/dags/download_data.py
[2022-02-18 01:58:11,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:58:11,734] {logging_mixin.py:112} INFO - [2022-02-18 01:58:11,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:58:12,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:58:12,267] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:58:12,274] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:58:12,278] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 01:58:25,007] {scheduler_job.py:155} INFO - Started process (PID=45133) to work on /airflow/dags/download_data.py
[2022-02-18 01:58:25,015] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:58:25,018] {logging_mixin.py:112} INFO - [2022-02-18 01:58:25,017] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:58:25,519] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:58:25,576] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:58:25,585] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:58:25,594] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 01:58:38,286] {scheduler_job.py:155} INFO - Started process (PID=45159) to work on /airflow/dags/download_data.py
[2022-02-18 01:58:38,292] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:58:38,294] {logging_mixin.py:112} INFO - [2022-02-18 01:58:38,294] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:58:38,857] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:58:38,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:58:38,941] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:58:38,969] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.683 seconds
[2022-02-18 01:58:51,609] {scheduler_job.py:155} INFO - Started process (PID=45185) to work on /airflow/dags/download_data.py
[2022-02-18 01:58:51,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:58:51,616] {logging_mixin.py:112} INFO - [2022-02-18 01:58:51,616] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:58:52,178] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:58:52,224] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:58:52,234] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:58:52,240] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-18 01:59:04,889] {scheduler_job.py:155} INFO - Started process (PID=45211) to work on /airflow/dags/download_data.py
[2022-02-18 01:59:04,895] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:59:04,897] {logging_mixin.py:112} INFO - [2022-02-18 01:59:04,897] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:59:05,393] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:59:05,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:59:05,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:59:05,454] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 01:59:18,193] {scheduler_job.py:155} INFO - Started process (PID=45237) to work on /airflow/dags/download_data.py
[2022-02-18 01:59:18,200] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:59:18,203] {logging_mixin.py:112} INFO - [2022-02-18 01:59:18,202] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:59:18,721] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:59:18,776] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:59:18,785] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:59:18,789] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 01:59:31,418] {scheduler_job.py:155} INFO - Started process (PID=45263) to work on /airflow/dags/download_data.py
[2022-02-18 01:59:31,423] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:59:31,424] {logging_mixin.py:112} INFO - [2022-02-18 01:59:31,424] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:59:31,861] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:59:31,911] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:59:31,919] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:59:31,926] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 01:59:44,703] {scheduler_job.py:155} INFO - Started process (PID=45289) to work on /airflow/dags/download_data.py
[2022-02-18 01:59:44,708] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:59:44,709] {logging_mixin.py:112} INFO - [2022-02-18 01:59:44,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:59:45,148] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:59:45,197] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:59:45,207] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:59:45,212] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 01:59:57,949] {scheduler_job.py:155} INFO - Started process (PID=45315) to work on /airflow/dags/download_data.py
[2022-02-18 01:59:57,956] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 01:59:57,959] {logging_mixin.py:112} INFO - [2022-02-18 01:59:57,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 01:59:58,418] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 01:59:58,479] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 01:59:58,492] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 01:59:58,499] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 02:00:11,258] {scheduler_job.py:155} INFO - Started process (PID=45341) to work on /airflow/dags/download_data.py
[2022-02-18 02:00:11,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:00:11,268] {logging_mixin.py:112} INFO - [2022-02-18 02:00:11,268] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:00:11,730] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:00:11,784] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:00:11,790] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:00:11,797] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 02:00:24,543] {scheduler_job.py:155} INFO - Started process (PID=45367) to work on /airflow/dags/download_data.py
[2022-02-18 02:00:24,548] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:00:24,549] {logging_mixin.py:112} INFO - [2022-02-18 02:00:24,549] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:00:25,021] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:00:25,078] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:00:25,086] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:00:25,090] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 02:00:37,779] {scheduler_job.py:155} INFO - Started process (PID=45393) to work on /airflow/dags/download_data.py
[2022-02-18 02:00:37,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:00:37,785] {logging_mixin.py:112} INFO - [2022-02-18 02:00:37,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:00:38,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:00:38,272] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:00:38,278] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:00:38,281] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 02:00:51,060] {scheduler_job.py:155} INFO - Started process (PID=45419) to work on /airflow/dags/download_data.py
[2022-02-18 02:00:51,065] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:00:51,067] {logging_mixin.py:112} INFO - [2022-02-18 02:00:51,067] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:00:51,566] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:00:51,615] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:00:51,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:00:51,627] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 02:01:04,321] {scheduler_job.py:155} INFO - Started process (PID=45445) to work on /airflow/dags/download_data.py
[2022-02-18 02:01:04,328] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:01:04,330] {logging_mixin.py:112} INFO - [2022-02-18 02:01:04,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:01:04,761] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:01:04,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:01:04,813] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:01:04,817] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 02:01:17,574] {scheduler_job.py:155} INFO - Started process (PID=45471) to work on /airflow/dags/download_data.py
[2022-02-18 02:01:17,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:01:17,580] {logging_mixin.py:112} INFO - [2022-02-18 02:01:17,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:01:18,024] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:01:18,074] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:01:18,081] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:01:18,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 02:01:30,861] {scheduler_job.py:155} INFO - Started process (PID=45497) to work on /airflow/dags/download_data.py
[2022-02-18 02:01:30,865] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:01:30,867] {logging_mixin.py:112} INFO - [2022-02-18 02:01:30,866] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:01:31,334] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:01:31,379] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:01:31,387] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:01:31,391] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 02:01:44,178] {scheduler_job.py:155} INFO - Started process (PID=45523) to work on /airflow/dags/download_data.py
[2022-02-18 02:01:44,182] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:01:44,184] {logging_mixin.py:112} INFO - [2022-02-18 02:01:44,184] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:01:44,619] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:01:44,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:01:44,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:01:44,677] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 02:25:23,258] {scheduler_job.py:155} INFO - Started process (PID=45549) to work on /airflow/dags/download_data.py
[2022-02-18 02:25:23,268] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:25:23,270] {logging_mixin.py:112} INFO - [2022-02-18 02:25:23,270] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:25:23,770] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:25:23,903] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:25:23,917] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:25:23,923] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.665 seconds
[2022-02-18 02:25:36,596] {scheduler_job.py:155} INFO - Started process (PID=45575) to work on /airflow/dags/download_data.py
[2022-02-18 02:25:36,605] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:25:36,611] {logging_mixin.py:112} INFO - [2022-02-18 02:25:36,610] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:25:37,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:25:37,290] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:25:37,300] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:25:37,305] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.709 seconds
[2022-02-18 02:25:49,902] {scheduler_job.py:155} INFO - Started process (PID=45601) to work on /airflow/dags/download_data.py
[2022-02-18 02:25:49,914] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:25:49,916] {logging_mixin.py:112} INFO - [2022-02-18 02:25:49,916] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:25:50,564] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:25:50,625] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:25:50,638] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:25:50,645] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.742 seconds
[2022-02-18 02:26:03,775] {scheduler_job.py:155} INFO - Started process (PID=45627) to work on /airflow/dags/download_data.py
[2022-02-18 02:26:03,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:26:03,787] {logging_mixin.py:112} INFO - [2022-02-18 02:26:03,786] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:26:04,284] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:26:04,345] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:26:04,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:26:04,359] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 02:26:17,050] {scheduler_job.py:155} INFO - Started process (PID=45653) to work on /airflow/dags/download_data.py
[2022-02-18 02:26:17,059] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:26:17,063] {logging_mixin.py:112} INFO - [2022-02-18 02:26:17,063] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:26:17,654] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:26:17,726] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:26:17,737] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:26:17,743] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.693 seconds
[2022-02-18 02:26:30,329] {scheduler_job.py:155} INFO - Started process (PID=45679) to work on /airflow/dags/download_data.py
[2022-02-18 02:26:30,334] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:26:30,335] {logging_mixin.py:112} INFO - [2022-02-18 02:26:30,335] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:26:30,802] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:26:30,846] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:26:30,853] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:26:30,856] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 02:26:43,614] {scheduler_job.py:155} INFO - Started process (PID=45705) to work on /airflow/dags/download_data.py
[2022-02-18 02:26:43,619] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:26:43,621] {logging_mixin.py:112} INFO - [2022-02-18 02:26:43,621] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:26:44,115] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:26:44,155] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:26:44,163] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:26:44,169] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 02:26:56,895] {scheduler_job.py:155} INFO - Started process (PID=45731) to work on /airflow/dags/download_data.py
[2022-02-18 02:26:56,905] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:26:56,907] {logging_mixin.py:112} INFO - [2022-02-18 02:26:56,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:26:57,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:26:57,447] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:26:57,458] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:26:57,465] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 02:27:10,162] {scheduler_job.py:155} INFO - Started process (PID=45757) to work on /airflow/dags/download_data.py
[2022-02-18 02:27:10,167] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:27:10,169] {logging_mixin.py:112} INFO - [2022-02-18 02:27:10,169] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:27:10,644] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:27:10,681] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:27:10,689] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:27:10,693] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 02:27:23,406] {scheduler_job.py:155} INFO - Started process (PID=45783) to work on /airflow/dags/download_data.py
[2022-02-18 02:27:23,418] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:27:23,420] {logging_mixin.py:112} INFO - [2022-02-18 02:27:23,420] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:27:23,929] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:27:23,983] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:27:23,989] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:27:23,992] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 02:27:36,745] {scheduler_job.py:155} INFO - Started process (PID=45809) to work on /airflow/dags/download_data.py
[2022-02-18 02:27:36,751] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:27:36,753] {logging_mixin.py:112} INFO - [2022-02-18 02:27:36,752] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:27:37,222] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:27:37,274] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:27:37,284] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:27:37,291] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 02:27:50,032] {scheduler_job.py:155} INFO - Started process (PID=45835) to work on /airflow/dags/download_data.py
[2022-02-18 02:27:50,043] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:27:50,046] {logging_mixin.py:112} INFO - [2022-02-18 02:27:50,045] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:27:50,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:27:50,573] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:27:50,578] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:27:50,584] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 02:28:03,289] {scheduler_job.py:155} INFO - Started process (PID=45861) to work on /airflow/dags/download_data.py
[2022-02-18 02:28:03,293] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:28:03,295] {logging_mixin.py:112} INFO - [2022-02-18 02:28:03,294] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:28:03,734] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:28:03,786] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:28:03,797] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:28:03,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 02:28:16,598] {scheduler_job.py:155} INFO - Started process (PID=45887) to work on /airflow/dags/download_data.py
[2022-02-18 02:28:16,608] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:28:16,611] {logging_mixin.py:112} INFO - [2022-02-18 02:28:16,611] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:28:17,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:28:17,139] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:28:17,153] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:28:17,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 02:28:29,885] {scheduler_job.py:155} INFO - Started process (PID=45913) to work on /airflow/dags/download_data.py
[2022-02-18 02:28:29,892] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:28:29,894] {logging_mixin.py:112} INFO - [2022-02-18 02:28:29,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:28:30,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:28:30,396] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:28:30,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:28:30,410] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 02:28:43,169] {scheduler_job.py:155} INFO - Started process (PID=45939) to work on /airflow/dags/download_data.py
[2022-02-18 02:28:43,173] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:28:43,181] {logging_mixin.py:112} INFO - [2022-02-18 02:28:43,178] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:28:43,610] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:28:43,650] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:28:43,658] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:28:43,662] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 02:28:56,420] {scheduler_job.py:155} INFO - Started process (PID=45965) to work on /airflow/dags/download_data.py
[2022-02-18 02:28:56,425] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:28:56,427] {logging_mixin.py:112} INFO - [2022-02-18 02:28:56,427] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:28:56,887] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:28:56,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:28:56,945] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:28:56,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 02:29:09,733] {scheduler_job.py:155} INFO - Started process (PID=45991) to work on /airflow/dags/download_data.py
[2022-02-18 02:29:09,737] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:29:09,738] {logging_mixin.py:112} INFO - [2022-02-18 02:29:09,738] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:29:10,162] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:29:10,204] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:29:10,213] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:29:10,219] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.487 seconds
[2022-02-18 02:29:22,963] {scheduler_job.py:155} INFO - Started process (PID=46017) to work on /airflow/dags/download_data.py
[2022-02-18 02:29:22,969] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:29:22,971] {logging_mixin.py:112} INFO - [2022-02-18 02:29:22,971] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:29:23,445] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:29:23,498] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:29:23,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:29:23,519] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 02:29:36,259] {scheduler_job.py:155} INFO - Started process (PID=46043) to work on /airflow/dags/download_data.py
[2022-02-18 02:29:36,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:29:36,266] {logging_mixin.py:112} INFO - [2022-02-18 02:29:36,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:29:36,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:29:36,799] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:29:36,810] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:29:36,816] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 02:29:49,559] {scheduler_job.py:155} INFO - Started process (PID=46069) to work on /airflow/dags/download_data.py
[2022-02-18 02:29:49,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:29:49,570] {logging_mixin.py:112} INFO - [2022-02-18 02:29:49,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:29:50,074] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:29:50,133] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:29:50,141] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:29:50,149] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 02:30:02,870] {scheduler_job.py:155} INFO - Started process (PID=46095) to work on /airflow/dags/download_data.py
[2022-02-18 02:30:02,878] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:30:02,880] {logging_mixin.py:112} INFO - [2022-02-18 02:30:02,879] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:30:03,335] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:30:03,382] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:30:03,391] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:30:03,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 02:30:16,141] {scheduler_job.py:155} INFO - Started process (PID=46121) to work on /airflow/dags/download_data.py
[2022-02-18 02:30:16,146] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:30:16,148] {logging_mixin.py:112} INFO - [2022-02-18 02:30:16,148] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:30:16,619] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:30:16,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:30:16,696] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:30:16,703] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 02:30:29,413] {scheduler_job.py:155} INFO - Started process (PID=46147) to work on /airflow/dags/download_data.py
[2022-02-18 02:30:29,419] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:30:29,422] {logging_mixin.py:112} INFO - [2022-02-18 02:30:29,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:30:29,895] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:30:29,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:30:29,952] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:30:29,957] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 02:30:42,716] {scheduler_job.py:155} INFO - Started process (PID=46173) to work on /airflow/dags/download_data.py
[2022-02-18 02:30:42,721] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:30:42,723] {logging_mixin.py:112} INFO - [2022-02-18 02:30:42,723] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:30:43,181] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:30:43,223] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:30:43,229] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:30:43,233] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 02:30:55,965] {scheduler_job.py:155} INFO - Started process (PID=46199) to work on /airflow/dags/download_data.py
[2022-02-18 02:30:55,974] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:30:55,976] {logging_mixin.py:112} INFO - [2022-02-18 02:30:55,976] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:30:56,434] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:30:56,485] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:30:56,492] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:30:56,499] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 02:31:09,315] {scheduler_job.py:155} INFO - Started process (PID=46225) to work on /airflow/dags/download_data.py
[2022-02-18 02:31:09,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:31:09,327] {logging_mixin.py:112} INFO - [2022-02-18 02:31:09,327] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:31:09,802] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:31:09,858] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:31:09,868] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:31:09,873] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 02:31:22,702] {scheduler_job.py:155} INFO - Started process (PID=46251) to work on /airflow/dags/download_data.py
[2022-02-18 02:31:22,712] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:31:22,715] {logging_mixin.py:112} INFO - [2022-02-18 02:31:22,714] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:31:23,366] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:31:23,453] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:31:23,463] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:31:23,471] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.769 seconds
[2022-02-18 02:31:36,001] {scheduler_job.py:155} INFO - Started process (PID=46277) to work on /airflow/dags/download_data.py
[2022-02-18 02:31:36,009] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:31:36,011] {logging_mixin.py:112} INFO - [2022-02-18 02:31:36,011] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:31:36,670] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:31:36,710] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:31:36,717] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:31:36,721] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.720 seconds
[2022-02-18 02:31:49,297] {scheduler_job.py:155} INFO - Started process (PID=46303) to work on /airflow/dags/download_data.py
[2022-02-18 02:31:49,308] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:31:49,311] {logging_mixin.py:112} INFO - [2022-02-18 02:31:49,310] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:31:49,788] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:31:49,846] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:31:49,856] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:31:49,861] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 02:32:02,566] {scheduler_job.py:155} INFO - Started process (PID=46329) to work on /airflow/dags/download_data.py
[2022-02-18 02:32:02,572] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:32:02,573] {logging_mixin.py:112} INFO - [2022-02-18 02:32:02,573] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:32:03,036] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:32:03,085] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:32:03,093] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:32:03,098] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 02:32:15,850] {scheduler_job.py:155} INFO - Started process (PID=46355) to work on /airflow/dags/download_data.py
[2022-02-18 02:32:15,855] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:32:15,857] {logging_mixin.py:112} INFO - [2022-02-18 02:32:15,857] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:32:16,339] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:32:16,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:32:16,395] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:32:16,400] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 02:32:29,113] {scheduler_job.py:155} INFO - Started process (PID=46381) to work on /airflow/dags/download_data.py
[2022-02-18 02:32:29,121] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:32:29,123] {logging_mixin.py:112} INFO - [2022-02-18 02:32:29,123] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:32:29,574] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:32:29,628] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:32:29,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:32:29,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 02:32:42,366] {scheduler_job.py:155} INFO - Started process (PID=46407) to work on /airflow/dags/download_data.py
[2022-02-18 02:32:42,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:32:42,375] {logging_mixin.py:112} INFO - [2022-02-18 02:32:42,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:32:42,836] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:32:42,889] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:32:42,896] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:32:42,899] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 02:32:55,614] {scheduler_job.py:155} INFO - Started process (PID=46433) to work on /airflow/dags/download_data.py
[2022-02-18 02:32:55,622] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:32:55,625] {logging_mixin.py:112} INFO - [2022-02-18 02:32:55,624] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:32:56,058] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:32:56,099] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:32:56,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:32:56,115] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 02:33:08,912] {scheduler_job.py:155} INFO - Started process (PID=46459) to work on /airflow/dags/download_data.py
[2022-02-18 02:33:08,922] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:33:08,924] {logging_mixin.py:112} INFO - [2022-02-18 02:33:08,924] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:33:09,361] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:33:09,408] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:33:09,420] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:33:09,425] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 02:33:22,199] {scheduler_job.py:155} INFO - Started process (PID=46485) to work on /airflow/dags/download_data.py
[2022-02-18 02:33:22,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:33:22,209] {logging_mixin.py:112} INFO - [2022-02-18 02:33:22,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:33:22,632] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:33:22,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:33:22,696] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:33:22,705] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 02:33:35,498] {scheduler_job.py:155} INFO - Started process (PID=46511) to work on /airflow/dags/download_data.py
[2022-02-18 02:33:35,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:33:35,505] {logging_mixin.py:112} INFO - [2022-02-18 02:33:35,505] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:33:35,940] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:33:35,995] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:33:36,006] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:33:36,012] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 02:33:48,798] {scheduler_job.py:155} INFO - Started process (PID=46537) to work on /airflow/dags/download_data.py
[2022-02-18 02:33:48,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:33:48,811] {logging_mixin.py:112} INFO - [2022-02-18 02:33:48,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:33:49,325] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:33:49,362] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:33:49,372] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:33:49,378] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 02:34:02,022] {scheduler_job.py:155} INFO - Started process (PID=46563) to work on /airflow/dags/download_data.py
[2022-02-18 02:34:02,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:34:02,028] {logging_mixin.py:112} INFO - [2022-02-18 02:34:02,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:34:02,474] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:34:02,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:34:02,524] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:34:02,528] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 02:34:15,327] {scheduler_job.py:155} INFO - Started process (PID=46589) to work on /airflow/dags/download_data.py
[2022-02-18 02:34:15,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:34:15,334] {logging_mixin.py:112} INFO - [2022-02-18 02:34:15,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:34:15,824] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:34:15,879] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:34:15,888] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:34:15,892] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 02:34:28,570] {scheduler_job.py:155} INFO - Started process (PID=46615) to work on /airflow/dags/download_data.py
[2022-02-18 02:34:28,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:34:28,580] {logging_mixin.py:112} INFO - [2022-02-18 02:34:28,580] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:34:29,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:34:29,059] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:34:29,070] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:34:29,074] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 02:34:41,879] {scheduler_job.py:155} INFO - Started process (PID=46641) to work on /airflow/dags/download_data.py
[2022-02-18 02:34:41,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:34:41,890] {logging_mixin.py:112} INFO - [2022-02-18 02:34:41,890] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:34:42,335] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:34:42,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:34:42,396] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:34:42,405] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 02:34:55,106] {scheduler_job.py:155} INFO - Started process (PID=46667) to work on /airflow/dags/download_data.py
[2022-02-18 02:34:55,110] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:34:55,114] {logging_mixin.py:112} INFO - [2022-02-18 02:34:55,113] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:34:55,615] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:34:55,670] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:34:55,684] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:34:55,689] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 02:35:08,401] {scheduler_job.py:155} INFO - Started process (PID=46693) to work on /airflow/dags/download_data.py
[2022-02-18 02:35:08,412] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:35:08,414] {logging_mixin.py:112} INFO - [2022-02-18 02:35:08,414] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:35:08,876] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:35:08,920] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:35:08,926] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:35:08,930] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 02:35:21,718] {scheduler_job.py:155} INFO - Started process (PID=46719) to work on /airflow/dags/download_data.py
[2022-02-18 02:35:21,730] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:35:21,732] {logging_mixin.py:112} INFO - [2022-02-18 02:35:21,732] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:35:22,230] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:35:22,286] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:35:22,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:35:22,272] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 02:35:35,010] {scheduler_job.py:155} INFO - Started process (PID=46745) to work on /airflow/dags/download_data.py
[2022-02-18 02:35:35,019] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:35:35,023] {logging_mixin.py:112} INFO - [2022-02-18 02:35:35,023] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:35:35,583] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:35:35,625] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:35:35,634] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:35:35,640] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-18 02:35:48,340] {scheduler_job.py:155} INFO - Started process (PID=46771) to work on /airflow/dags/download_data.py
[2022-02-18 02:35:48,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:35:48,353] {logging_mixin.py:112} INFO - [2022-02-18 02:35:48,352] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:35:48,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:35:48,950] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:35:48,966] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:35:48,977] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-18 02:36:01,574] {scheduler_job.py:155} INFO - Started process (PID=46797) to work on /airflow/dags/download_data.py
[2022-02-18 02:36:01,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:36:01,580] {logging_mixin.py:112} INFO - [2022-02-18 02:36:01,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:36:02,040] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:36:02,087] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:36:02,095] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:36:02,100] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 02:36:14,839] {scheduler_job.py:155} INFO - Started process (PID=46823) to work on /airflow/dags/download_data.py
[2022-02-18 02:36:14,845] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:36:14,846] {logging_mixin.py:112} INFO - [2022-02-18 02:36:14,846] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:36:15,307] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:36:15,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:36:15,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:36:15,359] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 02:36:28,106] {scheduler_job.py:155} INFO - Started process (PID=46849) to work on /airflow/dags/download_data.py
[2022-02-18 02:36:28,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:36:28,115] {logging_mixin.py:112} INFO - [2022-02-18 02:36:28,115] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:36:28,660] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:36:28,709] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:36:28,722] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:36:28,728] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-18 02:36:41,463] {scheduler_job.py:155} INFO - Started process (PID=46875) to work on /airflow/dags/download_data.py
[2022-02-18 02:36:41,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:36:41,472] {logging_mixin.py:112} INFO - [2022-02-18 02:36:41,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:36:41,950] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:36:42,005] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:36:42,013] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:36:42,018] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 02:36:54,729] {scheduler_job.py:155} INFO - Started process (PID=46901) to work on /airflow/dags/download_data.py
[2022-02-18 02:36:54,739] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:36:54,742] {logging_mixin.py:112} INFO - [2022-02-18 02:36:54,741] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:36:55,222] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:36:55,280] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:36:55,286] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:36:55,294] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 02:37:08,008] {scheduler_job.py:155} INFO - Started process (PID=46927) to work on /airflow/dags/download_data.py
[2022-02-18 02:37:08,013] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:37:08,014] {logging_mixin.py:112} INFO - [2022-02-18 02:37:08,014] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:37:08,516] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:37:08,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:37:08,580] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:37:08,586] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 02:37:21,337] {scheduler_job.py:155} INFO - Started process (PID=46953) to work on /airflow/dags/download_data.py
[2022-02-18 02:37:21,347] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:37:21,350] {logging_mixin.py:112} INFO - [2022-02-18 02:37:21,349] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:37:21,860] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:37:21,927] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:37:21,939] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:37:21,946] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-18 02:37:34,564] {scheduler_job.py:155} INFO - Started process (PID=46979) to work on /airflow/dags/download_data.py
[2022-02-18 02:37:34,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:37:34,570] {logging_mixin.py:112} INFO - [2022-02-18 02:37:34,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:37:35,068] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:37:35,124] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:37:35,139] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:37:35,145] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 02:37:47,884] {scheduler_job.py:155} INFO - Started process (PID=47005) to work on /airflow/dags/download_data.py
[2022-02-18 02:37:47,892] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:37:47,895] {logging_mixin.py:112} INFO - [2022-02-18 02:37:47,895] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:37:48,366] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:37:48,425] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:37:48,435] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:37:48,441] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 02:38:01,146] {scheduler_job.py:155} INFO - Started process (PID=47031) to work on /airflow/dags/download_data.py
[2022-02-18 02:38:01,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:38:01,153] {logging_mixin.py:112} INFO - [2022-02-18 02:38:01,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:38:01,935] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:38:02,013] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:38:02,031] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:38:02,044] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.898 seconds
[2022-02-18 02:38:14,513] {scheduler_job.py:155} INFO - Started process (PID=47057) to work on /airflow/dags/download_data.py
[2022-02-18 02:38:14,517] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:38:14,519] {logging_mixin.py:112} INFO - [2022-02-18 02:38:14,519] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:38:15,127] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:38:15,170] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:38:15,177] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:38:15,182] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.669 seconds
[2022-02-18 02:38:27,724] {scheduler_job.py:155} INFO - Started process (PID=47083) to work on /airflow/dags/download_data.py
[2022-02-18 02:38:27,728] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:38:27,730] {logging_mixin.py:112} INFO - [2022-02-18 02:38:27,729] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:38:28,181] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:38:28,232] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:38:28,240] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:38:28,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 02:38:41,027] {scheduler_job.py:155} INFO - Started process (PID=47109) to work on /airflow/dags/download_data.py
[2022-02-18 02:38:41,037] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:38:41,038] {logging_mixin.py:112} INFO - [2022-02-18 02:38:41,038] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:38:41,482] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:38:41,527] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:38:41,536] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:38:41,541] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 02:38:54,259] {scheduler_job.py:155} INFO - Started process (PID=47135) to work on /airflow/dags/download_data.py
[2022-02-18 02:38:54,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:38:54,266] {logging_mixin.py:112} INFO - [2022-02-18 02:38:54,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:38:54,749] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:38:54,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:38:54,809] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:38:54,814] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 02:39:07,567] {scheduler_job.py:155} INFO - Started process (PID=47161) to work on /airflow/dags/download_data.py
[2022-02-18 02:39:07,574] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:39:07,576] {logging_mixin.py:112} INFO - [2022-02-18 02:39:07,576] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:39:08,019] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:39:08,070] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:39:08,079] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:39:08,084] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 02:39:20,864] {scheduler_job.py:155} INFO - Started process (PID=47187) to work on /airflow/dags/download_data.py
[2022-02-18 02:39:20,872] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:39:20,875] {logging_mixin.py:112} INFO - [2022-02-18 02:39:20,875] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:39:21,340] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:39:21,390] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:39:21,400] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:39:21,405] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 02:39:34,107] {scheduler_job.py:155} INFO - Started process (PID=47213) to work on /airflow/dags/download_data.py
[2022-02-18 02:39:34,111] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:39:34,113] {logging_mixin.py:112} INFO - [2022-02-18 02:39:34,112] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:39:34,565] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:39:34,616] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:39:34,624] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:39:34,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 02:39:47,393] {scheduler_job.py:155} INFO - Started process (PID=47239) to work on /airflow/dags/download_data.py
[2022-02-18 02:39:47,399] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:39:47,401] {logging_mixin.py:112} INFO - [2022-02-18 02:39:47,401] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:39:47,876] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:39:47,931] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:39:47,946] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:39:47,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 02:40:00,639] {scheduler_job.py:155} INFO - Started process (PID=47265) to work on /airflow/dags/download_data.py
[2022-02-18 02:40:00,651] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:40:00,653] {logging_mixin.py:112} INFO - [2022-02-18 02:40:00,653] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:40:01,095] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:40:01,144] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:40:01,151] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:40:01,156] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 02:40:13,948] {scheduler_job.py:155} INFO - Started process (PID=47291) to work on /airflow/dags/download_data.py
[2022-02-18 02:40:13,960] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:40:13,962] {logging_mixin.py:112} INFO - [2022-02-18 02:40:13,962] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:40:14,439] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:40:14,501] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:40:14,508] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:40:14,513] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 02:40:27,237] {scheduler_job.py:155} INFO - Started process (PID=47317) to work on /airflow/dags/download_data.py
[2022-02-18 02:40:27,242] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:40:27,247] {logging_mixin.py:112} INFO - [2022-02-18 02:40:27,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:40:27,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:40:28,095] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:40:28,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:40:28,132] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.895 seconds
[2022-02-18 02:40:40,487] {scheduler_job.py:155} INFO - Started process (PID=47343) to work on /airflow/dags/download_data.py
[2022-02-18 02:40:40,498] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:40:40,501] {logging_mixin.py:112} INFO - [2022-02-18 02:40:40,500] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:40:40,944] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:40:40,995] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:40:41,001] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:40:41,005] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 02:40:53,803] {scheduler_job.py:155} INFO - Started process (PID=47369) to work on /airflow/dags/download_data.py
[2022-02-18 02:40:53,820] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:40:53,837] {logging_mixin.py:112} INFO - [2022-02-18 02:40:53,837] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:40:54,438] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:40:54,486] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:40:54,495] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:40:54,504] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.705 seconds
[2022-02-18 02:41:07,099] {scheduler_job.py:155} INFO - Started process (PID=47395) to work on /airflow/dags/download_data.py
[2022-02-18 02:41:07,103] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:41:07,106] {logging_mixin.py:112} INFO - [2022-02-18 02:41:07,105] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:41:07,592] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:41:07,640] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:41:07,648] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:41:07,654] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 02:41:20,474] {scheduler_job.py:155} INFO - Started process (PID=47421) to work on /airflow/dags/download_data.py
[2022-02-18 02:41:20,483] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:41:20,485] {logging_mixin.py:112} INFO - [2022-02-18 02:41:20,484] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:41:20,955] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:41:21,017] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:41:21,024] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:41:21,030] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 02:41:33,735] {scheduler_job.py:155} INFO - Started process (PID=47447) to work on /airflow/dags/download_data.py
[2022-02-18 02:41:33,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:41:33,745] {logging_mixin.py:112} INFO - [2022-02-18 02:41:33,744] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:41:34,208] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:41:34,268] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:41:34,275] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:41:34,281] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 02:41:47,038] {scheduler_job.py:155} INFO - Started process (PID=47473) to work on /airflow/dags/download_data.py
[2022-02-18 02:41:47,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:41:47,048] {logging_mixin.py:112} INFO - [2022-02-18 02:41:47,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:41:47,552] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:41:47,605] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:41:47,616] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:41:47,620] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 02:42:00,288] {scheduler_job.py:155} INFO - Started process (PID=47499) to work on /airflow/dags/download_data.py
[2022-02-18 02:42:00,292] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:42:00,294] {logging_mixin.py:112} INFO - [2022-02-18 02:42:00,294] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:42:00,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:42:00,822] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:42:00,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:42:00,834] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 02:42:13,569] {scheduler_job.py:155} INFO - Started process (PID=47525) to work on /airflow/dags/download_data.py
[2022-02-18 02:42:13,574] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:42:13,575] {logging_mixin.py:112} INFO - [2022-02-18 02:42:13,575] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:42:14,042] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:42:14,099] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:42:14,108] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:42:14,114] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 02:42:26,869] {scheduler_job.py:155} INFO - Started process (PID=47551) to work on /airflow/dags/download_data.py
[2022-02-18 02:42:26,877] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:42:26,879] {logging_mixin.py:112} INFO - [2022-02-18 02:42:26,879] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:42:27,320] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:42:27,371] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:42:27,378] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:42:27,382] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 02:42:40,171] {scheduler_job.py:155} INFO - Started process (PID=47577) to work on /airflow/dags/download_data.py
[2022-02-18 02:42:40,250] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:42:40,266] {logging_mixin.py:112} INFO - [2022-02-18 02:42:40,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:42:40,789] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:42:40,838] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:42:40,846] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:42:40,854] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.684 seconds
[2022-02-18 02:42:53,431] {scheduler_job.py:155} INFO - Started process (PID=47603) to work on /airflow/dags/download_data.py
[2022-02-18 02:42:53,439] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:42:53,443] {logging_mixin.py:112} INFO - [2022-02-18 02:42:53,443] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:42:54,226] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:42:54,298] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:42:54,311] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:42:54,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.895 seconds
[2022-02-18 02:43:06,762] {scheduler_job.py:155} INFO - Started process (PID=47629) to work on /airflow/dags/download_data.py
[2022-02-18 02:43:06,770] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:43:06,772] {logging_mixin.py:112} INFO - [2022-02-18 02:43:06,772] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:43:07,637] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:43:07,689] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:43:07,699] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:43:07,706] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.944 seconds
[2022-02-18 02:43:20,084] {scheduler_job.py:155} INFO - Started process (PID=47655) to work on /airflow/dags/download_data.py
[2022-02-18 02:43:20,092] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:43:20,094] {logging_mixin.py:112} INFO - [2022-02-18 02:43:20,094] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:43:20,540] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:43:20,584] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:43:20,591] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:43:20,597] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 02:43:33,337] {scheduler_job.py:155} INFO - Started process (PID=47681) to work on /airflow/dags/download_data.py
[2022-02-18 02:43:33,351] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:43:33,368] {logging_mixin.py:112} INFO - [2022-02-18 02:43:33,367] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:43:34,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:43:34,537] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:43:34,552] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:43:34,561] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.224 seconds
[2022-02-18 02:43:47,682] {scheduler_job.py:155} INFO - Started process (PID=47707) to work on /airflow/dags/download_data.py
[2022-02-18 02:43:47,693] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:43:47,697] {logging_mixin.py:112} INFO - [2022-02-18 02:43:47,695] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:43:48,195] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:43:48,251] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:43:48,258] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:43:48,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-18 02:43:59,926] {scheduler_job.py:155} INFO - Started process (PID=47732) to work on /airflow/dags/download_data.py
[2022-02-18 02:43:59,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:43:59,932] {logging_mixin.py:112} INFO - [2022-02-18 02:43:59,932] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:44:00,442] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:44:00,489] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:44:00,497] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:44:00,501] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 02:44:13,206] {scheduler_job.py:155} INFO - Started process (PID=47758) to work on /airflow/dags/download_data.py
[2022-02-18 02:44:13,218] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:44:13,221] {logging_mixin.py:112} INFO - [2022-02-18 02:44:13,220] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:44:13,715] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:44:13,770] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:44:13,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:44:13,788] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 02:44:26,488] {scheduler_job.py:155} INFO - Started process (PID=47784) to work on /airflow/dags/download_data.py
[2022-02-18 02:44:26,497] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:44:26,499] {logging_mixin.py:112} INFO - [2022-02-18 02:44:26,499] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:44:27,072] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:44:27,133] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:44:27,139] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:44:27,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.656 seconds
[2022-02-18 02:44:39,832] {scheduler_job.py:155} INFO - Started process (PID=47810) to work on /airflow/dags/download_data.py
[2022-02-18 02:44:39,840] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:44:39,843] {logging_mixin.py:112} INFO - [2022-02-18 02:44:39,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:44:40,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:44:41,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:44:41,061] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:44:41,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.249 seconds
[2022-02-18 02:44:54,089] {scheduler_job.py:155} INFO - Started process (PID=47836) to work on /airflow/dags/download_data.py
[2022-02-18 02:44:54,098] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:44:54,100] {logging_mixin.py:112} INFO - [2022-02-18 02:44:54,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:44:54,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:44:54,718] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:44:54,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:44:54,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-18 02:45:06,386] {scheduler_job.py:155} INFO - Started process (PID=47861) to work on /airflow/dags/download_data.py
[2022-02-18 02:45:06,394] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:45:06,396] {logging_mixin.py:112} INFO - [2022-02-18 02:45:06,395] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:45:07,494] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:45:07,582] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:45:07,590] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:45:07,595] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.210 seconds
[2022-02-18 02:45:20,695] {scheduler_job.py:155} INFO - Started process (PID=47887) to work on /airflow/dags/download_data.py
[2022-02-18 02:45:20,701] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:45:20,703] {logging_mixin.py:112} INFO - [2022-02-18 02:45:20,703] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:45:21,168] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:45:21,213] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:45:21,227] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:45:21,233] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 02:45:32,998] {scheduler_job.py:155} INFO - Started process (PID=47912) to work on /airflow/dags/download_data.py
[2022-02-18 02:45:33,008] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:45:33,011] {logging_mixin.py:112} INFO - [2022-02-18 02:45:33,011] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:45:33,505] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:45:33,547] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:45:33,558] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:45:33,564] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 02:45:46,304] {scheduler_job.py:155} INFO - Started process (PID=47938) to work on /airflow/dags/download_data.py
[2022-02-18 02:45:46,308] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:45:46,311] {logging_mixin.py:112} INFO - [2022-02-18 02:45:46,311] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:45:46,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:45:46,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:45:46,954] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:45:46,959] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.655 seconds
[2022-02-18 02:45:59,604] {scheduler_job.py:155} INFO - Started process (PID=47964) to work on /airflow/dags/download_data.py
[2022-02-18 02:45:59,609] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:45:59,611] {logging_mixin.py:112} INFO - [2022-02-18 02:45:59,611] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:46:00,284] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:46:00,338] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:46:00,348] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:46:00,358] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.753 seconds
[2022-02-18 02:46:12,916] {scheduler_job.py:155} INFO - Started process (PID=47990) to work on /airflow/dags/download_data.py
[2022-02-18 02:46:12,924] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:46:12,929] {logging_mixin.py:112} INFO - [2022-02-18 02:46:12,927] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:46:13,496] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:46:13,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:46:13,587] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:46:13,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-18 02:46:26,191] {scheduler_job.py:155} INFO - Started process (PID=48016) to work on /airflow/dags/download_data.py
[2022-02-18 02:46:26,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:46:26,202] {logging_mixin.py:112} INFO - [2022-02-18 02:46:26,202] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:46:26,721] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:46:26,758] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:46:26,764] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:46:26,767] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 02:46:39,498] {scheduler_job.py:155} INFO - Started process (PID=48042) to work on /airflow/dags/download_data.py
[2022-02-18 02:46:39,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:46:39,506] {logging_mixin.py:112} INFO - [2022-02-18 02:46:39,505] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:46:40,018] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:46:40,073] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:46:40,081] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:46:40,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 02:46:52,779] {scheduler_job.py:155} INFO - Started process (PID=48068) to work on /airflow/dags/download_data.py
[2022-02-18 02:46:52,787] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:46:52,789] {logging_mixin.py:112} INFO - [2022-02-18 02:46:52,789] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:46:53,361] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:46:53,440] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:46:53,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:46:53,458] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-18 02:47:06,088] {scheduler_job.py:155} INFO - Started process (PID=48094) to work on /airflow/dags/download_data.py
[2022-02-18 02:47:06,092] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:47:06,094] {logging_mixin.py:112} INFO - [2022-02-18 02:47:06,094] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:47:06,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:47:06,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:47:06,709] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:47:06,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-18 02:47:19,389] {scheduler_job.py:155} INFO - Started process (PID=48120) to work on /airflow/dags/download_data.py
[2022-02-18 02:47:19,393] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:47:19,396] {logging_mixin.py:112} INFO - [2022-02-18 02:47:19,396] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:47:19,987] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:47:20,047] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:47:20,057] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:47:20,063] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.674 seconds
[2022-02-18 02:47:32,660] {scheduler_job.py:155} INFO - Started process (PID=48146) to work on /airflow/dags/download_data.py
[2022-02-18 02:47:32,665] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:47:32,666] {logging_mixin.py:112} INFO - [2022-02-18 02:47:32,666] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:47:33,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:47:33,224] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:47:33,234] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:47:33,243] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 02:47:45,955] {scheduler_job.py:155} INFO - Started process (PID=48172) to work on /airflow/dags/download_data.py
[2022-02-18 02:47:45,962] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:47:45,964] {logging_mixin.py:112} INFO - [2022-02-18 02:47:45,964] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:47:46,716] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:47:46,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:47:46,805] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:47:46,816] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.862 seconds
[2022-02-18 02:47:59,249] {scheduler_job.py:155} INFO - Started process (PID=48198) to work on /airflow/dags/download_data.py
[2022-02-18 02:47:59,261] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:47:59,263] {logging_mixin.py:112} INFO - [2022-02-18 02:47:59,263] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:47:59,862] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:47:59,933] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:47:59,942] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:47:59,973] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.724 seconds
[2022-02-18 02:48:12,580] {scheduler_job.py:155} INFO - Started process (PID=48224) to work on /airflow/dags/download_data.py
[2022-02-18 02:48:12,589] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:48:12,592] {logging_mixin.py:112} INFO - [2022-02-18 02:48:12,591] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:48:13,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:48:13,239] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:48:13,246] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:48:13,250] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.671 seconds
[2022-02-18 02:48:25,862] {scheduler_job.py:155} INFO - Started process (PID=48250) to work on /airflow/dags/download_data.py
[2022-02-18 02:48:25,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:48:25,875] {logging_mixin.py:112} INFO - [2022-02-18 02:48:25,874] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:48:26,440] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:48:26,487] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:48:26,498] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:48:26,501] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.639 seconds
[2022-02-18 02:48:39,202] {scheduler_job.py:155} INFO - Started process (PID=48276) to work on /airflow/dags/download_data.py
[2022-02-18 02:48:39,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:48:39,217] {logging_mixin.py:112} INFO - [2022-02-18 02:48:39,216] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:48:39,729] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:48:39,783] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:48:39,793] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:48:39,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 02:48:52,454] {scheduler_job.py:155} INFO - Started process (PID=48302) to work on /airflow/dags/download_data.py
[2022-02-18 02:48:52,458] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:48:52,460] {logging_mixin.py:112} INFO - [2022-02-18 02:48:52,459] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:48:53,043] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:48:53,121] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:48:53,130] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:48:53,139] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.685 seconds
[2022-02-18 02:49:05,802] {scheduler_job.py:155} INFO - Started process (PID=48328) to work on /airflow/dags/download_data.py
[2022-02-18 02:49:05,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:49:05,810] {logging_mixin.py:112} INFO - [2022-02-18 02:49:05,810] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:49:06,367] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:49:06,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:49:06,427] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:49:06,434] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-18 02:49:19,114] {scheduler_job.py:155} INFO - Started process (PID=48354) to work on /airflow/dags/download_data.py
[2022-02-18 02:49:19,123] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:49:19,125] {logging_mixin.py:112} INFO - [2022-02-18 02:49:19,124] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:49:19,925] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:49:19,993] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:49:20,005] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:49:20,011] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.897 seconds
[2022-02-18 02:49:32,414] {scheduler_job.py:155} INFO - Started process (PID=48380) to work on /airflow/dags/download_data.py
[2022-02-18 02:49:32,427] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:49:32,430] {logging_mixin.py:112} INFO - [2022-02-18 02:49:32,429] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:49:32,960] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:49:33,027] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:49:33,038] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:49:33,044] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-18 02:49:45,712] {scheduler_job.py:155} INFO - Started process (PID=48406) to work on /airflow/dags/download_data.py
[2022-02-18 02:49:45,722] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:49:45,723] {logging_mixin.py:112} INFO - [2022-02-18 02:49:45,723] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:49:46,259] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:49:46,356] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:49:46,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:49:46,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.662 seconds
[2022-02-18 02:49:58,982] {scheduler_job.py:155} INFO - Started process (PID=48432) to work on /airflow/dags/download_data.py
[2022-02-18 02:49:58,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:49:59,000] {logging_mixin.py:112} INFO - [2022-02-18 02:49:59,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:49:59,469] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:49:59,512] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:49:59,523] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:49:59,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 02:50:12,244] {scheduler_job.py:155} INFO - Started process (PID=48458) to work on /airflow/dags/download_data.py
[2022-02-18 02:50:12,248] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:50:12,250] {logging_mixin.py:112} INFO - [2022-02-18 02:50:12,250] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:50:12,700] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:50:12,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:50:12,755] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:50:12,760] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 02:50:25,594] {scheduler_job.py:155} INFO - Started process (PID=48484) to work on /airflow/dags/download_data.py
[2022-02-18 02:50:25,610] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:50:25,615] {logging_mixin.py:112} INFO - [2022-02-18 02:50:25,614] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:50:26,202] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:50:26,264] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:50:26,273] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:50:26,281] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.687 seconds
[2022-02-18 02:50:38,920] {scheduler_job.py:155} INFO - Started process (PID=48510) to work on /airflow/dags/download_data.py
[2022-02-18 02:50:38,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:50:38,930] {logging_mixin.py:112} INFO - [2022-02-18 02:50:38,930] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:50:39,545] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:50:39,744] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:50:39,770] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:50:39,777] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.856 seconds
[2022-02-18 02:50:52,190] {scheduler_job.py:155} INFO - Started process (PID=48536) to work on /airflow/dags/download_data.py
[2022-02-18 02:50:52,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:50:52,200] {logging_mixin.py:112} INFO - [2022-02-18 02:50:52,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:50:52,763] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:50:52,836] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:50:52,848] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:50:52,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.664 seconds
[2022-02-18 02:51:05,539] {scheduler_job.py:155} INFO - Started process (PID=48562) to work on /airflow/dags/download_data.py
[2022-02-18 02:51:05,558] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:51:05,563] {logging_mixin.py:112} INFO - [2022-02-18 02:51:05,562] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:51:06,114] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:51:06,176] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:51:06,190] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:51:06,194] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.655 seconds
[2022-02-18 02:51:18,828] {scheduler_job.py:155} INFO - Started process (PID=48588) to work on /airflow/dags/download_data.py
[2022-02-18 02:51:18,835] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:51:18,837] {logging_mixin.py:112} INFO - [2022-02-18 02:51:18,837] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:51:19,605] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:51:19,661] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:51:19,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:51:19,683] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.854 seconds
[2022-02-18 02:51:32,126] {scheduler_job.py:155} INFO - Started process (PID=48614) to work on /airflow/dags/download_data.py
[2022-02-18 02:51:32,146] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:51:32,148] {logging_mixin.py:112} INFO - [2022-02-18 02:51:32,148] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:51:32,654] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:51:32,705] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:51:32,713] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:51:32,718] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 02:51:45,434] {scheduler_job.py:155} INFO - Started process (PID=48640) to work on /airflow/dags/download_data.py
[2022-02-18 02:51:45,468] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:51:45,471] {logging_mixin.py:112} INFO - [2022-02-18 02:51:45,470] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:51:46,089] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:51:46,153] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:51:46,166] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:51:46,174] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.740 seconds
[2022-02-18 02:51:58,749] {scheduler_job.py:155} INFO - Started process (PID=48666) to work on /airflow/dags/download_data.py
[2022-02-18 02:51:58,755] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:51:58,756] {logging_mixin.py:112} INFO - [2022-02-18 02:51:58,756] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:51:59,275] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:51:59,327] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:51:59,339] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:51:59,352] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 02:52:12,031] {scheduler_job.py:155} INFO - Started process (PID=48692) to work on /airflow/dags/download_data.py
[2022-02-18 02:52:12,036] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:52:12,037] {logging_mixin.py:112} INFO - [2022-02-18 02:52:12,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:52:12,490] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:52:12,542] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:52:12,550] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:52:12,555] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 02:52:25,309] {scheduler_job.py:155} INFO - Started process (PID=48718) to work on /airflow/dags/download_data.py
[2022-02-18 02:52:25,316] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:52:25,318] {logging_mixin.py:112} INFO - [2022-02-18 02:52:25,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:52:25,870] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:52:25,931] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:52:25,938] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:52:25,942] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-18 02:52:38,620] {scheduler_job.py:155} INFO - Started process (PID=48744) to work on /airflow/dags/download_data.py
[2022-02-18 02:52:38,629] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:52:38,631] {logging_mixin.py:112} INFO - [2022-02-18 02:52:38,630] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:52:39,117] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:52:39,160] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:52:39,167] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:52:39,174] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 02:52:51,875] {scheduler_job.py:155} INFO - Started process (PID=48770) to work on /airflow/dags/download_data.py
[2022-02-18 02:52:51,879] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:52:51,882] {logging_mixin.py:112} INFO - [2022-02-18 02:52:51,882] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:52:52,373] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:52:52,433] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:52:52,445] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:52:52,452] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 02:53:05,162] {scheduler_job.py:155} INFO - Started process (PID=48796) to work on /airflow/dags/download_data.py
[2022-02-18 02:53:05,167] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:53:05,168] {logging_mixin.py:112} INFO - [2022-02-18 02:53:05,168] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:53:05,641] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:53:05,696] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:53:05,707] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:53:05,714] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 02:53:18,462] {scheduler_job.py:155} INFO - Started process (PID=48822) to work on /airflow/dags/download_data.py
[2022-02-18 02:53:18,473] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:53:18,475] {logging_mixin.py:112} INFO - [2022-02-18 02:53:18,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:53:18,959] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:53:19,007] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:53:19,019] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:53:19,024] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 02:53:31,698] {scheduler_job.py:155} INFO - Started process (PID=48848) to work on /airflow/dags/download_data.py
[2022-02-18 02:53:31,702] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:53:31,704] {logging_mixin.py:112} INFO - [2022-02-18 02:53:31,704] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:53:32,300] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:53:32,370] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:53:32,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:53:32,386] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.688 seconds
[2022-02-18 02:53:44,968] {scheduler_job.py:155} INFO - Started process (PID=48874) to work on /airflow/dags/download_data.py
[2022-02-18 02:53:44,973] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:53:44,975] {logging_mixin.py:112} INFO - [2022-02-18 02:53:44,974] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:53:45,645] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:53:45,694] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:53:45,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:53:45,708] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.740 seconds
[2022-02-18 02:53:58,229] {scheduler_job.py:155} INFO - Started process (PID=48900) to work on /airflow/dags/download_data.py
[2022-02-18 02:53:58,236] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:53:58,238] {logging_mixin.py:112} INFO - [2022-02-18 02:53:58,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:53:58,767] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:53:58,817] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:53:58,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:53:58,837] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 02:54:11,639] {scheduler_job.py:155} INFO - Started process (PID=48926) to work on /airflow/dags/download_data.py
[2022-02-18 02:54:11,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:54:11,658] {logging_mixin.py:112} INFO - [2022-02-18 02:54:11,657] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:54:12,268] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:54:12,341] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:54:12,353] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:54:12,359] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.720 seconds
[2022-02-18 02:54:24,856] {scheduler_job.py:155} INFO - Started process (PID=48952) to work on /airflow/dags/download_data.py
[2022-02-18 02:54:24,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:54:24,866] {logging_mixin.py:112} INFO - [2022-02-18 02:54:24,865] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:54:25,475] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:54:25,545] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:54:25,556] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:54:25,570] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.715 seconds
[2022-02-18 02:54:38,170] {scheduler_job.py:155} INFO - Started process (PID=48978) to work on /airflow/dags/download_data.py
[2022-02-18 02:54:38,180] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:54:38,182] {logging_mixin.py:112} INFO - [2022-02-18 02:54:38,182] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:54:38,710] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:54:38,773] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:54:38,785] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:54:38,796] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-18 02:54:51,435] {scheduler_job.py:155} INFO - Started process (PID=49004) to work on /airflow/dags/download_data.py
[2022-02-18 02:54:51,444] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:54:51,450] {logging_mixin.py:112} INFO - [2022-02-18 02:54:51,449] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:54:52,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:54:52,178] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:54:52,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:54:52,202] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.768 seconds
[2022-02-18 02:55:04,768] {scheduler_job.py:155} INFO - Started process (PID=49030) to work on /airflow/dags/download_data.py
[2022-02-18 02:55:04,778] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:55:04,779] {logging_mixin.py:112} INFO - [2022-02-18 02:55:04,779] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:55:05,318] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:55:05,388] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:55:05,403] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:55:05,414] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.647 seconds
[2022-02-18 02:55:18,086] {scheduler_job.py:155} INFO - Started process (PID=49056) to work on /airflow/dags/download_data.py
[2022-02-18 02:55:18,096] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:55:18,099] {logging_mixin.py:112} INFO - [2022-02-18 02:55:18,099] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:55:18,740] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:55:18,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:55:18,818] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:55:18,828] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.742 seconds
[2022-02-18 02:55:31,459] {scheduler_job.py:155} INFO - Started process (PID=49082) to work on /airflow/dags/download_data.py
[2022-02-18 02:55:31,472] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:55:31,476] {logging_mixin.py:112} INFO - [2022-02-18 02:55:31,476] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:55:32,067] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:55:32,125] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:55:32,131] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:55:32,139] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-18 02:55:44,737] {scheduler_job.py:155} INFO - Started process (PID=49108) to work on /airflow/dags/download_data.py
[2022-02-18 02:55:44,745] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:55:44,747] {logging_mixin.py:112} INFO - [2022-02-18 02:55:44,747] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:55:45,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:55:45,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:55:45,468] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:55:45,477] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.740 seconds
[2022-02-18 02:55:58,016] {scheduler_job.py:155} INFO - Started process (PID=49134) to work on /airflow/dags/download_data.py
[2022-02-18 02:55:58,021] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:55:58,024] {logging_mixin.py:112} INFO - [2022-02-18 02:55:58,023] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:55:58,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:55:58,704] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:55:58,715] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:55:58,719] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.704 seconds
[2022-02-18 02:56:11,333] {scheduler_job.py:155} INFO - Started process (PID=49160) to work on /airflow/dags/download_data.py
[2022-02-18 02:56:11,339] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:56:11,341] {logging_mixin.py:112} INFO - [2022-02-18 02:56:11,341] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:56:11,838] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:56:11,893] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:56:11,903] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:56:11,909] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 02:56:24,597] {scheduler_job.py:155} INFO - Started process (PID=49186) to work on /airflow/dags/download_data.py
[2022-02-18 02:56:24,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:56:24,605] {logging_mixin.py:112} INFO - [2022-02-18 02:56:24,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:56:25,066] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:56:25,121] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:56:25,133] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:56:25,140] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 02:56:37,870] {scheduler_job.py:155} INFO - Started process (PID=49212) to work on /airflow/dags/download_data.py
[2022-02-18 02:56:37,874] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:56:37,876] {logging_mixin.py:112} INFO - [2022-02-18 02:56:37,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:56:38,332] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:56:38,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:56:38,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:56:38,397] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 02:56:51,118] {scheduler_job.py:155} INFO - Started process (PID=49238) to work on /airflow/dags/download_data.py
[2022-02-18 02:56:51,128] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:56:51,130] {logging_mixin.py:112} INFO - [2022-02-18 02:56:51,130] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:56:51,608] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:56:51,653] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:56:51,661] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:56:51,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 02:57:04,383] {scheduler_job.py:155} INFO - Started process (PID=49264) to work on /airflow/dags/download_data.py
[2022-02-18 02:57:04,389] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:57:04,391] {logging_mixin.py:112} INFO - [2022-02-18 02:57:04,391] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:57:04,818] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:57:04,861] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:57:04,867] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:57:04,871] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-18 02:57:17,707] {scheduler_job.py:155} INFO - Started process (PID=49290) to work on /airflow/dags/download_data.py
[2022-02-18 02:57:17,717] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:57:17,720] {logging_mixin.py:112} INFO - [2022-02-18 02:57:17,719] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:57:18,486] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:57:18,548] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:57:18,557] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:57:18,561] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.854 seconds
[2022-02-18 02:57:30,955] {scheduler_job.py:155} INFO - Started process (PID=49316) to work on /airflow/dags/download_data.py
[2022-02-18 02:57:30,962] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:57:30,963] {logging_mixin.py:112} INFO - [2022-02-18 02:57:30,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:57:31,491] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:57:31,546] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:57:31,575] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:57:31,592] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-18 02:57:44,281] {scheduler_job.py:155} INFO - Started process (PID=49342) to work on /airflow/dags/download_data.py
[2022-02-18 02:57:44,289] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:57:44,291] {logging_mixin.py:112} INFO - [2022-02-18 02:57:44,291] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:57:44,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:57:44,857] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:57:44,882] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:57:44,887] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 02:57:57,559] {scheduler_job.py:155} INFO - Started process (PID=49368) to work on /airflow/dags/download_data.py
[2022-02-18 02:57:57,563] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:57:57,566] {logging_mixin.py:112} INFO - [2022-02-18 02:57:57,566] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:57:58,022] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:57:58,066] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:57:58,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:57:58,079] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 02:58:10,849] {scheduler_job.py:155} INFO - Started process (PID=49394) to work on /airflow/dags/download_data.py
[2022-02-18 02:58:10,854] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:58:10,855] {logging_mixin.py:112} INFO - [2022-02-18 02:58:10,855] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:58:11,302] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:58:11,356] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:58:11,366] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:58:11,371] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 02:58:24,116] {scheduler_job.py:155} INFO - Started process (PID=49420) to work on /airflow/dags/download_data.py
[2022-02-18 02:58:24,121] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:58:24,123] {logging_mixin.py:112} INFO - [2022-02-18 02:58:24,123] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:58:24,562] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:58:24,616] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:58:24,623] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:58:24,628] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 02:58:37,433] {scheduler_job.py:155} INFO - Started process (PID=49446) to work on /airflow/dags/download_data.py
[2022-02-18 02:58:37,438] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:58:37,440] {logging_mixin.py:112} INFO - [2022-02-18 02:58:37,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:58:38,035] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:58:38,098] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:58:38,106] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:58:38,113] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.681 seconds
[2022-02-18 02:58:50,731] {scheduler_job.py:155} INFO - Started process (PID=49472) to work on /airflow/dags/download_data.py
[2022-02-18 02:58:50,754] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:58:50,757] {logging_mixin.py:112} INFO - [2022-02-18 02:58:50,756] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:58:51,225] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:58:51,272] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:58:51,280] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:58:51,287] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 02:59:03,960] {scheduler_job.py:155} INFO - Started process (PID=49498) to work on /airflow/dags/download_data.py
[2022-02-18 02:59:03,968] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:59:03,971] {logging_mixin.py:112} INFO - [2022-02-18 02:59:03,970] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:59:04,515] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:59:04,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:59:04,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:59:04,605] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-18 02:59:17,237] {scheduler_job.py:155} INFO - Started process (PID=49524) to work on /airflow/dags/download_data.py
[2022-02-18 02:59:17,256] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:59:17,259] {logging_mixin.py:112} INFO - [2022-02-18 02:59:17,259] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:59:17,797] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:59:17,903] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:59:17,916] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:59:17,923] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.686 seconds
[2022-02-18 02:59:30,486] {scheduler_job.py:155} INFO - Started process (PID=49550) to work on /airflow/dags/download_data.py
[2022-02-18 02:59:30,491] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:59:30,493] {logging_mixin.py:112} INFO - [2022-02-18 02:59:30,493] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:59:30,974] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:59:31,027] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:59:31,038] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:59:31,042] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 02:59:43,794] {scheduler_job.py:155} INFO - Started process (PID=49576) to work on /airflow/dags/download_data.py
[2022-02-18 02:59:43,806] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:59:43,810] {logging_mixin.py:112} INFO - [2022-02-18 02:59:43,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:59:44,313] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:59:44,364] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:59:44,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:59:44,375] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 02:59:57,033] {scheduler_job.py:155} INFO - Started process (PID=49602) to work on /airflow/dags/download_data.py
[2022-02-18 02:59:57,037] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 02:59:57,038] {logging_mixin.py:112} INFO - [2022-02-18 02:59:57,038] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 02:59:57,500] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 02:59:57,546] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 02:59:57,556] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 02:59:57,564] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 03:00:10,442] {scheduler_job.py:155} INFO - Started process (PID=49628) to work on /airflow/dags/download_data.py
[2022-02-18 03:00:10,447] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:00:10,448] {logging_mixin.py:112} INFO - [2022-02-18 03:00:10,448] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:00:10,900] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:00:10,950] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:00:10,956] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:00:10,962] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 03:00:23,698] {scheduler_job.py:155} INFO - Started process (PID=49654) to work on /airflow/dags/download_data.py
[2022-02-18 03:00:23,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:00:23,709] {logging_mixin.py:112} INFO - [2022-02-18 03:00:23,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:00:24,157] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:00:24,209] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:00:24,215] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:00:24,219] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 03:00:36,976] {scheduler_job.py:155} INFO - Started process (PID=49680) to work on /airflow/dags/download_data.py
[2022-02-18 03:00:36,980] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:00:36,982] {logging_mixin.py:112} INFO - [2022-02-18 03:00:36,982] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:00:37,436] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:00:37,483] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:00:37,492] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:00:37,497] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 03:00:50,280] {scheduler_job.py:155} INFO - Started process (PID=49706) to work on /airflow/dags/download_data.py
[2022-02-18 03:00:50,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:00:50,289] {logging_mixin.py:112} INFO - [2022-02-18 03:00:50,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:00:50,787] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:00:50,818] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:00:50,832] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:00:50,840] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 03:01:03,587] {scheduler_job.py:155} INFO - Started process (PID=49732) to work on /airflow/dags/download_data.py
[2022-02-18 03:01:03,595] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:01:03,600] {logging_mixin.py:112} INFO - [2022-02-18 03:01:03,597] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:01:04,055] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:01:04,106] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:01:04,114] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:01:04,119] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 03:01:16,871] {scheduler_job.py:155} INFO - Started process (PID=49758) to work on /airflow/dags/download_data.py
[2022-02-18 03:01:16,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:01:16,877] {logging_mixin.py:112} INFO - [2022-02-18 03:01:16,877] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:01:17,336] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:01:17,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:01:17,392] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:01:17,395] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 03:01:30,146] {scheduler_job.py:155} INFO - Started process (PID=49784) to work on /airflow/dags/download_data.py
[2022-02-18 03:01:30,155] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:01:30,157] {logging_mixin.py:112} INFO - [2022-02-18 03:01:30,157] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:01:30,610] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:01:30,664] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:01:30,674] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:01:30,679] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 03:01:43,450] {scheduler_job.py:155} INFO - Started process (PID=49810) to work on /airflow/dags/download_data.py
[2022-02-18 03:01:43,459] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:01:43,461] {logging_mixin.py:112} INFO - [2022-02-18 03:01:43,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:01:43,980] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:01:44,034] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:01:44,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:01:44,051] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 03:01:56,702] {scheduler_job.py:155} INFO - Started process (PID=49836) to work on /airflow/dags/download_data.py
[2022-02-18 03:01:56,708] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:01:56,711] {logging_mixin.py:112} INFO - [2022-02-18 03:01:56,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:01:57,160] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:01:57,209] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:01:57,218] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:01:57,225] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 03:02:09,943] {scheduler_job.py:155} INFO - Started process (PID=49862) to work on /airflow/dags/download_data.py
[2022-02-18 03:02:09,950] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:02:09,952] {logging_mixin.py:112} INFO - [2022-02-18 03:02:09,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:02:10,422] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:02:10,471] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:02:10,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:02:10,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 03:02:23,231] {scheduler_job.py:155} INFO - Started process (PID=49888) to work on /airflow/dags/download_data.py
[2022-02-18 03:02:23,243] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:02:23,247] {logging_mixin.py:112} INFO - [2022-02-18 03:02:23,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:02:23,701] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:02:23,751] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:02:23,761] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:02:23,769] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 03:02:36,502] {scheduler_job.py:155} INFO - Started process (PID=49914) to work on /airflow/dags/download_data.py
[2022-02-18 03:02:36,512] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:02:36,514] {logging_mixin.py:112} INFO - [2022-02-18 03:02:36,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:02:36,966] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:02:37,013] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:02:37,026] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:02:37,032] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 03:02:49,809] {scheduler_job.py:155} INFO - Started process (PID=49940) to work on /airflow/dags/download_data.py
[2022-02-18 03:02:49,813] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:02:49,815] {logging_mixin.py:112} INFO - [2022-02-18 03:02:49,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:02:50,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:02:50,372] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:02:50,385] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:02:50,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 03:03:03,041] {scheduler_job.py:155} INFO - Started process (PID=49966) to work on /airflow/dags/download_data.py
[2022-02-18 03:03:03,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:03:03,048] {logging_mixin.py:112} INFO - [2022-02-18 03:03:03,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:03:03,528] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:03:03,577] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:03:03,585] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:03:03,590] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 03:03:16,384] {scheduler_job.py:155} INFO - Started process (PID=49992) to work on /airflow/dags/download_data.py
[2022-02-18 03:03:16,389] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:03:16,391] {logging_mixin.py:112} INFO - [2022-02-18 03:03:16,391] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:03:16,862] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:03:16,919] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:03:16,932] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:03:16,936] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 03:27:12,557] {scheduler_job.py:155} INFO - Started process (PID=50018) to work on /airflow/dags/download_data.py
[2022-02-18 03:27:12,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:27:12,570] {logging_mixin.py:112} INFO - [2022-02-18 03:27:12,569] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:27:13,096] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:27:13,148] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:27:13,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:27:13,162] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 03:27:19,694] {scheduler_job.py:155} INFO - Started process (PID=50045) to work on /airflow/dags/download_data.py
[2022-02-18 03:27:19,698] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:27:19,700] {logging_mixin.py:112} INFO - [2022-02-18 03:27:19,700] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:27:21,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:27:21,837] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:27:21,907] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:27:21,945] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.251 seconds
[2022-02-18 03:27:28,953] {scheduler_job.py:155} INFO - Started process (PID=50072) to work on /airflow/dags/download_data.py
[2022-02-18 03:27:28,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:27:28,964] {logging_mixin.py:112} INFO - [2022-02-18 03:27:28,964] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:27:29,429] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:27:29,472] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:27:29,482] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:27:29,488] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 03:27:36,629] {scheduler_job.py:155} INFO - Started process (PID=50099) to work on /airflow/dags/download_data.py
[2022-02-18 03:27:36,681] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:27:36,690] {logging_mixin.py:112} INFO - [2022-02-18 03:27:36,690] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:27:37,392] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:27:37,465] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:27:37,479] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:27:37,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.857 seconds
[2022-02-18 03:27:50,004] {scheduler_job.py:155} INFO - Started process (PID=50126) to work on /airflow/dags/download_data.py
[2022-02-18 03:27:50,010] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:27:50,012] {logging_mixin.py:112} INFO - [2022-02-18 03:27:50,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:27:50,502] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:27:50,546] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:27:50,557] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:27:50,563] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 03:28:03,289] {scheduler_job.py:155} INFO - Started process (PID=50152) to work on /airflow/dags/download_data.py
[2022-02-18 03:28:03,297] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:28:03,299] {logging_mixin.py:112} INFO - [2022-02-18 03:28:03,299] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:28:03,810] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:28:03,866] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:28:03,874] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:28:03,879] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 03:28:16,615] {scheduler_job.py:155} INFO - Started process (PID=50178) to work on /airflow/dags/download_data.py
[2022-02-18 03:28:16,620] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:28:16,621] {logging_mixin.py:112} INFO - [2022-02-18 03:28:16,621] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:28:17,112] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:28:17,144] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:28:17,149] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:28:17,152] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 03:28:29,932] {scheduler_job.py:155} INFO - Started process (PID=50204) to work on /airflow/dags/download_data.py
[2022-02-18 03:28:29,947] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:28:29,951] {logging_mixin.py:112} INFO - [2022-02-18 03:28:29,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:28:30,492] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:28:30,548] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:28:30,557] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:28:30,563] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.631 seconds
[2022-02-18 03:28:43,200] {scheduler_job.py:155} INFO - Started process (PID=50230) to work on /airflow/dags/download_data.py
[2022-02-18 03:28:43,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:28:43,208] {logging_mixin.py:112} INFO - [2022-02-18 03:28:43,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:28:43,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:28:43,813] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:28:43,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:28:43,836] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.636 seconds
[2022-02-18 03:28:56,518] {scheduler_job.py:155} INFO - Started process (PID=50256) to work on /airflow/dags/download_data.py
[2022-02-18 03:28:56,541] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:28:56,548] {logging_mixin.py:112} INFO - [2022-02-18 03:28:56,548] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:28:57,116] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:28:57,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:28:57,190] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:28:57,196] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.678 seconds
[2022-02-18 03:29:09,816] {scheduler_job.py:155} INFO - Started process (PID=50282) to work on /airflow/dags/download_data.py
[2022-02-18 03:29:09,822] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:29:09,823] {logging_mixin.py:112} INFO - [2022-02-18 03:29:09,823] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:29:10,424] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:29:10,473] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:29:10,488] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:29:10,499] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.683 seconds
[2022-02-18 03:29:23,098] {scheduler_job.py:155} INFO - Started process (PID=50308) to work on /airflow/dags/download_data.py
[2022-02-18 03:29:23,109] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:29:23,111] {logging_mixin.py:112} INFO - [2022-02-18 03:29:23,111] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:29:23,657] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:29:23,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:29:23,710] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:29:23,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-18 03:29:36,380] {scheduler_job.py:155} INFO - Started process (PID=50334) to work on /airflow/dags/download_data.py
[2022-02-18 03:29:36,389] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:29:36,393] {logging_mixin.py:112} INFO - [2022-02-18 03:29:36,393] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:29:36,853] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:29:36,904] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:29:36,911] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:29:36,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 03:29:49,659] {scheduler_job.py:155} INFO - Started process (PID=50360) to work on /airflow/dags/download_data.py
[2022-02-18 03:29:49,668] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:29:49,689] {logging_mixin.py:112} INFO - [2022-02-18 03:29:49,688] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:29:50,331] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:29:50,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:29:50,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:29:50,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.767 seconds
[2022-02-18 03:30:02,972] {scheduler_job.py:155} INFO - Started process (PID=50386) to work on /airflow/dags/download_data.py
[2022-02-18 03:30:02,978] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:30:02,980] {logging_mixin.py:112} INFO - [2022-02-18 03:30:02,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:30:03,503] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:30:03,552] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:30:03,564] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:30:03,573] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 03:30:16,216] {scheduler_job.py:155} INFO - Started process (PID=50412) to work on /airflow/dags/download_data.py
[2022-02-18 03:30:16,229] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:30:16,230] {logging_mixin.py:112} INFO - [2022-02-18 03:30:16,230] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:30:16,810] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:30:16,930] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:30:16,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:30:16,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.748 seconds
[2022-02-18 03:30:29,520] {scheduler_job.py:155} INFO - Started process (PID=50438) to work on /airflow/dags/download_data.py
[2022-02-18 03:30:29,525] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:30:29,527] {logging_mixin.py:112} INFO - [2022-02-18 03:30:29,526] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:30:30,016] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:30:30,071] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:30:30,078] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:30:30,083] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 03:30:42,804] {scheduler_job.py:155} INFO - Started process (PID=50464) to work on /airflow/dags/download_data.py
[2022-02-18 03:30:42,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:30:42,812] {logging_mixin.py:112} INFO - [2022-02-18 03:30:42,812] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:30:43,409] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:30:43,469] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:30:43,485] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:30:43,507] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.703 seconds
[2022-02-18 03:30:56,121] {scheduler_job.py:155} INFO - Started process (PID=50490) to work on /airflow/dags/download_data.py
[2022-02-18 03:30:56,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:30:56,137] {logging_mixin.py:112} INFO - [2022-02-18 03:30:56,136] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:30:56,698] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:30:56,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:30:56,762] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:30:56,767] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.649 seconds
[2022-02-18 03:31:09,371] {scheduler_job.py:155} INFO - Started process (PID=50516) to work on /airflow/dags/download_data.py
[2022-02-18 03:31:09,383] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:31:09,386] {logging_mixin.py:112} INFO - [2022-02-18 03:31:09,385] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:31:09,992] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:31:10,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:31:10,038] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:31:10,048] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-18 03:31:22,707] {scheduler_job.py:155} INFO - Started process (PID=50542) to work on /airflow/dags/download_data.py
[2022-02-18 03:31:22,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:31:22,719] {logging_mixin.py:112} INFO - [2022-02-18 03:31:22,719] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:31:23,441] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:31:23,498] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:31:23,511] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:31:23,522] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.814 seconds
[2022-02-18 03:31:35,985] {scheduler_job.py:155} INFO - Started process (PID=50568) to work on /airflow/dags/download_data.py
[2022-02-18 03:31:35,990] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:31:35,992] {logging_mixin.py:112} INFO - [2022-02-18 03:31:35,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:31:36,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:31:36,517] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:31:36,530] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:31:36,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 03:31:49,271] {scheduler_job.py:155} INFO - Started process (PID=50594) to work on /airflow/dags/download_data.py
[2022-02-18 03:31:49,284] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:31:49,287] {logging_mixin.py:112} INFO - [2022-02-18 03:31:49,287] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:31:50,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:31:50,145] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:31:50,181] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:31:50,191] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.923 seconds
[2022-02-18 03:32:02,574] {scheduler_job.py:155} INFO - Started process (PID=50620) to work on /airflow/dags/download_data.py
[2022-02-18 03:32:02,579] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:32:02,581] {logging_mixin.py:112} INFO - [2022-02-18 03:32:02,580] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:32:03,140] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:32:03,179] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:32:03,186] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:32:03,191] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-18 03:32:15,901] {scheduler_job.py:155} INFO - Started process (PID=50646) to work on /airflow/dags/download_data.py
[2022-02-18 03:32:15,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:32:15,919] {logging_mixin.py:112} INFO - [2022-02-18 03:32:15,919] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:32:16,431] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:32:16,470] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:32:16,478] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:32:16,482] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 03:32:29,178] {scheduler_job.py:155} INFO - Started process (PID=50672) to work on /airflow/dags/download_data.py
[2022-02-18 03:32:29,188] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:32:29,191] {logging_mixin.py:112} INFO - [2022-02-18 03:32:29,190] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:32:29,737] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:32:29,784] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:32:29,797] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:32:29,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-18 03:32:42,443] {scheduler_job.py:155} INFO - Started process (PID=50698) to work on /airflow/dags/download_data.py
[2022-02-18 03:32:42,455] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:32:42,458] {logging_mixin.py:112} INFO - [2022-02-18 03:32:42,457] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:32:42,944] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:32:43,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:32:43,018] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:32:43,025] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 03:32:55,767] {scheduler_job.py:155} INFO - Started process (PID=50724) to work on /airflow/dags/download_data.py
[2022-02-18 03:32:55,776] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:32:55,778] {logging_mixin.py:112} INFO - [2022-02-18 03:32:55,778] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:32:56,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:32:56,322] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:32:56,338] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:32:56,355] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 03:33:09,032] {scheduler_job.py:155} INFO - Started process (PID=50750) to work on /airflow/dags/download_data.py
[2022-02-18 03:33:09,041] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:33:09,043] {logging_mixin.py:112} INFO - [2022-02-18 03:33:09,042] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:33:09,519] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:33:09,580] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:33:09,590] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:33:09,595] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 03:33:22,308] {scheduler_job.py:155} INFO - Started process (PID=50776) to work on /airflow/dags/download_data.py
[2022-02-18 03:33:22,316] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:33:22,318] {logging_mixin.py:112} INFO - [2022-02-18 03:33:22,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:33:22,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:33:22,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:33:22,796] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:33:22,801] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 03:33:35,606] {scheduler_job.py:155} INFO - Started process (PID=50802) to work on /airflow/dags/download_data.py
[2022-02-18 03:33:35,618] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:33:35,622] {logging_mixin.py:112} INFO - [2022-02-18 03:33:35,622] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:33:36,190] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:33:36,251] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:33:36,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:33:36,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.660 seconds
[2022-02-18 03:33:48,867] {scheduler_job.py:155} INFO - Started process (PID=50828) to work on /airflow/dags/download_data.py
[2022-02-18 03:33:48,880] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:33:48,893] {logging_mixin.py:112} INFO - [2022-02-18 03:33:48,892] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:33:49,350] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:33:49,401] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:33:49,410] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:33:49,415] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 03:34:02,161] {scheduler_job.py:155} INFO - Started process (PID=50854) to work on /airflow/dags/download_data.py
[2022-02-18 03:34:02,226] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:34:02,235] {logging_mixin.py:112} INFO - [2022-02-18 03:34:02,235] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:34:02,758] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:34:02,813] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:34:02,832] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:34:02,839] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-18 03:34:15,466] {scheduler_job.py:155} INFO - Started process (PID=50880) to work on /airflow/dags/download_data.py
[2022-02-18 03:34:15,473] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:34:15,475] {logging_mixin.py:112} INFO - [2022-02-18 03:34:15,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:34:15,962] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:34:16,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:34:16,029] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:34:16,036] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 03:34:28,755] {scheduler_job.py:155} INFO - Started process (PID=50906) to work on /airflow/dags/download_data.py
[2022-02-18 03:34:28,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:34:28,765] {logging_mixin.py:112} INFO - [2022-02-18 03:34:28,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:34:29,291] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:34:29,363] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:34:29,380] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:34:29,388] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-18 03:34:42,058] {scheduler_job.py:155} INFO - Started process (PID=50932) to work on /airflow/dags/download_data.py
[2022-02-18 03:34:42,080] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:34:42,083] {logging_mixin.py:112} INFO - [2022-02-18 03:34:42,082] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:34:42,677] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:34:42,726] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:34:42,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:34:42,741] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.684 seconds
[2022-02-18 03:34:55,329] {scheduler_job.py:155} INFO - Started process (PID=50958) to work on /airflow/dags/download_data.py
[2022-02-18 03:34:55,333] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:34:55,335] {logging_mixin.py:112} INFO - [2022-02-18 03:34:55,335] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:34:55,833] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:34:55,882] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:34:55,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:34:55,899] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 03:35:08,653] {scheduler_job.py:155} INFO - Started process (PID=50984) to work on /airflow/dags/download_data.py
[2022-02-18 03:35:08,658] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:35:08,661] {logging_mixin.py:112} INFO - [2022-02-18 03:35:08,660] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:35:09,176] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:35:09,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:35:09,226] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:35:09,230] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 03:35:21,971] {scheduler_job.py:155} INFO - Started process (PID=51010) to work on /airflow/dags/download_data.py
[2022-02-18 03:35:21,983] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:35:21,988] {logging_mixin.py:112} INFO - [2022-02-18 03:35:21,988] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:35:22,578] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:35:22,652] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:35:22,664] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:35:22,671] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.700 seconds
[2022-02-18 03:35:35,256] {scheduler_job.py:155} INFO - Started process (PID=51036) to work on /airflow/dags/download_data.py
[2022-02-18 03:35:35,270] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:35:35,272] {logging_mixin.py:112} INFO - [2022-02-18 03:35:35,272] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:35:35,891] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:35:35,964] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:35:35,975] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:35:35,982] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.726 seconds
[2022-02-18 03:35:48,578] {scheduler_job.py:155} INFO - Started process (PID=51062) to work on /airflow/dags/download_data.py
[2022-02-18 03:35:48,581] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:35:48,583] {logging_mixin.py:112} INFO - [2022-02-18 03:35:48,583] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:35:49,142] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:35:49,197] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:35:49,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:35:49,220] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-18 03:36:01,914] {scheduler_job.py:155} INFO - Started process (PID=51088) to work on /airflow/dags/download_data.py
[2022-02-18 03:36:01,918] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:36:01,920] {logging_mixin.py:112} INFO - [2022-02-18 03:36:01,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:36:02,444] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:36:02,489] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:36:02,497] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:36:02,501] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 03:36:15,162] {scheduler_job.py:155} INFO - Started process (PID=51114) to work on /airflow/dags/download_data.py
[2022-02-18 03:36:15,168] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:36:15,170] {logging_mixin.py:112} INFO - [2022-02-18 03:36:15,170] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:36:15,658] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:36:15,710] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:36:15,718] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:36:15,724] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 03:36:28,519] {scheduler_job.py:155} INFO - Started process (PID=51140) to work on /airflow/dags/download_data.py
[2022-02-18 03:36:28,529] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:36:28,531] {logging_mixin.py:112} INFO - [2022-02-18 03:36:28,531] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:36:29,077] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:36:29,121] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:36:29,138] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:36:29,147] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-18 03:36:41,766] {scheduler_job.py:155} INFO - Started process (PID=51166) to work on /airflow/dags/download_data.py
[2022-02-18 03:36:41,775] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:36:41,803] {logging_mixin.py:112} INFO - [2022-02-18 03:36:41,802] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:36:42,576] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:36:42,672] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:36:42,705] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:36:42,729] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.963 seconds
[2022-02-18 03:36:55,110] {scheduler_job.py:155} INFO - Started process (PID=51192) to work on /airflow/dags/download_data.py
[2022-02-18 03:36:55,120] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:36:55,125] {logging_mixin.py:112} INFO - [2022-02-18 03:36:55,124] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:36:55,576] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:36:55,628] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:36:55,636] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:36:55,642] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 03:37:08,369] {scheduler_job.py:155} INFO - Started process (PID=51218) to work on /airflow/dags/download_data.py
[2022-02-18 03:37:08,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:37:08,377] {logging_mixin.py:112} INFO - [2022-02-18 03:37:08,377] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:37:09,035] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:37:09,087] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:37:09,099] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:37:09,106] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.737 seconds
[2022-02-18 03:37:21,719] {scheduler_job.py:155} INFO - Started process (PID=51244) to work on /airflow/dags/download_data.py
[2022-02-18 03:37:21,726] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:37:21,728] {logging_mixin.py:112} INFO - [2022-02-18 03:37:21,727] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:37:22,360] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:37:22,416] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:37:22,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:37:22,431] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.712 seconds
[2022-02-18 03:37:35,009] {scheduler_job.py:155} INFO - Started process (PID=51270) to work on /airflow/dags/download_data.py
[2022-02-18 03:37:35,014] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:37:35,016] {logging_mixin.py:112} INFO - [2022-02-18 03:37:35,015] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:37:35,574] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:37:35,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:37:35,637] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:37:35,644] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-18 03:37:48,285] {scheduler_job.py:155} INFO - Started process (PID=51296) to work on /airflow/dags/download_data.py
[2022-02-18 03:37:48,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:37:48,302] {logging_mixin.py:112} INFO - [2022-02-18 03:37:48,302] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:37:48,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:37:48,870] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:37:48,877] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:37:48,881] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 03:38:01,580] {scheduler_job.py:155} INFO - Started process (PID=51322) to work on /airflow/dags/download_data.py
[2022-02-18 03:38:01,585] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:38:01,587] {logging_mixin.py:112} INFO - [2022-02-18 03:38:01,587] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:38:02,203] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:38:02,252] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:38:02,260] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:38:02,265] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.685 seconds
[2022-02-18 03:38:14,821] {scheduler_job.py:155} INFO - Started process (PID=51348) to work on /airflow/dags/download_data.py
[2022-02-18 03:38:14,825] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:38:14,827] {logging_mixin.py:112} INFO - [2022-02-18 03:38:14,827] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:38:15,307] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:38:15,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:38:15,372] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:38:15,376] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 03:38:28,139] {scheduler_job.py:155} INFO - Started process (PID=51374) to work on /airflow/dags/download_data.py
[2022-02-18 03:38:28,155] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:38:28,157] {logging_mixin.py:112} INFO - [2022-02-18 03:38:28,157] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:38:29,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:38:29,060] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:38:29,071] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:38:29,076] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.937 seconds
[2022-02-18 03:38:41,406] {scheduler_job.py:155} INFO - Started process (PID=51400) to work on /airflow/dags/download_data.py
[2022-02-18 03:38:41,411] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:38:41,415] {logging_mixin.py:112} INFO - [2022-02-18 03:38:41,415] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:38:41,980] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:38:42,034] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:38:42,043] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:38:42,049] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.643 seconds
[2022-02-18 03:38:54,697] {scheduler_job.py:155} INFO - Started process (PID=51426) to work on /airflow/dags/download_data.py
[2022-02-18 03:38:54,706] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:38:54,708] {logging_mixin.py:112} INFO - [2022-02-18 03:38:54,708] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:38:55,169] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:38:55,216] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:38:55,226] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:38:55,229] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 03:39:07,934] {scheduler_job.py:155} INFO - Started process (PID=51452) to work on /airflow/dags/download_data.py
[2022-02-18 03:39:07,939] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:39:07,940] {logging_mixin.py:112} INFO - [2022-02-18 03:39:07,940] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:39:08,465] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:39:08,510] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:39:08,517] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:39:08,522] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 03:39:21,236] {scheduler_job.py:155} INFO - Started process (PID=51478) to work on /airflow/dags/download_data.py
[2022-02-18 03:39:21,246] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:39:21,249] {logging_mixin.py:112} INFO - [2022-02-18 03:39:21,248] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:39:21,697] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:39:21,751] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:39:21,765] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:39:21,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 03:39:34,567] {scheduler_job.py:155} INFO - Started process (PID=51504) to work on /airflow/dags/download_data.py
[2022-02-18 03:39:34,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:39:34,579] {logging_mixin.py:112} INFO - [2022-02-18 03:39:34,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:39:35,129] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:39:35,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:39:35,187] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:39:35,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-18 03:39:47,813] {scheduler_job.py:155} INFO - Started process (PID=51530) to work on /airflow/dags/download_data.py
[2022-02-18 03:39:47,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:39:47,825] {logging_mixin.py:112} INFO - [2022-02-18 03:39:47,824] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:39:48,284] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:39:48,319] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:39:48,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:39:48,334] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 03:40:01,116] {scheduler_job.py:155} INFO - Started process (PID=51556) to work on /airflow/dags/download_data.py
[2022-02-18 03:40:01,121] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:40:01,122] {logging_mixin.py:112} INFO - [2022-02-18 03:40:01,122] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:40:01,576] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:40:01,620] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:40:01,630] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:40:01,637] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 03:40:14,370] {scheduler_job.py:155} INFO - Started process (PID=51582) to work on /airflow/dags/download_data.py
[2022-02-18 03:40:14,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:40:14,376] {logging_mixin.py:112} INFO - [2022-02-18 03:40:14,376] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:40:14,813] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:40:14,855] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:40:14,861] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:40:14,865] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 03:40:27,630] {scheduler_job.py:155} INFO - Started process (PID=51608) to work on /airflow/dags/download_data.py
[2022-02-18 03:40:27,635] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:40:27,636] {logging_mixin.py:112} INFO - [2022-02-18 03:40:27,636] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:40:28,102] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:40:28,152] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:40:28,162] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:40:28,167] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 03:40:40,905] {scheduler_job.py:155} INFO - Started process (PID=51634) to work on /airflow/dags/download_data.py
[2022-02-18 03:40:40,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:40:40,921] {logging_mixin.py:112} INFO - [2022-02-18 03:40:40,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:40:41,489] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:40:41,546] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:40:41,554] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:40:41,560] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.656 seconds
[2022-02-18 03:40:54,252] {scheduler_job.py:155} INFO - Started process (PID=51660) to work on /airflow/dags/download_data.py
[2022-02-18 03:40:54,275] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:40:54,296] {logging_mixin.py:112} INFO - [2022-02-18 03:40:54,295] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:40:54,845] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:40:54,894] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:40:54,924] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:40:54,930] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.678 seconds
[2022-02-18 03:41:07,561] {scheduler_job.py:155} INFO - Started process (PID=51686) to work on /airflow/dags/download_data.py
[2022-02-18 03:41:07,575] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:41:07,578] {logging_mixin.py:112} INFO - [2022-02-18 03:41:07,578] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:41:08,068] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:41:08,125] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:41:08,137] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:41:08,142] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 03:41:20,917] {scheduler_job.py:155} INFO - Started process (PID=51712) to work on /airflow/dags/download_data.py
[2022-02-18 03:41:20,925] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:41:20,931] {logging_mixin.py:112} INFO - [2022-02-18 03:41:20,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:41:21,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:41:21,480] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:41:21,490] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:41:21,496] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 03:41:34,270] {scheduler_job.py:155} INFO - Started process (PID=51738) to work on /airflow/dags/download_data.py
[2022-02-18 03:41:34,277] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:41:34,279] {logging_mixin.py:112} INFO - [2022-02-18 03:41:34,279] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:41:34,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:41:34,851] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:41:34,866] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:41:34,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-18 03:41:47,543] {scheduler_job.py:155} INFO - Started process (PID=51764) to work on /airflow/dags/download_data.py
[2022-02-18 03:41:47,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:41:47,557] {logging_mixin.py:112} INFO - [2022-02-18 03:41:47,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:41:48,077] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:41:48,121] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:41:48,130] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:41:48,137] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 03:42:00,837] {scheduler_job.py:155} INFO - Started process (PID=51790) to work on /airflow/dags/download_data.py
[2022-02-18 03:42:00,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:42:00,852] {logging_mixin.py:112} INFO - [2022-02-18 03:42:00,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:42:01,359] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:42:01,414] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:42:01,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:42:01,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 03:42:14,112] {scheduler_job.py:155} INFO - Started process (PID=51816) to work on /airflow/dags/download_data.py
[2022-02-18 03:42:14,121] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:42:14,123] {logging_mixin.py:112} INFO - [2022-02-18 03:42:14,123] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:42:14,725] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:42:14,798] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:42:14,809] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:42:14,814] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.702 seconds
[2022-02-18 03:42:27,393] {scheduler_job.py:155} INFO - Started process (PID=51842) to work on /airflow/dags/download_data.py
[2022-02-18 03:42:27,398] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:42:27,400] {logging_mixin.py:112} INFO - [2022-02-18 03:42:27,399] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:42:27,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:42:27,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:42:27,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:42:27,973] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 03:42:40,669] {scheduler_job.py:155} INFO - Started process (PID=51868) to work on /airflow/dags/download_data.py
[2022-02-18 03:42:40,675] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:42:40,677] {logging_mixin.py:112} INFO - [2022-02-18 03:42:40,677] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:42:41,202] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:42:41,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:42:41,256] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:42:41,269] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 03:42:53,962] {scheduler_job.py:155} INFO - Started process (PID=51894) to work on /airflow/dags/download_data.py
[2022-02-18 03:42:53,974] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:42:53,977] {logging_mixin.py:112} INFO - [2022-02-18 03:42:53,977] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:42:54,645] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:42:54,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:42:54,692] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:42:54,696] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.735 seconds
[2022-02-18 03:43:07,232] {scheduler_job.py:155} INFO - Started process (PID=51920) to work on /airflow/dags/download_data.py
[2022-02-18 03:43:07,238] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:43:07,240] {logging_mixin.py:112} INFO - [2022-02-18 03:43:07,239] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:43:07,775] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:43:07,809] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:43:07,818] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:43:07,824] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 03:43:20,523] {scheduler_job.py:155} INFO - Started process (PID=51946) to work on /airflow/dags/download_data.py
[2022-02-18 03:43:20,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:43:20,529] {logging_mixin.py:112} INFO - [2022-02-18 03:43:20,529] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:43:21,113] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:43:21,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:43:21,174] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:43:21,180] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-18 03:43:33,861] {scheduler_job.py:155} INFO - Started process (PID=51972) to work on /airflow/dags/download_data.py
[2022-02-18 03:43:33,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:43:33,870] {logging_mixin.py:112} INFO - [2022-02-18 03:43:33,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:43:34,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:43:34,571] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:43:34,583] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:43:34,593] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.732 seconds
[2022-02-18 03:43:47,130] {scheduler_job.py:155} INFO - Started process (PID=51998) to work on /airflow/dags/download_data.py
[2022-02-18 03:43:47,137] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:43:47,139] {logging_mixin.py:112} INFO - [2022-02-18 03:43:47,139] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:43:47,701] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:43:47,770] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:43:47,793] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:43:47,798] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.668 seconds
[2022-02-18 03:44:00,484] {scheduler_job.py:155} INFO - Started process (PID=52024) to work on /airflow/dags/download_data.py
[2022-02-18 03:44:00,495] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:44:00,497] {logging_mixin.py:112} INFO - [2022-02-18 03:44:00,497] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:44:00,993] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:44:01,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:44:01,047] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:44:01,051] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 03:44:13,741] {scheduler_job.py:155} INFO - Started process (PID=52050) to work on /airflow/dags/download_data.py
[2022-02-18 03:44:13,746] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:44:13,748] {logging_mixin.py:112} INFO - [2022-02-18 03:44:13,747] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:44:14,270] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:44:14,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:44:14,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:44:14,334] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 03:44:27,121] {scheduler_job.py:155} INFO - Started process (PID=52076) to work on /airflow/dags/download_data.py
[2022-02-18 03:44:27,130] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:44:27,133] {logging_mixin.py:112} INFO - [2022-02-18 03:44:27,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:44:27,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:44:27,765] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:44:27,771] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:44:27,778] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-18 03:44:40,440] {scheduler_job.py:155} INFO - Started process (PID=52102) to work on /airflow/dags/download_data.py
[2022-02-18 03:44:40,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:44:40,462] {logging_mixin.py:112} INFO - [2022-02-18 03:44:40,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:44:41,444] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:44:41,510] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:44:41,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:44:41,533] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.093 seconds
[2022-02-18 03:44:54,706] {scheduler_job.py:155} INFO - Started process (PID=52128) to work on /airflow/dags/download_data.py
[2022-02-18 03:44:54,714] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:44:54,716] {logging_mixin.py:112} INFO - [2022-02-18 03:44:54,716] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:44:55,303] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:44:55,362] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:44:55,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:44:55,376] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.671 seconds
[2022-02-18 03:45:06,965] {scheduler_job.py:155} INFO - Started process (PID=52153) to work on /airflow/dags/download_data.py
[2022-02-18 03:45:06,978] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:45:06,981] {logging_mixin.py:112} INFO - [2022-02-18 03:45:06,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:45:07,505] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:45:07,551] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:45:07,560] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:45:07,566] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-18 03:45:20,295] {scheduler_job.py:155} INFO - Started process (PID=52179) to work on /airflow/dags/download_data.py
[2022-02-18 03:45:20,303] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:45:20,306] {logging_mixin.py:112} INFO - [2022-02-18 03:45:20,305] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:45:21,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:45:21,170] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:45:21,184] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:45:21,191] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.896 seconds
[2022-02-18 03:45:33,616] {scheduler_job.py:155} INFO - Started process (PID=52205) to work on /airflow/dags/download_data.py
[2022-02-18 03:45:33,622] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:45:33,627] {logging_mixin.py:112} INFO - [2022-02-18 03:45:33,627] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:45:34,189] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:45:34,226] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:45:34,233] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:45:34,237] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-18 03:45:46,942] {scheduler_job.py:155} INFO - Started process (PID=52231) to work on /airflow/dags/download_data.py
[2022-02-18 03:45:46,948] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:45:46,951] {logging_mixin.py:112} INFO - [2022-02-18 03:45:46,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:45:47,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:45:47,478] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:45:47,490] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:45:47,494] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 03:46:00,224] {scheduler_job.py:155} INFO - Started process (PID=52257) to work on /airflow/dags/download_data.py
[2022-02-18 03:46:00,233] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:46:00,234] {logging_mixin.py:112} INFO - [2022-02-18 03:46:00,234] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:46:00,987] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:46:01,055] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:46:01,064] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:46:01,070] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.846 seconds
[2022-02-18 03:46:13,490] {scheduler_job.py:155} INFO - Started process (PID=52283) to work on /airflow/dags/download_data.py
[2022-02-18 03:46:13,498] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:46:13,502] {logging_mixin.py:112} INFO - [2022-02-18 03:46:13,502] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:46:13,991] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:46:14,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:46:14,053] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:46:14,058] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 03:46:26,758] {scheduler_job.py:155} INFO - Started process (PID=52309) to work on /airflow/dags/download_data.py
[2022-02-18 03:46:26,766] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:46:26,768] {logging_mixin.py:112} INFO - [2022-02-18 03:46:26,768] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:46:27,288] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:46:27,334] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:46:27,345] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:46:27,351] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 03:46:40,047] {scheduler_job.py:155} INFO - Started process (PID=52335) to work on /airflow/dags/download_data.py
[2022-02-18 03:46:40,058] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:46:40,070] {logging_mixin.py:112} INFO - [2022-02-18 03:46:40,070] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:46:40,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:46:40,668] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:46:40,679] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:46:40,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-18 03:46:53,322] {scheduler_job.py:155} INFO - Started process (PID=52361) to work on /airflow/dags/download_data.py
[2022-02-18 03:46:53,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:46:53,335] {logging_mixin.py:112} INFO - [2022-02-18 03:46:53,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:46:53,837] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:46:53,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:46:53,905] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:46:53,911] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 03:47:06,638] {scheduler_job.py:155} INFO - Started process (PID=52387) to work on /airflow/dags/download_data.py
[2022-02-18 03:47:06,646] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:47:06,648] {logging_mixin.py:112} INFO - [2022-02-18 03:47:06,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:47:07,288] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:47:07,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:47:07,356] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:47:07,362] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.723 seconds
[2022-02-18 03:47:19,957] {scheduler_job.py:155} INFO - Started process (PID=52413) to work on /airflow/dags/download_data.py
[2022-02-18 03:47:19,963] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:47:19,964] {logging_mixin.py:112} INFO - [2022-02-18 03:47:19,964] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:47:20,588] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:47:20,639] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:47:20,651] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:47:20,656] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-18 03:47:33,249] {scheduler_job.py:155} INFO - Started process (PID=52439) to work on /airflow/dags/download_data.py
[2022-02-18 03:47:33,261] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:47:33,266] {logging_mixin.py:112} INFO - [2022-02-18 03:47:33,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:47:33,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:47:33,889] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:47:33,897] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:47:33,902] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-18 03:47:46,502] {scheduler_job.py:155} INFO - Started process (PID=52465) to work on /airflow/dags/download_data.py
[2022-02-18 03:47:46,507] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:47:46,509] {logging_mixin.py:112} INFO - [2022-02-18 03:47:46,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:47:47,049] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:47:47,107] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:47:47,124] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:47:47,136] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.634 seconds
[2022-02-18 03:47:59,800] {scheduler_job.py:155} INFO - Started process (PID=52491) to work on /airflow/dags/download_data.py
[2022-02-18 03:47:59,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:47:59,807] {logging_mixin.py:112} INFO - [2022-02-18 03:47:59,807] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:48:00,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:48:00,324] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:48:00,329] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:48:00,333] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 03:48:13,045] {scheduler_job.py:155} INFO - Started process (PID=52517) to work on /airflow/dags/download_data.py
[2022-02-18 03:48:13,051] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:48:13,054] {logging_mixin.py:112} INFO - [2022-02-18 03:48:13,054] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:48:13,632] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:48:13,687] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:48:13,699] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:48:13,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.665 seconds
[2022-02-18 03:48:26,337] {scheduler_job.py:155} INFO - Started process (PID=52543) to work on /airflow/dags/download_data.py
[2022-02-18 03:48:26,341] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:48:26,342] {logging_mixin.py:112} INFO - [2022-02-18 03:48:26,342] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:48:26,822] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:48:26,871] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:48:26,882] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:48:26,889] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 03:48:39,627] {scheduler_job.py:155} INFO - Started process (PID=52569) to work on /airflow/dags/download_data.py
[2022-02-18 03:48:39,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:48:39,634] {logging_mixin.py:112} INFO - [2022-02-18 03:48:39,634] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:48:40,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:48:40,295] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:48:40,309] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:48:40,316] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.689 seconds
[2022-02-18 03:48:52,906] {scheduler_job.py:155} INFO - Started process (PID=52595) to work on /airflow/dags/download_data.py
[2022-02-18 03:48:52,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:48:52,919] {logging_mixin.py:112} INFO - [2022-02-18 03:48:52,919] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:48:53,388] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:48:53,444] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:48:53,453] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:48:53,456] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 03:49:06,253] {scheduler_job.py:155} INFO - Started process (PID=52621) to work on /airflow/dags/download_data.py
[2022-02-18 03:49:06,265] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:49:06,269] {logging_mixin.py:112} INFO - [2022-02-18 03:49:06,269] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:49:06,727] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:49:06,759] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:49:06,764] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:49:06,768] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 03:49:19,516] {scheduler_job.py:155} INFO - Started process (PID=52647) to work on /airflow/dags/download_data.py
[2022-02-18 03:49:19,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:49:19,533] {logging_mixin.py:112} INFO - [2022-02-18 03:49:19,533] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:49:20,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:49:20,454] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:49:20,491] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:49:20,497] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.981 seconds
[2022-02-18 03:49:32,944] {scheduler_job.py:155} INFO - Started process (PID=52673) to work on /airflow/dags/download_data.py
[2022-02-18 03:49:32,965] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:49:32,968] {logging_mixin.py:112} INFO - [2022-02-18 03:49:32,967] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:49:33,988] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:49:34,047] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:49:34,057] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:49:34,063] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.119 seconds
[2022-02-18 03:49:47,217] {scheduler_job.py:155} INFO - Started process (PID=52699) to work on /airflow/dags/download_data.py
[2022-02-18 03:49:47,231] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:49:47,238] {logging_mixin.py:112} INFO - [2022-02-18 03:49:47,235] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:49:48,620] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:49:49,033] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:49:49,042] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:49:49,047] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.830 seconds
[2022-02-18 03:50:00,506] {scheduler_job.py:155} INFO - Started process (PID=52724) to work on /airflow/dags/download_data.py
[2022-02-18 03:50:00,513] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:50:00,517] {logging_mixin.py:112} INFO - [2022-02-18 03:50:00,516] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:50:01,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:50:01,076] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:50:01,081] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:50:01,087] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 03:50:12,784] {scheduler_job.py:155} INFO - Started process (PID=52749) to work on /airflow/dags/download_data.py
[2022-02-18 03:50:12,790] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:50:12,793] {logging_mixin.py:112} INFO - [2022-02-18 03:50:12,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:50:13,260] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:50:13,319] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:50:13,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:50:13,334] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 03:50:26,071] {scheduler_job.py:155} INFO - Started process (PID=52775) to work on /airflow/dags/download_data.py
[2022-02-18 03:50:26,076] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:50:26,078] {logging_mixin.py:112} INFO - [2022-02-18 03:50:26,078] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:50:26,624] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:50:26,671] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:50:26,680] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:50:26,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 03:50:39,382] {scheduler_job.py:155} INFO - Started process (PID=52801) to work on /airflow/dags/download_data.py
[2022-02-18 03:50:39,393] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:50:39,395] {logging_mixin.py:112} INFO - [2022-02-18 03:50:39,395] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:50:39,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:50:39,947] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:50:39,960] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:50:39,965] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 03:50:52,662] {scheduler_job.py:155} INFO - Started process (PID=52827) to work on /airflow/dags/download_data.py
[2022-02-18 03:50:52,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:50:52,671] {logging_mixin.py:112} INFO - [2022-02-18 03:50:52,670] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:50:53,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:50:53,262] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:50:53,272] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:50:53,276] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-18 03:51:05,902] {scheduler_job.py:155} INFO - Started process (PID=52853) to work on /airflow/dags/download_data.py
[2022-02-18 03:51:05,908] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:51:05,909] {logging_mixin.py:112} INFO - [2022-02-18 03:51:05,909] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:51:06,414] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:51:06,466] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:51:06,477] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:51:06,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 03:51:19,235] {scheduler_job.py:155} INFO - Started process (PID=52879) to work on /airflow/dags/download_data.py
[2022-02-18 03:51:19,241] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:51:19,243] {logging_mixin.py:112} INFO - [2022-02-18 03:51:19,243] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:51:20,503] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:51:20,602] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:51:20,611] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:51:20,622] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.388 seconds
[2022-02-18 03:51:33,566] {scheduler_job.py:155} INFO - Started process (PID=52905) to work on /airflow/dags/download_data.py
[2022-02-18 03:51:33,575] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:51:33,579] {logging_mixin.py:112} INFO - [2022-02-18 03:51:33,578] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:51:34,323] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:51:34,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:51:34,424] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:51:34,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.873 seconds
[2022-02-18 03:51:45,889] {scheduler_job.py:155} INFO - Started process (PID=52930) to work on /airflow/dags/download_data.py
[2022-02-18 03:51:45,904] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:51:45,907] {logging_mixin.py:112} INFO - [2022-02-18 03:51:45,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:51:46,361] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:51:46,416] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:51:46,427] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:51:46,433] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 03:51:59,185] {scheduler_job.py:155} INFO - Started process (PID=52956) to work on /airflow/dags/download_data.py
[2022-02-18 03:51:59,211] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:51:59,237] {logging_mixin.py:112} INFO - [2022-02-18 03:51:59,237] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:51:59,874] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:51:59,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:51:59,943] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:51:59,949] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.765 seconds
[2022-02-18 03:52:12,458] {scheduler_job.py:155} INFO - Started process (PID=52982) to work on /airflow/dags/download_data.py
[2022-02-18 03:52:12,463] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:52:12,464] {logging_mixin.py:112} INFO - [2022-02-18 03:52:12,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:52:12,944] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:52:13,005] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:52:13,016] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:52:13,020] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 03:52:25,779] {scheduler_job.py:155} INFO - Started process (PID=53008) to work on /airflow/dags/download_data.py
[2022-02-18 03:52:25,804] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:52:25,806] {logging_mixin.py:112} INFO - [2022-02-18 03:52:25,806] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:52:26,481] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:52:26,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:52:26,538] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:52:26,544] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.764 seconds
[2022-02-18 03:52:39,005] {scheduler_job.py:155} INFO - Started process (PID=53034) to work on /airflow/dags/download_data.py
[2022-02-18 03:52:39,011] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:52:39,013] {logging_mixin.py:112} INFO - [2022-02-18 03:52:39,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:52:39,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:52:39,540] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:52:39,551] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:52:39,556] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 03:52:52,290] {scheduler_job.py:155} INFO - Started process (PID=53060) to work on /airflow/dags/download_data.py
[2022-02-18 03:52:52,294] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:52:52,295] {logging_mixin.py:112} INFO - [2022-02-18 03:52:52,295] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:52:52,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:52:52,799] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:52:52,810] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:52:52,817] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 03:53:05,541] {scheduler_job.py:155} INFO - Started process (PID=53086) to work on /airflow/dags/download_data.py
[2022-02-18 03:53:05,553] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:53:05,559] {logging_mixin.py:112} INFO - [2022-02-18 03:53:05,559] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:53:06,277] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:53:06,337] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:53:06,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:53:06,357] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.816 seconds
[2022-02-18 03:53:18,827] {scheduler_job.py:155} INFO - Started process (PID=53112) to work on /airflow/dags/download_data.py
[2022-02-18 03:53:18,831] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:53:18,832] {logging_mixin.py:112} INFO - [2022-02-18 03:53:18,832] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:53:19,277] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:53:19,318] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:53:19,327] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:53:19,332] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 03:53:32,121] {scheduler_job.py:155} INFO - Started process (PID=53138) to work on /airflow/dags/download_data.py
[2022-02-18 03:53:32,135] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:53:32,139] {logging_mixin.py:112} INFO - [2022-02-18 03:53:32,139] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:53:32,734] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:53:32,784] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:53:32,796] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:53:32,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.683 seconds
[2022-02-18 03:53:45,370] {scheduler_job.py:155} INFO - Started process (PID=53164) to work on /airflow/dags/download_data.py
[2022-02-18 03:53:45,374] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:53:45,376] {logging_mixin.py:112} INFO - [2022-02-18 03:53:45,376] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:53:45,865] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:53:45,913] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:53:45,920] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:53:45,928] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 03:53:58,638] {scheduler_job.py:155} INFO - Started process (PID=53190) to work on /airflow/dags/download_data.py
[2022-02-18 03:53:58,646] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:53:58,647] {logging_mixin.py:112} INFO - [2022-02-18 03:53:58,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:53:59,081] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:53:59,133] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:53:59,141] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:53:59,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 03:54:11,852] {scheduler_job.py:155} INFO - Started process (PID=53216) to work on /airflow/dags/download_data.py
[2022-02-18 03:54:11,856] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:54:11,857] {logging_mixin.py:112} INFO - [2022-02-18 03:54:11,857] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:54:12,302] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:54:12,352] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:54:12,360] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:54:12,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 03:54:25,151] {scheduler_job.py:155} INFO - Started process (PID=53242) to work on /airflow/dags/download_data.py
[2022-02-18 03:54:25,155] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:54:25,157] {logging_mixin.py:112} INFO - [2022-02-18 03:54:25,157] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:54:25,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:54:25,649] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:54:25,656] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:54:25,662] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 03:54:38,414] {scheduler_job.py:155} INFO - Started process (PID=53268) to work on /airflow/dags/download_data.py
[2022-02-18 03:54:38,422] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:54:38,424] {logging_mixin.py:112} INFO - [2022-02-18 03:54:38,424] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:54:38,878] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:54:38,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:54:38,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:54:38,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 03:54:51,721] {scheduler_job.py:155} INFO - Started process (PID=53294) to work on /airflow/dags/download_data.py
[2022-02-18 03:54:51,725] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:54:51,729] {logging_mixin.py:112} INFO - [2022-02-18 03:54:51,729] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:54:52,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:54:52,252] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:54:52,259] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:54:52,265] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 03:55:04,992] {scheduler_job.py:155} INFO - Started process (PID=53320) to work on /airflow/dags/download_data.py
[2022-02-18 03:55:04,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:55:05,000] {logging_mixin.py:112} INFO - [2022-02-18 03:55:05,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:55:05,436] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:55:05,499] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:55:05,513] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:55:05,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 03:55:18,263] {scheduler_job.py:155} INFO - Started process (PID=53346) to work on /airflow/dags/download_data.py
[2022-02-18 03:55:18,270] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:55:18,272] {logging_mixin.py:112} INFO - [2022-02-18 03:55:18,272] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:55:18,700] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:55:18,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:55:18,756] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:55:18,759] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 03:55:31,541] {scheduler_job.py:155} INFO - Started process (PID=53372) to work on /airflow/dags/download_data.py
[2022-02-18 03:55:31,545] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:55:31,547] {logging_mixin.py:112} INFO - [2022-02-18 03:55:31,547] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:55:32,027] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:55:32,091] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:55:32,101] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:55:32,105] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 03:55:44,813] {scheduler_job.py:155} INFO - Started process (PID=53398) to work on /airflow/dags/download_data.py
[2022-02-18 03:55:44,828] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:55:44,830] {logging_mixin.py:112} INFO - [2022-02-18 03:55:44,829] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:55:45,316] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:55:45,362] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:55:45,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:55:45,376] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 03:55:58,094] {scheduler_job.py:155} INFO - Started process (PID=53424) to work on /airflow/dags/download_data.py
[2022-02-18 03:55:58,101] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:55:58,104] {logging_mixin.py:112} INFO - [2022-02-18 03:55:58,104] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:55:58,557] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:55:58,607] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:55:58,616] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:55:58,622] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 03:56:11,330] {scheduler_job.py:155} INFO - Started process (PID=53450) to work on /airflow/dags/download_data.py
[2022-02-18 03:56:11,337] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:56:11,339] {logging_mixin.py:112} INFO - [2022-02-18 03:56:11,339] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:56:11,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:56:11,909] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:56:11,918] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:56:11,923] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 03:56:24,666] {scheduler_job.py:155} INFO - Started process (PID=53476) to work on /airflow/dags/download_data.py
[2022-02-18 03:56:24,673] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 03:56:24,680] {logging_mixin.py:112} INFO - [2022-02-18 03:56:24,680] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 03:56:25,165] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 03:56:25,206] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 03:56:25,217] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 03:56:25,223] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 04:10:43,442] {scheduler_job.py:155} INFO - Started process (PID=53502) to work on /airflow/dags/download_data.py
[2022-02-18 04:10:43,452] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:10:43,454] {logging_mixin.py:112} INFO - [2022-02-18 04:10:43,454] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:10:44,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:10:44,074] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:10:44,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:10:44,090] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.649 seconds
[2022-02-18 04:10:56,869] {scheduler_job.py:155} INFO - Started process (PID=53528) to work on /airflow/dags/download_data.py
[2022-02-18 04:10:56,876] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:10:56,881] {logging_mixin.py:112} INFO - [2022-02-18 04:10:56,880] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:10:57,576] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:10:57,636] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:10:57,651] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:10:57,657] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.788 seconds
[2022-02-18 04:11:10,584] {scheduler_job.py:155} INFO - Started process (PID=53554) to work on /airflow/dags/download_data.py
[2022-02-18 04:11:10,593] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:11:10,599] {logging_mixin.py:112} INFO - [2022-02-18 04:11:10,598] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:11:11,247] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:11:11,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:11:11,309] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:11:11,315] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.732 seconds
[2022-02-18 04:11:23,902] {scheduler_job.py:155} INFO - Started process (PID=53580) to work on /airflow/dags/download_data.py
[2022-02-18 04:11:23,907] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:11:23,909] {logging_mixin.py:112} INFO - [2022-02-18 04:11:23,909] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:11:24,525] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:11:24,579] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:11:24,594] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:11:24,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.699 seconds
[2022-02-18 04:11:37,203] {scheduler_job.py:155} INFO - Started process (PID=53606) to work on /airflow/dags/download_data.py
[2022-02-18 04:11:37,220] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:11:37,226] {logging_mixin.py:112} INFO - [2022-02-18 04:11:37,225] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:11:37,862] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:11:37,919] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:11:37,930] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:11:37,938] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.735 seconds
[2022-02-18 04:11:50,481] {scheduler_job.py:155} INFO - Started process (PID=53632) to work on /airflow/dags/download_data.py
[2022-02-18 04:11:50,486] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:11:50,489] {logging_mixin.py:112} INFO - [2022-02-18 04:11:50,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:11:51,047] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:11:51,093] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:11:51,099] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:11:51,104] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-18 04:12:03,821] {scheduler_job.py:155} INFO - Started process (PID=53658) to work on /airflow/dags/download_data.py
[2022-02-18 04:12:03,832] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:12:03,864] {logging_mixin.py:112} INFO - [2022-02-18 04:12:03,864] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:12:04,494] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:12:04,549] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:12:04,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:12:04,570] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.748 seconds
[2022-02-18 04:12:17,069] {scheduler_job.py:155} INFO - Started process (PID=53684) to work on /airflow/dags/download_data.py
[2022-02-18 04:12:17,074] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:12:17,076] {logging_mixin.py:112} INFO - [2022-02-18 04:12:17,075] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:12:17,557] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:12:17,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:12:17,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:12:17,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 04:12:30,349] {scheduler_job.py:155} INFO - Started process (PID=53710) to work on /airflow/dags/download_data.py
[2022-02-18 04:12:30,353] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:12:30,355] {logging_mixin.py:112} INFO - [2022-02-18 04:12:30,355] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:12:30,837] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:12:30,886] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:12:30,894] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:12:30,902] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 04:12:43,652] {scheduler_job.py:155} INFO - Started process (PID=53736) to work on /airflow/dags/download_data.py
[2022-02-18 04:12:43,658] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:12:43,660] {logging_mixin.py:112} INFO - [2022-02-18 04:12:43,660] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:12:44,172] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:12:44,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:12:44,252] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:12:44,258] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 04:12:56,926] {scheduler_job.py:155} INFO - Started process (PID=53762) to work on /airflow/dags/download_data.py
[2022-02-18 04:12:56,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:12:56,932] {logging_mixin.py:112} INFO - [2022-02-18 04:12:56,932] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:12:57,466] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:12:57,526] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:12:57,547] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:12:57,575] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.649 seconds
[2022-02-18 04:13:10,181] {scheduler_job.py:155} INFO - Started process (PID=53788) to work on /airflow/dags/download_data.py
[2022-02-18 04:13:10,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:13:10,193] {logging_mixin.py:112} INFO - [2022-02-18 04:13:10,192] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:13:10,711] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:13:10,761] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:13:10,775] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:13:10,784] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 04:13:23,468] {scheduler_job.py:155} INFO - Started process (PID=53814) to work on /airflow/dags/download_data.py
[2022-02-18 04:13:23,474] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:13:23,476] {logging_mixin.py:112} INFO - [2022-02-18 04:13:23,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:13:23,979] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:13:24,034] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:13:24,043] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:13:24,048] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 04:13:36,776] {scheduler_job.py:155} INFO - Started process (PID=53840) to work on /airflow/dags/download_data.py
[2022-02-18 04:13:36,790] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:13:36,794] {logging_mixin.py:112} INFO - [2022-02-18 04:13:36,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:13:37,501] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:13:37,568] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:13:37,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:13:37,597] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.821 seconds
[2022-02-18 04:13:50,077] {scheduler_job.py:155} INFO - Started process (PID=53866) to work on /airflow/dags/download_data.py
[2022-02-18 04:13:50,094] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:13:50,099] {logging_mixin.py:112} INFO - [2022-02-18 04:13:50,098] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:13:50,731] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:13:50,790] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:13:50,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:13:50,811] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.733 seconds
[2022-02-18 04:14:03,383] {scheduler_job.py:155} INFO - Started process (PID=53892) to work on /airflow/dags/download_data.py
[2022-02-18 04:14:03,400] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:14:03,405] {logging_mixin.py:112} INFO - [2022-02-18 04:14:03,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:14:04,886] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:14:04,968] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:14:04,986] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:14:04,998] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.617 seconds
[2022-02-18 04:14:17,696] {scheduler_job.py:155} INFO - Started process (PID=53918) to work on /airflow/dags/download_data.py
[2022-02-18 04:14:17,706] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:14:17,709] {logging_mixin.py:112} INFO - [2022-02-18 04:14:17,708] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:14:18,187] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:14:18,266] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:14:18,276] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:14:18,281] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-18 04:14:29,977] {scheduler_job.py:155} INFO - Started process (PID=53943) to work on /airflow/dags/download_data.py
[2022-02-18 04:14:29,981] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:14:29,984] {logging_mixin.py:112} INFO - [2022-02-18 04:14:29,983] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:14:30,463] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:14:30,515] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:14:30,524] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:14:30,531] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 04:14:43,236] {scheduler_job.py:155} INFO - Started process (PID=53969) to work on /airflow/dags/download_data.py
[2022-02-18 04:14:43,240] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:14:43,243] {logging_mixin.py:112} INFO - [2022-02-18 04:14:43,243] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:14:43,741] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:14:43,804] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:14:43,819] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:14:43,829] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 04:14:56,589] {scheduler_job.py:155} INFO - Started process (PID=53995) to work on /airflow/dags/download_data.py
[2022-02-18 04:14:56,593] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:14:56,595] {logging_mixin.py:112} INFO - [2022-02-18 04:14:56,595] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:14:57,075] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:14:57,123] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:14:57,131] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:14:57,136] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 04:15:09,859] {scheduler_job.py:155} INFO - Started process (PID=54021) to work on /airflow/dags/download_data.py
[2022-02-18 04:15:09,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:15:09,872] {logging_mixin.py:112} INFO - [2022-02-18 04:15:09,871] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:15:10,422] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:15:10,483] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:15:10,491] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:15:10,497] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-18 04:15:23,166] {scheduler_job.py:155} INFO - Started process (PID=54047) to work on /airflow/dags/download_data.py
[2022-02-18 04:15:23,177] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:15:23,180] {logging_mixin.py:112} INFO - [2022-02-18 04:15:23,180] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:15:23,632] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:15:23,677] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:15:23,687] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:15:23,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 04:15:36,453] {scheduler_job.py:155} INFO - Started process (PID=54073) to work on /airflow/dags/download_data.py
[2022-02-18 04:15:36,466] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:15:36,469] {logging_mixin.py:112} INFO - [2022-02-18 04:15:36,468] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:15:36,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:15:36,983] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:15:36,990] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:15:36,994] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 04:15:49,777] {scheduler_job.py:155} INFO - Started process (PID=54099) to work on /airflow/dags/download_data.py
[2022-02-18 04:15:49,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:15:49,794] {logging_mixin.py:112} INFO - [2022-02-18 04:15:49,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:15:50,267] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:15:50,318] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:15:50,326] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:15:50,331] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 04:16:03,023] {scheduler_job.py:155} INFO - Started process (PID=54125) to work on /airflow/dags/download_data.py
[2022-02-18 04:16:03,029] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:16:03,031] {logging_mixin.py:112} INFO - [2022-02-18 04:16:03,031] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:16:03,524] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:16:03,580] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:16:03,591] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:16:03,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 04:16:16,250] {scheduler_job.py:155} INFO - Started process (PID=54151) to work on /airflow/dags/download_data.py
[2022-02-18 04:16:16,262] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:16:16,265] {logging_mixin.py:112} INFO - [2022-02-18 04:16:16,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:16:16,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:16:16,783] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:16:16,793] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:16:16,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 04:16:29,525] {scheduler_job.py:155} INFO - Started process (PID=54177) to work on /airflow/dags/download_data.py
[2022-02-18 04:16:29,529] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:16:29,531] {logging_mixin.py:112} INFO - [2022-02-18 04:16:29,531] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:16:30,016] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:16:30,062] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:16:30,068] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:16:30,073] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 04:16:42,819] {scheduler_job.py:155} INFO - Started process (PID=54203) to work on /airflow/dags/download_data.py
[2022-02-18 04:16:42,834] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:16:42,837] {logging_mixin.py:112} INFO - [2022-02-18 04:16:42,836] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:16:43,329] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:16:43,373] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:16:43,383] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:16:43,388] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 04:16:56,112] {scheduler_job.py:155} INFO - Started process (PID=54229) to work on /airflow/dags/download_data.py
[2022-02-18 04:16:56,116] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:16:56,119] {logging_mixin.py:112} INFO - [2022-02-18 04:16:56,118] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:16:56,624] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:16:56,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:16:56,674] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:16:56,677] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 04:17:09,383] {scheduler_job.py:155} INFO - Started process (PID=54255) to work on /airflow/dags/download_data.py
[2022-02-18 04:17:09,388] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:17:09,390] {logging_mixin.py:112} INFO - [2022-02-18 04:17:09,390] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:17:09,884] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:17:09,947] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:17:09,960] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:17:09,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 04:17:22,695] {scheduler_job.py:155} INFO - Started process (PID=54281) to work on /airflow/dags/download_data.py
[2022-02-18 04:17:22,708] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:17:22,709] {logging_mixin.py:112} INFO - [2022-02-18 04:17:22,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:17:23,270] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:17:23,357] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:17:23,365] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:17:23,371] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-18 04:17:35,980] {scheduler_job.py:155} INFO - Started process (PID=54307) to work on /airflow/dags/download_data.py
[2022-02-18 04:17:35,985] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:17:35,987] {logging_mixin.py:112} INFO - [2022-02-18 04:17:35,987] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:17:36,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:17:36,570] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:17:36,579] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:17:36,584] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 04:17:49,230] {scheduler_job.py:155} INFO - Started process (PID=54333) to work on /airflow/dags/download_data.py
[2022-02-18 04:17:49,234] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:17:49,236] {logging_mixin.py:112} INFO - [2022-02-18 04:17:49,236] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:17:49,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:17:49,783] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:17:49,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:17:49,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 04:18:02,529] {scheduler_job.py:155} INFO - Started process (PID=54359) to work on /airflow/dags/download_data.py
[2022-02-18 04:18:02,534] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:18:02,536] {logging_mixin.py:112} INFO - [2022-02-18 04:18:02,536] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:18:03,058] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:18:03,106] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:18:03,114] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:18:03,119] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 04:18:15,764] {scheduler_job.py:155} INFO - Started process (PID=54385) to work on /airflow/dags/download_data.py
[2022-02-18 04:18:15,769] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:18:15,771] {logging_mixin.py:112} INFO - [2022-02-18 04:18:15,771] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:18:16,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:18:16,298] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:18:16,305] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:18:16,308] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 04:18:29,035] {scheduler_job.py:155} INFO - Started process (PID=54411) to work on /airflow/dags/download_data.py
[2022-02-18 04:18:29,039] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:18:29,041] {logging_mixin.py:112} INFO - [2022-02-18 04:18:29,040] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:18:29,519] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:18:29,568] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:18:29,575] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:18:29,581] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 04:18:42,287] {scheduler_job.py:155} INFO - Started process (PID=54437) to work on /airflow/dags/download_data.py
[2022-02-18 04:18:42,300] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:18:42,305] {logging_mixin.py:112} INFO - [2022-02-18 04:18:42,304] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:18:42,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:18:42,863] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:18:42,873] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:18:42,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 04:18:55,612] {scheduler_job.py:155} INFO - Started process (PID=54463) to work on /airflow/dags/download_data.py
[2022-02-18 04:18:55,624] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:18:55,627] {logging_mixin.py:112} INFO - [2022-02-18 04:18:55,627] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:18:56,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:18:56,397] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:18:56,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:18:56,411] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.799 seconds
[2022-02-18 04:19:08,873] {scheduler_job.py:155} INFO - Started process (PID=54489) to work on /airflow/dags/download_data.py
[2022-02-18 04:19:08,878] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:19:08,880] {logging_mixin.py:112} INFO - [2022-02-18 04:19:08,879] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:19:09,355] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:19:09,415] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:19:09,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:19:09,446] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 04:19:22,185] {scheduler_job.py:155} INFO - Started process (PID=54515) to work on /airflow/dags/download_data.py
[2022-02-18 04:19:22,195] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:19:22,196] {logging_mixin.py:112} INFO - [2022-02-18 04:19:22,196] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:19:22,898] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:19:22,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:19:22,939] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:19:22,944] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.765 seconds
[2022-02-18 04:19:35,477] {scheduler_job.py:155} INFO - Started process (PID=54541) to work on /airflow/dags/download_data.py
[2022-02-18 04:19:35,488] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:19:35,490] {logging_mixin.py:112} INFO - [2022-02-18 04:19:35,490] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:19:37,220] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:19:37,321] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:19:37,342] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:19:37,350] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.874 seconds
[2022-02-18 04:19:50,055] {scheduler_job.py:155} INFO - Started process (PID=54567) to work on /airflow/dags/download_data.py
[2022-02-18 04:19:50,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:19:50,072] {logging_mixin.py:112} INFO - [2022-02-18 04:19:50,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:19:50,723] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:19:50,780] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:19:50,791] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:19:50,796] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.742 seconds
[2022-02-18 04:20:02,353] {scheduler_job.py:155} INFO - Started process (PID=54592) to work on /airflow/dags/download_data.py
[2022-02-18 04:20:02,361] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:20:02,362] {logging_mixin.py:112} INFO - [2022-02-18 04:20:02,362] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:20:02,988] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:20:03,048] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:20:03,058] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:20:03,064] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.711 seconds
[2022-02-18 04:20:15,592] {scheduler_job.py:155} INFO - Started process (PID=54618) to work on /airflow/dags/download_data.py
[2022-02-18 04:20:15,597] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:20:15,599] {logging_mixin.py:112} INFO - [2022-02-18 04:20:15,599] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:20:16,109] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:20:16,166] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:20:16,179] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:20:16,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 04:20:28,898] {scheduler_job.py:155} INFO - Started process (PID=54644) to work on /airflow/dags/download_data.py
[2022-02-18 04:20:28,903] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:20:28,905] {logging_mixin.py:112} INFO - [2022-02-18 04:20:28,905] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:20:29,380] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:20:29,425] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:20:29,433] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:20:29,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 04:20:42,391] {scheduler_job.py:155} INFO - Started process (PID=54670) to work on /airflow/dags/download_data.py
[2022-02-18 04:20:42,403] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:20:42,405] {logging_mixin.py:112} INFO - [2022-02-18 04:20:42,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:20:43,024] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:20:43,073] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:20:43,080] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:20:43,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.696 seconds
[2022-02-18 04:20:55,791] {scheduler_job.py:155} INFO - Started process (PID=54696) to work on /airflow/dags/download_data.py
[2022-02-18 04:20:55,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:20:55,814] {logging_mixin.py:112} INFO - [2022-02-18 04:20:55,813] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:20:56,368] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:20:56,427] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:20:56,444] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:20:56,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.664 seconds
[2022-02-18 04:21:09,090] {scheduler_job.py:155} INFO - Started process (PID=54722) to work on /airflow/dags/download_data.py
[2022-02-18 04:21:09,096] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:21:09,098] {logging_mixin.py:112} INFO - [2022-02-18 04:21:09,097] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:21:09,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:21:09,638] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:21:09,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:21:09,649] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 04:21:22,345] {scheduler_job.py:155} INFO - Started process (PID=54748) to work on /airflow/dags/download_data.py
[2022-02-18 04:21:22,352] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:21:22,354] {logging_mixin.py:112} INFO - [2022-02-18 04:21:22,354] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:21:22,842] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:21:22,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:21:22,900] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:21:22,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 04:21:35,646] {scheduler_job.py:155} INFO - Started process (PID=54774) to work on /airflow/dags/download_data.py
[2022-02-18 04:21:35,651] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:21:35,653] {logging_mixin.py:112} INFO - [2022-02-18 04:21:35,653] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:21:36,160] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:21:36,203] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:21:36,210] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:21:36,214] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 04:21:48,885] {scheduler_job.py:155} INFO - Started process (PID=54800) to work on /airflow/dags/download_data.py
[2022-02-18 04:21:48,890] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:21:48,893] {logging_mixin.py:112} INFO - [2022-02-18 04:21:48,893] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:21:49,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:21:49,481] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:21:49,492] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:21:49,497] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-18 04:22:02,206] {scheduler_job.py:155} INFO - Started process (PID=54826) to work on /airflow/dags/download_data.py
[2022-02-18 04:22:02,210] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:22:02,213] {logging_mixin.py:112} INFO - [2022-02-18 04:22:02,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:22:02,705] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:22:02,754] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:22:02,765] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:22:02,770] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 04:22:15,597] {scheduler_job.py:155} INFO - Started process (PID=54852) to work on /airflow/dags/download_data.py
[2022-02-18 04:22:15,603] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:22:15,605] {logging_mixin.py:112} INFO - [2022-02-18 04:22:15,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:22:16,331] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:22:16,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:22:16,398] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:22:16,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.807 seconds
[2022-02-18 04:22:28,889] {scheduler_job.py:155} INFO - Started process (PID=54878) to work on /airflow/dags/download_data.py
[2022-02-18 04:22:28,894] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:22:28,896] {logging_mixin.py:112} INFO - [2022-02-18 04:22:28,895] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:22:29,348] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:22:29,392] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:22:29,403] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:22:29,408] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 04:22:42,596] {scheduler_job.py:155} INFO - Started process (PID=54904) to work on /airflow/dags/download_data.py
[2022-02-18 04:22:42,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:22:42,606] {logging_mixin.py:112} INFO - [2022-02-18 04:22:42,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:22:43,153] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:22:43,211] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:22:43,221] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:22:43,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-18 04:22:55,896] {scheduler_job.py:155} INFO - Started process (PID=54930) to work on /airflow/dags/download_data.py
[2022-02-18 04:22:55,905] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:22:55,915] {logging_mixin.py:112} INFO - [2022-02-18 04:22:55,914] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:22:56,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:22:56,734] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:22:56,742] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:22:56,747] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.851 seconds
[2022-02-18 04:23:09,188] {scheduler_job.py:155} INFO - Started process (PID=54956) to work on /airflow/dags/download_data.py
[2022-02-18 04:23:09,205] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:23:09,208] {logging_mixin.py:112} INFO - [2022-02-18 04:23:09,206] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:23:09,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:23:09,823] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:23:09,835] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:23:09,841] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-18 04:23:22,467] {scheduler_job.py:155} INFO - Started process (PID=54982) to work on /airflow/dags/download_data.py
[2022-02-18 04:23:22,472] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:23:22,476] {logging_mixin.py:112} INFO - [2022-02-18 04:23:22,476] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:23:22,929] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:23:22,981] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:23:22,992] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:23:22,998] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 04:23:35,778] {scheduler_job.py:155} INFO - Started process (PID=55008) to work on /airflow/dags/download_data.py
[2022-02-18 04:23:35,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:23:35,786] {logging_mixin.py:112} INFO - [2022-02-18 04:23:35,786] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:23:36,424] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:23:36,478] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:23:36,493] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:23:36,498] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.720 seconds
[2022-02-18 04:23:49,031] {scheduler_job.py:155} INFO - Started process (PID=55034) to work on /airflow/dags/download_data.py
[2022-02-18 04:23:49,036] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:23:49,038] {logging_mixin.py:112} INFO - [2022-02-18 04:23:49,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:23:49,515] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:23:49,568] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:23:49,581] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:23:49,588] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 04:24:02,327] {scheduler_job.py:155} INFO - Started process (PID=55060) to work on /airflow/dags/download_data.py
[2022-02-18 04:24:02,331] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:24:02,333] {logging_mixin.py:112} INFO - [2022-02-18 04:24:02,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:24:02,797] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:24:02,841] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:24:02,849] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:24:02,855] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 04:24:15,560] {scheduler_job.py:155} INFO - Started process (PID=55086) to work on /airflow/dags/download_data.py
[2022-02-18 04:24:15,565] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:24:15,567] {logging_mixin.py:112} INFO - [2022-02-18 04:24:15,567] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:24:16,038] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:24:16,085] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:24:16,093] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:24:16,098] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 04:24:28,828] {scheduler_job.py:155} INFO - Started process (PID=55112) to work on /airflow/dags/download_data.py
[2022-02-18 04:24:28,833] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:24:28,834] {logging_mixin.py:112} INFO - [2022-02-18 04:24:28,834] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:24:29,267] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:24:29,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:24:29,321] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:24:29,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 04:24:42,093] {scheduler_job.py:155} INFO - Started process (PID=55138) to work on /airflow/dags/download_data.py
[2022-02-18 04:24:42,101] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:24:42,105] {logging_mixin.py:112} INFO - [2022-02-18 04:24:42,104] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:24:42,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:24:42,635] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:24:42,650] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:24:42,657] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 04:24:55,355] {scheduler_job.py:155} INFO - Started process (PID=55164) to work on /airflow/dags/download_data.py
[2022-02-18 04:24:55,364] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:24:55,366] {logging_mixin.py:112} INFO - [2022-02-18 04:24:55,366] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:24:55,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:24:55,937] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:24:55,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:24:55,957] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 04:25:08,776] {scheduler_job.py:155} INFO - Started process (PID=55190) to work on /airflow/dags/download_data.py
[2022-02-18 04:25:08,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:25:08,787] {logging_mixin.py:112} INFO - [2022-02-18 04:25:08,787] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:25:09,252] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:25:09,311] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:25:09,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:25:09,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 04:25:22,041] {scheduler_job.py:155} INFO - Started process (PID=55216) to work on /airflow/dags/download_data.py
[2022-02-18 04:25:22,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:25:22,047] {logging_mixin.py:112} INFO - [2022-02-18 04:25:22,047] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:25:22,500] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:25:22,554] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:25:22,561] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:25:22,566] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 04:25:35,361] {scheduler_job.py:155} INFO - Started process (PID=55242) to work on /airflow/dags/download_data.py
[2022-02-18 04:25:35,372] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:25:35,375] {logging_mixin.py:112} INFO - [2022-02-18 04:25:35,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:25:35,865] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:25:35,923] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:25:35,932] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:25:35,939] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 04:25:48,600] {scheduler_job.py:155} INFO - Started process (PID=55268) to work on /airflow/dags/download_data.py
[2022-02-18 04:25:48,607] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:25:48,608] {logging_mixin.py:112} INFO - [2022-02-18 04:25:48,608] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:25:49,096] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:25:49,150] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:25:49,158] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:25:49,164] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 04:26:01,892] {scheduler_job.py:155} INFO - Started process (PID=55294) to work on /airflow/dags/download_data.py
[2022-02-18 04:26:01,897] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:26:01,899] {logging_mixin.py:112} INFO - [2022-02-18 04:26:01,898] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:26:02,371] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:26:02,415] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:26:02,426] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:26:02,429] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 04:26:15,155] {scheduler_job.py:155} INFO - Started process (PID=55320) to work on /airflow/dags/download_data.py
[2022-02-18 04:26:15,164] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:26:15,166] {logging_mixin.py:112} INFO - [2022-02-18 04:26:15,166] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:26:15,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:26:15,930] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:26:15,937] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:26:15,943] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.788 seconds
[2022-02-18 04:26:28,455] {scheduler_job.py:155} INFO - Started process (PID=55346) to work on /airflow/dags/download_data.py
[2022-02-18 04:26:28,460] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:26:28,462] {logging_mixin.py:112} INFO - [2022-02-18 04:26:28,462] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:26:28,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:26:29,011] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:26:29,033] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:26:29,040] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-18 04:26:41,725] {scheduler_job.py:155} INFO - Started process (PID=55372) to work on /airflow/dags/download_data.py
[2022-02-18 04:26:41,730] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:26:41,733] {logging_mixin.py:112} INFO - [2022-02-18 04:26:41,732] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:26:42,224] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:26:42,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:26:42,292] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:26:42,297] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 04:26:55,023] {scheduler_job.py:155} INFO - Started process (PID=55398) to work on /airflow/dags/download_data.py
[2022-02-18 04:26:55,033] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:26:55,035] {logging_mixin.py:112} INFO - [2022-02-18 04:26:55,035] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:26:55,581] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:26:55,638] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:26:55,649] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:26:55,653] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-18 04:27:08,319] {scheduler_job.py:155} INFO - Started process (PID=55424) to work on /airflow/dags/download_data.py
[2022-02-18 04:27:08,328] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:27:08,330] {logging_mixin.py:112} INFO - [2022-02-18 04:27:08,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:27:08,790] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:27:08,816] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:27:08,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:27:08,829] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 04:27:21,548] {scheduler_job.py:155} INFO - Started process (PID=55450) to work on /airflow/dags/download_data.py
[2022-02-18 04:27:21,552] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:27:21,554] {logging_mixin.py:112} INFO - [2022-02-18 04:27:21,553] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:27:22,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:27:22,061] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:27:22,067] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:27:22,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 04:27:34,843] {scheduler_job.py:155} INFO - Started process (PID=55476) to work on /airflow/dags/download_data.py
[2022-02-18 04:27:34,852] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:27:34,855] {logging_mixin.py:112} INFO - [2022-02-18 04:27:34,854] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:27:35,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:27:35,394] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:27:35,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:27:35,410] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 04:27:48,096] {scheduler_job.py:155} INFO - Started process (PID=55502) to work on /airflow/dags/download_data.py
[2022-02-18 04:27:48,103] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:27:48,105] {logging_mixin.py:112} INFO - [2022-02-18 04:27:48,105] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:27:48,540] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:27:48,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:27:48,595] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:27:48,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 04:28:01,348] {scheduler_job.py:155} INFO - Started process (PID=55528) to work on /airflow/dags/download_data.py
[2022-02-18 04:28:01,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:28:01,360] {logging_mixin.py:112} INFO - [2022-02-18 04:28:01,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:28:01,822] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:28:01,877] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:28:01,885] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:28:01,892] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 04:28:14,767] {scheduler_job.py:155} INFO - Started process (PID=55554) to work on /airflow/dags/download_data.py
[2022-02-18 04:28:14,777] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:28:14,780] {logging_mixin.py:112} INFO - [2022-02-18 04:28:14,780] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:28:15,248] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:28:15,295] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:28:15,303] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:28:15,308] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 04:28:28,039] {scheduler_job.py:155} INFO - Started process (PID=55580) to work on /airflow/dags/download_data.py
[2022-02-18 04:28:28,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:28:28,046] {logging_mixin.py:112} INFO - [2022-02-18 04:28:28,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:28:28,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:28:28,555] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:28:28,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:28:28,568] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 04:28:41,301] {scheduler_job.py:155} INFO - Started process (PID=55606) to work on /airflow/dags/download_data.py
[2022-02-18 04:28:41,306] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:28:41,307] {logging_mixin.py:112} INFO - [2022-02-18 04:28:41,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:28:41,834] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:28:41,890] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:28:41,902] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:28:41,906] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 04:28:54,588] {scheduler_job.py:155} INFO - Started process (PID=55632) to work on /airflow/dags/download_data.py
[2022-02-18 04:28:54,597] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:28:54,600] {logging_mixin.py:112} INFO - [2022-02-18 04:28:54,599] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:28:55,042] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:28:55,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:28:55,107] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:28:55,111] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 04:29:07,899] {scheduler_job.py:155} INFO - Started process (PID=55658) to work on /airflow/dags/download_data.py
[2022-02-18 04:29:07,905] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:29:07,907] {logging_mixin.py:112} INFO - [2022-02-18 04:29:07,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:29:08,508] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:29:08,567] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:29:08,577] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:29:08,588] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.689 seconds
[2022-02-18 04:29:21,161] {scheduler_job.py:155} INFO - Started process (PID=55684) to work on /airflow/dags/download_data.py
[2022-02-18 04:29:21,170] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:29:21,172] {logging_mixin.py:112} INFO - [2022-02-18 04:29:21,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:29:21,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:29:21,683] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:29:21,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:29:21,697] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 04:29:34,408] {scheduler_job.py:155} INFO - Started process (PID=55710) to work on /airflow/dags/download_data.py
[2022-02-18 04:29:34,416] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:29:34,419] {logging_mixin.py:112} INFO - [2022-02-18 04:29:34,419] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:29:34,948] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:29:35,012] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:29:35,023] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:29:35,028] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-18 04:29:47,685] {scheduler_job.py:155} INFO - Started process (PID=55736) to work on /airflow/dags/download_data.py
[2022-02-18 04:29:47,696] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:29:47,699] {logging_mixin.py:112} INFO - [2022-02-18 04:29:47,698] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:29:48,170] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:29:48,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:29:48,227] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:29:48,234] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 04:30:00,995] {scheduler_job.py:155} INFO - Started process (PID=55762) to work on /airflow/dags/download_data.py
[2022-02-18 04:30:01,005] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:30:01,025] {logging_mixin.py:112} INFO - [2022-02-18 04:30:01,024] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:30:01,563] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:30:01,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:30:01,625] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:30:01,632] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-18 04:30:14,269] {scheduler_job.py:155} INFO - Started process (PID=55788) to work on /airflow/dags/download_data.py
[2022-02-18 04:30:14,289] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:30:14,292] {logging_mixin.py:112} INFO - [2022-02-18 04:30:14,291] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:30:15,311] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:30:15,379] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:30:15,386] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:30:15,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.127 seconds
[2022-02-18 04:30:28,553] {scheduler_job.py:155} INFO - Started process (PID=55814) to work on /airflow/dags/download_data.py
[2022-02-18 04:30:28,558] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:30:28,560] {logging_mixin.py:112} INFO - [2022-02-18 04:30:28,560] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:30:29,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:30:29,081] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:30:29,089] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:30:29,093] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 04:30:40,948] {scheduler_job.py:155} INFO - Started process (PID=55839) to work on /airflow/dags/download_data.py
[2022-02-18 04:30:40,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:30:40,970] {logging_mixin.py:112} INFO - [2022-02-18 04:30:40,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:30:41,555] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:30:41,610] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:30:41,622] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:30:41,627] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-18 04:30:54,217] {scheduler_job.py:155} INFO - Started process (PID=55865) to work on /airflow/dags/download_data.py
[2022-02-18 04:30:54,222] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:30:54,223] {logging_mixin.py:112} INFO - [2022-02-18 04:30:54,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:30:54,686] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:30:54,729] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:30:54,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:30:54,741] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 04:31:07,533] {scheduler_job.py:155} INFO - Started process (PID=55891) to work on /airflow/dags/download_data.py
[2022-02-18 04:31:07,542] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:31:07,544] {logging_mixin.py:112} INFO - [2022-02-18 04:31:07,544] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:31:08,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:31:08,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:31:08,165] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:31:08,174] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 04:31:20,787] {scheduler_job.py:155} INFO - Started process (PID=55917) to work on /airflow/dags/download_data.py
[2022-02-18 04:31:20,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:31:20,793] {logging_mixin.py:112} INFO - [2022-02-18 04:31:20,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:31:21,237] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:31:21,279] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:31:21,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:31:21,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 04:31:34,083] {scheduler_job.py:155} INFO - Started process (PID=55943) to work on /airflow/dags/download_data.py
[2022-02-18 04:31:34,091] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:31:34,093] {logging_mixin.py:112} INFO - [2022-02-18 04:31:34,093] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:31:34,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:31:34,707] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:31:34,717] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:31:34,723] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 04:31:47,363] {scheduler_job.py:155} INFO - Started process (PID=55969) to work on /airflow/dags/download_data.py
[2022-02-18 04:31:47,370] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:31:47,376] {logging_mixin.py:112} INFO - [2022-02-18 04:31:47,376] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:31:47,838] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:31:47,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:31:47,905] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:31:47,909] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 04:32:00,676] {scheduler_job.py:155} INFO - Started process (PID=55995) to work on /airflow/dags/download_data.py
[2022-02-18 04:32:00,680] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:32:00,682] {logging_mixin.py:112} INFO - [2022-02-18 04:32:00,682] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:32:01,144] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:32:01,200] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:32:01,213] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:32:01,221] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 04:32:13,955] {scheduler_job.py:155} INFO - Started process (PID=56021) to work on /airflow/dags/download_data.py
[2022-02-18 04:32:13,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:32:13,962] {logging_mixin.py:112} INFO - [2022-02-18 04:32:13,962] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:32:14,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:32:14,506] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:32:14,517] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:32:14,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 04:32:27,233] {scheduler_job.py:155} INFO - Started process (PID=56047) to work on /airflow/dags/download_data.py
[2022-02-18 04:32:27,237] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:32:27,239] {logging_mixin.py:112} INFO - [2022-02-18 04:32:27,239] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:32:27,687] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:32:27,733] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:32:27,739] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:32:27,742] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 04:32:40,528] {scheduler_job.py:155} INFO - Started process (PID=56073) to work on /airflow/dags/download_data.py
[2022-02-18 04:32:40,533] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:32:40,535] {logging_mixin.py:112} INFO - [2022-02-18 04:32:40,534] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:32:41,038] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:32:41,087] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:32:41,098] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:32:41,104] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 04:32:53,829] {scheduler_job.py:155} INFO - Started process (PID=56099) to work on /airflow/dags/download_data.py
[2022-02-18 04:32:53,848] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:32:53,856] {logging_mixin.py:112} INFO - [2022-02-18 04:32:53,856] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:32:54,376] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:32:54,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:32:54,430] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:32:54,435] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-18 04:33:07,098] {scheduler_job.py:155} INFO - Started process (PID=56125) to work on /airflow/dags/download_data.py
[2022-02-18 04:33:07,105] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:33:07,108] {logging_mixin.py:112} INFO - [2022-02-18 04:33:07,107] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:33:07,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:33:07,817] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:33:07,831] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:33:07,847] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.749 seconds
[2022-02-18 04:33:20,373] {scheduler_job.py:155} INFO - Started process (PID=56151) to work on /airflow/dags/download_data.py
[2022-02-18 04:33:20,379] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:33:20,381] {logging_mixin.py:112} INFO - [2022-02-18 04:33:20,381] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:33:20,837] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:33:20,890] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:33:20,903] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:33:20,911] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 04:33:33,634] {scheduler_job.py:155} INFO - Started process (PID=56177) to work on /airflow/dags/download_data.py
[2022-02-18 04:33:33,639] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:33:33,641] {logging_mixin.py:112} INFO - [2022-02-18 04:33:33,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:33:34,279] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:33:34,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:33:34,395] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:33:34,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.770 seconds
[2022-02-18 04:33:46,954] {scheduler_job.py:155} INFO - Started process (PID=56203) to work on /airflow/dags/download_data.py
[2022-02-18 04:33:46,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:33:46,966] {logging_mixin.py:112} INFO - [2022-02-18 04:33:46,964] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:33:47,477] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:33:47,534] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:33:47,542] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:33:47,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 04:34:00,185] {scheduler_job.py:155} INFO - Started process (PID=56229) to work on /airflow/dags/download_data.py
[2022-02-18 04:34:00,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:34:00,195] {logging_mixin.py:112} INFO - [2022-02-18 04:34:00,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:34:00,704] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:34:00,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:34:00,770] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:34:00,778] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 04:34:13,493] {scheduler_job.py:155} INFO - Started process (PID=56255) to work on /airflow/dags/download_data.py
[2022-02-18 04:34:13,501] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:34:13,504] {logging_mixin.py:112} INFO - [2022-02-18 04:34:13,503] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:34:14,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:34:14,078] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:34:14,086] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:34:14,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-18 04:34:26,815] {scheduler_job.py:155} INFO - Started process (PID=56281) to work on /airflow/dags/download_data.py
[2022-02-18 04:34:26,820] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:34:26,821] {logging_mixin.py:112} INFO - [2022-02-18 04:34:26,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:34:27,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:34:27,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:34:27,353] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:34:27,358] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 04:34:40,099] {scheduler_job.py:155} INFO - Started process (PID=56307) to work on /airflow/dags/download_data.py
[2022-02-18 04:34:40,106] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:34:40,108] {logging_mixin.py:112} INFO - [2022-02-18 04:34:40,108] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:34:40,618] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:34:40,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:34:40,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:34:40,689] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 04:34:53,437] {scheduler_job.py:155} INFO - Started process (PID=56333) to work on /airflow/dags/download_data.py
[2022-02-18 04:34:53,445] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:34:53,448] {logging_mixin.py:112} INFO - [2022-02-18 04:34:53,447] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:34:53,976] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:34:54,031] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:34:54,039] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:34:54,043] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-18 04:35:06,695] {scheduler_job.py:155} INFO - Started process (PID=56359) to work on /airflow/dags/download_data.py
[2022-02-18 04:35:06,704] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:35:06,706] {logging_mixin.py:112} INFO - [2022-02-18 04:35:06,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:35:07,181] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:35:07,234] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:35:07,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:35:07,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 04:35:19,949] {scheduler_job.py:155} INFO - Started process (PID=56385) to work on /airflow/dags/download_data.py
[2022-02-18 04:35:19,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:35:19,956] {logging_mixin.py:112} INFO - [2022-02-18 04:35:19,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:35:20,460] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:35:20,507] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:35:20,517] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:35:20,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 04:35:33,270] {scheduler_job.py:155} INFO - Started process (PID=56411) to work on /airflow/dags/download_data.py
[2022-02-18 04:35:33,275] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:35:33,276] {logging_mixin.py:112} INFO - [2022-02-18 04:35:33,276] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:35:33,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:35:33,824] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:35:33,833] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:35:33,837] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 04:35:46,615] {scheduler_job.py:155} INFO - Started process (PID=56437) to work on /airflow/dags/download_data.py
[2022-02-18 04:35:46,631] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:35:46,635] {logging_mixin.py:112} INFO - [2022-02-18 04:35:46,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:35:47,203] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:35:47,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:35:47,275] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:35:47,281] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-18 04:35:59,904] {scheduler_job.py:155} INFO - Started process (PID=56463) to work on /airflow/dags/download_data.py
[2022-02-18 04:35:59,908] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:35:59,910] {logging_mixin.py:112} INFO - [2022-02-18 04:35:59,909] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:36:00,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:36:00,411] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:36:00,417] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:36:00,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 04:36:13,141] {scheduler_job.py:155} INFO - Started process (PID=56489) to work on /airflow/dags/download_data.py
[2022-02-18 04:36:13,145] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:36:13,147] {logging_mixin.py:112} INFO - [2022-02-18 04:36:13,147] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:36:13,625] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:36:13,678] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:36:13,690] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:36:13,693] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 04:36:26,417] {scheduler_job.py:155} INFO - Started process (PID=56515) to work on /airflow/dags/download_data.py
[2022-02-18 04:36:26,421] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:36:26,425] {logging_mixin.py:112} INFO - [2022-02-18 04:36:26,424] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:36:26,900] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:36:26,947] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:36:26,954] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:36:26,961] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 04:36:39,689] {scheduler_job.py:155} INFO - Started process (PID=56541) to work on /airflow/dags/download_data.py
[2022-02-18 04:36:39,701] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:36:39,704] {logging_mixin.py:112} INFO - [2022-02-18 04:36:39,703] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:36:40,249] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:36:40,286] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:36:40,293] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:36:40,298] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 04:36:53,017] {scheduler_job.py:155} INFO - Started process (PID=56567) to work on /airflow/dags/download_data.py
[2022-02-18 04:36:53,026] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:36:53,028] {logging_mixin.py:112} INFO - [2022-02-18 04:36:53,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:36:53,488] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:36:53,549] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:36:53,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:36:53,573] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 04:37:06,294] {scheduler_job.py:155} INFO - Started process (PID=56593) to work on /airflow/dags/download_data.py
[2022-02-18 04:37:06,302] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:37:06,304] {logging_mixin.py:112} INFO - [2022-02-18 04:37:06,304] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:37:06,788] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:37:06,850] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:37:06,863] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:37:06,869] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 04:37:19,567] {scheduler_job.py:155} INFO - Started process (PID=56619) to work on /airflow/dags/download_data.py
[2022-02-18 04:37:19,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:37:19,579] {logging_mixin.py:112} INFO - [2022-02-18 04:37:19,578] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:37:20,121] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:37:20,158] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:37:20,166] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:37:20,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 04:37:32,860] {scheduler_job.py:155} INFO - Started process (PID=56645) to work on /airflow/dags/download_data.py
[2022-02-18 04:37:32,865] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:37:32,867] {logging_mixin.py:112} INFO - [2022-02-18 04:37:32,867] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:37:33,322] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:37:33,371] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:37:33,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:37:33,388] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 04:37:46,123] {scheduler_job.py:155} INFO - Started process (PID=56671) to work on /airflow/dags/download_data.py
[2022-02-18 04:37:46,126] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:37:46,131] {logging_mixin.py:112} INFO - [2022-02-18 04:37:46,130] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:37:46,620] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:37:46,669] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:37:46,677] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:37:46,681] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 04:37:59,422] {scheduler_job.py:155} INFO - Started process (PID=56697) to work on /airflow/dags/download_data.py
[2022-02-18 04:37:59,429] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:37:59,431] {logging_mixin.py:112} INFO - [2022-02-18 04:37:59,431] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:37:59,895] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:37:59,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:37:59,951] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:37:59,959] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 04:38:12,659] {scheduler_job.py:155} INFO - Started process (PID=56723) to work on /airflow/dags/download_data.py
[2022-02-18 04:38:12,673] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:38:12,675] {logging_mixin.py:112} INFO - [2022-02-18 04:38:12,675] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:38:13,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:38:13,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:38:13,191] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:38:13,196] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 04:38:25,895] {scheduler_job.py:155} INFO - Started process (PID=56749) to work on /airflow/dags/download_data.py
[2022-02-18 04:38:25,899] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:38:25,902] {logging_mixin.py:112} INFO - [2022-02-18 04:38:25,901] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:38:26,365] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:38:26,414] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:38:26,424] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:38:26,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 04:38:39,187] {scheduler_job.py:155} INFO - Started process (PID=56775) to work on /airflow/dags/download_data.py
[2022-02-18 04:38:39,196] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:38:39,199] {logging_mixin.py:112} INFO - [2022-02-18 04:38:39,198] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:38:39,692] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:38:39,754] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:38:39,767] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:38:39,778] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 04:38:52,487] {scheduler_job.py:155} INFO - Started process (PID=56801) to work on /airflow/dags/download_data.py
[2022-02-18 04:38:52,492] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:38:52,497] {logging_mixin.py:112} INFO - [2022-02-18 04:38:52,497] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:38:53,019] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:38:53,060] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:38:53,068] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:38:53,073] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 04:39:05,786] {scheduler_job.py:155} INFO - Started process (PID=56827) to work on /airflow/dags/download_data.py
[2022-02-18 04:39:05,792] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:39:05,795] {logging_mixin.py:112} INFO - [2022-02-18 04:39:05,794] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:39:06,308] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:39:06,359] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:39:06,370] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:39:06,375] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 04:39:19,074] {scheduler_job.py:155} INFO - Started process (PID=56853) to work on /airflow/dags/download_data.py
[2022-02-18 04:39:19,080] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:39:19,082] {logging_mixin.py:112} INFO - [2022-02-18 04:39:19,081] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:39:19,581] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:39:19,639] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:39:19,650] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:39:19,657] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 04:39:32,350] {scheduler_job.py:155} INFO - Started process (PID=56879) to work on /airflow/dags/download_data.py
[2022-02-18 04:39:32,362] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:39:32,369] {logging_mixin.py:112} INFO - [2022-02-18 04:39:32,369] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:39:33,396] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:39:33,449] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:39:33,456] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:39:33,461] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.111 seconds
[2022-02-18 04:39:46,593] {scheduler_job.py:155} INFO - Started process (PID=56905) to work on /airflow/dags/download_data.py
[2022-02-18 04:39:46,601] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:39:46,605] {logging_mixin.py:112} INFO - [2022-02-18 04:39:46,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:39:47,054] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:39:47,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:39:47,108] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:39:47,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 04:39:58,948] {scheduler_job.py:155} INFO - Started process (PID=56930) to work on /airflow/dags/download_data.py
[2022-02-18 04:39:58,957] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:39:58,960] {logging_mixin.py:112} INFO - [2022-02-18 04:39:58,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:39:59,978] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:40:00,191] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:40:00,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:40:00,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.256 seconds
[2022-02-18 04:40:13,169] {scheduler_job.py:155} INFO - Started process (PID=56956) to work on /airflow/dags/download_data.py
[2022-02-18 04:40:13,174] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:40:13,175] {logging_mixin.py:112} INFO - [2022-02-18 04:40:13,175] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:40:13,630] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:40:13,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:40:13,684] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:40:13,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 04:40:25,468] {scheduler_job.py:155} INFO - Started process (PID=56981) to work on /airflow/dags/download_data.py
[2022-02-18 04:40:25,474] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:40:25,476] {logging_mixin.py:112} INFO - [2022-02-18 04:40:25,476] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:40:25,966] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:40:26,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:40:26,029] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:40:26,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 04:40:38,716] {scheduler_job.py:155} INFO - Started process (PID=57007) to work on /airflow/dags/download_data.py
[2022-02-18 04:40:38,724] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:40:38,726] {logging_mixin.py:112} INFO - [2022-02-18 04:40:38,726] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:40:39,276] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:40:39,322] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:40:39,331] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:40:39,336] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.620 seconds
[2022-02-18 04:40:52,152] {scheduler_job.py:155} INFO - Started process (PID=57033) to work on /airflow/dags/download_data.py
[2022-02-18 04:40:52,160] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:40:52,164] {logging_mixin.py:112} INFO - [2022-02-18 04:40:52,163] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:40:52,644] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:40:52,684] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:40:52,690] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:40:52,694] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 04:41:05,416] {scheduler_job.py:155} INFO - Started process (PID=57059) to work on /airflow/dags/download_data.py
[2022-02-18 04:41:05,425] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:41:05,428] {logging_mixin.py:112} INFO - [2022-02-18 04:41:05,427] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:41:05,878] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:41:05,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:41:05,952] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:41:05,958] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 04:41:18,662] {scheduler_job.py:155} INFO - Started process (PID=57085) to work on /airflow/dags/download_data.py
[2022-02-18 04:41:18,667] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:41:18,668] {logging_mixin.py:112} INFO - [2022-02-18 04:41:18,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:41:19,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:41:19,189] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:41:19,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:41:19,206] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 04:41:31,974] {scheduler_job.py:155} INFO - Started process (PID=57111) to work on /airflow/dags/download_data.py
[2022-02-18 04:41:31,989] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:41:31,992] {logging_mixin.py:112} INFO - [2022-02-18 04:41:31,991] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:41:32,488] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:41:32,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:41:32,545] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:41:32,553] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 04:41:45,219] {scheduler_job.py:155} INFO - Started process (PID=57137) to work on /airflow/dags/download_data.py
[2022-02-18 04:41:45,223] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:41:45,225] {logging_mixin.py:112} INFO - [2022-02-18 04:41:45,225] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:41:45,691] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:41:45,739] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:41:45,746] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:41:45,750] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 04:41:58,520] {scheduler_job.py:155} INFO - Started process (PID=57163) to work on /airflow/dags/download_data.py
[2022-02-18 04:41:58,526] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:41:58,529] {logging_mixin.py:112} INFO - [2022-02-18 04:41:58,528] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:41:59,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:41:59,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:41:59,174] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:41:59,181] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.660 seconds
[2022-02-18 04:42:11,766] {scheduler_job.py:155} INFO - Started process (PID=57189) to work on /airflow/dags/download_data.py
[2022-02-18 04:42:11,770] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:42:11,772] {logging_mixin.py:112} INFO - [2022-02-18 04:42:11,772] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:42:12,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:42:12,288] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:42:12,295] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:42:12,298] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 04:42:25,060] {scheduler_job.py:155} INFO - Started process (PID=57215) to work on /airflow/dags/download_data.py
[2022-02-18 04:42:25,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:42:25,070] {logging_mixin.py:112} INFO - [2022-02-18 04:42:25,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:42:25,522] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:42:25,572] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:42:25,578] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:42:25,582] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 04:42:38,347] {scheduler_job.py:155} INFO - Started process (PID=57241) to work on /airflow/dags/download_data.py
[2022-02-18 04:42:38,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:42:38,361] {logging_mixin.py:112} INFO - [2022-02-18 04:42:38,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:42:38,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:42:38,977] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:42:38,986] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:42:38,991] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-18 04:42:51,652] {scheduler_job.py:155} INFO - Started process (PID=57267) to work on /airflow/dags/download_data.py
[2022-02-18 04:42:51,666] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:42:51,668] {logging_mixin.py:112} INFO - [2022-02-18 04:42:51,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:42:52,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:42:52,210] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:42:52,217] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:42:52,221] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-18 04:43:04,966] {scheduler_job.py:155} INFO - Started process (PID=57293) to work on /airflow/dags/download_data.py
[2022-02-18 04:43:04,977] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:43:04,980] {logging_mixin.py:112} INFO - [2022-02-18 04:43:04,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:43:05,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:43:05,565] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:43:05,577] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:43:05,582] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-18 04:43:18,224] {scheduler_job.py:155} INFO - Started process (PID=57319) to work on /airflow/dags/download_data.py
[2022-02-18 04:43:18,240] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:43:18,242] {logging_mixin.py:112} INFO - [2022-02-18 04:43:18,242] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:43:18,775] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:43:18,825] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:43:18,835] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:43:18,839] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-18 04:43:31,542] {scheduler_job.py:155} INFO - Started process (PID=57345) to work on /airflow/dags/download_data.py
[2022-02-18 04:43:31,550] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:43:31,554] {logging_mixin.py:112} INFO - [2022-02-18 04:43:31,553] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:43:31,989] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:43:32,033] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:43:32,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:43:32,050] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 04:43:44,785] {scheduler_job.py:155} INFO - Started process (PID=57371) to work on /airflow/dags/download_data.py
[2022-02-18 04:43:44,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:43:44,792] {logging_mixin.py:112} INFO - [2022-02-18 04:43:44,792] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:43:45,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:43:45,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:43:45,332] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:43:45,336] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 04:43:58,102] {scheduler_job.py:155} INFO - Started process (PID=57397) to work on /airflow/dags/download_data.py
[2022-02-18 04:43:58,109] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:43:58,111] {logging_mixin.py:112} INFO - [2022-02-18 04:43:58,110] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:43:58,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:43:58,623] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:43:58,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:43:58,640] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 04:44:11,327] {scheduler_job.py:155} INFO - Started process (PID=57423) to work on /airflow/dags/download_data.py
[2022-02-18 04:44:11,331] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:44:11,333] {logging_mixin.py:112} INFO - [2022-02-18 04:44:11,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:44:11,792] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:44:11,841] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:44:11,847] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:44:11,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 04:44:24,682] {scheduler_job.py:155} INFO - Started process (PID=57449) to work on /airflow/dags/download_data.py
[2022-02-18 04:44:24,687] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:44:24,689] {logging_mixin.py:112} INFO - [2022-02-18 04:44:24,688] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:44:25,311] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:44:25,367] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:44:25,376] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:44:25,383] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.701 seconds
[2022-02-18 04:44:38,037] {scheduler_job.py:155} INFO - Started process (PID=57475) to work on /airflow/dags/download_data.py
[2022-02-18 04:44:38,043] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:44:38,076] {logging_mixin.py:112} INFO - [2022-02-18 04:44:38,076] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:44:38,757] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:44:38,851] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:44:38,866] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:44:38,872] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.835 seconds
[2022-02-18 04:44:51,289] {scheduler_job.py:155} INFO - Started process (PID=57501) to work on /airflow/dags/download_data.py
[2022-02-18 04:44:51,295] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:44:51,297] {logging_mixin.py:112} INFO - [2022-02-18 04:44:51,297] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:44:51,822] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:44:51,864] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:44:51,872] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:44:51,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 04:45:04,552] {scheduler_job.py:155} INFO - Started process (PID=57527) to work on /airflow/dags/download_data.py
[2022-02-18 04:45:04,557] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:45:04,559] {logging_mixin.py:112} INFO - [2022-02-18 04:45:04,559] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:45:05,061] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:45:05,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:45:05,134] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:45:05,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 04:45:17,806] {scheduler_job.py:155} INFO - Started process (PID=57553) to work on /airflow/dags/download_data.py
[2022-02-18 04:45:17,813] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:45:17,815] {logging_mixin.py:112} INFO - [2022-02-18 04:45:17,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:45:18,265] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:45:18,321] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:45:18,331] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:45:18,338] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 04:45:31,098] {scheduler_job.py:155} INFO - Started process (PID=57579) to work on /airflow/dags/download_data.py
[2022-02-18 04:45:31,107] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:45:31,110] {logging_mixin.py:112} INFO - [2022-02-18 04:45:31,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:45:31,586] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:45:31,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:45:31,638] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:45:31,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 04:45:44,386] {scheduler_job.py:155} INFO - Started process (PID=57605) to work on /airflow/dags/download_data.py
[2022-02-18 04:45:44,401] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:45:44,404] {logging_mixin.py:112} INFO - [2022-02-18 04:45:44,403] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:45:44,905] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:45:44,961] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:45:44,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:45:44,975] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 04:45:57,758] {scheduler_job.py:155} INFO - Started process (PID=57631) to work on /airflow/dags/download_data.py
[2022-02-18 04:45:57,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:45:57,764] {logging_mixin.py:112} INFO - [2022-02-18 04:45:57,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:45:58,291] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:45:58,326] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:45:58,332] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:45:58,337] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 04:46:10,995] {scheduler_job.py:155} INFO - Started process (PID=57657) to work on /airflow/dags/download_data.py
[2022-02-18 04:46:11,007] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:46:11,009] {logging_mixin.py:112} INFO - [2022-02-18 04:46:11,009] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:46:11,471] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:46:11,521] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:46:11,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:46:11,533] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 04:46:24,276] {scheduler_job.py:155} INFO - Started process (PID=57683) to work on /airflow/dags/download_data.py
[2022-02-18 04:46:24,282] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:46:24,284] {logging_mixin.py:112} INFO - [2022-02-18 04:46:24,284] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:46:24,807] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:46:24,859] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:46:24,865] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:46:24,869] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 04:46:37,574] {scheduler_job.py:155} INFO - Started process (PID=57709) to work on /airflow/dags/download_data.py
[2022-02-18 04:46:37,579] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:46:37,583] {logging_mixin.py:112} INFO - [2022-02-18 04:46:37,583] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:46:38,064] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:46:38,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:46:38,136] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:46:38,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 04:46:50,834] {scheduler_job.py:155} INFO - Started process (PID=57735) to work on /airflow/dags/download_data.py
[2022-02-18 04:46:50,846] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:46:50,850] {logging_mixin.py:112} INFO - [2022-02-18 04:46:50,849] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:46:51,343] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:46:51,389] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:46:51,401] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:46:51,407] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 04:47:04,123] {scheduler_job.py:155} INFO - Started process (PID=57761) to work on /airflow/dags/download_data.py
[2022-02-18 04:47:04,137] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:47:04,147] {logging_mixin.py:112} INFO - [2022-02-18 04:47:04,147] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:47:04,731] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:47:04,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:47:04,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:47:04,796] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.673 seconds
[2022-02-18 04:47:17,382] {scheduler_job.py:155} INFO - Started process (PID=57787) to work on /airflow/dags/download_data.py
[2022-02-18 04:47:17,389] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:47:17,391] {logging_mixin.py:112} INFO - [2022-02-18 04:47:17,391] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:47:17,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:47:17,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:47:17,952] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:47:17,961] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 04:47:30,719] {scheduler_job.py:155} INFO - Started process (PID=57813) to work on /airflow/dags/download_data.py
[2022-02-18 04:47:30,724] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:47:30,740] {logging_mixin.py:112} INFO - [2022-02-18 04:47:30,739] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:47:31,289] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:47:31,331] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:47:31,337] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:47:31,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-18 04:47:43,972] {scheduler_job.py:155} INFO - Started process (PID=57839) to work on /airflow/dags/download_data.py
[2022-02-18 04:47:43,983] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:47:43,985] {logging_mixin.py:112} INFO - [2022-02-18 04:47:43,985] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:47:44,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:47:44,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:47:44,603] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:47:44,609] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-18 04:47:57,276] {scheduler_job.py:155} INFO - Started process (PID=57865) to work on /airflow/dags/download_data.py
[2022-02-18 04:47:57,281] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:47:57,282] {logging_mixin.py:112} INFO - [2022-02-18 04:47:57,282] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:47:57,745] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:47:57,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:47:57,795] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:47:57,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 04:48:10,567] {scheduler_job.py:155} INFO - Started process (PID=57891) to work on /airflow/dags/download_data.py
[2022-02-18 04:48:10,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:48:10,579] {logging_mixin.py:112} INFO - [2022-02-18 04:48:10,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:48:11,047] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:48:11,101] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:48:11,110] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:48:11,116] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 04:48:23,815] {scheduler_job.py:155} INFO - Started process (PID=57917) to work on /airflow/dags/download_data.py
[2022-02-18 04:48:23,821] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:48:23,822] {logging_mixin.py:112} INFO - [2022-02-18 04:48:23,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:48:24,341] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:48:24,394] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:48:24,404] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:48:24,414] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 04:48:37,120] {scheduler_job.py:155} INFO - Started process (PID=57943) to work on /airflow/dags/download_data.py
[2022-02-18 04:48:37,128] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:48:37,130] {logging_mixin.py:112} INFO - [2022-02-18 04:48:37,130] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:48:37,583] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:48:37,627] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:48:37,636] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:48:37,640] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 04:48:50,377] {scheduler_job.py:155} INFO - Started process (PID=57969) to work on /airflow/dags/download_data.py
[2022-02-18 04:48:50,386] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:48:50,388] {logging_mixin.py:112} INFO - [2022-02-18 04:48:50,388] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:48:51,018] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:48:51,073] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:48:51,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:48:51,090] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.713 seconds
[2022-02-18 04:49:03,708] {scheduler_job.py:155} INFO - Started process (PID=57995) to work on /airflow/dags/download_data.py
[2022-02-18 04:49:03,715] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:49:03,718] {logging_mixin.py:112} INFO - [2022-02-18 04:49:03,717] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:49:04,163] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:49:04,214] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:49:04,222] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:49:04,226] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 04:49:17,001] {scheduler_job.py:155} INFO - Started process (PID=58021) to work on /airflow/dags/download_data.py
[2022-02-18 04:49:17,013] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:49:17,015] {logging_mixin.py:112} INFO - [2022-02-18 04:49:17,015] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:49:17,516] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:49:17,560] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:49:17,570] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:49:17,575] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 04:49:30,288] {scheduler_job.py:155} INFO - Started process (PID=58047) to work on /airflow/dags/download_data.py
[2022-02-18 04:49:30,294] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:49:30,297] {logging_mixin.py:112} INFO - [2022-02-18 04:49:30,297] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:49:30,905] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:49:30,941] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:49:30,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:49:30,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-18 04:49:43,635] {scheduler_job.py:155} INFO - Started process (PID=58073) to work on /airflow/dags/download_data.py
[2022-02-18 04:49:43,645] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:49:43,648] {logging_mixin.py:112} INFO - [2022-02-18 04:49:43,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:49:44,238] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:49:44,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:49:44,317] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:49:44,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.695 seconds
[2022-02-18 04:49:56,929] {scheduler_job.py:155} INFO - Started process (PID=58099) to work on /airflow/dags/download_data.py
[2022-02-18 04:49:56,944] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:49:56,948] {logging_mixin.py:112} INFO - [2022-02-18 04:49:56,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:49:57,453] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:49:57,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:49:57,512] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:49:57,519] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 04:50:10,178] {scheduler_job.py:155} INFO - Started process (PID=58125) to work on /airflow/dags/download_data.py
[2022-02-18 04:50:10,184] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:50:10,185] {logging_mixin.py:112} INFO - [2022-02-18 04:50:10,185] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:50:10,696] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:50:10,740] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:50:10,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:50:10,755] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 04:50:23,450] {scheduler_job.py:155} INFO - Started process (PID=58151) to work on /airflow/dags/download_data.py
[2022-02-18 04:50:23,456] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:50:23,460] {logging_mixin.py:112} INFO - [2022-02-18 04:50:23,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:50:23,934] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:50:23,987] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:50:23,995] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:50:24,000] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 04:50:36,739] {scheduler_job.py:155} INFO - Started process (PID=58177) to work on /airflow/dags/download_data.py
[2022-02-18 04:50:36,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:50:36,750] {logging_mixin.py:112} INFO - [2022-02-18 04:50:36,749] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:50:37,221] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:50:37,282] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:50:37,292] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:50:37,299] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 04:50:50,014] {scheduler_job.py:155} INFO - Started process (PID=58203) to work on /airflow/dags/download_data.py
[2022-02-18 04:50:50,025] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:50:50,026] {logging_mixin.py:112} INFO - [2022-02-18 04:50:50,026] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:50:50,497] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:50:50,540] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:50:50,549] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:50:50,554] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 04:51:03,316] {scheduler_job.py:155} INFO - Started process (PID=58229) to work on /airflow/dags/download_data.py
[2022-02-18 04:51:03,326] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:51:03,327] {logging_mixin.py:112} INFO - [2022-02-18 04:51:03,327] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:51:03,809] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:51:03,856] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:51:03,864] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:51:03,869] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 04:51:16,952] {scheduler_job.py:155} INFO - Started process (PID=58255) to work on /airflow/dags/download_data.py
[2022-02-18 04:51:16,964] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:51:16,967] {logging_mixin.py:112} INFO - [2022-02-18 04:51:16,967] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:51:17,486] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:51:17,531] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:51:17,541] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:51:17,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 04:51:30,237] {scheduler_job.py:155} INFO - Started process (PID=58281) to work on /airflow/dags/download_data.py
[2022-02-18 04:51:30,244] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:51:30,246] {logging_mixin.py:112} INFO - [2022-02-18 04:51:30,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:51:30,731] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:51:30,775] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:51:30,785] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:51:30,790] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 04:51:43,500] {scheduler_job.py:155} INFO - Started process (PID=58307) to work on /airflow/dags/download_data.py
[2022-02-18 04:51:43,506] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:51:43,508] {logging_mixin.py:112} INFO - [2022-02-18 04:51:43,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:51:44,021] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:51:44,125] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:51:44,137] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:51:44,145] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-18 04:51:56,829] {scheduler_job.py:155} INFO - Started process (PID=58333) to work on /airflow/dags/download_data.py
[2022-02-18 04:51:56,840] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:51:56,842] {logging_mixin.py:112} INFO - [2022-02-18 04:51:56,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:51:57,346] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:51:57,401] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:51:57,409] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:51:57,419] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 04:52:10,093] {scheduler_job.py:155} INFO - Started process (PID=58359) to work on /airflow/dags/download_data.py
[2022-02-18 04:52:10,106] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:52:10,108] {logging_mixin.py:112} INFO - [2022-02-18 04:52:10,108] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:52:10,630] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:52:10,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:52:10,695] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:52:10,699] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 04:52:23,410] {scheduler_job.py:155} INFO - Started process (PID=58385) to work on /airflow/dags/download_data.py
[2022-02-18 04:52:23,417] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:52:23,421] {logging_mixin.py:112} INFO - [2022-02-18 04:52:23,420] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:52:24,045] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:52:24,118] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:52:24,152] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:52:24,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.776 seconds
[2022-02-18 04:52:36,728] {scheduler_job.py:155} INFO - Started process (PID=58411) to work on /airflow/dags/download_data.py
[2022-02-18 04:52:36,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:52:36,734] {logging_mixin.py:112} INFO - [2022-02-18 04:52:36,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:52:37,282] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:52:37,307] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:52:37,314] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:52:37,323] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 04:52:50,035] {scheduler_job.py:155} INFO - Started process (PID=58437) to work on /airflow/dags/download_data.py
[2022-02-18 04:52:50,049] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:52:50,054] {logging_mixin.py:112} INFO - [2022-02-18 04:52:50,054] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:52:50,699] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:52:50,752] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:52:50,771] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:52:50,777] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.742 seconds
[2022-02-18 04:53:03,336] {scheduler_job.py:155} INFO - Started process (PID=58463) to work on /airflow/dags/download_data.py
[2022-02-18 04:53:03,344] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:53:03,347] {logging_mixin.py:112} INFO - [2022-02-18 04:53:03,346] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:53:03,818] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:53:03,865] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:53:03,872] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:53:03,878] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 04:53:16,639] {scheduler_job.py:155} INFO - Started process (PID=58489) to work on /airflow/dags/download_data.py
[2022-02-18 04:53:16,644] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:53:16,645] {logging_mixin.py:112} INFO - [2022-02-18 04:53:16,645] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:53:17,135] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:53:17,196] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:53:17,205] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:53:17,210] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 04:53:29,958] {scheduler_job.py:155} INFO - Started process (PID=58515) to work on /airflow/dags/download_data.py
[2022-02-18 04:53:29,968] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:53:29,971] {logging_mixin.py:112} INFO - [2022-02-18 04:53:29,970] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:53:30,544] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:53:30,587] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:53:30,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:53:30,604] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.646 seconds
[2022-02-18 04:53:43,214] {scheduler_job.py:155} INFO - Started process (PID=58541) to work on /airflow/dags/download_data.py
[2022-02-18 04:53:43,223] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:53:43,225] {logging_mixin.py:112} INFO - [2022-02-18 04:53:43,225] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:53:43,740] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:53:43,791] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:53:43,805] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:53:43,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-18 04:53:56,489] {scheduler_job.py:155} INFO - Started process (PID=58567) to work on /airflow/dags/download_data.py
[2022-02-18 04:53:56,494] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:53:56,497] {logging_mixin.py:112} INFO - [2022-02-18 04:53:56,496] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:53:56,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:53:57,031] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:53:57,043] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:53:57,051] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 04:54:09,838] {scheduler_job.py:155} INFO - Started process (PID=58593) to work on /airflow/dags/download_data.py
[2022-02-18 04:54:09,845] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:54:09,847] {logging_mixin.py:112} INFO - [2022-02-18 04:54:09,847] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:54:10,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:54:10,351] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:54:10,360] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:54:10,363] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 04:54:23,106] {scheduler_job.py:155} INFO - Started process (PID=58619) to work on /airflow/dags/download_data.py
[2022-02-18 04:54:23,116] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:54:23,117] {logging_mixin.py:112} INFO - [2022-02-18 04:54:23,117] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:54:23,572] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:54:23,620] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:54:23,627] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:54:23,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 04:54:36,389] {scheduler_job.py:155} INFO - Started process (PID=58645) to work on /airflow/dags/download_data.py
[2022-02-18 04:54:36,396] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:54:36,398] {logging_mixin.py:112} INFO - [2022-02-18 04:54:36,398] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:54:36,878] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:54:36,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:54:36,933] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:54:36,940] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 04:54:49,639] {scheduler_job.py:155} INFO - Started process (PID=58671) to work on /airflow/dags/download_data.py
[2022-02-18 04:54:49,646] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:54:49,648] {logging_mixin.py:112} INFO - [2022-02-18 04:54:49,648] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:54:50,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:54:50,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:54:50,167] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:54:50,172] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 04:55:02,920] {scheduler_job.py:155} INFO - Started process (PID=58697) to work on /airflow/dags/download_data.py
[2022-02-18 04:55:02,924] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:55:02,926] {logging_mixin.py:112} INFO - [2022-02-18 04:55:02,926] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:55:03,399] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:55:03,441] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:55:03,447] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:55:03,454] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 04:55:16,203] {scheduler_job.py:155} INFO - Started process (PID=58723) to work on /airflow/dags/download_data.py
[2022-02-18 04:55:16,209] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:55:16,210] {logging_mixin.py:112} INFO - [2022-02-18 04:55:16,210] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:55:16,688] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:55:16,742] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:55:16,753] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:55:16,760] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 04:55:29,515] {scheduler_job.py:155} INFO - Started process (PID=58749) to work on /airflow/dags/download_data.py
[2022-02-18 04:55:29,522] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:55:29,524] {logging_mixin.py:112} INFO - [2022-02-18 04:55:29,523] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:55:29,991] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:55:30,033] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:55:30,041] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:55:30,045] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 04:55:42,778] {scheduler_job.py:155} INFO - Started process (PID=58775) to work on /airflow/dags/download_data.py
[2022-02-18 04:55:42,793] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:55:42,796] {logging_mixin.py:112} INFO - [2022-02-18 04:55:42,795] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:55:43,284] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:55:43,343] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:55:43,354] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:55:43,359] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 04:55:56,057] {scheduler_job.py:155} INFO - Started process (PID=58801) to work on /airflow/dags/download_data.py
[2022-02-18 04:55:56,065] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:55:56,067] {logging_mixin.py:112} INFO - [2022-02-18 04:55:56,067] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:55:56,555] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:55:56,608] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:55:56,619] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:55:56,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 04:56:09,301] {scheduler_job.py:155} INFO - Started process (PID=58827) to work on /airflow/dags/download_data.py
[2022-02-18 04:56:09,311] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:56:09,313] {logging_mixin.py:112} INFO - [2022-02-18 04:56:09,312] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:56:09,752] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:56:09,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:56:09,808] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:56:09,813] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 04:56:22,574] {scheduler_job.py:155} INFO - Started process (PID=58853) to work on /airflow/dags/download_data.py
[2022-02-18 04:56:22,580] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:56:22,581] {logging_mixin.py:112} INFO - [2022-02-18 04:56:22,581] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:56:23,035] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:56:23,084] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:56:23,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:56:23,098] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 04:56:35,883] {scheduler_job.py:155} INFO - Started process (PID=58879) to work on /airflow/dags/download_data.py
[2022-02-18 04:56:35,891] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:56:35,895] {logging_mixin.py:112} INFO - [2022-02-18 04:56:35,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:56:36,416] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:56:36,470] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:56:36,486] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:56:36,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 04:56:49,310] {scheduler_job.py:155} INFO - Started process (PID=58905) to work on /airflow/dags/download_data.py
[2022-02-18 04:56:49,317] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:56:49,319] {logging_mixin.py:112} INFO - [2022-02-18 04:56:49,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:56:49,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:56:49,825] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:56:49,834] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:56:49,841] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 04:57:03,839] {scheduler_job.py:155} INFO - Started process (PID=58931) to work on /airflow/dags/download_data.py
[2022-02-18 04:57:03,855] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 04:57:03,857] {logging_mixin.py:112} INFO - [2022-02-18 04:57:03,857] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 04:57:04,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 04:57:04,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 04:57:04,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 04:57:04,990] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.150 seconds
[2022-02-18 05:04:12,791] {scheduler_job.py:155} INFO - Started process (PID=58957) to work on /airflow/dags/download_data.py
[2022-02-18 05:04:12,800] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:04:12,802] {logging_mixin.py:112} INFO - [2022-02-18 05:04:12,802] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:04:13,336] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:04:13,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:04:13,387] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:04:13,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 05:04:25,043] {scheduler_job.py:155} INFO - Started process (PID=58982) to work on /airflow/dags/download_data.py
[2022-02-18 05:04:25,047] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:04:25,049] {logging_mixin.py:112} INFO - [2022-02-18 05:04:25,049] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:04:25,605] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:04:25,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:04:25,663] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:04:25,669] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-18 05:04:38,337] {scheduler_job.py:155} INFO - Started process (PID=59008) to work on /airflow/dags/download_data.py
[2022-02-18 05:04:38,342] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:04:38,344] {logging_mixin.py:112} INFO - [2022-02-18 05:04:38,343] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:04:38,874] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:04:38,925] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:04:38,933] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:04:38,938] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 05:04:51,600] {scheduler_job.py:155} INFO - Started process (PID=59034) to work on /airflow/dags/download_data.py
[2022-02-18 05:04:51,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:04:51,607] {logging_mixin.py:112} INFO - [2022-02-18 05:04:51,606] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:04:52,103] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:04:52,149] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:04:52,161] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:04:52,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 05:05:04,879] {scheduler_job.py:155} INFO - Started process (PID=59060) to work on /airflow/dags/download_data.py
[2022-02-18 05:05:04,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:05:04,891] {logging_mixin.py:112} INFO - [2022-02-18 05:05:04,891] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:05:05,402] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:05:05,447] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:05:05,458] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:05:05,464] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 05:05:18,196] {scheduler_job.py:155} INFO - Started process (PID=59086) to work on /airflow/dags/download_data.py
[2022-02-18 05:05:18,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:05:18,216] {logging_mixin.py:112} INFO - [2022-02-18 05:05:18,216] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:05:19,092] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:05:19,140] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:05:19,150] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:05:19,156] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.960 seconds
[2022-02-18 05:05:31,486] {scheduler_job.py:155} INFO - Started process (PID=59112) to work on /airflow/dags/download_data.py
[2022-02-18 05:05:31,492] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:05:31,494] {logging_mixin.py:112} INFO - [2022-02-18 05:05:31,494] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:05:31,949] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:05:31,980] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:05:31,985] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:05:31,989] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 05:05:44,743] {scheduler_job.py:155} INFO - Started process (PID=59138) to work on /airflow/dags/download_data.py
[2022-02-18 05:05:44,748] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:05:44,750] {logging_mixin.py:112} INFO - [2022-02-18 05:05:44,750] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:05:45,312] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:05:45,366] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:05:45,377] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:05:45,384] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 05:05:58,034] {scheduler_job.py:155} INFO - Started process (PID=59164) to work on /airflow/dags/download_data.py
[2022-02-18 05:05:58,040] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:05:58,043] {logging_mixin.py:112} INFO - [2022-02-18 05:05:58,042] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:05:58,516] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:05:58,568] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:05:58,582] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:05:58,585] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 05:06:11,330] {scheduler_job.py:155} INFO - Started process (PID=59190) to work on /airflow/dags/download_data.py
[2022-02-18 05:06:11,337] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:06:11,340] {logging_mixin.py:112} INFO - [2022-02-18 05:06:11,339] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:06:11,809] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:06:11,866] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:06:11,876] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:06:11,881] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 05:06:24,637] {scheduler_job.py:155} INFO - Started process (PID=59216) to work on /airflow/dags/download_data.py
[2022-02-18 05:06:24,644] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:06:24,647] {logging_mixin.py:112} INFO - [2022-02-18 05:06:24,646] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:06:25,376] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:06:25,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:06:25,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:06:25,439] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.802 seconds
[2022-02-18 05:06:37,982] {scheduler_job.py:155} INFO - Started process (PID=59242) to work on /airflow/dags/download_data.py
[2022-02-18 05:06:37,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:06:38,001] {logging_mixin.py:112} INFO - [2022-02-18 05:06:38,001] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:06:38,697] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:06:38,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:06:38,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:06:38,814] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.832 seconds
[2022-02-18 05:06:51,230] {scheduler_job.py:155} INFO - Started process (PID=59268) to work on /airflow/dags/download_data.py
[2022-02-18 05:06:51,244] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:06:51,246] {logging_mixin.py:112} INFO - [2022-02-18 05:06:51,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:06:51,713] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:06:51,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:06:51,769] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:06:51,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 05:07:04,487] {scheduler_job.py:155} INFO - Started process (PID=59294) to work on /airflow/dags/download_data.py
[2022-02-18 05:07:04,499] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:07:04,502] {logging_mixin.py:112} INFO - [2022-02-18 05:07:04,502] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:07:04,997] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:07:05,060] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:07:05,075] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:07:05,083] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 05:07:17,863] {scheduler_job.py:155} INFO - Started process (PID=59320) to work on /airflow/dags/download_data.py
[2022-02-18 05:07:17,872] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:07:17,874] {logging_mixin.py:112} INFO - [2022-02-18 05:07:17,874] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:07:18,476] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:07:18,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:07:18,552] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:07:18,558] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.695 seconds
[2022-02-18 05:07:31,163] {scheduler_job.py:155} INFO - Started process (PID=59346) to work on /airflow/dags/download_data.py
[2022-02-18 05:07:31,169] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:07:31,172] {logging_mixin.py:112} INFO - [2022-02-18 05:07:31,171] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:07:31,753] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:07:31,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:07:31,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:07:31,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.671 seconds
[2022-02-18 05:07:44,427] {scheduler_job.py:155} INFO - Started process (PID=59372) to work on /airflow/dags/download_data.py
[2022-02-18 05:07:44,438] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:07:44,440] {logging_mixin.py:112} INFO - [2022-02-18 05:07:44,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:07:44,939] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:07:44,985] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:07:44,994] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:07:45,000] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 05:07:58,601] {scheduler_job.py:155} INFO - Started process (PID=59398) to work on /airflow/dags/download_data.py
[2022-02-18 05:07:58,606] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:07:58,610] {logging_mixin.py:112} INFO - [2022-02-18 05:07:58,609] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:07:59,090] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:07:59,139] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:07:59,149] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:07:59,154] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 05:08:11,871] {scheduler_job.py:155} INFO - Started process (PID=59424) to work on /airflow/dags/download_data.py
[2022-02-18 05:08:11,881] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:08:11,883] {logging_mixin.py:112} INFO - [2022-02-18 05:08:11,883] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:08:12,377] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:08:12,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:08:12,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:08:12,434] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 05:08:25,160] {scheduler_job.py:155} INFO - Started process (PID=59450) to work on /airflow/dags/download_data.py
[2022-02-18 05:08:25,167] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:08:25,169] {logging_mixin.py:112} INFO - [2022-02-18 05:08:25,168] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:08:25,708] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:08:25,761] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:08:25,767] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:08:25,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 05:08:38,442] {scheduler_job.py:155} INFO - Started process (PID=59476) to work on /airflow/dags/download_data.py
[2022-02-18 05:08:38,446] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:08:38,448] {logging_mixin.py:112} INFO - [2022-02-18 05:08:38,448] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:08:38,952] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:08:39,015] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:08:39,029] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:08:39,035] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 05:08:51,770] {scheduler_job.py:155} INFO - Started process (PID=59502) to work on /airflow/dags/download_data.py
[2022-02-18 05:08:51,782] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:08:51,786] {logging_mixin.py:112} INFO - [2022-02-18 05:08:51,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:08:52,286] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:08:52,340] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:08:52,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:08:52,358] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 05:09:05,074] {scheduler_job.py:155} INFO - Started process (PID=59528) to work on /airflow/dags/download_data.py
[2022-02-18 05:09:05,085] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:09:05,088] {logging_mixin.py:112} INFO - [2022-02-18 05:09:05,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:09:05,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:09:05,634] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:09:05,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:09:05,653] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 05:09:18,366] {scheduler_job.py:155} INFO - Started process (PID=59554) to work on /airflow/dags/download_data.py
[2022-02-18 05:09:18,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:09:18,378] {logging_mixin.py:112} INFO - [2022-02-18 05:09:18,377] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:09:18,861] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:09:18,911] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:09:18,923] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:09:18,931] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 05:09:31,626] {scheduler_job.py:155} INFO - Started process (PID=59580) to work on /airflow/dags/download_data.py
[2022-02-18 05:09:31,634] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:09:31,636] {logging_mixin.py:112} INFO - [2022-02-18 05:09:31,636] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:09:32,143] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:09:32,194] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:09:32,206] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:09:32,215] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 05:09:44,986] {scheduler_job.py:155} INFO - Started process (PID=59606) to work on /airflow/dags/download_data.py
[2022-02-18 05:09:44,990] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:09:44,992] {logging_mixin.py:112} INFO - [2022-02-18 05:09:44,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:09:45,579] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:09:45,628] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:09:45,642] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:09:45,649] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.663 seconds
[2022-02-18 05:09:58,263] {scheduler_job.py:155} INFO - Started process (PID=59632) to work on /airflow/dags/download_data.py
[2022-02-18 05:09:58,269] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:09:58,271] {logging_mixin.py:112} INFO - [2022-02-18 05:09:58,271] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:09:58,781] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:09:58,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:09:58,839] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:09:58,847] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 05:10:11,553] {scheduler_job.py:155} INFO - Started process (PID=59658) to work on /airflow/dags/download_data.py
[2022-02-18 05:10:11,561] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:10:11,563] {logging_mixin.py:112} INFO - [2022-02-18 05:10:11,562] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:10:12,083] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:10:12,141] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:10:12,152] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:10:12,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-18 05:10:24,836] {scheduler_job.py:155} INFO - Started process (PID=59684) to work on /airflow/dags/download_data.py
[2022-02-18 05:10:24,840] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:10:24,842] {logging_mixin.py:112} INFO - [2022-02-18 05:10:24,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:10:25,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:10:25,399] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:10:25,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:10:25,414] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 05:10:38,108] {scheduler_job.py:155} INFO - Started process (PID=59710) to work on /airflow/dags/download_data.py
[2022-02-18 05:10:38,118] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:10:38,122] {logging_mixin.py:112} INFO - [2022-02-18 05:10:38,122] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:10:38,634] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:10:38,681] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:10:38,688] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:10:38,694] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 05:10:51,445] {scheduler_job.py:155} INFO - Started process (PID=59736) to work on /airflow/dags/download_data.py
[2022-02-18 05:10:51,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:10:51,454] {logging_mixin.py:112} INFO - [2022-02-18 05:10:51,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:10:51,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:10:51,986] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:10:51,992] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:10:51,997] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 05:11:04,699] {scheduler_job.py:155} INFO - Started process (PID=59762) to work on /airflow/dags/download_data.py
[2022-02-18 05:11:04,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:11:04,710] {logging_mixin.py:112} INFO - [2022-02-18 05:11:04,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:11:05,267] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:11:05,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:11:05,331] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:11:05,337] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.639 seconds
[2022-02-18 05:11:18,035] {scheduler_job.py:155} INFO - Started process (PID=59788) to work on /airflow/dags/download_data.py
[2022-02-18 05:11:18,041] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:11:18,042] {logging_mixin.py:112} INFO - [2022-02-18 05:11:18,042] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:11:18,538] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:11:18,580] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:11:18,591] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:11:18,599] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 05:11:31,327] {scheduler_job.py:155} INFO - Started process (PID=59814) to work on /airflow/dags/download_data.py
[2022-02-18 05:11:31,334] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:11:31,337] {logging_mixin.py:112} INFO - [2022-02-18 05:11:31,336] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:11:31,826] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:11:31,895] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:11:31,904] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:11:31,914] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 05:11:44,793] {scheduler_job.py:155} INFO - Started process (PID=59840) to work on /airflow/dags/download_data.py
[2022-02-18 05:11:44,799] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:11:44,801] {logging_mixin.py:112} INFO - [2022-02-18 05:11:44,800] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:11:45,450] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:11:45,542] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:11:45,552] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:11:45,565] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.772 seconds
[2022-02-18 05:11:58,049] {scheduler_job.py:155} INFO - Started process (PID=59866) to work on /airflow/dags/download_data.py
[2022-02-18 05:11:58,054] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:11:58,057] {logging_mixin.py:112} INFO - [2022-02-18 05:11:58,055] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:11:58,515] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:11:58,558] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:11:58,567] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:11:58,573] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 05:12:11,280] {scheduler_job.py:155} INFO - Started process (PID=59892) to work on /airflow/dags/download_data.py
[2022-02-18 05:12:11,291] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:12:11,301] {logging_mixin.py:112} INFO - [2022-02-18 05:12:11,301] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:12:11,925] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:12:11,985] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:12:11,992] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:12:12,001] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.721 seconds
[2022-02-18 05:12:24,615] {scheduler_job.py:155} INFO - Started process (PID=59918) to work on /airflow/dags/download_data.py
[2022-02-18 05:12:24,620] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:12:24,622] {logging_mixin.py:112} INFO - [2022-02-18 05:12:24,621] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:12:25,138] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:12:25,186] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:12:25,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:12:25,196] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 05:12:37,874] {scheduler_job.py:155} INFO - Started process (PID=59944) to work on /airflow/dags/download_data.py
[2022-02-18 05:12:37,880] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:12:37,882] {logging_mixin.py:112} INFO - [2022-02-18 05:12:37,882] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:12:38,380] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:12:38,420] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:12:38,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:12:38,433] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 05:12:51,201] {scheduler_job.py:155} INFO - Started process (PID=59970) to work on /airflow/dags/download_data.py
[2022-02-18 05:12:51,211] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:12:51,213] {logging_mixin.py:112} INFO - [2022-02-18 05:12:51,213] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:12:51,738] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:12:51,784] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:12:51,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:12:51,797] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 05:13:04,480] {scheduler_job.py:155} INFO - Started process (PID=59996) to work on /airflow/dags/download_data.py
[2022-02-18 05:13:04,485] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:13:04,487] {logging_mixin.py:112} INFO - [2022-02-18 05:13:04,487] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:13:05,003] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:13:05,049] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:13:05,057] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:13:05,067] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 05:13:17,795] {scheduler_job.py:155} INFO - Started process (PID=60022) to work on /airflow/dags/download_data.py
[2022-02-18 05:13:17,807] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:13:17,809] {logging_mixin.py:112} INFO - [2022-02-18 05:13:17,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:13:18,264] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:13:18,313] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:13:18,323] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:13:18,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 05:13:31,246] {scheduler_job.py:155} INFO - Started process (PID=60048) to work on /airflow/dags/download_data.py
[2022-02-18 05:13:31,254] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:13:31,256] {logging_mixin.py:112} INFO - [2022-02-18 05:13:31,256] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:13:31,770] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:13:31,822] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:13:31,830] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:13:31,845] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 05:13:44,536] {scheduler_job.py:155} INFO - Started process (PID=60074) to work on /airflow/dags/download_data.py
[2022-02-18 05:13:44,544] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:13:44,547] {logging_mixin.py:112} INFO - [2022-02-18 05:13:44,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:13:45,000] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:13:45,041] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:13:45,047] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:13:45,053] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 05:13:57,823] {scheduler_job.py:155} INFO - Started process (PID=60100) to work on /airflow/dags/download_data.py
[2022-02-18 05:13:57,836] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:13:57,839] {logging_mixin.py:112} INFO - [2022-02-18 05:13:57,839] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:13:58,343] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:13:58,394] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:13:58,402] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:13:58,408] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-18 05:14:11,137] {scheduler_job.py:155} INFO - Started process (PID=60126) to work on /airflow/dags/download_data.py
[2022-02-18 05:14:11,146] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:14:11,148] {logging_mixin.py:112} INFO - [2022-02-18 05:14:11,148] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:14:11,654] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:14:11,702] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:14:11,711] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:14:11,718] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 05:14:24,446] {scheduler_job.py:155} INFO - Started process (PID=60152) to work on /airflow/dags/download_data.py
[2022-02-18 05:14:24,454] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:14:24,456] {logging_mixin.py:112} INFO - [2022-02-18 05:14:24,456] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:14:24,925] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:14:24,975] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:14:24,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:14:24,988] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 05:14:37,696] {scheduler_job.py:155} INFO - Started process (PID=60178) to work on /airflow/dags/download_data.py
[2022-02-18 05:14:37,710] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:14:37,717] {logging_mixin.py:112} INFO - [2022-02-18 05:14:37,717] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:14:38,215] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:14:38,255] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:14:38,267] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:14:38,274] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 05:14:51,253] {scheduler_job.py:155} INFO - Started process (PID=60204) to work on /airflow/dags/download_data.py
[2022-02-18 05:14:51,267] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:14:51,269] {logging_mixin.py:112} INFO - [2022-02-18 05:14:51,269] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:14:51,724] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:14:51,766] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:14:51,772] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:14:51,778] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 05:15:04,468] {scheduler_job.py:155} INFO - Started process (PID=60230) to work on /airflow/dags/download_data.py
[2022-02-18 05:15:04,474] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:15:04,477] {logging_mixin.py:112} INFO - [2022-02-18 05:15:04,477] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:15:05,009] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:15:05,062] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:15:05,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:15:05,078] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 05:15:17,743] {scheduler_job.py:155} INFO - Started process (PID=60256) to work on /airflow/dags/download_data.py
[2022-02-18 05:15:17,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:15:17,748] {logging_mixin.py:112} INFO - [2022-02-18 05:15:17,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:15:18,208] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:15:18,242] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:15:18,248] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:15:18,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 05:15:31,023] {scheduler_job.py:155} INFO - Started process (PID=60282) to work on /airflow/dags/download_data.py
[2022-02-18 05:15:31,030] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:15:31,032] {logging_mixin.py:112} INFO - [2022-02-18 05:15:31,032] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:15:31,513] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:15:31,574] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:15:31,585] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:15:31,590] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 05:15:44,309] {scheduler_job.py:155} INFO - Started process (PID=60308) to work on /airflow/dags/download_data.py
[2022-02-18 05:15:44,314] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:15:44,316] {logging_mixin.py:112} INFO - [2022-02-18 05:15:44,316] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:15:44,757] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:15:44,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:15:44,830] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:15:44,840] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 05:15:57,638] {scheduler_job.py:155} INFO - Started process (PID=60334) to work on /airflow/dags/download_data.py
[2022-02-18 05:15:57,643] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:15:57,645] {logging_mixin.py:112} INFO - [2022-02-18 05:15:57,645] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:15:58,103] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:15:58,148] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:15:58,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:15:58,161] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 05:16:10,887] {scheduler_job.py:155} INFO - Started process (PID=60360) to work on /airflow/dags/download_data.py
[2022-02-18 05:16:10,893] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:16:10,895] {logging_mixin.py:112} INFO - [2022-02-18 05:16:10,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:16:11,343] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:16:11,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:16:11,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:16:11,401] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 05:16:24,194] {scheduler_job.py:155} INFO - Started process (PID=60386) to work on /airflow/dags/download_data.py
[2022-02-18 05:16:24,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:16:24,208] {logging_mixin.py:112} INFO - [2022-02-18 05:16:24,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:16:24,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:16:24,691] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:16:24,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:16:24,701] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 05:16:37,422] {scheduler_job.py:155} INFO - Started process (PID=60412) to work on /airflow/dags/download_data.py
[2022-02-18 05:16:37,433] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:16:37,438] {logging_mixin.py:112} INFO - [2022-02-18 05:16:37,437] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:16:38,004] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:16:38,056] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:16:38,068] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:16:38,078] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.656 seconds
[2022-02-18 05:16:50,746] {scheduler_job.py:155} INFO - Started process (PID=60438) to work on /airflow/dags/download_data.py
[2022-02-18 05:16:50,755] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:16:50,758] {logging_mixin.py:112} INFO - [2022-02-18 05:16:50,758] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:16:51,237] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:16:51,285] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:16:51,294] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:16:51,298] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 05:17:04,005] {scheduler_job.py:155} INFO - Started process (PID=60464) to work on /airflow/dags/download_data.py
[2022-02-18 05:17:04,013] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:17:04,015] {logging_mixin.py:112} INFO - [2022-02-18 05:17:04,015] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:17:04,482] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:17:04,523] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:17:04,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:17:04,536] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 05:17:17,294] {scheduler_job.py:155} INFO - Started process (PID=60490) to work on /airflow/dags/download_data.py
[2022-02-18 05:17:17,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:17:17,303] {logging_mixin.py:112} INFO - [2022-02-18 05:17:17,302] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:17:17,765] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:17:17,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:17:17,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:17:17,832] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 05:17:30,580] {scheduler_job.py:155} INFO - Started process (PID=60516) to work on /airflow/dags/download_data.py
[2022-02-18 05:17:30,585] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:17:30,587] {logging_mixin.py:112} INFO - [2022-02-18 05:17:30,587] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:17:31,057] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:17:31,106] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:17:31,118] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:17:31,122] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 05:17:43,811] {scheduler_job.py:155} INFO - Started process (PID=60542) to work on /airflow/dags/download_data.py
[2022-02-18 05:17:43,817] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:17:43,818] {logging_mixin.py:112} INFO - [2022-02-18 05:17:43,818] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:17:44,324] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:17:44,374] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:17:44,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:17:44,388] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 05:17:57,123] {scheduler_job.py:155} INFO - Started process (PID=60568) to work on /airflow/dags/download_data.py
[2022-02-18 05:17:57,130] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:17:57,133] {logging_mixin.py:112} INFO - [2022-02-18 05:17:57,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:17:57,598] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:17:57,654] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:17:57,661] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:17:57,667] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 05:18:10,355] {scheduler_job.py:155} INFO - Started process (PID=60594) to work on /airflow/dags/download_data.py
[2022-02-18 05:18:10,365] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:18:10,368] {logging_mixin.py:112} INFO - [2022-02-18 05:18:10,367] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:18:11,026] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:18:11,144] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:18:11,152] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:18:11,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.803 seconds
[2022-02-18 05:18:23,994] {scheduler_job.py:155} INFO - Started process (PID=60620) to work on /airflow/dags/download_data.py
[2022-02-18 05:18:24,009] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:18:24,012] {logging_mixin.py:112} INFO - [2022-02-18 05:18:24,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:18:25,713] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:18:25,763] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:18:25,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:18:25,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.793 seconds
[2022-02-18 05:18:38,371] {scheduler_job.py:155} INFO - Started process (PID=60646) to work on /airflow/dags/download_data.py
[2022-02-18 05:18:38,382] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:18:38,384] {logging_mixin.py:112} INFO - [2022-02-18 05:18:38,384] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:18:38,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:18:38,945] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:18:38,953] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:18:38,960] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 05:18:50,667] {scheduler_job.py:155} INFO - Started process (PID=60671) to work on /airflow/dags/download_data.py
[2022-02-18 05:18:50,671] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:18:50,673] {logging_mixin.py:112} INFO - [2022-02-18 05:18:50,673] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:18:51,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:18:51,168] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:18:51,176] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:18:51,181] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 05:19:04,002] {scheduler_job.py:155} INFO - Started process (PID=60697) to work on /airflow/dags/download_data.py
[2022-02-18 05:19:04,008] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:19:04,010] {logging_mixin.py:112} INFO - [2022-02-18 05:19:04,010] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:19:04,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:19:04,603] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:19:04,612] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:19:04,620] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-18 05:19:17,287] {scheduler_job.py:155} INFO - Started process (PID=60723) to work on /airflow/dags/download_data.py
[2022-02-18 05:19:17,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:19:17,299] {logging_mixin.py:112} INFO - [2022-02-18 05:19:17,299] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:19:17,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:19:17,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:19:17,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:19:17,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 05:19:30,549] {scheduler_job.py:155} INFO - Started process (PID=60749) to work on /airflow/dags/download_data.py
[2022-02-18 05:19:30,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:19:30,557] {logging_mixin.py:112} INFO - [2022-02-18 05:19:30,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:19:30,999] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:19:31,046] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:19:31,051] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:19:31,055] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 05:19:43,831] {scheduler_job.py:155} INFO - Started process (PID=60775) to work on /airflow/dags/download_data.py
[2022-02-18 05:19:43,847] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:19:43,849] {logging_mixin.py:112} INFO - [2022-02-18 05:19:43,849] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:19:44,390] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:19:44,437] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:19:44,448] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:19:44,454] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-18 05:19:57,173] {scheduler_job.py:155} INFO - Started process (PID=60801) to work on /airflow/dags/download_data.py
[2022-02-18 05:19:57,182] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:19:57,185] {logging_mixin.py:112} INFO - [2022-02-18 05:19:57,185] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:19:57,649] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:19:57,694] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:19:57,699] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:19:57,703] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 05:20:10,457] {scheduler_job.py:155} INFO - Started process (PID=60827) to work on /airflow/dags/download_data.py
[2022-02-18 05:20:10,467] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:20:10,469] {logging_mixin.py:112} INFO - [2022-02-18 05:20:10,469] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:20:10,915] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:20:10,981] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:20:10,992] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:20:10,998] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 05:20:23,803] {scheduler_job.py:155} INFO - Started process (PID=60853) to work on /airflow/dags/download_data.py
[2022-02-18 05:20:23,810] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:20:23,816] {logging_mixin.py:112} INFO - [2022-02-18 05:20:23,816] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:20:24,329] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:20:24,376] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:20:24,384] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:20:24,391] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 05:20:37,119] {scheduler_job.py:155} INFO - Started process (PID=60879) to work on /airflow/dags/download_data.py
[2022-02-18 05:20:37,126] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:20:37,128] {logging_mixin.py:112} INFO - [2022-02-18 05:20:37,127] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:20:37,596] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:20:37,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:20:37,675] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:20:37,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 05:20:50,490] {scheduler_job.py:155} INFO - Started process (PID=60905) to work on /airflow/dags/download_data.py
[2022-02-18 05:20:50,502] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:20:50,503] {logging_mixin.py:112} INFO - [2022-02-18 05:20:50,503] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:20:51,087] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:20:51,133] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:20:51,141] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:20:51,147] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-18 05:21:03,762] {scheduler_job.py:155} INFO - Started process (PID=60931) to work on /airflow/dags/download_data.py
[2022-02-18 05:21:03,770] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:21:03,772] {logging_mixin.py:112} INFO - [2022-02-18 05:21:03,772] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:21:04,252] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:21:04,294] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:21:04,300] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:21:04,304] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 05:21:17,075] {scheduler_job.py:155} INFO - Started process (PID=60957) to work on /airflow/dags/download_data.py
[2022-02-18 05:21:17,089] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:21:17,091] {logging_mixin.py:112} INFO - [2022-02-18 05:21:17,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:21:17,672] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:21:17,736] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:21:17,750] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:21:17,756] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.681 seconds
[2022-02-18 05:21:30,344] {scheduler_job.py:155} INFO - Started process (PID=60983) to work on /airflow/dags/download_data.py
[2022-02-18 05:21:30,349] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:21:30,351] {logging_mixin.py:112} INFO - [2022-02-18 05:21:30,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:21:30,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:21:30,877] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:21:30,890] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:21:30,898] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 05:21:43,643] {scheduler_job.py:155} INFO - Started process (PID=61009) to work on /airflow/dags/download_data.py
[2022-02-18 05:21:43,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:21:43,655] {logging_mixin.py:112} INFO - [2022-02-18 05:21:43,655] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:21:44,118] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:21:44,154] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:21:44,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:21:44,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 05:21:56,939] {scheduler_job.py:155} INFO - Started process (PID=61035) to work on /airflow/dags/download_data.py
[2022-02-18 05:21:56,945] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:21:56,946] {logging_mixin.py:112} INFO - [2022-02-18 05:21:56,946] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:21:57,465] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:21:57,523] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:21:57,530] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:21:57,536] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-18 05:22:10,184] {scheduler_job.py:155} INFO - Started process (PID=61061) to work on /airflow/dags/download_data.py
[2022-02-18 05:22:10,195] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:22:10,198] {logging_mixin.py:112} INFO - [2022-02-18 05:22:10,198] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:22:10,800] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:22:10,864] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:22:10,874] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:22:10,879] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.695 seconds
[2022-02-18 05:22:23,504] {scheduler_job.py:155} INFO - Started process (PID=61087) to work on /airflow/dags/download_data.py
[2022-02-18 05:22:23,513] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:22:23,516] {logging_mixin.py:112} INFO - [2022-02-18 05:22:23,516] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:22:24,054] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:22:24,098] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:22:24,104] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:22:24,108] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 05:22:36,777] {scheduler_job.py:155} INFO - Started process (PID=61113) to work on /airflow/dags/download_data.py
[2022-02-18 05:22:36,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:22:36,793] {logging_mixin.py:112} INFO - [2022-02-18 05:22:36,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:22:37,275] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:22:37,326] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:22:37,337] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:22:37,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 05:22:50,073] {scheduler_job.py:155} INFO - Started process (PID=61139) to work on /airflow/dags/download_data.py
[2022-02-18 05:22:50,079] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:22:50,081] {logging_mixin.py:112} INFO - [2022-02-18 05:22:50,081] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:22:50,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:22:50,731] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:22:50,741] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:22:50,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.678 seconds
[2022-02-18 05:23:03,362] {scheduler_job.py:155} INFO - Started process (PID=61165) to work on /airflow/dags/download_data.py
[2022-02-18 05:23:03,371] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:23:03,377] {logging_mixin.py:112} INFO - [2022-02-18 05:23:03,372] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:23:03,881] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:23:03,930] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:23:03,937] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:23:03,941] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 05:23:17,630] {scheduler_job.py:155} INFO - Started process (PID=61191) to work on /airflow/dags/download_data.py
[2022-02-18 05:23:17,639] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:23:17,641] {logging_mixin.py:112} INFO - [2022-02-18 05:23:17,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:23:18,127] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:23:18,180] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:23:18,188] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:23:18,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 05:23:30,871] {scheduler_job.py:155} INFO - Started process (PID=61217) to work on /airflow/dags/download_data.py
[2022-02-18 05:23:30,882] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:23:30,885] {logging_mixin.py:112} INFO - [2022-02-18 05:23:30,884] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:23:31,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:23:31,415] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:23:31,427] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:23:31,433] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 05:23:43,143] {scheduler_job.py:155} INFO - Started process (PID=61242) to work on /airflow/dags/download_data.py
[2022-02-18 05:23:43,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:23:43,150] {logging_mixin.py:112} INFO - [2022-02-18 05:23:43,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:23:43,626] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:23:43,675] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:23:43,681] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:23:43,688] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 05:23:56,431] {scheduler_job.py:155} INFO - Started process (PID=61268) to work on /airflow/dags/download_data.py
[2022-02-18 05:23:56,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:23:56,437] {logging_mixin.py:112} INFO - [2022-02-18 05:23:56,437] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:23:56,949] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:23:57,002] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:23:57,014] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:23:57,020] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 05:24:09,744] {scheduler_job.py:155} INFO - Started process (PID=61294) to work on /airflow/dags/download_data.py
[2022-02-18 05:24:09,758] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:24:09,765] {logging_mixin.py:112} INFO - [2022-02-18 05:24:09,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:24:10,249] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:24:10,309] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:24:10,321] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:24:10,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 05:24:23,034] {scheduler_job.py:155} INFO - Started process (PID=61320) to work on /airflow/dags/download_data.py
[2022-02-18 05:24:23,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:24:23,046] {logging_mixin.py:112} INFO - [2022-02-18 05:24:23,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:24:23,548] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:24:23,607] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:24:23,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:24:23,625] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 05:24:36,322] {scheduler_job.py:155} INFO - Started process (PID=61346) to work on /airflow/dags/download_data.py
[2022-02-18 05:24:36,333] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:24:36,335] {logging_mixin.py:112} INFO - [2022-02-18 05:24:36,335] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:24:36,809] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:24:36,861] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:24:36,872] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:24:36,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 05:24:49,593] {scheduler_job.py:155} INFO - Started process (PID=61372) to work on /airflow/dags/download_data.py
[2022-02-18 05:24:49,606] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:24:49,614] {logging_mixin.py:112} INFO - [2022-02-18 05:24:49,613] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:24:50,063] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:24:50,116] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:24:50,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:24:50,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 05:25:02,847] {scheduler_job.py:155} INFO - Started process (PID=61398) to work on /airflow/dags/download_data.py
[2022-02-18 05:25:02,852] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:25:02,854] {logging_mixin.py:112} INFO - [2022-02-18 05:25:02,854] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:25:03,329] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:25:03,379] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:25:03,389] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:25:03,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 05:25:16,102] {scheduler_job.py:155} INFO - Started process (PID=61424) to work on /airflow/dags/download_data.py
[2022-02-18 05:25:16,107] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:25:16,109] {logging_mixin.py:112} INFO - [2022-02-18 05:25:16,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:25:16,573] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:25:16,625] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:25:16,632] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:25:16,637] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 05:25:29,368] {scheduler_job.py:155} INFO - Started process (PID=61450) to work on /airflow/dags/download_data.py
[2022-02-18 05:25:29,378] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:25:29,380] {logging_mixin.py:112} INFO - [2022-02-18 05:25:29,380] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:25:29,845] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:25:29,914] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:25:29,924] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:25:29,929] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 05:25:42,690] {scheduler_job.py:155} INFO - Started process (PID=61476) to work on /airflow/dags/download_data.py
[2022-02-18 05:25:42,696] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:25:42,699] {logging_mixin.py:112} INFO - [2022-02-18 05:25:42,698] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:25:43,180] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:25:43,226] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:25:43,237] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:25:43,243] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 05:25:55,959] {scheduler_job.py:155} INFO - Started process (PID=61502) to work on /airflow/dags/download_data.py
[2022-02-18 05:25:55,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:25:55,969] {logging_mixin.py:112} INFO - [2022-02-18 05:25:55,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:25:56,435] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:25:56,478] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:25:56,487] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:25:56,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 05:26:09,226] {scheduler_job.py:155} INFO - Started process (PID=61528) to work on /airflow/dags/download_data.py
[2022-02-18 05:26:09,232] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:26:09,234] {logging_mixin.py:112} INFO - [2022-02-18 05:26:09,234] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:26:09,700] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:26:09,758] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:26:09,768] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:26:09,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 05:26:22,523] {scheduler_job.py:155} INFO - Started process (PID=61554) to work on /airflow/dags/download_data.py
[2022-02-18 05:26:22,529] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:26:22,531] {logging_mixin.py:112} INFO - [2022-02-18 05:26:22,531] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:26:22,991] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:26:23,037] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:26:23,044] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:26:23,048] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 05:26:35,772] {scheduler_job.py:155} INFO - Started process (PID=61580) to work on /airflow/dags/download_data.py
[2022-02-18 05:26:35,780] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:26:35,783] {logging_mixin.py:112} INFO - [2022-02-18 05:26:35,782] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:26:36,316] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:26:36,371] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:26:36,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:26:36,388] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-18 05:26:49,038] {scheduler_job.py:155} INFO - Started process (PID=61606) to work on /airflow/dags/download_data.py
[2022-02-18 05:26:49,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:26:49,049] {logging_mixin.py:112} INFO - [2022-02-18 05:26:49,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:26:49,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:26:49,574] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:26:49,580] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:26:49,588] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 05:27:02,258] {scheduler_job.py:155} INFO - Started process (PID=61632) to work on /airflow/dags/download_data.py
[2022-02-18 05:27:02,263] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:27:02,265] {logging_mixin.py:112} INFO - [2022-02-18 05:27:02,264] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:27:02,716] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:27:02,767] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:27:02,776] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:27:02,780] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 05:27:15,557] {scheduler_job.py:155} INFO - Started process (PID=61658) to work on /airflow/dags/download_data.py
[2022-02-18 05:27:15,569] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:27:15,571] {logging_mixin.py:112} INFO - [2022-02-18 05:27:15,571] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:27:16,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:27:16,061] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:27:16,071] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:27:16,076] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 05:27:28,841] {scheduler_job.py:155} INFO - Started process (PID=61684) to work on /airflow/dags/download_data.py
[2022-02-18 05:27:28,850] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:27:28,853] {logging_mixin.py:112} INFO - [2022-02-18 05:27:28,853] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:27:29,350] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:27:29,403] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:27:29,413] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:27:29,420] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 05:27:42,103] {scheduler_job.py:155} INFO - Started process (PID=61710) to work on /airflow/dags/download_data.py
[2022-02-18 05:27:42,108] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:27:42,109] {logging_mixin.py:112} INFO - [2022-02-18 05:27:42,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:27:42,626] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:27:42,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:27:42,695] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:27:42,699] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-18 05:27:55,388] {scheduler_job.py:155} INFO - Started process (PID=61736) to work on /airflow/dags/download_data.py
[2022-02-18 05:27:55,398] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:27:55,400] {logging_mixin.py:112} INFO - [2022-02-18 05:27:55,400] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:27:55,889] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:27:55,943] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:27:55,952] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:27:55,958] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 05:28:08,670] {scheduler_job.py:155} INFO - Started process (PID=61762) to work on /airflow/dags/download_data.py
[2022-02-18 05:28:08,678] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:28:08,681] {logging_mixin.py:112} INFO - [2022-02-18 05:28:08,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:28:09,152] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:28:09,208] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:28:09,218] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:28:09,223] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 05:28:21,935] {scheduler_job.py:155} INFO - Started process (PID=61788) to work on /airflow/dags/download_data.py
[2022-02-18 05:28:21,943] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:28:21,947] {logging_mixin.py:112} INFO - [2022-02-18 05:28:21,946] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:28:22,408] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:28:22,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:28:22,459] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:28:22,463] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 05:28:35,200] {scheduler_job.py:155} INFO - Started process (PID=61814) to work on /airflow/dags/download_data.py
[2022-02-18 05:28:35,208] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:28:35,210] {logging_mixin.py:112} INFO - [2022-02-18 05:28:35,210] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:28:35,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:28:35,769] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:28:35,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:28:35,789] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 05:28:48,514] {scheduler_job.py:155} INFO - Started process (PID=61840) to work on /airflow/dags/download_data.py
[2022-02-18 05:28:48,520] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:28:48,521] {logging_mixin.py:112} INFO - [2022-02-18 05:28:48,521] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:28:49,000] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:28:49,058] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:28:49,068] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:28:49,075] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 05:29:01,759] {scheduler_job.py:155} INFO - Started process (PID=61866) to work on /airflow/dags/download_data.py
[2022-02-18 05:29:01,765] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:29:01,767] {logging_mixin.py:112} INFO - [2022-02-18 05:29:01,766] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:29:02,309] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:29:02,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:29:02,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:29:02,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-18 05:29:15,070] {scheduler_job.py:155} INFO - Started process (PID=61892) to work on /airflow/dags/download_data.py
[2022-02-18 05:29:15,079] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:29:15,082] {logging_mixin.py:112} INFO - [2022-02-18 05:29:15,081] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:29:15,541] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:29:15,597] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:29:15,603] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:29:15,607] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 05:29:28,322] {scheduler_job.py:155} INFO - Started process (PID=61918) to work on /airflow/dags/download_data.py
[2022-02-18 05:29:28,327] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:29:28,330] {logging_mixin.py:112} INFO - [2022-02-18 05:29:28,329] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:29:28,821] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:29:28,874] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:29:28,879] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:29:28,883] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 05:29:41,620] {scheduler_job.py:155} INFO - Started process (PID=61944) to work on /airflow/dags/download_data.py
[2022-02-18 05:29:41,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:29:41,628] {logging_mixin.py:112} INFO - [2022-02-18 05:29:41,628] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:29:42,140] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:29:42,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:29:42,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:29:42,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 05:29:54,889] {scheduler_job.py:155} INFO - Started process (PID=61970) to work on /airflow/dags/download_data.py
[2022-02-18 05:29:54,895] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:29:54,897] {logging_mixin.py:112} INFO - [2022-02-18 05:29:54,896] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:29:55,396] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:29:55,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:29:55,451] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:29:55,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 05:30:08,177] {scheduler_job.py:155} INFO - Started process (PID=61996) to work on /airflow/dags/download_data.py
[2022-02-18 05:30:08,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:30:08,196] {logging_mixin.py:112} INFO - [2022-02-18 05:30:08,195] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:30:08,690] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:30:08,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:30:08,756] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:30:08,760] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 05:30:21,498] {scheduler_job.py:155} INFO - Started process (PID=62022) to work on /airflow/dags/download_data.py
[2022-02-18 05:30:21,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:30:21,523] {logging_mixin.py:112} INFO - [2022-02-18 05:30:21,522] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:30:22,337] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:30:22,391] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:30:22,400] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:30:22,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.907 seconds
[2022-02-18 05:30:34,738] {scheduler_job.py:155} INFO - Started process (PID=62048) to work on /airflow/dags/download_data.py
[2022-02-18 05:30:34,744] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:30:34,746] {logging_mixin.py:112} INFO - [2022-02-18 05:30:34,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:30:35,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:30:35,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:30:35,327] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:30:35,332] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 05:30:48,274] {scheduler_job.py:155} INFO - Started process (PID=62074) to work on /airflow/dags/download_data.py
[2022-02-18 05:30:48,280] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:30:48,283] {logging_mixin.py:112} INFO - [2022-02-18 05:30:48,283] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:30:48,800] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:30:48,854] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:30:48,861] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:30:48,866] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 05:31:01,556] {scheduler_job.py:155} INFO - Started process (PID=62100) to work on /airflow/dags/download_data.py
[2022-02-18 05:31:01,566] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:31:01,568] {logging_mixin.py:112} INFO - [2022-02-18 05:31:01,568] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:31:02,114] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:31:02,178] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:31:02,185] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:31:02,197] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 05:31:14,851] {scheduler_job.py:155} INFO - Started process (PID=62126) to work on /airflow/dags/download_data.py
[2022-02-18 05:31:14,864] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:31:14,870] {logging_mixin.py:112} INFO - [2022-02-18 05:31:14,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:31:15,327] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:31:15,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:31:15,392] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:31:15,395] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 05:31:28,145] {scheduler_job.py:155} INFO - Started process (PID=62152) to work on /airflow/dags/download_data.py
[2022-02-18 05:31:28,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:31:28,153] {logging_mixin.py:112} INFO - [2022-02-18 05:31:28,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:31:28,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:31:28,692] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:31:28,700] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:31:28,704] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 05:31:41,443] {scheduler_job.py:155} INFO - Started process (PID=62178) to work on /airflow/dags/download_data.py
[2022-02-18 05:31:41,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:31:41,454] {logging_mixin.py:112} INFO - [2022-02-18 05:31:41,454] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:31:41,932] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:31:41,972] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:31:41,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:31:41,988] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 05:31:54,693] {scheduler_job.py:155} INFO - Started process (PID=62204) to work on /airflow/dags/download_data.py
[2022-02-18 05:31:54,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:31:54,702] {logging_mixin.py:112} INFO - [2022-02-18 05:31:54,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:31:55,159] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:31:55,211] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:31:55,219] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:31:55,224] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 05:32:07,952] {scheduler_job.py:155} INFO - Started process (PID=62230) to work on /airflow/dags/download_data.py
[2022-02-18 05:32:07,956] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:32:07,958] {logging_mixin.py:112} INFO - [2022-02-18 05:32:07,958] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:32:08,455] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:32:08,513] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:32:08,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:32:08,528] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 05:32:21,265] {scheduler_job.py:155} INFO - Started process (PID=62256) to work on /airflow/dags/download_data.py
[2022-02-18 05:32:21,273] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:32:21,275] {logging_mixin.py:112} INFO - [2022-02-18 05:32:21,275] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:32:21,740] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:32:21,785] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:32:21,792] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:32:21,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 05:32:34,501] {scheduler_job.py:155} INFO - Started process (PID=62282) to work on /airflow/dags/download_data.py
[2022-02-18 05:32:34,506] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:32:34,508] {logging_mixin.py:112} INFO - [2022-02-18 05:32:34,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:32:34,990] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:32:35,036] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:32:35,046] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:32:35,051] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 05:32:47,827] {scheduler_job.py:155} INFO - Started process (PID=62308) to work on /airflow/dags/download_data.py
[2022-02-18 05:32:47,835] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:32:47,837] {logging_mixin.py:112} INFO - [2022-02-18 05:32:47,837] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:32:48,328] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:32:48,377] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:32:48,383] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:32:48,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 05:33:01,060] {scheduler_job.py:155} INFO - Started process (PID=62334) to work on /airflow/dags/download_data.py
[2022-02-18 05:33:01,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:33:01,070] {logging_mixin.py:112} INFO - [2022-02-18 05:33:01,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:33:01,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:33:01,590] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:33:01,599] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:33:01,606] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 05:33:14,356] {scheduler_job.py:155} INFO - Started process (PID=62360) to work on /airflow/dags/download_data.py
[2022-02-18 05:33:14,363] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:33:14,365] {logging_mixin.py:112} INFO - [2022-02-18 05:33:14,365] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:33:14,948] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:33:14,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:33:15,004] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:33:15,011] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-18 05:33:27,637] {scheduler_job.py:155} INFO - Started process (PID=62386) to work on /airflow/dags/download_data.py
[2022-02-18 05:33:27,641] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:33:27,643] {logging_mixin.py:112} INFO - [2022-02-18 05:33:27,643] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:33:28,096] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:33:28,145] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:33:28,151] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:33:28,159] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 05:33:40,907] {scheduler_job.py:155} INFO - Started process (PID=62412) to work on /airflow/dags/download_data.py
[2022-02-18 05:33:40,913] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:33:40,916] {logging_mixin.py:112} INFO - [2022-02-18 05:33:40,915] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:33:41,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:33:41,514] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:33:41,524] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:33:41,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-18 05:33:54,206] {scheduler_job.py:155} INFO - Started process (PID=62438) to work on /airflow/dags/download_data.py
[2022-02-18 05:33:54,211] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:33:54,213] {logging_mixin.py:112} INFO - [2022-02-18 05:33:54,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:33:54,682] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:33:54,737] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:33:54,747] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:33:54,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 05:34:07,509] {scheduler_job.py:155} INFO - Started process (PID=62464) to work on /airflow/dags/download_data.py
[2022-02-18 05:34:07,518] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:34:07,520] {logging_mixin.py:112} INFO - [2022-02-18 05:34:07,520] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:34:08,008] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:34:08,058] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:34:08,071] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:34:08,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 05:34:20,778] {scheduler_job.py:155} INFO - Started process (PID=62490) to work on /airflow/dags/download_data.py
[2022-02-18 05:34:20,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:34:20,785] {logging_mixin.py:112} INFO - [2022-02-18 05:34:20,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:34:21,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:34:21,280] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:34:21,291] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:34:21,296] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 05:34:34,055] {scheduler_job.py:155} INFO - Started process (PID=62516) to work on /airflow/dags/download_data.py
[2022-02-18 05:34:34,070] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:34:34,072] {logging_mixin.py:112} INFO - [2022-02-18 05:34:34,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:34:34,578] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:34:34,626] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:34:34,634] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:34:34,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 05:34:47,341] {scheduler_job.py:155} INFO - Started process (PID=62542) to work on /airflow/dags/download_data.py
[2022-02-18 05:34:47,349] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:34:47,355] {logging_mixin.py:112} INFO - [2022-02-18 05:34:47,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:34:47,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:34:47,873] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:34:47,880] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:34:47,884] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 05:35:00,878] {scheduler_job.py:155} INFO - Started process (PID=62568) to work on /airflow/dags/download_data.py
[2022-02-18 05:35:00,889] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:35:00,892] {logging_mixin.py:112} INFO - [2022-02-18 05:35:00,892] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:35:01,437] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:35:01,490] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:35:01,501] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:35:01,506] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-18 05:35:14,103] {scheduler_job.py:155} INFO - Started process (PID=62594) to work on /airflow/dags/download_data.py
[2022-02-18 05:35:14,109] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:35:14,110] {logging_mixin.py:112} INFO - [2022-02-18 05:35:14,110] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:35:14,595] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:35:14,651] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:35:14,661] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:35:14,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 05:35:27,372] {scheduler_job.py:155} INFO - Started process (PID=62620) to work on /airflow/dags/download_data.py
[2022-02-18 05:35:27,376] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:35:27,379] {logging_mixin.py:112} INFO - [2022-02-18 05:35:27,378] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:35:27,846] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:35:27,887] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:35:27,894] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:35:27,899] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 05:35:40,630] {scheduler_job.py:155} INFO - Started process (PID=62646) to work on /airflow/dags/download_data.py
[2022-02-18 05:35:40,635] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:35:40,637] {logging_mixin.py:112} INFO - [2022-02-18 05:35:40,637] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:35:41,098] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:35:41,150] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:35:41,161] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:35:41,167] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 05:35:53,920] {scheduler_job.py:155} INFO - Started process (PID=62672) to work on /airflow/dags/download_data.py
[2022-02-18 05:35:53,924] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:35:53,926] {logging_mixin.py:112} INFO - [2022-02-18 05:35:53,926] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:35:54,432] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:35:54,482] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:35:54,491] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:35:54,498] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 05:36:07,188] {scheduler_job.py:155} INFO - Started process (PID=62698) to work on /airflow/dags/download_data.py
[2022-02-18 05:36:07,200] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:36:07,203] {logging_mixin.py:112} INFO - [2022-02-18 05:36:07,203] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:36:07,667] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:36:07,713] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:36:07,726] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:36:07,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 05:36:20,516] {scheduler_job.py:155} INFO - Started process (PID=62724) to work on /airflow/dags/download_data.py
[2022-02-18 05:36:20,523] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:36:20,526] {logging_mixin.py:112} INFO - [2022-02-18 05:36:20,525] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:36:20,956] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:36:21,008] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:36:21,018] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:36:21,024] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 05:36:33,756] {scheduler_job.py:155} INFO - Started process (PID=62750) to work on /airflow/dags/download_data.py
[2022-02-18 05:36:33,770] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:36:33,773] {logging_mixin.py:112} INFO - [2022-02-18 05:36:33,773] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:36:34,277] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:36:34,331] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:36:34,339] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:36:34,344] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 05:36:47,019] {scheduler_job.py:155} INFO - Started process (PID=62776) to work on /airflow/dags/download_data.py
[2022-02-18 05:36:47,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:36:47,025] {logging_mixin.py:112} INFO - [2022-02-18 05:36:47,024] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:36:47,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:36:47,518] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:36:47,525] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:36:47,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 05:37:00,272] {scheduler_job.py:155} INFO - Started process (PID=62802) to work on /airflow/dags/download_data.py
[2022-02-18 05:37:00,277] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:37:00,280] {logging_mixin.py:112} INFO - [2022-02-18 05:37:00,280] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:37:00,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:37:00,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:37:00,795] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:37:00,799] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 05:37:13,538] {scheduler_job.py:155} INFO - Started process (PID=62828) to work on /airflow/dags/download_data.py
[2022-02-18 05:37:13,546] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:37:13,549] {logging_mixin.py:112} INFO - [2022-02-18 05:37:13,548] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:37:13,974] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:37:14,026] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:37:14,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:37:14,038] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 05:37:26,828] {scheduler_job.py:155} INFO - Started process (PID=62854) to work on /airflow/dags/download_data.py
[2022-02-18 05:37:26,832] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:37:26,834] {logging_mixin.py:112} INFO - [2022-02-18 05:37:26,833] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:37:27,312] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:37:27,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:37:27,385] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:37:27,394] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 05:37:40,262] {scheduler_job.py:155} INFO - Started process (PID=62880) to work on /airflow/dags/download_data.py
[2022-02-18 05:37:40,270] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:37:40,273] {logging_mixin.py:112} INFO - [2022-02-18 05:37:40,273] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:37:40,745] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:37:40,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:37:40,812] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:37:40,819] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 05:37:54,592] {scheduler_job.py:155} INFO - Started process (PID=62906) to work on /airflow/dags/download_data.py
[2022-02-18 05:37:54,606] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:37:54,609] {logging_mixin.py:112} INFO - [2022-02-18 05:37:54,608] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:37:55,117] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:37:55,168] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:37:55,180] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:37:55,188] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 05:58:17,785] {scheduler_job.py:155} INFO - Started process (PID=62932) to work on /airflow/dags/download_data.py
[2022-02-18 05:58:17,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:58:17,793] {logging_mixin.py:112} INFO - [2022-02-18 05:58:17,792] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:58:18,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:58:18,336] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:58:18,343] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:58:18,347] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 05:58:31,116] {scheduler_job.py:155} INFO - Started process (PID=62958) to work on /airflow/dags/download_data.py
[2022-02-18 05:58:31,130] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:58:31,133] {logging_mixin.py:112} INFO - [2022-02-18 05:58:31,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:58:31,623] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:58:31,666] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:58:31,672] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:58:31,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 05:58:44,799] {scheduler_job.py:155} INFO - Started process (PID=62984) to work on /airflow/dags/download_data.py
[2022-02-18 05:58:44,827] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:58:44,829] {logging_mixin.py:112} INFO - [2022-02-18 05:58:44,828] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:58:45,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:58:45,416] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:58:45,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:58:45,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-18 05:58:58,141] {scheduler_job.py:155} INFO - Started process (PID=63010) to work on /airflow/dags/download_data.py
[2022-02-18 05:58:58,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:58:58,150] {logging_mixin.py:112} INFO - [2022-02-18 05:58:58,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:58:58,625] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:58:58,668] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:58:58,678] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:58:58,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 05:59:11,429] {scheduler_job.py:155} INFO - Started process (PID=63036) to work on /airflow/dags/download_data.py
[2022-02-18 05:59:11,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:59:11,438] {logging_mixin.py:112} INFO - [2022-02-18 05:59:11,437] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:59:11,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:59:11,993] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:59:12,001] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:59:12,006] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 05:59:24,729] {scheduler_job.py:155} INFO - Started process (PID=63062) to work on /airflow/dags/download_data.py
[2022-02-18 05:59:24,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:59:24,744] {logging_mixin.py:112} INFO - [2022-02-18 05:59:24,744] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:59:25,211] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:59:25,269] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:59:25,278] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:59:25,285] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 05:59:38,021] {scheduler_job.py:155} INFO - Started process (PID=63088) to work on /airflow/dags/download_data.py
[2022-02-18 05:59:38,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:59:38,029] {logging_mixin.py:112} INFO - [2022-02-18 05:59:38,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:59:38,524] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:59:38,568] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:59:38,575] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:59:38,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 05:59:51,295] {scheduler_job.py:155} INFO - Started process (PID=63114) to work on /airflow/dags/download_data.py
[2022-02-18 05:59:51,301] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 05:59:51,303] {logging_mixin.py:112} INFO - [2022-02-18 05:59:51,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 05:59:51,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 05:59:51,887] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 05:59:51,903] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 05:59:51,911] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-18 06:00:04,627] {scheduler_job.py:155} INFO - Started process (PID=63140) to work on /airflow/dags/download_data.py
[2022-02-18 06:00:04,636] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:00:04,639] {logging_mixin.py:112} INFO - [2022-02-18 06:00:04,638] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:00:05,142] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:00:05,186] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:00:05,194] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:00:05,200] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-18 06:00:17,876] {scheduler_job.py:155} INFO - Started process (PID=63166) to work on /airflow/dags/download_data.py
[2022-02-18 06:00:17,882] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:00:17,885] {logging_mixin.py:112} INFO - [2022-02-18 06:00:17,885] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:00:18,399] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:00:18,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:00:18,462] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:00:18,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 06:00:31,173] {scheduler_job.py:155} INFO - Started process (PID=63192) to work on /airflow/dags/download_data.py
[2022-02-18 06:00:31,180] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:00:31,181] {logging_mixin.py:112} INFO - [2022-02-18 06:00:31,181] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:00:31,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:00:31,771] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:00:31,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:00:31,789] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.620 seconds
[2022-02-18 06:00:44,474] {scheduler_job.py:155} INFO - Started process (PID=63218) to work on /airflow/dags/download_data.py
[2022-02-18 06:00:44,480] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:00:44,482] {logging_mixin.py:112} INFO - [2022-02-18 06:00:44,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:00:45,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:00:45,158] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:00:45,176] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:00:45,181] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.707 seconds
[2022-02-18 06:00:57,802] {scheduler_job.py:155} INFO - Started process (PID=63244) to work on /airflow/dags/download_data.py
[2022-02-18 06:00:57,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:00:57,811] {logging_mixin.py:112} INFO - [2022-02-18 06:00:57,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:00:58,303] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:00:58,451] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:00:58,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:00:58,467] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.665 seconds
[2022-02-18 06:01:11,053] {scheduler_job.py:155} INFO - Started process (PID=63270) to work on /airflow/dags/download_data.py
[2022-02-18 06:01:11,058] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:01:11,060] {logging_mixin.py:112} INFO - [2022-02-18 06:01:11,059] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:01:11,556] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:01:11,604] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:01:11,638] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:01:11,648] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 06:01:24,367] {scheduler_job.py:155} INFO - Started process (PID=63296) to work on /airflow/dags/download_data.py
[2022-02-18 06:01:24,381] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:01:24,384] {logging_mixin.py:112} INFO - [2022-02-18 06:01:24,383] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:01:24,981] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:01:25,024] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:01:25,030] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:01:25,037] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.670 seconds
[2022-02-18 06:01:37,710] {scheduler_job.py:155} INFO - Started process (PID=63322) to work on /airflow/dags/download_data.py
[2022-02-18 06:01:37,719] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:01:37,724] {logging_mixin.py:112} INFO - [2022-02-18 06:01:37,724] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:01:38,220] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:01:38,279] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:01:38,300] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:01:38,304] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 06:01:50,950] {scheduler_job.py:155} INFO - Started process (PID=63348) to work on /airflow/dags/download_data.py
[2022-02-18 06:01:50,957] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:01:50,961] {logging_mixin.py:112} INFO - [2022-02-18 06:01:50,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:01:51,448] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:01:51,502] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:01:51,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:01:51,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 06:02:04,322] {scheduler_job.py:155} INFO - Started process (PID=63374) to work on /airflow/dags/download_data.py
[2022-02-18 06:02:04,329] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:02:04,332] {logging_mixin.py:112} INFO - [2022-02-18 06:02:04,331] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:02:04,916] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:02:04,970] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:02:04,977] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:02:04,982] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.660 seconds
[2022-02-18 06:02:17,621] {scheduler_job.py:155} INFO - Started process (PID=63400) to work on /airflow/dags/download_data.py
[2022-02-18 06:02:17,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:02:17,628] {logging_mixin.py:112} INFO - [2022-02-18 06:02:17,627] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:02:18,170] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:02:18,228] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:02:18,234] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:02:18,239] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-18 06:02:30,922] {scheduler_job.py:155} INFO - Started process (PID=63426) to work on /airflow/dags/download_data.py
[2022-02-18 06:02:30,927] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:02:30,929] {logging_mixin.py:112} INFO - [2022-02-18 06:02:30,929] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:02:31,545] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:02:31,605] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:02:31,612] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:02:31,617] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.695 seconds
[2022-02-18 06:02:44,231] {scheduler_job.py:155} INFO - Started process (PID=63452) to work on /airflow/dags/download_data.py
[2022-02-18 06:02:44,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:02:44,237] {logging_mixin.py:112} INFO - [2022-02-18 06:02:44,237] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:02:44,716] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:02:44,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:02:44,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:02:44,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 06:02:57,553] {scheduler_job.py:155} INFO - Started process (PID=63478) to work on /airflow/dags/download_data.py
[2022-02-18 06:02:57,560] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:02:57,562] {logging_mixin.py:112} INFO - [2022-02-18 06:02:57,562] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:02:58,108] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:02:58,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:02:58,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:02:58,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-18 06:03:11,061] {scheduler_job.py:155} INFO - Started process (PID=63504) to work on /airflow/dags/download_data.py
[2022-02-18 06:03:11,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:03:11,071] {logging_mixin.py:112} INFO - [2022-02-18 06:03:11,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:03:11,804] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:03:11,875] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:03:11,890] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:03:11,897] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.835 seconds
[2022-02-18 06:03:24,366] {scheduler_job.py:155} INFO - Started process (PID=63530) to work on /airflow/dags/download_data.py
[2022-02-18 06:03:24,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:03:24,375] {logging_mixin.py:112} INFO - [2022-02-18 06:03:24,375] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:03:24,970] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:03:25,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:03:25,026] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:03:25,032] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-18 06:03:37,696] {scheduler_job.py:155} INFO - Started process (PID=63556) to work on /airflow/dags/download_data.py
[2022-02-18 06:03:37,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:03:37,709] {logging_mixin.py:112} INFO - [2022-02-18 06:03:37,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:03:38,294] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:03:38,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:03:38,362] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:03:38,368] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.673 seconds
[2022-02-18 06:03:50,992] {scheduler_job.py:155} INFO - Started process (PID=63582) to work on /airflow/dags/download_data.py
[2022-02-18 06:03:51,003] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:03:51,006] {logging_mixin.py:112} INFO - [2022-02-18 06:03:51,005] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:03:51,477] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:03:51,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:03:51,545] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:03:51,552] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 06:04:04,298] {scheduler_job.py:155} INFO - Started process (PID=63608) to work on /airflow/dags/download_data.py
[2022-02-18 06:04:04,304] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:04:04,305] {logging_mixin.py:112} INFO - [2022-02-18 06:04:04,305] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:04:04,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:04:04,885] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:04:04,896] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:04:04,901] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 06:04:17,542] {scheduler_job.py:155} INFO - Started process (PID=63634) to work on /airflow/dags/download_data.py
[2022-02-18 06:04:17,548] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:04:17,551] {logging_mixin.py:112} INFO - [2022-02-18 06:04:17,550] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:04:18,116] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:04:18,168] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:04:18,179] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:04:18,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-18 06:04:30,863] {scheduler_job.py:155} INFO - Started process (PID=63660) to work on /airflow/dags/download_data.py
[2022-02-18 06:04:30,870] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:04:30,872] {logging_mixin.py:112} INFO - [2022-02-18 06:04:30,871] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:04:31,412] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:04:31,466] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:04:31,473] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:04:31,479] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-18 06:04:44,107] {scheduler_job.py:155} INFO - Started process (PID=63686) to work on /airflow/dags/download_data.py
[2022-02-18 06:04:44,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:04:44,115] {logging_mixin.py:112} INFO - [2022-02-18 06:04:44,115] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:04:44,685] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:04:44,732] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:04:44,743] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:04:44,748] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 06:04:57,453] {scheduler_job.py:155} INFO - Started process (PID=63712) to work on /airflow/dags/download_data.py
[2022-02-18 06:04:57,466] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:04:57,469] {logging_mixin.py:112} INFO - [2022-02-18 06:04:57,468] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:04:57,949] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:04:57,998] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:04:58,008] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:04:58,014] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 06:05:10,740] {scheduler_job.py:155} INFO - Started process (PID=63738) to work on /airflow/dags/download_data.py
[2022-02-18 06:05:10,750] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:05:10,752] {logging_mixin.py:112} INFO - [2022-02-18 06:05:10,752] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:05:11,216] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:05:11,261] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:05:11,270] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:05:11,274] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 06:05:24,048] {scheduler_job.py:155} INFO - Started process (PID=63764) to work on /airflow/dags/download_data.py
[2022-02-18 06:05:24,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:05:24,057] {logging_mixin.py:112} INFO - [2022-02-18 06:05:24,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:05:24,570] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:05:24,620] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:05:24,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:05:24,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 06:05:37,340] {scheduler_job.py:155} INFO - Started process (PID=63790) to work on /airflow/dags/download_data.py
[2022-02-18 06:05:37,346] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:05:37,347] {logging_mixin.py:112} INFO - [2022-02-18 06:05:37,347] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:05:37,845] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:05:37,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:05:37,905] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:05:37,911] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 06:05:49,583] {scheduler_job.py:155} INFO - Started process (PID=63815) to work on /airflow/dags/download_data.py
[2022-02-18 06:05:49,592] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:05:49,594] {logging_mixin.py:112} INFO - [2022-02-18 06:05:49,594] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:05:50,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:05:50,093] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:05:50,102] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:05:50,108] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 06:06:02,890] {scheduler_job.py:155} INFO - Started process (PID=63841) to work on /airflow/dags/download_data.py
[2022-02-18 06:06:02,897] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:06:02,900] {logging_mixin.py:112} INFO - [2022-02-18 06:06:02,899] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:06:03,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:06:03,390] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:06:03,396] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:06:03,400] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 06:06:16,119] {scheduler_job.py:155} INFO - Started process (PID=63867) to work on /airflow/dags/download_data.py
[2022-02-18 06:06:16,128] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:06:16,131] {logging_mixin.py:112} INFO - [2022-02-18 06:06:16,131] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:06:16,594] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:06:16,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:06:16,675] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:06:16,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 06:06:29,431] {scheduler_job.py:155} INFO - Started process (PID=63893) to work on /airflow/dags/download_data.py
[2022-02-18 06:06:29,443] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:06:29,447] {logging_mixin.py:112} INFO - [2022-02-18 06:06:29,447] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:06:29,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:06:29,931] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:06:29,939] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:06:29,944] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 06:06:42,697] {scheduler_job.py:155} INFO - Started process (PID=63919) to work on /airflow/dags/download_data.py
[2022-02-18 06:06:42,702] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:06:42,704] {logging_mixin.py:112} INFO - [2022-02-18 06:06:42,704] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:06:43,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:06:43,246] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:06:43,256] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:06:43,262] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 06:06:56,014] {scheduler_job.py:155} INFO - Started process (PID=63945) to work on /airflow/dags/download_data.py
[2022-02-18 06:06:56,028] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:06:56,032] {logging_mixin.py:112} INFO - [2022-02-18 06:06:56,031] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:06:56,591] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:06:56,645] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:06:56,652] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:06:56,658] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-18 06:07:09,270] {scheduler_job.py:155} INFO - Started process (PID=63971) to work on /airflow/dags/download_data.py
[2022-02-18 06:07:09,274] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:07:09,275] {logging_mixin.py:112} INFO - [2022-02-18 06:07:09,275] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:07:09,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:07:09,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:07:09,796] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:07:09,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 06:07:22,524] {scheduler_job.py:155} INFO - Started process (PID=63997) to work on /airflow/dags/download_data.py
[2022-02-18 06:07:22,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:07:22,529] {logging_mixin.py:112} INFO - [2022-02-18 06:07:22,529] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:07:23,023] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:07:23,067] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:07:23,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:07:23,080] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 06:07:35,817] {scheduler_job.py:155} INFO - Started process (PID=64023) to work on /airflow/dags/download_data.py
[2022-02-18 06:07:35,826] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:07:35,829] {logging_mixin.py:112} INFO - [2022-02-18 06:07:35,828] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:07:36,312] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:07:36,358] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:07:36,368] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:07:36,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 06:07:49,071] {scheduler_job.py:155} INFO - Started process (PID=64049) to work on /airflow/dags/download_data.py
[2022-02-18 06:07:49,078] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:07:49,081] {logging_mixin.py:112} INFO - [2022-02-18 06:07:49,081] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:07:49,595] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:07:49,640] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:07:49,647] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:07:49,650] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 06:08:02,345] {scheduler_job.py:155} INFO - Started process (PID=64075) to work on /airflow/dags/download_data.py
[2022-02-18 06:08:02,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:08:02,353] {logging_mixin.py:112} INFO - [2022-02-18 06:08:02,352] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:08:02,816] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:08:02,859] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:08:02,872] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:08:02,879] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 06:08:15,712] {scheduler_job.py:155} INFO - Started process (PID=64101) to work on /airflow/dags/download_data.py
[2022-02-18 06:08:15,725] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:08:15,728] {logging_mixin.py:112} INFO - [2022-02-18 06:08:15,727] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:08:16,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:08:16,267] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:08:16,279] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:08:16,288] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 06:08:28,971] {scheduler_job.py:155} INFO - Started process (PID=64127) to work on /airflow/dags/download_data.py
[2022-02-18 06:08:28,977] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:08:28,979] {logging_mixin.py:112} INFO - [2022-02-18 06:08:28,979] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:08:29,448] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:08:29,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:08:29,511] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:08:29,516] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 06:08:42,214] {scheduler_job.py:155} INFO - Started process (PID=64153) to work on /airflow/dags/download_data.py
[2022-02-18 06:08:42,222] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:08:42,224] {logging_mixin.py:112} INFO - [2022-02-18 06:08:42,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:08:42,723] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:08:42,782] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:08:42,791] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:08:42,796] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 06:08:55,515] {scheduler_job.py:155} INFO - Started process (PID=64179) to work on /airflow/dags/download_data.py
[2022-02-18 06:08:55,520] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:08:55,521] {logging_mixin.py:112} INFO - [2022-02-18 06:08:55,521] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:08:56,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:08:56,053] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:08:56,062] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:08:56,068] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 06:09:08,793] {scheduler_job.py:155} INFO - Started process (PID=64205) to work on /airflow/dags/download_data.py
[2022-02-18 06:09:08,797] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:09:08,799] {logging_mixin.py:112} INFO - [2022-02-18 06:09:08,799] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:09:09,252] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:09:09,302] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:09:09,307] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:09:09,311] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 06:09:22,019] {scheduler_job.py:155} INFO - Started process (PID=64231) to work on /airflow/dags/download_data.py
[2022-02-18 06:09:22,025] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:09:22,026] {logging_mixin.py:112} INFO - [2022-02-18 06:09:22,026] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:09:22,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:09:22,565] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:09:22,573] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:09:22,580] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 06:09:35,316] {scheduler_job.py:155} INFO - Started process (PID=64257) to work on /airflow/dags/download_data.py
[2022-02-18 06:09:35,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:09:35,326] {logging_mixin.py:112} INFO - [2022-02-18 06:09:35,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:09:35,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:09:35,820] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:09:35,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:09:35,832] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 06:09:48,583] {scheduler_job.py:155} INFO - Started process (PID=64283) to work on /airflow/dags/download_data.py
[2022-02-18 06:09:48,592] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:09:48,596] {logging_mixin.py:112} INFO - [2022-02-18 06:09:48,596] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:09:49,072] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:09:49,119] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:09:49,128] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:09:49,138] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 06:10:01,846] {scheduler_job.py:155} INFO - Started process (PID=64309) to work on /airflow/dags/download_data.py
[2022-02-18 06:10:01,850] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:10:01,852] {logging_mixin.py:112} INFO - [2022-02-18 06:10:01,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:10:02,321] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:10:02,372] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:10:02,384] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:10:02,390] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 06:10:15,074] {scheduler_job.py:155} INFO - Started process (PID=64335) to work on /airflow/dags/download_data.py
[2022-02-18 06:10:15,080] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:10:15,082] {logging_mixin.py:112} INFO - [2022-02-18 06:10:15,082] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:10:15,594] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:10:15,637] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:10:15,644] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:10:15,648] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-18 06:10:28,387] {scheduler_job.py:155} INFO - Started process (PID=64361) to work on /airflow/dags/download_data.py
[2022-02-18 06:10:28,393] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:10:28,394] {logging_mixin.py:112} INFO - [2022-02-18 06:10:28,394] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:10:28,884] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:10:28,936] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:10:28,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:10:28,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 06:10:41,642] {scheduler_job.py:155} INFO - Started process (PID=64387) to work on /airflow/dags/download_data.py
[2022-02-18 06:10:41,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:10:41,654] {logging_mixin.py:112} INFO - [2022-02-18 06:10:41,654] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:10:42,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:10:42,185] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:10:42,198] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:10:42,202] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 06:10:54,927] {scheduler_job.py:155} INFO - Started process (PID=64413) to work on /airflow/dags/download_data.py
[2022-02-18 06:10:54,936] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:10:54,939] {logging_mixin.py:112} INFO - [2022-02-18 06:10:54,938] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:10:55,417] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:10:55,469] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:10:55,479] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:10:55,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 06:11:08,257] {scheduler_job.py:155} INFO - Started process (PID=64439) to work on /airflow/dags/download_data.py
[2022-02-18 06:11:08,267] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:11:08,269] {logging_mixin.py:112} INFO - [2022-02-18 06:11:08,268] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:11:08,852] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:11:08,903] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:11:08,913] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:11:08,917] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.660 seconds
[2022-02-18 06:11:21,491] {scheduler_job.py:155} INFO - Started process (PID=64465) to work on /airflow/dags/download_data.py
[2022-02-18 06:11:21,496] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:11:21,499] {logging_mixin.py:112} INFO - [2022-02-18 06:11:21,498] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:11:22,016] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:11:22,060] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:11:22,068] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:11:22,074] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 06:11:34,786] {scheduler_job.py:155} INFO - Started process (PID=64491) to work on /airflow/dags/download_data.py
[2022-02-18 06:11:34,797] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:11:34,800] {logging_mixin.py:112} INFO - [2022-02-18 06:11:34,799] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:11:35,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:11:35,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:11:35,312] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:11:35,316] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 06:11:48,018] {scheduler_job.py:155} INFO - Started process (PID=64517) to work on /airflow/dags/download_data.py
[2022-02-18 06:11:48,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:11:48,030] {logging_mixin.py:112} INFO - [2022-02-18 06:11:48,029] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:11:48,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:11:48,583] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:11:48,593] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:11:48,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 06:12:01,295] {scheduler_job.py:155} INFO - Started process (PID=64543) to work on /airflow/dags/download_data.py
[2022-02-18 06:12:01,303] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:12:01,307] {logging_mixin.py:112} INFO - [2022-02-18 06:12:01,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:12:01,815] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:12:01,872] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:12:01,885] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:12:01,891] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 06:12:14,559] {scheduler_job.py:155} INFO - Started process (PID=64569) to work on /airflow/dags/download_data.py
[2022-02-18 06:12:14,565] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:12:14,567] {logging_mixin.py:112} INFO - [2022-02-18 06:12:14,566] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:12:15,053] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:12:15,114] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:12:15,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:12:15,134] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 06:12:27,853] {scheduler_job.py:155} INFO - Started process (PID=64595) to work on /airflow/dags/download_data.py
[2022-02-18 06:12:27,866] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:12:27,869] {logging_mixin.py:112} INFO - [2022-02-18 06:12:27,868] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:12:28,335] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:12:28,395] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:12:28,407] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:12:28,412] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 06:12:41,130] {scheduler_job.py:155} INFO - Started process (PID=64621) to work on /airflow/dags/download_data.py
[2022-02-18 06:12:41,135] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:12:41,136] {logging_mixin.py:112} INFO - [2022-02-18 06:12:41,136] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:12:41,633] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:12:41,689] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:12:41,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:12:41,711] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 06:12:54,420] {scheduler_job.py:155} INFO - Started process (PID=64647) to work on /airflow/dags/download_data.py
[2022-02-18 06:12:54,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:12:54,432] {logging_mixin.py:112} INFO - [2022-02-18 06:12:54,432] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:12:54,945] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:12:55,001] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:12:55,009] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:12:55,014] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 06:13:07,698] {scheduler_job.py:155} INFO - Started process (PID=64673) to work on /airflow/dags/download_data.py
[2022-02-18 06:13:07,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:13:07,711] {logging_mixin.py:112} INFO - [2022-02-18 06:13:07,710] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:13:08,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:13:08,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:13:08,230] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:13:08,234] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 06:13:20,988] {scheduler_job.py:155} INFO - Started process (PID=64699) to work on /airflow/dags/download_data.py
[2022-02-18 06:13:20,995] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:13:20,997] {logging_mixin.py:112} INFO - [2022-02-18 06:13:20,997] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:13:21,485] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:13:21,527] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:13:21,535] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:13:21,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 06:13:34,301] {scheduler_job.py:155} INFO - Started process (PID=64725) to work on /airflow/dags/download_data.py
[2022-02-18 06:13:34,305] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:13:34,307] {logging_mixin.py:112} INFO - [2022-02-18 06:13:34,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:13:34,822] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:13:34,884] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:13:34,892] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:13:34,896] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 06:13:47,557] {scheduler_job.py:155} INFO - Started process (PID=64751) to work on /airflow/dags/download_data.py
[2022-02-18 06:13:47,561] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:13:47,563] {logging_mixin.py:112} INFO - [2022-02-18 06:13:47,563] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:13:48,039] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:13:48,092] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:13:48,104] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:13:48,111] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 06:14:00,851] {scheduler_job.py:155} INFO - Started process (PID=64777) to work on /airflow/dags/download_data.py
[2022-02-18 06:14:00,855] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:14:00,856] {logging_mixin.py:112} INFO - [2022-02-18 06:14:00,856] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:14:01,325] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:14:01,372] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:14:01,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:14:01,389] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 06:14:14,094] {scheduler_job.py:155} INFO - Started process (PID=64803) to work on /airflow/dags/download_data.py
[2022-02-18 06:14:14,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:14:14,101] {logging_mixin.py:112} INFO - [2022-02-18 06:14:14,101] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:14:14,593] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:14:14,662] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:14:14,672] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:14:14,678] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 06:14:27,381] {scheduler_job.py:155} INFO - Started process (PID=64829) to work on /airflow/dags/download_data.py
[2022-02-18 06:14:27,386] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:14:27,391] {logging_mixin.py:112} INFO - [2022-02-18 06:14:27,391] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:14:27,896] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:14:27,952] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:14:27,961] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:14:27,967] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 06:14:40,629] {scheduler_job.py:155} INFO - Started process (PID=64855) to work on /airflow/dags/download_data.py
[2022-02-18 06:14:40,639] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:14:40,640] {logging_mixin.py:112} INFO - [2022-02-18 06:14:40,640] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:14:41,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:14:41,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:14:41,468] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:14:41,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.863 seconds
[2022-02-18 06:14:53,917] {scheduler_job.py:155} INFO - Started process (PID=64881) to work on /airflow/dags/download_data.py
[2022-02-18 06:14:53,922] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:14:53,924] {logging_mixin.py:112} INFO - [2022-02-18 06:14:53,924] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:14:54,454] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:14:54,500] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:14:54,512] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:14:54,517] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 06:15:07,230] {scheduler_job.py:155} INFO - Started process (PID=64907) to work on /airflow/dags/download_data.py
[2022-02-18 06:15:07,236] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:15:07,238] {logging_mixin.py:112} INFO - [2022-02-18 06:15:07,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:15:07,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:15:07,758] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:15:07,767] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:15:07,777] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 06:15:20,482] {scheduler_job.py:155} INFO - Started process (PID=64933) to work on /airflow/dags/download_data.py
[2022-02-18 06:15:20,492] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:15:20,495] {logging_mixin.py:112} INFO - [2022-02-18 06:15:20,494] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:15:20,971] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:15:21,021] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:15:21,031] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:15:21,038] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 06:15:33,767] {scheduler_job.py:155} INFO - Started process (PID=64959) to work on /airflow/dags/download_data.py
[2022-02-18 06:15:33,772] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:15:33,774] {logging_mixin.py:112} INFO - [2022-02-18 06:15:33,774] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:15:34,248] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:15:34,293] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:15:34,299] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:15:34,303] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 06:15:47,601] {scheduler_job.py:155} INFO - Started process (PID=64985) to work on /airflow/dags/download_data.py
[2022-02-18 06:15:47,606] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:15:47,608] {logging_mixin.py:112} INFO - [2022-02-18 06:15:47,608] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:15:48,107] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:15:48,171] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:15:48,183] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:15:48,188] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 06:16:00,869] {scheduler_job.py:155} INFO - Started process (PID=65011) to work on /airflow/dags/download_data.py
[2022-02-18 06:16:00,873] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:16:00,875] {logging_mixin.py:112} INFO - [2022-02-18 06:16:00,875] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:16:01,401] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:16:01,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:16:01,459] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:16:01,464] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 06:16:14,149] {scheduler_job.py:155} INFO - Started process (PID=65037) to work on /airflow/dags/download_data.py
[2022-02-18 06:16:14,157] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:16:14,159] {logging_mixin.py:112} INFO - [2022-02-18 06:16:14,159] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:16:14,729] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:16:14,781] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:16:14,793] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:16:14,797] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-18 06:16:27,438] {scheduler_job.py:155} INFO - Started process (PID=65063) to work on /airflow/dags/download_data.py
[2022-02-18 06:16:27,448] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:16:27,450] {logging_mixin.py:112} INFO - [2022-02-18 06:16:27,449] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:16:27,915] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:16:27,962] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:16:27,971] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:16:27,977] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 06:16:40,686] {scheduler_job.py:155} INFO - Started process (PID=65089) to work on /airflow/dags/download_data.py
[2022-02-18 06:16:40,693] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:16:40,695] {logging_mixin.py:112} INFO - [2022-02-18 06:16:40,695] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:16:41,174] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:16:41,233] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:16:41,240] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:16:41,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 06:16:53,952] {scheduler_job.py:155} INFO - Started process (PID=65115) to work on /airflow/dags/download_data.py
[2022-02-18 06:16:53,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:16:53,963] {logging_mixin.py:112} INFO - [2022-02-18 06:16:53,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:16:54,710] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:16:54,764] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:16:54,771] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:16:54,777] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.825 seconds
[2022-02-18 06:17:07,224] {scheduler_job.py:155} INFO - Started process (PID=65141) to work on /airflow/dags/download_data.py
[2022-02-18 06:17:07,229] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:17:07,230] {logging_mixin.py:112} INFO - [2022-02-18 06:17:07,230] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:17:07,721] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:17:07,778] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:17:07,790] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:17:07,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 06:17:20,472] {scheduler_job.py:155} INFO - Started process (PID=65167) to work on /airflow/dags/download_data.py
[2022-02-18 06:17:20,477] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:17:20,479] {logging_mixin.py:112} INFO - [2022-02-18 06:17:20,478] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:17:20,919] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:17:20,970] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:17:20,980] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:17:20,987] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 06:17:33,761] {scheduler_job.py:155} INFO - Started process (PID=65193) to work on /airflow/dags/download_data.py
[2022-02-18 06:17:33,766] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:17:33,770] {logging_mixin.py:112} INFO - [2022-02-18 06:17:33,769] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:17:34,267] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:17:34,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:17:34,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:17:34,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 06:17:47,249] {scheduler_job.py:155} INFO - Started process (PID=65219) to work on /airflow/dags/download_data.py
[2022-02-18 06:17:47,260] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:17:47,265] {logging_mixin.py:112} INFO - [2022-02-18 06:17:47,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:17:47,777] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:17:47,831] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:17:47,840] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:17:47,844] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 06:18:00,654] {scheduler_job.py:155} INFO - Started process (PID=65245) to work on /airflow/dags/download_data.py
[2022-02-18 06:18:00,659] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:18:00,663] {logging_mixin.py:112} INFO - [2022-02-18 06:18:00,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:18:01,164] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:18:01,222] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:18:01,230] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:18:01,235] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 06:18:13,931] {scheduler_job.py:155} INFO - Started process (PID=65271) to work on /airflow/dags/download_data.py
[2022-02-18 06:18:13,937] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:18:13,939] {logging_mixin.py:112} INFO - [2022-02-18 06:18:13,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:18:14,436] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:18:14,483] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:18:14,492] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:18:14,496] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 06:18:27,225] {scheduler_job.py:155} INFO - Started process (PID=65297) to work on /airflow/dags/download_data.py
[2022-02-18 06:18:27,234] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:18:27,237] {logging_mixin.py:112} INFO - [2022-02-18 06:18:27,236] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:18:27,674] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:18:27,722] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:18:27,728] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:18:27,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 06:18:40,481] {scheduler_job.py:155} INFO - Started process (PID=65323) to work on /airflow/dags/download_data.py
[2022-02-18 06:18:40,497] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:18:40,503] {logging_mixin.py:112} INFO - [2022-02-18 06:18:40,499] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:18:40,963] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:18:41,024] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:18:41,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:18:41,041] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 06:18:53,755] {scheduler_job.py:155} INFO - Started process (PID=65349) to work on /airflow/dags/download_data.py
[2022-02-18 06:18:53,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:18:53,764] {logging_mixin.py:112} INFO - [2022-02-18 06:18:53,763] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:18:54,244] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:18:54,289] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:18:54,299] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:18:54,303] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 06:19:07,067] {scheduler_job.py:155} INFO - Started process (PID=65375) to work on /airflow/dags/download_data.py
[2022-02-18 06:19:07,073] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:19:07,075] {logging_mixin.py:112} INFO - [2022-02-18 06:19:07,075] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:19:07,529] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:19:07,582] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:19:07,590] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:19:07,595] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 06:19:20,303] {scheduler_job.py:155} INFO - Started process (PID=65401) to work on /airflow/dags/download_data.py
[2022-02-18 06:19:20,310] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:19:20,312] {logging_mixin.py:112} INFO - [2022-02-18 06:19:20,312] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:19:20,738] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:19:20,782] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:19:20,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:19:20,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-18 06:19:33,574] {scheduler_job.py:155} INFO - Started process (PID=65427) to work on /airflow/dags/download_data.py
[2022-02-18 06:19:33,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:19:33,580] {logging_mixin.py:112} INFO - [2022-02-18 06:19:33,580] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:19:34,022] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:19:34,063] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:19:34,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:19:34,078] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 06:19:46,825] {scheduler_job.py:155} INFO - Started process (PID=65453) to work on /airflow/dags/download_data.py
[2022-02-18 06:19:46,831] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:19:46,833] {logging_mixin.py:112} INFO - [2022-02-18 06:19:46,832] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:19:47,296] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:19:47,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:19:47,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:19:47,360] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 06:20:00,146] {scheduler_job.py:155} INFO - Started process (PID=65479) to work on /airflow/dags/download_data.py
[2022-02-18 06:20:00,159] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:20:00,161] {logging_mixin.py:112} INFO - [2022-02-18 06:20:00,161] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:20:00,605] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:20:00,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:20:00,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:20:00,668] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 06:20:13,384] {scheduler_job.py:155} INFO - Started process (PID=65505) to work on /airflow/dags/download_data.py
[2022-02-18 06:20:13,390] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:20:13,391] {logging_mixin.py:112} INFO - [2022-02-18 06:20:13,391] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:20:13,872] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:20:13,926] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:20:13,934] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:20:13,941] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 06:20:26,674] {scheduler_job.py:155} INFO - Started process (PID=65531) to work on /airflow/dags/download_data.py
[2022-02-18 06:20:26,678] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:20:26,680] {logging_mixin.py:112} INFO - [2022-02-18 06:20:26,680] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:20:27,147] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:20:27,197] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:20:27,206] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:20:27,211] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 06:20:39,899] {scheduler_job.py:155} INFO - Started process (PID=65557) to work on /airflow/dags/download_data.py
[2022-02-18 06:20:39,905] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:20:39,907] {logging_mixin.py:112} INFO - [2022-02-18 06:20:39,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:20:40,356] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:20:40,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:20:40,415] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:20:40,422] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 06:20:53,192] {scheduler_job.py:155} INFO - Started process (PID=65583) to work on /airflow/dags/download_data.py
[2022-02-18 06:20:53,197] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:20:53,199] {logging_mixin.py:112} INFO - [2022-02-18 06:20:53,198] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:20:53,682] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:20:53,726] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:20:53,733] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:20:53,739] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 06:21:06,487] {scheduler_job.py:155} INFO - Started process (PID=65609) to work on /airflow/dags/download_data.py
[2022-02-18 06:21:06,492] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:21:06,493] {logging_mixin.py:112} INFO - [2022-02-18 06:21:06,493] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:21:06,942] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:21:06,991] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:21:06,999] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:21:07,004] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 06:21:19,740] {scheduler_job.py:155} INFO - Started process (PID=65635) to work on /airflow/dags/download_data.py
[2022-02-18 06:21:19,746] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:21:19,748] {logging_mixin.py:112} INFO - [2022-02-18 06:21:19,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:21:20,178] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:21:20,227] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:21:20,233] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:21:20,236] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 06:21:33,069] {scheduler_job.py:155} INFO - Started process (PID=65661) to work on /airflow/dags/download_data.py
[2022-02-18 06:21:33,076] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:21:33,078] {logging_mixin.py:112} INFO - [2022-02-18 06:21:33,078] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:21:33,524] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:21:33,570] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:21:33,576] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:21:33,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 06:21:46,309] {scheduler_job.py:155} INFO - Started process (PID=65687) to work on /airflow/dags/download_data.py
[2022-02-18 06:21:46,315] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:21:46,317] {logging_mixin.py:112} INFO - [2022-02-18 06:21:46,317] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:21:46,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:21:46,837] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:21:46,847] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:21:46,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 06:21:59,608] {scheduler_job.py:155} INFO - Started process (PID=65713) to work on /airflow/dags/download_data.py
[2022-02-18 06:21:59,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:21:59,617] {logging_mixin.py:112} INFO - [2022-02-18 06:21:59,616] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:22:00,052] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:22:00,092] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:22:00,101] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:22:00,106] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 06:22:12,865] {scheduler_job.py:155} INFO - Started process (PID=65739) to work on /airflow/dags/download_data.py
[2022-02-18 06:22:12,876] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:22:12,878] {logging_mixin.py:112} INFO - [2022-02-18 06:22:12,878] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:22:13,349] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:22:13,397] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:22:13,406] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:22:13,411] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 06:22:26,156] {scheduler_job.py:155} INFO - Started process (PID=65765) to work on /airflow/dags/download_data.py
[2022-02-18 06:22:26,166] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:22:26,169] {logging_mixin.py:112} INFO - [2022-02-18 06:22:26,168] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:22:26,616] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:22:26,659] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:22:26,669] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:22:26,673] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 06:22:39,396] {scheduler_job.py:155} INFO - Started process (PID=65791) to work on /airflow/dags/download_data.py
[2022-02-18 06:22:39,402] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:22:39,405] {logging_mixin.py:112} INFO - [2022-02-18 06:22:39,404] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:22:39,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:22:39,947] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:22:39,954] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:22:39,959] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 06:22:52,667] {scheduler_job.py:155} INFO - Started process (PID=65817) to work on /airflow/dags/download_data.py
[2022-02-18 06:22:52,673] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:22:52,674] {logging_mixin.py:112} INFO - [2022-02-18 06:22:52,674] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:22:53,115] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:22:53,165] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:22:53,171] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:22:53,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 06:23:05,944] {scheduler_job.py:155} INFO - Started process (PID=65843) to work on /airflow/dags/download_data.py
[2022-02-18 06:23:05,949] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:23:05,951] {logging_mixin.py:112} INFO - [2022-02-18 06:23:05,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:23:06,396] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:23:06,441] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:23:06,450] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:23:06,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 06:23:19,245] {scheduler_job.py:155} INFO - Started process (PID=65869) to work on /airflow/dags/download_data.py
[2022-02-18 06:23:19,255] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:23:19,257] {logging_mixin.py:112} INFO - [2022-02-18 06:23:19,257] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:23:19,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:23:19,762] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:23:19,769] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:23:19,775] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 06:23:32,573] {scheduler_job.py:155} INFO - Started process (PID=65895) to work on /airflow/dags/download_data.py
[2022-02-18 06:23:32,583] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:23:32,586] {logging_mixin.py:112} INFO - [2022-02-18 06:23:32,586] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:23:33,033] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:23:33,090] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:23:33,097] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:23:33,103] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 06:23:45,912] {scheduler_job.py:155} INFO - Started process (PID=65921) to work on /airflow/dags/download_data.py
[2022-02-18 06:23:45,925] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:23:45,928] {logging_mixin.py:112} INFO - [2022-02-18 06:23:45,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:23:46,496] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:23:46,562] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:23:46,572] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:23:46,580] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.668 seconds
[2022-02-18 06:23:59,219] {scheduler_job.py:155} INFO - Started process (PID=65947) to work on /airflow/dags/download_data.py
[2022-02-18 06:23:59,228] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:23:59,230] {logging_mixin.py:112} INFO - [2022-02-18 06:23:59,230] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:23:59,681] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:23:59,733] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:23:59,742] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:23:59,748] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 06:24:12,509] {scheduler_job.py:155} INFO - Started process (PID=65973) to work on /airflow/dags/download_data.py
[2022-02-18 06:24:12,515] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:24:12,517] {logging_mixin.py:112} INFO - [2022-02-18 06:24:12,517] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:24:13,077] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:24:13,140] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:24:13,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:24:13,161] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.652 seconds
[2022-02-18 06:24:25,858] {scheduler_job.py:155} INFO - Started process (PID=65999) to work on /airflow/dags/download_data.py
[2022-02-18 06:24:25,865] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:24:25,867] {logging_mixin.py:112} INFO - [2022-02-18 06:24:25,866] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:24:26,377] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:24:26,436] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:24:26,445] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:24:26,452] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 06:24:39,112] {scheduler_job.py:155} INFO - Started process (PID=66025) to work on /airflow/dags/download_data.py
[2022-02-18 06:24:39,117] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:24:39,119] {logging_mixin.py:112} INFO - [2022-02-18 06:24:39,119] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:24:39,675] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:24:39,732] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:24:39,742] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:24:39,750] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-18 06:24:52,454] {scheduler_job.py:155} INFO - Started process (PID=66051) to work on /airflow/dags/download_data.py
[2022-02-18 06:24:52,459] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:24:52,461] {logging_mixin.py:112} INFO - [2022-02-18 06:24:52,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:24:53,051] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:24:53,092] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:24:53,097] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:24:53,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.647 seconds
[2022-02-18 06:25:05,823] {scheduler_job.py:155} INFO - Started process (PID=66077) to work on /airflow/dags/download_data.py
[2022-02-18 06:25:05,833] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:25:05,835] {logging_mixin.py:112} INFO - [2022-02-18 06:25:05,835] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:25:06,367] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:25:06,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:25:06,432] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:25:06,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-18 06:25:19,125] {scheduler_job.py:155} INFO - Started process (PID=66103) to work on /airflow/dags/download_data.py
[2022-02-18 06:25:19,130] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:25:19,132] {logging_mixin.py:112} INFO - [2022-02-18 06:25:19,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:25:19,801] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:25:19,857] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:25:19,867] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:25:19,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.750 seconds
[2022-02-18 06:25:32,448] {scheduler_job.py:155} INFO - Started process (PID=66129) to work on /airflow/dags/download_data.py
[2022-02-18 06:25:32,454] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:25:32,456] {logging_mixin.py:112} INFO - [2022-02-18 06:25:32,455] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:25:33,019] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:25:33,071] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:25:33,083] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:25:33,089] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 06:25:45,743] {scheduler_job.py:155} INFO - Started process (PID=66155) to work on /airflow/dags/download_data.py
[2022-02-18 06:25:45,748] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:25:45,749] {logging_mixin.py:112} INFO - [2022-02-18 06:25:45,749] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:25:46,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:25:46,416] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:25:46,424] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:25:46,429] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.686 seconds
[2022-02-18 06:25:59,081] {scheduler_job.py:155} INFO - Started process (PID=66181) to work on /airflow/dags/download_data.py
[2022-02-18 06:25:59,096] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:25:59,099] {logging_mixin.py:112} INFO - [2022-02-18 06:25:59,099] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:25:59,697] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:25:59,764] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:25:59,773] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:25:59,778] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.698 seconds
[2022-02-18 06:26:12,359] {scheduler_job.py:155} INFO - Started process (PID=66207) to work on /airflow/dags/download_data.py
[2022-02-18 06:26:12,366] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:26:12,368] {logging_mixin.py:112} INFO - [2022-02-18 06:26:12,368] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:26:12,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:26:13,000] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:26:13,011] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:26:13,017] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.658 seconds
[2022-02-18 06:26:25,700] {scheduler_job.py:155} INFO - Started process (PID=66233) to work on /airflow/dags/download_data.py
[2022-02-18 06:26:25,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:26:25,709] {logging_mixin.py:112} INFO - [2022-02-18 06:26:25,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:26:26,248] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:26:26,293] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:26:26,300] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:26:26,306] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 06:26:38,974] {scheduler_job.py:155} INFO - Started process (PID=66259) to work on /airflow/dags/download_data.py
[2022-02-18 06:26:38,979] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:26:38,980] {logging_mixin.py:112} INFO - [2022-02-18 06:26:38,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:26:39,432] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:26:39,485] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:26:39,493] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:26:39,502] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 06:26:52,348] {scheduler_job.py:155} INFO - Started process (PID=66285) to work on /airflow/dags/download_data.py
[2022-02-18 06:26:52,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:26:52,359] {logging_mixin.py:112} INFO - [2022-02-18 06:26:52,358] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:26:52,835] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:26:52,879] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:26:52,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:26:52,900] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 06:27:05,661] {scheduler_job.py:155} INFO - Started process (PID=66311) to work on /airflow/dags/download_data.py
[2022-02-18 06:27:05,667] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:27:05,669] {logging_mixin.py:112} INFO - [2022-02-18 06:27:05,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:27:06,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:27:06,288] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:27:06,295] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:27:06,301] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-18 06:27:18,945] {scheduler_job.py:155} INFO - Started process (PID=66337) to work on /airflow/dags/download_data.py
[2022-02-18 06:27:18,951] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:27:18,953] {logging_mixin.py:112} INFO - [2022-02-18 06:27:18,953] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:27:19,516] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:27:19,566] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:27:19,573] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:27:19,578] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.633 seconds
[2022-02-18 06:27:32,285] {scheduler_job.py:155} INFO - Started process (PID=66363) to work on /airflow/dags/download_data.py
[2022-02-18 06:27:32,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:27:32,299] {logging_mixin.py:112} INFO - [2022-02-18 06:27:32,299] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:27:32,845] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:27:32,903] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:27:32,911] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:27:32,917] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-18 06:27:45,537] {scheduler_job.py:155} INFO - Started process (PID=66389) to work on /airflow/dags/download_data.py
[2022-02-18 06:27:45,543] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:27:45,545] {logging_mixin.py:112} INFO - [2022-02-18 06:27:45,545] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:27:46,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:27:46,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:27:46,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:27:46,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.662 seconds
[2022-02-18 06:27:58,884] {scheduler_job.py:155} INFO - Started process (PID=66415) to work on /airflow/dags/download_data.py
[2022-02-18 06:27:58,894] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:27:58,896] {logging_mixin.py:112} INFO - [2022-02-18 06:27:58,895] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:27:59,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:27:59,401] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:27:59,409] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:27:59,413] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 06:28:12,226] {scheduler_job.py:155} INFO - Started process (PID=66441) to work on /airflow/dags/download_data.py
[2022-02-18 06:28:12,232] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:28:12,234] {logging_mixin.py:112} INFO - [2022-02-18 06:28:12,234] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:28:12,763] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:28:12,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:28:12,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:28:12,834] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 06:28:25,582] {scheduler_job.py:155} INFO - Started process (PID=66467) to work on /airflow/dags/download_data.py
[2022-02-18 06:28:25,595] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:28:25,597] {logging_mixin.py:112} INFO - [2022-02-18 06:28:25,597] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:28:26,066] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:28:26,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:28:26,141] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:28:26,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 06:28:38,996] {scheduler_job.py:155} INFO - Started process (PID=66493) to work on /airflow/dags/download_data.py
[2022-02-18 06:28:39,000] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:28:39,002] {logging_mixin.py:112} INFO - [2022-02-18 06:28:39,002] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:28:39,436] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:28:39,486] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:28:39,493] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:28:39,498] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 06:28:53,763] {scheduler_job.py:155} INFO - Started process (PID=66519) to work on /airflow/dags/download_data.py
[2022-02-18 06:28:53,773] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:28:53,777] {logging_mixin.py:112} INFO - [2022-02-18 06:28:53,777] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:28:55,134] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:28:55,272] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:28:55,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:28:55,304] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.542 seconds
[2022-02-18 06:29:05,647] {scheduler_job.py:155} INFO - Started process (PID=66545) to work on /airflow/dags/download_data.py
[2022-02-18 06:29:05,654] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:29:05,656] {logging_mixin.py:112} INFO - [2022-02-18 06:29:05,656] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:29:06,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:29:06,178] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:29:06,191] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:29:06,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 06:29:20,301] {scheduler_job.py:155} INFO - Started process (PID=66570) to work on /airflow/dags/download_data.py
[2022-02-18 06:29:20,305] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:29:20,307] {logging_mixin.py:112} INFO - [2022-02-18 06:29:20,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:29:20,801] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:29:20,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:29:20,854] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:29:20,857] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 06:29:33,633] {scheduler_job.py:155} INFO - Started process (PID=66597) to work on /airflow/dags/download_data.py
[2022-02-18 06:29:33,639] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:29:33,641] {logging_mixin.py:112} INFO - [2022-02-18 06:29:33,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:29:34,073] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:29:34,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:29:34,137] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:29:34,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 06:29:47,876] {scheduler_job.py:155} INFO - Started process (PID=66623) to work on /airflow/dags/download_data.py
[2022-02-18 06:29:47,887] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:29:47,890] {logging_mixin.py:112} INFO - [2022-02-18 06:29:47,890] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:29:48,661] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:29:48,702] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:29:48,708] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:29:48,714] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.838 seconds
[2022-02-18 06:30:10,001] {scheduler_job.py:155} INFO - Started process (PID=66649) to work on /airflow/dags/download_data.py
[2022-02-18 06:30:10,015] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 06:30:10,020] {logging_mixin.py:112} INFO - [2022-02-18 06:30:10,019] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 06:30:10,676] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 06:30:10,742] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 06:30:10,757] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 06:30:10,765] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.764 seconds
[2022-02-18 07:00:15,893] {scheduler_job.py:155} INFO - Started process (PID=66675) to work on /airflow/dags/download_data.py
[2022-02-18 07:00:15,908] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:00:15,916] {logging_mixin.py:112} INFO - [2022-02-18 07:00:15,915] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:00:16,418] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:00:16,458] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:00:16,465] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:00:16,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 07:00:29,239] {scheduler_job.py:155} INFO - Started process (PID=66701) to work on /airflow/dags/download_data.py
[2022-02-18 07:00:29,246] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:00:29,248] {logging_mixin.py:112} INFO - [2022-02-18 07:00:29,248] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:00:29,780] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:00:29,825] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:00:29,830] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:00:29,834] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 07:00:42,541] {scheduler_job.py:155} INFO - Started process (PID=66727) to work on /airflow/dags/download_data.py
[2022-02-18 07:00:42,549] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:00:42,552] {logging_mixin.py:112} INFO - [2022-02-18 07:00:42,551] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:00:43,151] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:00:43,207] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:00:43,216] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:00:43,222] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.681 seconds
[2022-02-18 07:00:55,849] {scheduler_job.py:155} INFO - Started process (PID=66753) to work on /airflow/dags/download_data.py
[2022-02-18 07:00:55,855] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:00:55,857] {logging_mixin.py:112} INFO - [2022-02-18 07:00:55,856] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:00:56,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:00:56,397] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:00:56,408] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:00:56,414] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 07:01:09,126] {scheduler_job.py:155} INFO - Started process (PID=66779) to work on /airflow/dags/download_data.py
[2022-02-18 07:01:09,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:01:09,133] {logging_mixin.py:112} INFO - [2022-02-18 07:01:09,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:01:09,618] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:01:09,674] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:01:09,683] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:01:09,688] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 07:01:22,424] {scheduler_job.py:155} INFO - Started process (PID=66805) to work on /airflow/dags/download_data.py
[2022-02-18 07:01:22,447] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:01:22,449] {logging_mixin.py:112} INFO - [2022-02-18 07:01:22,449] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:01:22,912] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:01:22,972] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:01:22,986] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:01:22,992] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 07:01:38,484] {scheduler_job.py:155} INFO - Started process (PID=66831) to work on /airflow/dags/download_data.py
[2022-02-18 07:01:38,652] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:01:38,659] {logging_mixin.py:112} INFO - [2022-02-18 07:01:38,658] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:01:43,862] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:01:44,235] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:01:44,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:01:44,262] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 5.778 seconds
[2022-02-18 07:01:53,942] {scheduler_job.py:155} INFO - Started process (PID=66857) to work on /airflow/dags/download_data.py
[2022-02-18 07:01:53,951] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:01:53,954] {logging_mixin.py:112} INFO - [2022-02-18 07:01:53,954] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:01:55,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:01:55,429] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:01:55,464] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:01:55,476] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.533 seconds
[2022-02-18 07:02:02,137] {scheduler_job.py:155} INFO - Started process (PID=66884) to work on /airflow/dags/download_data.py
[2022-02-18 07:02:02,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:02:02,153] {logging_mixin.py:112} INFO - [2022-02-18 07:02:02,152] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:02:02,768] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:02:02,821] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:02:02,831] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:02:02,838] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.701 seconds
[2022-02-18 07:02:09,296] {scheduler_job.py:155} INFO - Started process (PID=66911) to work on /airflow/dags/download_data.py
[2022-02-18 07:02:09,305] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:02:09,307] {logging_mixin.py:112} INFO - [2022-02-18 07:02:09,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:02:09,905] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:02:09,951] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:02:09,957] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:02:09,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-18 07:02:16,496] {scheduler_job.py:155} INFO - Started process (PID=66938) to work on /airflow/dags/download_data.py
[2022-02-18 07:02:16,508] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:02:16,510] {logging_mixin.py:112} INFO - [2022-02-18 07:02:16,509] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:02:17,058] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:02:17,109] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:02:17,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:02:17,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-18 07:02:23,679] {scheduler_job.py:155} INFO - Started process (PID=66965) to work on /airflow/dags/download_data.py
[2022-02-18 07:02:23,695] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:02:23,697] {logging_mixin.py:112} INFO - [2022-02-18 07:02:23,697] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:02:24,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:02:24,309] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:02:24,317] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:02:24,322] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.643 seconds
[2022-02-18 07:02:30,841] {scheduler_job.py:155} INFO - Started process (PID=66992) to work on /airflow/dags/download_data.py
[2022-02-18 07:02:30,847] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:02:30,849] {logging_mixin.py:112} INFO - [2022-02-18 07:02:30,849] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:02:31,564] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:02:31,625] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:02:31,638] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:02:31,646] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.805 seconds
[2022-02-18 07:02:38,049] {scheduler_job.py:155} INFO - Started process (PID=67019) to work on /airflow/dags/download_data.py
[2022-02-18 07:02:38,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:02:38,057] {logging_mixin.py:112} INFO - [2022-02-18 07:02:38,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:02:38,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:02:38,789] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:02:38,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:02:38,805] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.756 seconds
[2022-02-18 07:02:45,259] {scheduler_job.py:155} INFO - Started process (PID=67046) to work on /airflow/dags/download_data.py
[2022-02-18 07:02:45,272] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:02:45,275] {logging_mixin.py:112} INFO - [2022-02-18 07:02:45,274] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:02:45,957] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:02:46,015] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:02:46,027] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:02:46,032] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.774 seconds
[2022-02-18 07:02:52,609] {scheduler_job.py:155} INFO - Started process (PID=67073) to work on /airflow/dags/download_data.py
[2022-02-18 07:02:52,615] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:02:52,622] {logging_mixin.py:112} INFO - [2022-02-18 07:02:52,622] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:02:53,143] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:02:53,187] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:02:53,195] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:02:53,201] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 07:02:59,748] {scheduler_job.py:155} INFO - Started process (PID=67100) to work on /airflow/dags/download_data.py
[2022-02-18 07:02:59,757] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:02:59,760] {logging_mixin.py:112} INFO - [2022-02-18 07:02:59,760] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:03:00,341] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:03:00,394] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:03:00,399] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:03:00,407] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.660 seconds
[2022-02-18 07:03:13,951] {scheduler_job.py:155} INFO - Started process (PID=67127) to work on /airflow/dags/download_data.py
[2022-02-18 07:03:13,963] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:03:13,966] {logging_mixin.py:112} INFO - [2022-02-18 07:03:13,965] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:03:14,511] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:03:14,582] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:03:14,593] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:03:14,597] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.646 seconds
[2022-02-18 07:03:26,230] {scheduler_job.py:155} INFO - Started process (PID=67152) to work on /airflow/dags/download_data.py
[2022-02-18 07:03:26,237] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:03:26,239] {logging_mixin.py:112} INFO - [2022-02-18 07:03:26,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:03:26,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:03:26,764] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:03:26,775] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:03:26,780] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 07:03:39,530] {scheduler_job.py:155} INFO - Started process (PID=67178) to work on /airflow/dags/download_data.py
[2022-02-18 07:03:39,534] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:03:39,538] {logging_mixin.py:112} INFO - [2022-02-18 07:03:39,537] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:03:39,992] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:03:40,047] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:03:40,056] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:03:40,061] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 07:03:52,860] {scheduler_job.py:155} INFO - Started process (PID=67204) to work on /airflow/dags/download_data.py
[2022-02-18 07:03:52,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:03:52,869] {logging_mixin.py:112} INFO - [2022-02-18 07:03:52,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:03:53,323] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:03:53,371] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:03:53,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:03:53,386] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 07:04:06,124] {scheduler_job.py:155} INFO - Started process (PID=67230) to work on /airflow/dags/download_data.py
[2022-02-18 07:04:06,143] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:04:06,145] {logging_mixin.py:112} INFO - [2022-02-18 07:04:06,145] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:04:06,670] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:04:06,730] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:04:06,743] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:04:06,749] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-18 07:04:19,445] {scheduler_job.py:155} INFO - Started process (PID=67256) to work on /airflow/dags/download_data.py
[2022-02-18 07:04:19,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:04:19,454] {logging_mixin.py:112} INFO - [2022-02-18 07:04:19,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:04:19,933] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:04:19,984] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:04:19,994] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:04:20,003] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 07:04:32,740] {scheduler_job.py:155} INFO - Started process (PID=67282) to work on /airflow/dags/download_data.py
[2022-02-18 07:04:32,750] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:04:32,753] {logging_mixin.py:112} INFO - [2022-02-18 07:04:32,752] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:04:33,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:04:33,241] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:04:33,246] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:04:33,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 07:04:46,016] {scheduler_job.py:155} INFO - Started process (PID=67308) to work on /airflow/dags/download_data.py
[2022-02-18 07:04:46,022] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:04:46,023] {logging_mixin.py:112} INFO - [2022-02-18 07:04:46,023] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:04:46,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:04:46,541] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:04:46,548] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:04:46,552] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 07:04:59,301] {scheduler_job.py:155} INFO - Started process (PID=67334) to work on /airflow/dags/download_data.py
[2022-02-18 07:04:59,308] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:04:59,310] {logging_mixin.py:112} INFO - [2022-02-18 07:04:59,310] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:04:59,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:04:59,809] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:04:59,817] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:04:59,823] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 07:05:12,599] {scheduler_job.py:155} INFO - Started process (PID=67360) to work on /airflow/dags/download_data.py
[2022-02-18 07:05:12,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:05:12,606] {logging_mixin.py:112} INFO - [2022-02-18 07:05:12,606] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:05:13,100] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:05:13,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:05:13,148] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:05:13,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 07:05:25,911] {scheduler_job.py:155} INFO - Started process (PID=67386) to work on /airflow/dags/download_data.py
[2022-02-18 07:05:25,916] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:05:25,918] {logging_mixin.py:112} INFO - [2022-02-18 07:05:25,917] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:05:26,398] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:05:26,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:05:26,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:05:26,466] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 07:05:39,202] {scheduler_job.py:155} INFO - Started process (PID=67412) to work on /airflow/dags/download_data.py
[2022-02-18 07:05:39,210] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:05:39,213] {logging_mixin.py:112} INFO - [2022-02-18 07:05:39,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:05:39,702] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:05:39,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:05:39,757] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:05:39,762] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 07:05:52,514] {scheduler_job.py:155} INFO - Started process (PID=67438) to work on /airflow/dags/download_data.py
[2022-02-18 07:05:52,524] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:05:52,526] {logging_mixin.py:112} INFO - [2022-02-18 07:05:52,526] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:05:52,992] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:05:53,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:05:53,051] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:05:53,056] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 07:06:05,756] {scheduler_job.py:155} INFO - Started process (PID=67464) to work on /airflow/dags/download_data.py
[2022-02-18 07:06:05,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:06:05,764] {logging_mixin.py:112} INFO - [2022-02-18 07:06:05,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:06:06,242] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:06:06,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:06:06,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:06:06,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 07:06:19,075] {scheduler_job.py:155} INFO - Started process (PID=67490) to work on /airflow/dags/download_data.py
[2022-02-18 07:06:19,085] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:06:19,088] {logging_mixin.py:112} INFO - [2022-02-18 07:06:19,087] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:06:19,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:06:19,632] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:06:19,642] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:06:19,647] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 07:06:32,390] {scheduler_job.py:155} INFO - Started process (PID=67516) to work on /airflow/dags/download_data.py
[2022-02-18 07:06:32,397] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:06:32,398] {logging_mixin.py:112} INFO - [2022-02-18 07:06:32,398] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:06:32,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:06:32,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:06:32,940] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:06:32,944] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 07:06:45,665] {scheduler_job.py:155} INFO - Started process (PID=67542) to work on /airflow/dags/download_data.py
[2022-02-18 07:06:45,673] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:06:45,676] {logging_mixin.py:112} INFO - [2022-02-18 07:06:45,675] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:06:46,160] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:06:46,222] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:06:46,235] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:06:46,244] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 07:06:58,958] {scheduler_job.py:155} INFO - Started process (PID=67568) to work on /airflow/dags/download_data.py
[2022-02-18 07:06:58,965] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:06:58,967] {logging_mixin.py:112} INFO - [2022-02-18 07:06:58,966] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:06:59,466] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:06:59,538] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:06:59,549] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:06:59,563] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 07:07:12,224] {scheduler_job.py:155} INFO - Started process (PID=67594) to work on /airflow/dags/download_data.py
[2022-02-18 07:07:12,229] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:07:12,232] {logging_mixin.py:112} INFO - [2022-02-18 07:07:12,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:07:12,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:07:12,792] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:07:12,801] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:07:12,809] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 07:07:25,580] {scheduler_job.py:155} INFO - Started process (PID=67620) to work on /airflow/dags/download_data.py
[2022-02-18 07:07:25,589] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:07:25,592] {logging_mixin.py:112} INFO - [2022-02-18 07:07:25,591] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:07:26,061] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:07:26,115] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:07:26,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:07:26,137] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 07:07:38,852] {scheduler_job.py:155} INFO - Started process (PID=67646) to work on /airflow/dags/download_data.py
[2022-02-18 07:07:38,866] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:07:38,868] {logging_mixin.py:112} INFO - [2022-02-18 07:07:38,868] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:07:39,361] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:07:39,401] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:07:39,409] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:07:39,414] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 07:07:52,169] {scheduler_job.py:155} INFO - Started process (PID=67672) to work on /airflow/dags/download_data.py
[2022-02-18 07:07:52,173] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:07:52,174] {logging_mixin.py:112} INFO - [2022-02-18 07:07:52,174] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:07:52,641] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:07:52,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:07:52,696] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:07:52,701] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 07:08:05,448] {scheduler_job.py:155} INFO - Started process (PID=67698) to work on /airflow/dags/download_data.py
[2022-02-18 07:08:05,461] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:08:05,463] {logging_mixin.py:112} INFO - [2022-02-18 07:08:05,463] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:08:05,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:08:05,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:08:06,001] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:08:06,007] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 07:08:18,757] {scheduler_job.py:155} INFO - Started process (PID=67724) to work on /airflow/dags/download_data.py
[2022-02-18 07:08:18,770] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:08:18,772] {logging_mixin.py:112} INFO - [2022-02-18 07:08:18,772] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:08:19,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:08:19,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:08:19,325] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:08:19,331] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-18 07:08:32,052] {scheduler_job.py:155} INFO - Started process (PID=67750) to work on /airflow/dags/download_data.py
[2022-02-18 07:08:32,058] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:08:32,060] {logging_mixin.py:112} INFO - [2022-02-18 07:08:32,059] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:08:32,550] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:08:32,599] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:08:32,605] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:08:32,609] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 07:08:45,352] {scheduler_job.py:155} INFO - Started process (PID=67776) to work on /airflow/dags/download_data.py
[2022-02-18 07:08:45,359] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:08:45,361] {logging_mixin.py:112} INFO - [2022-02-18 07:08:45,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:08:45,846] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:08:45,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:08:45,906] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:08:45,911] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 07:08:58,658] {scheduler_job.py:155} INFO - Started process (PID=67802) to work on /airflow/dags/download_data.py
[2022-02-18 07:08:58,664] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:08:58,665] {logging_mixin.py:112} INFO - [2022-02-18 07:08:58,665] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:08:59,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:08:59,216] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:08:59,225] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:08:59,228] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 07:09:11,953] {scheduler_job.py:155} INFO - Started process (PID=67828) to work on /airflow/dags/download_data.py
[2022-02-18 07:09:11,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:09:11,959] {logging_mixin.py:112} INFO - [2022-02-18 07:09:11,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:09:12,440] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:09:12,491] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:09:12,497] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:09:12,502] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 07:09:25,268] {scheduler_job.py:155} INFO - Started process (PID=67854) to work on /airflow/dags/download_data.py
[2022-02-18 07:09:25,276] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:09:25,278] {logging_mixin.py:112} INFO - [2022-02-18 07:09:25,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:09:25,742] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:09:25,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:09:25,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:09:25,809] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 07:09:38,501] {scheduler_job.py:155} INFO - Started process (PID=67880) to work on /airflow/dags/download_data.py
[2022-02-18 07:09:38,506] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:09:38,509] {logging_mixin.py:112} INFO - [2022-02-18 07:09:38,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:09:39,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:09:39,125] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:09:39,131] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:09:39,135] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.634 seconds
[2022-02-18 07:09:51,824] {scheduler_job.py:155} INFO - Started process (PID=67906) to work on /airflow/dags/download_data.py
[2022-02-18 07:09:51,828] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:09:51,829] {logging_mixin.py:112} INFO - [2022-02-18 07:09:51,829] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:09:52,303] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:09:52,345] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:09:52,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:09:52,355] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 07:10:05,079] {scheduler_job.py:155} INFO - Started process (PID=67932) to work on /airflow/dags/download_data.py
[2022-02-18 07:10:05,088] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:10:05,091] {logging_mixin.py:112} INFO - [2022-02-18 07:10:05,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:10:05,584] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:10:05,628] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:10:05,635] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:10:05,639] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 07:10:18,443] {scheduler_job.py:155} INFO - Started process (PID=67958) to work on /airflow/dags/download_data.py
[2022-02-18 07:10:18,454] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:10:18,457] {logging_mixin.py:112} INFO - [2022-02-18 07:10:18,456] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:10:18,923] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:10:18,976] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:10:18,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:10:18,989] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 07:10:31,749] {scheduler_job.py:155} INFO - Started process (PID=67984) to work on /airflow/dags/download_data.py
[2022-02-18 07:10:31,754] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:10:31,756] {logging_mixin.py:112} INFO - [2022-02-18 07:10:31,756] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:10:32,248] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:10:32,313] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:10:32,324] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:10:32,331] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 07:10:45,038] {scheduler_job.py:155} INFO - Started process (PID=68010) to work on /airflow/dags/download_data.py
[2022-02-18 07:10:45,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:10:45,051] {logging_mixin.py:112} INFO - [2022-02-18 07:10:45,050] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:10:45,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:10:45,602] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:10:45,610] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:10:45,614] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 07:10:58,344] {scheduler_job.py:155} INFO - Started process (PID=68036) to work on /airflow/dags/download_data.py
[2022-02-18 07:10:58,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:10:58,351] {logging_mixin.py:112} INFO - [2022-02-18 07:10:58,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:10:58,792] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:10:58,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:10:58,848] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:10:58,854] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 07:11:11,638] {scheduler_job.py:155} INFO - Started process (PID=68062) to work on /airflow/dags/download_data.py
[2022-02-18 07:11:11,646] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:11:11,648] {logging_mixin.py:112} INFO - [2022-02-18 07:11:11,648] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:11:12,083] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:11:12,124] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:11:12,131] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:11:12,135] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 07:11:24,948] {scheduler_job.py:155} INFO - Started process (PID=68088) to work on /airflow/dags/download_data.py
[2022-02-18 07:11:24,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:11:24,961] {logging_mixin.py:112} INFO - [2022-02-18 07:11:24,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:11:25,420] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:11:25,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:11:25,480] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:11:25,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 07:11:38,205] {scheduler_job.py:155} INFO - Started process (PID=68114) to work on /airflow/dags/download_data.py
[2022-02-18 07:11:38,211] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:11:38,213] {logging_mixin.py:112} INFO - [2022-02-18 07:11:38,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:11:38,674] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:11:38,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:11:38,724] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:11:38,728] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 07:11:51,524] {scheduler_job.py:155} INFO - Started process (PID=68140) to work on /airflow/dags/download_data.py
[2022-02-18 07:11:51,528] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:11:51,530] {logging_mixin.py:112} INFO - [2022-02-18 07:11:51,530] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:11:51,976] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:11:52,017] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:11:52,024] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:11:52,029] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 07:12:04,823] {scheduler_job.py:155} INFO - Started process (PID=68166) to work on /airflow/dags/download_data.py
[2022-02-18 07:12:04,831] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:12:04,833] {logging_mixin.py:112} INFO - [2022-02-18 07:12:04,832] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:12:05,265] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:12:05,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:12:05,325] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:12:05,331] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 07:12:18,106] {scheduler_job.py:155} INFO - Started process (PID=68192) to work on /airflow/dags/download_data.py
[2022-02-18 07:12:18,112] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:12:18,119] {logging_mixin.py:112} INFO - [2022-02-18 07:12:18,116] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:12:18,549] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:12:18,599] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:12:18,607] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:12:18,612] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 07:12:31,423] {scheduler_job.py:155} INFO - Started process (PID=68218) to work on /airflow/dags/download_data.py
[2022-02-18 07:12:31,429] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:12:31,430] {logging_mixin.py:112} INFO - [2022-02-18 07:12:31,430] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:12:31,869] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:12:31,911] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:12:31,918] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:12:31,924] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 07:12:44,710] {scheduler_job.py:155} INFO - Started process (PID=68244) to work on /airflow/dags/download_data.py
[2022-02-18 07:12:44,714] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:12:44,716] {logging_mixin.py:112} INFO - [2022-02-18 07:12:44,716] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:12:45,156] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:12:45,205] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:12:45,212] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:12:45,217] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 07:12:58,048] {scheduler_job.py:155} INFO - Started process (PID=68270) to work on /airflow/dags/download_data.py
[2022-02-18 07:12:58,052] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:12:58,053] {logging_mixin.py:112} INFO - [2022-02-18 07:12:58,053] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:12:58,507] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:12:58,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:12:58,566] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:12:58,572] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 07:13:11,316] {scheduler_job.py:155} INFO - Started process (PID=68296) to work on /airflow/dags/download_data.py
[2022-02-18 07:13:11,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:13:11,325] {logging_mixin.py:112} INFO - [2022-02-18 07:13:11,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:13:11,764] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:13:11,807] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:13:11,813] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:13:11,818] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 07:13:24,657] {scheduler_job.py:155} INFO - Started process (PID=68322) to work on /airflow/dags/download_data.py
[2022-02-18 07:13:24,662] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:13:24,668] {logging_mixin.py:112} INFO - [2022-02-18 07:13:24,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:13:25,126] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:13:25,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:13:25,186] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:13:25,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 07:13:37,925] {scheduler_job.py:155} INFO - Started process (PID=68348) to work on /airflow/dags/download_data.py
[2022-02-18 07:13:37,933] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:13:37,936] {logging_mixin.py:112} INFO - [2022-02-18 07:13:37,936] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:13:38,388] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:13:38,455] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:13:38,463] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:13:38,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 07:13:51,192] {scheduler_job.py:155} INFO - Started process (PID=68374) to work on /airflow/dags/download_data.py
[2022-02-18 07:13:51,196] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:13:51,198] {logging_mixin.py:112} INFO - [2022-02-18 07:13:51,198] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:13:51,653] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:13:51,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:13:51,711] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:13:51,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 07:14:04,478] {scheduler_job.py:155} INFO - Started process (PID=68400) to work on /airflow/dags/download_data.py
[2022-02-18 07:14:04,482] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:14:04,484] {logging_mixin.py:112} INFO - [2022-02-18 07:14:04,484] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:14:04,917] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:14:04,968] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:14:04,975] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:14:04,979] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 07:14:17,781] {scheduler_job.py:155} INFO - Started process (PID=68426) to work on /airflow/dags/download_data.py
[2022-02-18 07:14:17,789] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:14:17,791] {logging_mixin.py:112} INFO - [2022-02-18 07:14:17,791] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:14:18,222] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:14:18,271] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:14:18,279] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:14:18,286] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 07:14:31,078] {scheduler_job.py:155} INFO - Started process (PID=68452) to work on /airflow/dags/download_data.py
[2022-02-18 07:14:31,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:14:31,084] {logging_mixin.py:112} INFO - [2022-02-18 07:14:31,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:14:31,523] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:14:31,570] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:14:31,578] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:14:31,584] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 07:14:44,344] {scheduler_job.py:155} INFO - Started process (PID=68478) to work on /airflow/dags/download_data.py
[2022-02-18 07:14:44,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:14:44,350] {logging_mixin.py:112} INFO - [2022-02-18 07:14:44,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:14:44,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:14:44,843] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:14:44,853] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:14:44,859] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 07:14:57,672] {scheduler_job.py:155} INFO - Started process (PID=68504) to work on /airflow/dags/download_data.py
[2022-02-18 07:14:57,681] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:14:57,683] {logging_mixin.py:112} INFO - [2022-02-18 07:14:57,683] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:14:58,122] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:14:58,176] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:14:58,186] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:14:58,191] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 07:15:10,961] {scheduler_job.py:155} INFO - Started process (PID=68530) to work on /airflow/dags/download_data.py
[2022-02-18 07:15:10,973] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:15:10,974] {logging_mixin.py:112} INFO - [2022-02-18 07:15:10,974] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:15:11,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:15:11,446] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:15:11,453] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:15:11,456] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 07:15:24,284] {scheduler_job.py:155} INFO - Started process (PID=68556) to work on /airflow/dags/download_data.py
[2022-02-18 07:15:24,289] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:15:24,290] {logging_mixin.py:112} INFO - [2022-02-18 07:15:24,290] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:15:24,727] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:15:24,778] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:15:24,787] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:15:24,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 07:15:37,561] {scheduler_job.py:155} INFO - Started process (PID=68582) to work on /airflow/dags/download_data.py
[2022-02-18 07:15:37,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:15:37,570] {logging_mixin.py:112} INFO - [2022-02-18 07:15:37,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:15:38,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:15:38,080] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:15:38,089] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:15:38,094] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 07:15:50,855] {scheduler_job.py:155} INFO - Started process (PID=68608) to work on /airflow/dags/download_data.py
[2022-02-18 07:15:50,860] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:15:50,862] {logging_mixin.py:112} INFO - [2022-02-18 07:15:50,861] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:15:51,318] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:15:51,363] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:15:51,372] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:15:51,378] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 07:16:04,144] {scheduler_job.py:155} INFO - Started process (PID=68634) to work on /airflow/dags/download_data.py
[2022-02-18 07:16:04,150] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:16:04,151] {logging_mixin.py:112} INFO - [2022-02-18 07:16:04,151] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:16:04,578] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:16:04,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:16:04,635] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:16:04,641] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 07:16:17,438] {scheduler_job.py:155} INFO - Started process (PID=68660) to work on /airflow/dags/download_data.py
[2022-02-18 07:16:17,444] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:16:17,445] {logging_mixin.py:112} INFO - [2022-02-18 07:16:17,445] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:16:17,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:16:17,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:16:17,940] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:16:17,945] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 07:16:30,755] {scheduler_job.py:155} INFO - Started process (PID=68686) to work on /airflow/dags/download_data.py
[2022-02-18 07:16:30,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:16:30,765] {logging_mixin.py:112} INFO - [2022-02-18 07:16:30,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:16:31,201] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:16:31,255] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:16:31,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:16:31,265] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 07:16:44,003] {scheduler_job.py:155} INFO - Started process (PID=68712) to work on /airflow/dags/download_data.py
[2022-02-18 07:16:44,010] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:16:44,012] {logging_mixin.py:112} INFO - [2022-02-18 07:16:44,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:16:44,462] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:16:44,514] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:16:44,526] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:16:44,531] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 07:16:57,344] {scheduler_job.py:155} INFO - Started process (PID=68738) to work on /airflow/dags/download_data.py
[2022-02-18 07:16:57,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:16:57,352] {logging_mixin.py:112} INFO - [2022-02-18 07:16:57,352] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:16:57,800] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:16:57,869] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:16:57,874] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:16:57,879] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 07:17:10,618] {scheduler_job.py:155} INFO - Started process (PID=68764) to work on /airflow/dags/download_data.py
[2022-02-18 07:17:10,625] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:17:10,627] {logging_mixin.py:112} INFO - [2022-02-18 07:17:10,627] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:17:11,077] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:17:11,124] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:17:11,132] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:17:11,137] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 07:17:23,921] {scheduler_job.py:155} INFO - Started process (PID=68790) to work on /airflow/dags/download_data.py
[2022-02-18 07:17:23,926] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:17:23,928] {logging_mixin.py:112} INFO - [2022-02-18 07:17:23,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:17:24,396] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:17:24,449] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:17:24,455] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:17:24,461] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 07:17:37,185] {scheduler_job.py:155} INFO - Started process (PID=68816) to work on /airflow/dags/download_data.py
[2022-02-18 07:17:37,190] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:17:37,192] {logging_mixin.py:112} INFO - [2022-02-18 07:17:37,192] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:17:37,655] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:17:37,720] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:17:37,728] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:17:37,734] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 07:17:50,509] {scheduler_job.py:155} INFO - Started process (PID=68842) to work on /airflow/dags/download_data.py
[2022-02-18 07:17:50,519] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:17:50,521] {logging_mixin.py:112} INFO - [2022-02-18 07:17:50,521] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:17:50,945] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:17:50,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:17:51,004] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:17:51,009] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 07:18:03,791] {scheduler_job.py:155} INFO - Started process (PID=68868) to work on /airflow/dags/download_data.py
[2022-02-18 07:18:03,795] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:18:03,797] {logging_mixin.py:112} INFO - [2022-02-18 07:18:03,797] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:18:04,215] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:18:04,264] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:18:04,272] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:18:04,277] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.486 seconds
[2022-02-18 07:18:17,055] {scheduler_job.py:155} INFO - Started process (PID=68894) to work on /airflow/dags/download_data.py
[2022-02-18 07:18:17,063] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:18:17,067] {logging_mixin.py:112} INFO - [2022-02-18 07:18:17,067] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:18:17,494] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:18:17,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:18:17,542] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:18:17,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 07:18:30,347] {scheduler_job.py:155} INFO - Started process (PID=68920) to work on /airflow/dags/download_data.py
[2022-02-18 07:18:30,354] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:18:30,362] {logging_mixin.py:112} INFO - [2022-02-18 07:18:30,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:18:30,804] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:18:30,855] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:18:30,862] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:18:30,868] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 07:18:43,597] {scheduler_job.py:155} INFO - Started process (PID=68946) to work on /airflow/dags/download_data.py
[2022-02-18 07:18:43,603] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:18:43,605] {logging_mixin.py:112} INFO - [2022-02-18 07:18:43,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:18:44,047] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:18:44,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:18:44,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:18:44,115] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 07:18:56,843] {scheduler_job.py:155} INFO - Started process (PID=68972) to work on /airflow/dags/download_data.py
[2022-02-18 07:18:56,848] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:18:56,850] {logging_mixin.py:112} INFO - [2022-02-18 07:18:56,849] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:18:57,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:18:57,364] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:18:57,373] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:18:57,377] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 07:19:10,262] {scheduler_job.py:155} INFO - Started process (PID=68998) to work on /airflow/dags/download_data.py
[2022-02-18 07:19:10,274] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:19:10,276] {logging_mixin.py:112} INFO - [2022-02-18 07:19:10,276] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:19:10,701] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:19:10,748] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:19:10,758] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:19:10,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 07:19:23,570] {scheduler_job.py:155} INFO - Started process (PID=69024) to work on /airflow/dags/download_data.py
[2022-02-18 07:19:23,579] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:19:23,580] {logging_mixin.py:112} INFO - [2022-02-18 07:19:23,580] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:19:24,023] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:19:24,069] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:19:24,079] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:19:24,084] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 07:19:36,860] {scheduler_job.py:155} INFO - Started process (PID=69050) to work on /airflow/dags/download_data.py
[2022-02-18 07:19:36,873] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:19:36,877] {logging_mixin.py:112} INFO - [2022-02-18 07:19:36,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:19:37,323] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:19:37,377] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:19:37,386] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:19:37,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 07:19:50,156] {scheduler_job.py:155} INFO - Started process (PID=69076) to work on /airflow/dags/download_data.py
[2022-02-18 07:19:50,162] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:19:50,164] {logging_mixin.py:112} INFO - [2022-02-18 07:19:50,164] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:19:50,586] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:19:50,634] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:19:50,641] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:19:50,647] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 07:20:03,443] {scheduler_job.py:155} INFO - Started process (PID=69102) to work on /airflow/dags/download_data.py
[2022-02-18 07:20:03,448] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:20:03,450] {logging_mixin.py:112} INFO - [2022-02-18 07:20:03,449] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:20:03,868] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:20:03,921] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:20:03,930] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:20:03,934] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 07:20:16,755] {scheduler_job.py:155} INFO - Started process (PID=69128) to work on /airflow/dags/download_data.py
[2022-02-18 07:20:16,760] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:20:16,763] {logging_mixin.py:112} INFO - [2022-02-18 07:20:16,762] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:20:17,190] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:20:17,242] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:20:17,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:20:17,255] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 07:20:30,046] {scheduler_job.py:155} INFO - Started process (PID=69154) to work on /airflow/dags/download_data.py
[2022-02-18 07:20:30,051] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:20:30,052] {logging_mixin.py:112} INFO - [2022-02-18 07:20:30,052] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:20:30,493] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:20:30,545] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:20:30,552] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:20:30,558] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 07:20:43,306] {scheduler_job.py:155} INFO - Started process (PID=69180) to work on /airflow/dags/download_data.py
[2022-02-18 07:20:43,311] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:20:43,312] {logging_mixin.py:112} INFO - [2022-02-18 07:20:43,312] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:20:43,751] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:20:43,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:20:43,811] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:20:43,816] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 07:20:56,646] {scheduler_job.py:155} INFO - Started process (PID=69206) to work on /airflow/dags/download_data.py
[2022-02-18 07:20:56,654] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:20:56,656] {logging_mixin.py:112} INFO - [2022-02-18 07:20:56,655] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:20:57,088] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:20:57,134] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:20:57,145] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:20:57,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 07:21:09,926] {scheduler_job.py:155} INFO - Started process (PID=69232) to work on /airflow/dags/download_data.py
[2022-02-18 07:21:09,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:21:09,937] {logging_mixin.py:112} INFO - [2022-02-18 07:21:09,937] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:21:10,372] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:21:10,426] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:21:10,434] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:21:10,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 07:21:23,212] {scheduler_job.py:155} INFO - Started process (PID=69258) to work on /airflow/dags/download_data.py
[2022-02-18 07:21:23,216] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:21:23,218] {logging_mixin.py:112} INFO - [2022-02-18 07:21:23,218] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:21:23,656] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:21:23,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:21:23,723] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:21:23,730] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 07:21:36,512] {scheduler_job.py:155} INFO - Started process (PID=69284) to work on /airflow/dags/download_data.py
[2022-02-18 07:21:36,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:21:36,531] {logging_mixin.py:112} INFO - [2022-02-18 07:21:36,531] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:21:37,013] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:21:37,071] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:21:37,084] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:21:37,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 07:21:49,821] {scheduler_job.py:155} INFO - Started process (PID=69310) to work on /airflow/dags/download_data.py
[2022-02-18 07:21:49,827] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:21:49,829] {logging_mixin.py:112} INFO - [2022-02-18 07:21:49,829] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:21:50,257] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:21:50,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:21:50,312] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:21:50,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 07:22:03,133] {scheduler_job.py:155} INFO - Started process (PID=69336) to work on /airflow/dags/download_data.py
[2022-02-18 07:22:03,136] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:22:03,138] {logging_mixin.py:112} INFO - [2022-02-18 07:22:03,138] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:22:03,572] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:22:03,623] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:22:03,628] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:22:03,633] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 07:22:16,424] {scheduler_job.py:155} INFO - Started process (PID=69362) to work on /airflow/dags/download_data.py
[2022-02-18 07:22:16,432] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:22:16,434] {logging_mixin.py:112} INFO - [2022-02-18 07:22:16,434] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:22:16,861] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:22:16,906] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:22:16,912] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:22:16,916] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 07:22:29,720] {scheduler_job.py:155} INFO - Started process (PID=69388) to work on /airflow/dags/download_data.py
[2022-02-18 07:22:29,729] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:22:29,731] {logging_mixin.py:112} INFO - [2022-02-18 07:22:29,731] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:22:30,175] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:22:30,226] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:22:30,232] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:22:30,237] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 07:22:43,000] {scheduler_job.py:155} INFO - Started process (PID=69414) to work on /airflow/dags/download_data.py
[2022-02-18 07:22:43,004] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:22:43,006] {logging_mixin.py:112} INFO - [2022-02-18 07:22:43,006] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:22:43,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:22:43,494] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:22:43,499] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:22:43,505] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 07:22:56,298] {scheduler_job.py:155} INFO - Started process (PID=69440) to work on /airflow/dags/download_data.py
[2022-02-18 07:22:56,305] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:22:56,307] {logging_mixin.py:112} INFO - [2022-02-18 07:22:56,306] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:22:56,733] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:22:56,783] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:22:56,793] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:22:56,798] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 07:23:09,541] {scheduler_job.py:155} INFO - Started process (PID=69466) to work on /airflow/dags/download_data.py
[2022-02-18 07:23:09,545] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:23:09,547] {logging_mixin.py:112} INFO - [2022-02-18 07:23:09,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:23:09,986] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:23:10,040] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:23:10,050] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:23:10,053] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 07:23:22,837] {scheduler_job.py:155} INFO - Started process (PID=69492) to work on /airflow/dags/download_data.py
[2022-02-18 07:23:22,845] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:23:22,847] {logging_mixin.py:112} INFO - [2022-02-18 07:23:22,847] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:23:23,273] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:23:23,321] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:23:23,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:23:23,332] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 07:23:36,108] {scheduler_job.py:155} INFO - Started process (PID=69518) to work on /airflow/dags/download_data.py
[2022-02-18 07:23:36,114] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:23:36,116] {logging_mixin.py:112} INFO - [2022-02-18 07:23:36,116] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:23:36,561] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:23:36,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:23:36,626] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:23:36,631] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 07:23:49,409] {scheduler_job.py:155} INFO - Started process (PID=69544) to work on /airflow/dags/download_data.py
[2022-02-18 07:23:49,415] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:23:49,417] {logging_mixin.py:112} INFO - [2022-02-18 07:23:49,417] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:23:49,844] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:23:49,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:23:49,899] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:23:49,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 07:24:02,753] {scheduler_job.py:155} INFO - Started process (PID=69570) to work on /airflow/dags/download_data.py
[2022-02-18 07:24:02,757] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:24:02,759] {logging_mixin.py:112} INFO - [2022-02-18 07:24:02,759] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:24:03,191] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:24:03,238] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:24:03,245] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:24:03,250] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 07:24:16,020] {scheduler_job.py:155} INFO - Started process (PID=69596) to work on /airflow/dags/download_data.py
[2022-02-18 07:24:16,026] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:24:16,029] {logging_mixin.py:112} INFO - [2022-02-18 07:24:16,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:24:16,463] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:24:16,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:24:16,523] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:24:16,527] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 07:24:29,296] {scheduler_job.py:155} INFO - Started process (PID=69622) to work on /airflow/dags/download_data.py
[2022-02-18 07:24:29,301] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:24:29,303] {logging_mixin.py:112} INFO - [2022-02-18 07:24:29,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:24:29,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:24:29,796] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:24:29,805] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:24:29,811] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 07:24:42,598] {scheduler_job.py:155} INFO - Started process (PID=69648) to work on /airflow/dags/download_data.py
[2022-02-18 07:24:42,602] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:24:42,604] {logging_mixin.py:112} INFO - [2022-02-18 07:24:42,603] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:24:43,032] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:24:43,082] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:24:43,087] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:24:43,090] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 07:24:55,856] {scheduler_job.py:155} INFO - Started process (PID=69674) to work on /airflow/dags/download_data.py
[2022-02-18 07:24:55,862] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:24:55,864] {logging_mixin.py:112} INFO - [2022-02-18 07:24:55,864] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:24:56,295] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:24:56,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:24:56,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:24:56,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 07:25:09,145] {scheduler_job.py:155} INFO - Started process (PID=69700) to work on /airflow/dags/download_data.py
[2022-02-18 07:25:09,149] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:25:09,151] {logging_mixin.py:112} INFO - [2022-02-18 07:25:09,150] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:25:09,594] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:25:09,644] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:25:09,654] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:25:09,660] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 07:25:22,441] {scheduler_job.py:155} INFO - Started process (PID=69726) to work on /airflow/dags/download_data.py
[2022-02-18 07:25:22,447] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:25:22,448] {logging_mixin.py:112} INFO - [2022-02-18 07:25:22,448] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:25:22,910] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:25:22,956] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:25:22,965] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:25:22,969] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 07:25:35,679] {scheduler_job.py:155} INFO - Started process (PID=69752) to work on /airflow/dags/download_data.py
[2022-02-18 07:25:35,684] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:25:35,686] {logging_mixin.py:112} INFO - [2022-02-18 07:25:35,686] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:25:36,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:25:36,168] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:25:36,175] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:25:36,179] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 07:25:48,998] {scheduler_job.py:155} INFO - Started process (PID=69778) to work on /airflow/dags/download_data.py
[2022-02-18 07:25:49,006] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:25:49,007] {logging_mixin.py:112} INFO - [2022-02-18 07:25:49,007] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:25:49,453] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:25:49,505] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:25:49,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:25:49,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 07:26:02,293] {scheduler_job.py:155} INFO - Started process (PID=69804) to work on /airflow/dags/download_data.py
[2022-02-18 07:26:02,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:26:02,300] {logging_mixin.py:112} INFO - [2022-02-18 07:26:02,300] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:26:02,742] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:26:02,783] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:26:02,789] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:26:02,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 07:26:15,569] {scheduler_job.py:155} INFO - Started process (PID=69830) to work on /airflow/dags/download_data.py
[2022-02-18 07:26:15,573] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:26:15,575] {logging_mixin.py:112} INFO - [2022-02-18 07:26:15,575] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:26:16,006] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:26:16,047] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:26:16,056] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:26:16,060] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 07:26:28,850] {scheduler_job.py:155} INFO - Started process (PID=69856) to work on /airflow/dags/download_data.py
[2022-02-18 07:26:28,858] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:26:28,860] {logging_mixin.py:112} INFO - [2022-02-18 07:26:28,859] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:26:29,299] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:26:29,350] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:26:29,357] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:26:29,363] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 07:26:42,126] {scheduler_job.py:155} INFO - Started process (PID=69882) to work on /airflow/dags/download_data.py
[2022-02-18 07:26:42,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:26:42,133] {logging_mixin.py:112} INFO - [2022-02-18 07:26:42,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:26:42,568] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:26:42,616] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:26:42,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:26:42,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 07:26:55,451] {scheduler_job.py:155} INFO - Started process (PID=69908) to work on /airflow/dags/download_data.py
[2022-02-18 07:26:55,458] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:26:55,459] {logging_mixin.py:112} INFO - [2022-02-18 07:26:55,459] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:26:55,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:26:55,941] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:26:55,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:26:55,952] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 07:27:08,709] {scheduler_job.py:155} INFO - Started process (PID=69934) to work on /airflow/dags/download_data.py
[2022-02-18 07:27:08,717] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:27:08,719] {logging_mixin.py:112} INFO - [2022-02-18 07:27:08,719] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:27:09,158] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:27:09,209] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:27:09,216] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:27:09,223] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 07:27:22,003] {scheduler_job.py:155} INFO - Started process (PID=69960) to work on /airflow/dags/download_data.py
[2022-02-18 07:27:22,010] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:27:22,011] {logging_mixin.py:112} INFO - [2022-02-18 07:27:22,011] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:27:22,437] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:27:22,488] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:27:22,499] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:27:22,504] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 07:27:35,248] {scheduler_job.py:155} INFO - Started process (PID=69986) to work on /airflow/dags/download_data.py
[2022-02-18 07:27:35,252] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:27:35,253] {logging_mixin.py:112} INFO - [2022-02-18 07:27:35,253] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:27:35,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:27:35,756] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:27:35,765] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:27:35,771] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 07:27:48,551] {scheduler_job.py:155} INFO - Started process (PID=70012) to work on /airflow/dags/download_data.py
[2022-02-18 07:27:48,555] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:27:48,557] {logging_mixin.py:112} INFO - [2022-02-18 07:27:48,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:27:48,985] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:27:49,031] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:27:49,036] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:27:49,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-18 07:28:01,822] {scheduler_job.py:155} INFO - Started process (PID=70038) to work on /airflow/dags/download_data.py
[2022-02-18 07:28:01,826] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:28:01,827] {logging_mixin.py:112} INFO - [2022-02-18 07:28:01,827] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:28:02,261] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:28:02,312] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:28:02,319] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:28:02,324] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 07:28:15,120] {scheduler_job.py:155} INFO - Started process (PID=70064) to work on /airflow/dags/download_data.py
[2022-02-18 07:28:15,126] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:28:15,128] {logging_mixin.py:112} INFO - [2022-02-18 07:28:15,128] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:28:15,559] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:28:15,611] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:28:15,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:28:15,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 07:28:28,374] {scheduler_job.py:155} INFO - Started process (PID=70090) to work on /airflow/dags/download_data.py
[2022-02-18 07:28:28,380] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:28:28,383] {logging_mixin.py:112} INFO - [2022-02-18 07:28:28,382] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:28:28,815] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:28:28,863] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:28:28,874] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:28:28,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 07:28:41,653] {scheduler_job.py:155} INFO - Started process (PID=70116) to work on /airflow/dags/download_data.py
[2022-02-18 07:28:41,657] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:28:41,659] {logging_mixin.py:112} INFO - [2022-02-18 07:28:41,659] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:28:42,112] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:28:42,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:28:42,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:28:42,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 07:28:54,992] {scheduler_job.py:155} INFO - Started process (PID=70142) to work on /airflow/dags/download_data.py
[2022-02-18 07:28:54,997] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:28:54,998] {logging_mixin.py:112} INFO - [2022-02-18 07:28:54,998] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:28:55,430] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:28:55,476] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:28:55,486] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:28:55,490] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 07:29:08,262] {scheduler_job.py:155} INFO - Started process (PID=70168) to work on /airflow/dags/download_data.py
[2022-02-18 07:29:08,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:29:08,267] {logging_mixin.py:112} INFO - [2022-02-18 07:29:08,267] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:29:08,719] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:29:08,763] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:29:08,769] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:29:08,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 07:29:21,579] {scheduler_job.py:155} INFO - Started process (PID=70194) to work on /airflow/dags/download_data.py
[2022-02-18 07:29:21,584] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:29:21,585] {logging_mixin.py:112} INFO - [2022-02-18 07:29:21,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:29:22,019] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:29:22,071] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:29:22,076] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:29:22,080] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 07:29:34,825] {scheduler_job.py:155} INFO - Started process (PID=70220) to work on /airflow/dags/download_data.py
[2022-02-18 07:29:34,831] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:29:34,832] {logging_mixin.py:112} INFO - [2022-02-18 07:29:34,832] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:29:35,272] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:29:35,323] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:29:35,329] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:29:35,335] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 07:29:49,311] {scheduler_job.py:155} INFO - Started process (PID=70246) to work on /airflow/dags/download_data.py
[2022-02-18 07:29:49,319] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 07:29:49,321] {logging_mixin.py:112} INFO - [2022-02-18 07:29:49,321] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 07:29:50,072] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 07:29:50,119] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 07:29:50,128] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 07:29:50,136] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.825 seconds
[2022-02-18 08:30:07,594] {scheduler_job.py:155} INFO - Started process (PID=70272) to work on /airflow/dags/download_data.py
[2022-02-18 08:30:07,628] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:30:07,635] {logging_mixin.py:112} INFO - [2022-02-18 08:30:07,634] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:30:08,605] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:30:08,671] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:30:08,683] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:30:08,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.097 seconds
[2022-02-18 08:30:20,877] {scheduler_job.py:155} INFO - Started process (PID=70298) to work on /airflow/dags/download_data.py
[2022-02-18 08:30:20,882] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:30:20,884] {logging_mixin.py:112} INFO - [2022-02-18 08:30:20,884] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:30:21,327] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:30:21,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:30:21,385] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:30:21,390] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 08:30:34,149] {scheduler_job.py:155} INFO - Started process (PID=70324) to work on /airflow/dags/download_data.py
[2022-02-18 08:30:34,156] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:30:34,157] {logging_mixin.py:112} INFO - [2022-02-18 08:30:34,157] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:30:34,603] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:30:34,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:30:34,674] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:30:34,680] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 08:30:47,454] {scheduler_job.py:155} INFO - Started process (PID=70350) to work on /airflow/dags/download_data.py
[2022-02-18 08:30:47,459] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:30:47,461] {logging_mixin.py:112} INFO - [2022-02-18 08:30:47,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:30:47,905] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:30:47,950] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:30:47,959] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:30:47,962] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 08:31:00,702] {scheduler_job.py:155} INFO - Started process (PID=70376) to work on /airflow/dags/download_data.py
[2022-02-18 08:31:00,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:31:00,711] {logging_mixin.py:112} INFO - [2022-02-18 08:31:00,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:31:01,141] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:31:01,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:31:01,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:31:01,193] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 08:31:13,991] {scheduler_job.py:155} INFO - Started process (PID=70402) to work on /airflow/dags/download_data.py
[2022-02-18 08:31:13,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:31:14,001] {logging_mixin.py:112} INFO - [2022-02-18 08:31:14,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:31:14,430] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:31:14,479] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:31:14,486] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:31:14,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 08:31:27,290] {scheduler_job.py:155} INFO - Started process (PID=70428) to work on /airflow/dags/download_data.py
[2022-02-18 08:31:27,298] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:31:27,301] {logging_mixin.py:112} INFO - [2022-02-18 08:31:27,300] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:31:27,729] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:31:27,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:31:27,784] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:31:27,789] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 08:31:40,547] {scheduler_job.py:155} INFO - Started process (PID=70454) to work on /airflow/dags/download_data.py
[2022-02-18 08:31:40,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:31:40,556] {logging_mixin.py:112} INFO - [2022-02-18 08:31:40,555] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:31:40,984] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:31:41,033] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:31:41,041] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:31:41,046] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 08:31:53,843] {scheduler_job.py:155} INFO - Started process (PID=70480) to work on /airflow/dags/download_data.py
[2022-02-18 08:31:53,850] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:31:53,852] {logging_mixin.py:112} INFO - [2022-02-18 08:31:53,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:31:54,315] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:31:54,357] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:31:54,362] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:31:54,367] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 08:32:07,072] {scheduler_job.py:155} INFO - Started process (PID=70506) to work on /airflow/dags/download_data.py
[2022-02-18 08:32:07,079] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:32:07,081] {logging_mixin.py:112} INFO - [2022-02-18 08:32:07,081] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:32:07,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:32:07,577] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:32:07,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:32:07,593] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 08:32:20,388] {scheduler_job.py:155} INFO - Started process (PID=70532) to work on /airflow/dags/download_data.py
[2022-02-18 08:32:20,393] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:32:20,394] {logging_mixin.py:112} INFO - [2022-02-18 08:32:20,394] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:32:20,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:32:20,896] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:32:20,903] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:32:20,908] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 08:32:33,690] {scheduler_job.py:155} INFO - Started process (PID=70558) to work on /airflow/dags/download_data.py
[2022-02-18 08:32:33,697] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:32:33,699] {logging_mixin.py:112} INFO - [2022-02-18 08:32:33,699] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:32:34,145] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:32:34,199] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:32:34,210] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:32:34,216] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 08:32:47,006] {scheduler_job.py:155} INFO - Started process (PID=70584) to work on /airflow/dags/download_data.py
[2022-02-18 08:32:47,014] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:32:47,016] {logging_mixin.py:112} INFO - [2022-02-18 08:32:47,015] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:32:47,464] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:32:47,517] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:32:47,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:32:47,532] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 08:33:00,278] {scheduler_job.py:155} INFO - Started process (PID=70610) to work on /airflow/dags/download_data.py
[2022-02-18 08:33:00,284] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:33:00,286] {logging_mixin.py:112} INFO - [2022-02-18 08:33:00,285] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:33:00,722] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:33:00,771] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:33:00,781] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:33:00,785] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 08:33:13,570] {scheduler_job.py:155} INFO - Started process (PID=70636) to work on /airflow/dags/download_data.py
[2022-02-18 08:33:13,574] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:33:13,575] {logging_mixin.py:112} INFO - [2022-02-18 08:33:13,575] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:33:14,014] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:33:14,062] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:33:14,072] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:33:14,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 08:33:26,838] {scheduler_job.py:155} INFO - Started process (PID=70662) to work on /airflow/dags/download_data.py
[2022-02-18 08:33:26,843] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:33:26,845] {logging_mixin.py:112} INFO - [2022-02-18 08:33:26,844] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:33:27,290] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:33:27,339] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:33:27,349] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:33:27,355] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 08:33:40,144] {scheduler_job.py:155} INFO - Started process (PID=70688) to work on /airflow/dags/download_data.py
[2022-02-18 08:33:40,149] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:33:40,151] {logging_mixin.py:112} INFO - [2022-02-18 08:33:40,150] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:33:40,578] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:33:40,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:33:40,635] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:33:40,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 08:33:53,452] {scheduler_job.py:155} INFO - Started process (PID=70714) to work on /airflow/dags/download_data.py
[2022-02-18 08:33:53,456] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:33:53,458] {logging_mixin.py:112} INFO - [2022-02-18 08:33:53,458] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:33:53,912] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:33:53,964] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:33:53,973] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:33:53,979] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 08:34:06,696] {scheduler_job.py:155} INFO - Started process (PID=70740) to work on /airflow/dags/download_data.py
[2022-02-18 08:34:06,702] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:34:06,703] {logging_mixin.py:112} INFO - [2022-02-18 08:34:06,703] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:34:07,152] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:34:07,199] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:34:07,209] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:34:07,215] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 08:34:20,006] {scheduler_job.py:155} INFO - Started process (PID=70766) to work on /airflow/dags/download_data.py
[2022-02-18 08:34:20,011] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:34:20,012] {logging_mixin.py:112} INFO - [2022-02-18 08:34:20,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:34:20,455] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:34:20,505] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:34:20,512] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:34:20,517] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 08:34:33,248] {scheduler_job.py:155} INFO - Started process (PID=70792) to work on /airflow/dags/download_data.py
[2022-02-18 08:34:33,252] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:34:33,253] {logging_mixin.py:112} INFO - [2022-02-18 08:34:33,253] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:34:33,735] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:34:33,793] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:34:33,803] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:34:33,808] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 08:34:46,571] {scheduler_job.py:155} INFO - Started process (PID=70818) to work on /airflow/dags/download_data.py
[2022-02-18 08:34:46,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:34:46,579] {logging_mixin.py:112} INFO - [2022-02-18 08:34:46,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:34:47,008] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:34:47,053] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:34:47,060] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:34:47,064] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 08:34:59,867] {scheduler_job.py:155} INFO - Started process (PID=70844) to work on /airflow/dags/download_data.py
[2022-02-18 08:34:59,876] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:34:59,878] {logging_mixin.py:112} INFO - [2022-02-18 08:34:59,878] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:35:00,302] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:35:00,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:35:00,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:35:00,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-18 08:35:13,163] {scheduler_job.py:155} INFO - Started process (PID=70870) to work on /airflow/dags/download_data.py
[2022-02-18 08:35:13,168] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:35:13,170] {logging_mixin.py:112} INFO - [2022-02-18 08:35:13,169] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:35:13,612] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:35:13,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:35:13,671] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:35:13,676] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 08:35:26,469] {scheduler_job.py:155} INFO - Started process (PID=70896) to work on /airflow/dags/download_data.py
[2022-02-18 08:35:26,476] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:35:26,478] {logging_mixin.py:112} INFO - [2022-02-18 08:35:26,478] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:35:26,906] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:35:26,956] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:35:26,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:35:26,976] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 08:35:39,691] {scheduler_job.py:155} INFO - Started process (PID=70922) to work on /airflow/dags/download_data.py
[2022-02-18 08:35:39,697] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:35:39,699] {logging_mixin.py:112} INFO - [2022-02-18 08:35:39,698] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:35:40,142] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:35:40,191] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:35:40,199] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:35:40,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 08:35:53,022] {scheduler_job.py:155} INFO - Started process (PID=70948) to work on /airflow/dags/download_data.py
[2022-02-18 08:35:53,028] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:35:53,030] {logging_mixin.py:112} INFO - [2022-02-18 08:35:53,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:35:53,465] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:35:53,507] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:35:53,513] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:35:53,517] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 08:36:06,275] {scheduler_job.py:155} INFO - Started process (PID=70974) to work on /airflow/dags/download_data.py
[2022-02-18 08:36:06,281] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:36:06,284] {logging_mixin.py:112} INFO - [2022-02-18 08:36:06,283] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:36:06,712] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:36:06,753] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:36:06,758] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:36:06,762] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-18 08:36:19,581] {scheduler_job.py:155} INFO - Started process (PID=71000) to work on /airflow/dags/download_data.py
[2022-02-18 08:36:19,587] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:36:19,588] {logging_mixin.py:112} INFO - [2022-02-18 08:36:19,588] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:36:20,016] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:36:20,068] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:36:20,076] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:36:20,082] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 08:36:32,834] {scheduler_job.py:155} INFO - Started process (PID=71026) to work on /airflow/dags/download_data.py
[2022-02-18 08:36:32,838] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:36:32,841] {logging_mixin.py:112} INFO - [2022-02-18 08:36:32,841] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:36:33,294] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:36:33,350] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:36:33,364] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:36:33,370] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 08:36:46,183] {scheduler_job.py:155} INFO - Started process (PID=71052) to work on /airflow/dags/download_data.py
[2022-02-18 08:36:46,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:36:46,191] {logging_mixin.py:112} INFO - [2022-02-18 08:36:46,190] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:36:46,632] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:36:46,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:36:46,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:36:46,703] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 08:36:59,509] {scheduler_job.py:155} INFO - Started process (PID=71078) to work on /airflow/dags/download_data.py
[2022-02-18 08:36:59,512] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:36:59,514] {logging_mixin.py:112} INFO - [2022-02-18 08:36:59,514] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:36:59,956] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:36:59,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:36:59,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:36:59,988] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.479 seconds
[2022-02-18 08:37:12,754] {scheduler_job.py:155} INFO - Started process (PID=71104) to work on /airflow/dags/download_data.py
[2022-02-18 08:37:12,759] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:37:12,761] {logging_mixin.py:112} INFO - [2022-02-18 08:37:12,761] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:37:13,203] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:37:13,253] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:37:13,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:37:13,267] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 08:37:26,039] {scheduler_job.py:155} INFO - Started process (PID=71130) to work on /airflow/dags/download_data.py
[2022-02-18 08:37:26,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:37:26,046] {logging_mixin.py:112} INFO - [2022-02-18 08:37:26,045] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:37:26,501] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:37:26,550] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:37:26,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:37:26,569] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 08:37:39,304] {scheduler_job.py:155} INFO - Started process (PID=71156) to work on /airflow/dags/download_data.py
[2022-02-18 08:37:39,308] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:37:39,310] {logging_mixin.py:112} INFO - [2022-02-18 08:37:39,310] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:37:39,749] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:37:39,795] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:37:39,801] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:37:39,805] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 08:37:52,604] {scheduler_job.py:155} INFO - Started process (PID=71182) to work on /airflow/dags/download_data.py
[2022-02-18 08:37:52,609] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:37:52,611] {logging_mixin.py:112} INFO - [2022-02-18 08:37:52,610] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:37:53,048] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:37:53,096] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:37:53,103] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:37:53,109] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 08:38:05,877] {scheduler_job.py:155} INFO - Started process (PID=71208) to work on /airflow/dags/download_data.py
[2022-02-18 08:38:05,881] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:38:05,883] {logging_mixin.py:112} INFO - [2022-02-18 08:38:05,883] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:38:06,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:38:06,392] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:38:06,402] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:38:06,408] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 08:38:19,205] {scheduler_job.py:155} INFO - Started process (PID=71234) to work on /airflow/dags/download_data.py
[2022-02-18 08:38:19,209] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:38:19,211] {logging_mixin.py:112} INFO - [2022-02-18 08:38:19,211] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:38:19,669] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:38:19,721] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:38:19,731] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:38:19,734] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 08:38:32,466] {scheduler_job.py:155} INFO - Started process (PID=71260) to work on /airflow/dags/download_data.py
[2022-02-18 08:38:32,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:38:32,472] {logging_mixin.py:112} INFO - [2022-02-18 08:38:32,471] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:38:32,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:38:32,949] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:38:32,954] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:38:32,958] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 08:38:45,773] {scheduler_job.py:155} INFO - Started process (PID=71286) to work on /airflow/dags/download_data.py
[2022-02-18 08:38:45,778] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:38:45,779] {logging_mixin.py:112} INFO - [2022-02-18 08:38:45,779] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:38:46,225] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:38:46,271] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:38:46,281] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:38:46,286] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 08:38:59,068] {scheduler_job.py:155} INFO - Started process (PID=71312) to work on /airflow/dags/download_data.py
[2022-02-18 08:38:59,072] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:38:59,073] {logging_mixin.py:112} INFO - [2022-02-18 08:38:59,073] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:38:59,514] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:38:59,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:38:59,564] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:38:59,569] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 08:39:12,343] {scheduler_job.py:155} INFO - Started process (PID=71338) to work on /airflow/dags/download_data.py
[2022-02-18 08:39:12,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:39:12,352] {logging_mixin.py:112} INFO - [2022-02-18 08:39:12,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:39:12,781] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:39:12,835] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:39:12,841] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:39:12,847] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 08:39:25,655] {scheduler_job.py:155} INFO - Started process (PID=71364) to work on /airflow/dags/download_data.py
[2022-02-18 08:39:25,663] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:39:25,665] {logging_mixin.py:112} INFO - [2022-02-18 08:39:25,665] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:39:26,102] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:39:26,150] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:39:26,157] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:39:26,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 08:39:38,913] {scheduler_job.py:155} INFO - Started process (PID=71390) to work on /airflow/dags/download_data.py
[2022-02-18 08:39:38,919] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:39:38,920] {logging_mixin.py:112} INFO - [2022-02-18 08:39:38,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:39:39,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:39:39,392] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:39:39,401] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:39:39,407] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 08:39:52,216] {scheduler_job.py:155} INFO - Started process (PID=71416) to work on /airflow/dags/download_data.py
[2022-02-18 08:39:52,224] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:39:52,228] {logging_mixin.py:112} INFO - [2022-02-18 08:39:52,228] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:39:52,655] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:39:52,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:39:52,708] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:39:52,711] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 08:40:05,462] {scheduler_job.py:155} INFO - Started process (PID=71442) to work on /airflow/dags/download_data.py
[2022-02-18 08:40:05,467] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:40:05,469] {logging_mixin.py:112} INFO - [2022-02-18 08:40:05,469] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:40:05,924] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:40:05,965] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:40:05,975] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:40:05,979] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 08:40:18,764] {scheduler_job.py:155} INFO - Started process (PID=71468) to work on /airflow/dags/download_data.py
[2022-02-18 08:40:18,767] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:40:18,770] {logging_mixin.py:112} INFO - [2022-02-18 08:40:18,769] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:40:19,196] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:40:19,245] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:40:19,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:40:19,256] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 08:40:32,050] {scheduler_job.py:155} INFO - Started process (PID=71494) to work on /airflow/dags/download_data.py
[2022-02-18 08:40:32,056] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:40:32,058] {logging_mixin.py:112} INFO - [2022-02-18 08:40:32,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:40:32,489] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:40:32,540] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:40:32,548] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:40:32,553] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 08:40:45,351] {scheduler_job.py:155} INFO - Started process (PID=71520) to work on /airflow/dags/download_data.py
[2022-02-18 08:40:45,355] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:40:45,357] {logging_mixin.py:112} INFO - [2022-02-18 08:40:45,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:40:45,788] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:40:45,837] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:40:45,843] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:40:45,848] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 08:40:58,694] {scheduler_job.py:155} INFO - Started process (PID=71546) to work on /airflow/dags/download_data.py
[2022-02-18 08:40:58,703] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:40:58,705] {logging_mixin.py:112} INFO - [2022-02-18 08:40:58,705] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:40:59,131] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:40:59,175] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:40:59,181] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:40:59,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 08:41:11,975] {scheduler_job.py:155} INFO - Started process (PID=71572) to work on /airflow/dags/download_data.py
[2022-02-18 08:41:11,979] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:41:11,981] {logging_mixin.py:112} INFO - [2022-02-18 08:41:11,981] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:41:12,423] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:41:12,473] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:41:12,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:41:12,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 08:41:25,287] {scheduler_job.py:155} INFO - Started process (PID=71598) to work on /airflow/dags/download_data.py
[2022-02-18 08:41:25,292] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:41:25,294] {logging_mixin.py:112} INFO - [2022-02-18 08:41:25,293] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:41:25,755] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:41:25,811] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:41:25,819] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:41:25,824] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 08:41:38,592] {scheduler_job.py:155} INFO - Started process (PID=71624) to work on /airflow/dags/download_data.py
[2022-02-18 08:41:38,596] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:41:38,598] {logging_mixin.py:112} INFO - [2022-02-18 08:41:38,598] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:41:39,021] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:41:39,069] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:41:39,076] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:41:39,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-18 08:41:51,909] {scheduler_job.py:155} INFO - Started process (PID=71650) to work on /airflow/dags/download_data.py
[2022-02-18 08:41:51,915] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:41:51,918] {logging_mixin.py:112} INFO - [2022-02-18 08:41:51,917] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:41:52,352] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:41:52,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:41:52,409] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:41:52,415] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 08:42:05,148] {scheduler_job.py:155} INFO - Started process (PID=71676) to work on /airflow/dags/download_data.py
[2022-02-18 08:42:05,154] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:42:05,156] {logging_mixin.py:112} INFO - [2022-02-18 08:42:05,156] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:42:05,614] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:42:05,677] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:42:05,690] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:42:05,698] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 08:42:18,451] {scheduler_job.py:155} INFO - Started process (PID=71702) to work on /airflow/dags/download_data.py
[2022-02-18 08:42:18,458] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:42:18,461] {logging_mixin.py:112} INFO - [2022-02-18 08:42:18,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:42:18,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:42:18,941] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:42:18,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:42:18,953] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 08:42:31,751] {scheduler_job.py:155} INFO - Started process (PID=71728) to work on /airflow/dags/download_data.py
[2022-02-18 08:42:31,755] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:42:31,759] {logging_mixin.py:112} INFO - [2022-02-18 08:42:31,758] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:42:32,185] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:42:32,227] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:42:32,236] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:42:32,241] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-18 08:42:45,030] {scheduler_job.py:155} INFO - Started process (PID=71754) to work on /airflow/dags/download_data.py
[2022-02-18 08:42:45,036] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:42:45,037] {logging_mixin.py:112} INFO - [2022-02-18 08:42:45,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:42:45,471] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:42:45,528] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:42:45,535] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:42:45,540] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 08:42:58,347] {scheduler_job.py:155} INFO - Started process (PID=71780) to work on /airflow/dags/download_data.py
[2022-02-18 08:42:58,353] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:42:58,355] {logging_mixin.py:112} INFO - [2022-02-18 08:42:58,355] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:42:58,788] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:42:58,827] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:42:58,836] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:42:58,841] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 08:43:11,601] {scheduler_job.py:155} INFO - Started process (PID=71806) to work on /airflow/dags/download_data.py
[2022-02-18 08:43:11,605] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:43:11,607] {logging_mixin.py:112} INFO - [2022-02-18 08:43:11,606] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:43:12,042] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:43:12,084] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:43:12,091] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:43:12,095] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 08:43:24,956] {scheduler_job.py:155} INFO - Started process (PID=71832) to work on /airflow/dags/download_data.py
[2022-02-18 08:43:24,963] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:43:24,964] {logging_mixin.py:112} INFO - [2022-02-18 08:43:24,964] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:43:25,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:43:25,462] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:43:25,471] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:43:25,477] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 08:43:38,236] {scheduler_job.py:155} INFO - Started process (PID=71858) to work on /airflow/dags/download_data.py
[2022-02-18 08:43:38,240] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:43:38,242] {logging_mixin.py:112} INFO - [2022-02-18 08:43:38,242] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:43:38,685] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:43:38,733] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:43:38,742] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:43:38,749] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 08:43:51,549] {scheduler_job.py:155} INFO - Started process (PID=71884) to work on /airflow/dags/download_data.py
[2022-02-18 08:43:51,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:43:51,556] {logging_mixin.py:112} INFO - [2022-02-18 08:43:51,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:43:51,999] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:43:52,049] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:43:52,056] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:43:52,060] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 08:44:04,830] {scheduler_job.py:155} INFO - Started process (PID=71910) to work on /airflow/dags/download_data.py
[2022-02-18 08:44:04,837] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:44:04,839] {logging_mixin.py:112} INFO - [2022-02-18 08:44:04,839] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:44:05,291] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:44:05,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:44:05,353] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:44:05,358] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 08:44:18,120] {scheduler_job.py:155} INFO - Started process (PID=71936) to work on /airflow/dags/download_data.py
[2022-02-18 08:44:18,126] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:44:18,129] {logging_mixin.py:112} INFO - [2022-02-18 08:44:18,128] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:44:18,568] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:44:18,621] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:44:18,629] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:44:18,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 08:44:31,378] {scheduler_job.py:155} INFO - Started process (PID=71962) to work on /airflow/dags/download_data.py
[2022-02-18 08:44:31,382] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:44:31,383] {logging_mixin.py:112} INFO - [2022-02-18 08:44:31,383] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:44:31,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:44:31,872] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:44:31,879] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:44:31,884] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 08:44:44,710] {scheduler_job.py:155} INFO - Started process (PID=71988) to work on /airflow/dags/download_data.py
[2022-02-18 08:44:44,719] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:44:44,721] {logging_mixin.py:112} INFO - [2022-02-18 08:44:44,721] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:44:45,152] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:44:45,202] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:44:45,209] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:44:45,214] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 08:44:58,038] {scheduler_job.py:155} INFO - Started process (PID=72014) to work on /airflow/dags/download_data.py
[2022-02-18 08:44:58,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:44:58,048] {logging_mixin.py:112} INFO - [2022-02-18 08:44:58,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:44:58,475] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:44:58,528] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:44:58,534] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:44:58,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 08:45:11,321] {scheduler_job.py:155} INFO - Started process (PID=72040) to work on /airflow/dags/download_data.py
[2022-02-18 08:45:11,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:45:11,327] {logging_mixin.py:112} INFO - [2022-02-18 08:45:11,327] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:45:11,763] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:45:11,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:45:11,819] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:45:11,824] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 08:45:24,605] {scheduler_job.py:155} INFO - Started process (PID=72066) to work on /airflow/dags/download_data.py
[2022-02-18 08:45:24,612] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:45:24,615] {logging_mixin.py:112} INFO - [2022-02-18 08:45:24,615] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:45:25,061] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:45:25,104] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:45:25,110] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:45:25,116] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 08:45:37,876] {scheduler_job.py:155} INFO - Started process (PID=72092) to work on /airflow/dags/download_data.py
[2022-02-18 08:45:37,882] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:45:37,883] {logging_mixin.py:112} INFO - [2022-02-18 08:45:37,883] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:45:38,307] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:45:38,354] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:45:38,361] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:45:38,366] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-18 08:45:51,193] {scheduler_job.py:155} INFO - Started process (PID=72118) to work on /airflow/dags/download_data.py
[2022-02-18 08:45:51,197] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:45:51,205] {logging_mixin.py:112} INFO - [2022-02-18 08:45:51,205] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:45:51,646] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:45:51,695] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:45:51,704] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:45:51,711] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 08:46:04,465] {scheduler_job.py:155} INFO - Started process (PID=72144) to work on /airflow/dags/download_data.py
[2022-02-18 08:46:04,471] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:46:04,472] {logging_mixin.py:112} INFO - [2022-02-18 08:46:04,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:46:04,932] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:46:04,991] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:46:05,000] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:46:05,006] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 08:46:17,758] {scheduler_job.py:155} INFO - Started process (PID=72170) to work on /airflow/dags/download_data.py
[2022-02-18 08:46:17,766] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:46:17,768] {logging_mixin.py:112} INFO - [2022-02-18 08:46:17,767] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:46:18,200] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:46:18,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:46:18,256] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:46:18,260] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 08:46:31,034] {scheduler_job.py:155} INFO - Started process (PID=72196) to work on /airflow/dags/download_data.py
[2022-02-18 08:46:31,040] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:46:31,044] {logging_mixin.py:112} INFO - [2022-02-18 08:46:31,043] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:46:31,488] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:46:31,539] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:46:31,545] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:46:31,548] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 08:46:44,328] {scheduler_job.py:155} INFO - Started process (PID=72222) to work on /airflow/dags/download_data.py
[2022-02-18 08:46:44,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:46:44,335] {logging_mixin.py:112} INFO - [2022-02-18 08:46:44,335] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:46:44,764] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:46:44,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:46:44,823] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:46:44,828] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 08:46:57,628] {scheduler_job.py:155} INFO - Started process (PID=72248) to work on /airflow/dags/download_data.py
[2022-02-18 08:46:57,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:46:57,635] {logging_mixin.py:112} INFO - [2022-02-18 08:46:57,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:46:58,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:46:58,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:46:58,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:46:58,147] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 08:47:10,897] {scheduler_job.py:155} INFO - Started process (PID=72274) to work on /airflow/dags/download_data.py
[2022-02-18 08:47:10,901] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:47:10,903] {logging_mixin.py:112} INFO - [2022-02-18 08:47:10,902] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:47:11,335] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:47:11,382] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:47:11,390] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:47:11,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 08:47:24,202] {scheduler_job.py:155} INFO - Started process (PID=72300) to work on /airflow/dags/download_data.py
[2022-02-18 08:47:24,212] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:47:24,215] {logging_mixin.py:112} INFO - [2022-02-18 08:47:24,214] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:47:24,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:47:24,713] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:47:24,721] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:47:24,726] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 08:47:37,466] {scheduler_job.py:155} INFO - Started process (PID=72326) to work on /airflow/dags/download_data.py
[2022-02-18 08:47:37,474] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:47:37,476] {logging_mixin.py:112} INFO - [2022-02-18 08:47:37,476] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:47:37,902] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:47:37,956] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:47:37,966] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:47:37,973] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 08:47:50,758] {scheduler_job.py:155} INFO - Started process (PID=72352) to work on /airflow/dags/download_data.py
[2022-02-18 08:47:50,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:47:50,766] {logging_mixin.py:112} INFO - [2022-02-18 08:47:50,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:47:51,222] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:47:51,274] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:47:51,284] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:47:51,291] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 08:48:04,058] {scheduler_job.py:155} INFO - Started process (PID=72378) to work on /airflow/dags/download_data.py
[2022-02-18 08:48:04,064] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:48:04,066] {logging_mixin.py:112} INFO - [2022-02-18 08:48:04,066] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:48:04,521] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:48:04,585] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:48:04,597] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:48:04,605] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 08:48:17,343] {scheduler_job.py:155} INFO - Started process (PID=72404) to work on /airflow/dags/download_data.py
[2022-02-18 08:48:17,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:48:17,349] {logging_mixin.py:112} INFO - [2022-02-18 08:48:17,349] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:48:17,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:48:17,834] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:48:17,842] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:48:17,847] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 08:48:30,617] {scheduler_job.py:155} INFO - Started process (PID=72430) to work on /airflow/dags/download_data.py
[2022-02-18 08:48:30,627] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:48:30,631] {logging_mixin.py:112} INFO - [2022-02-18 08:48:30,631] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:48:31,072] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:48:31,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:48:31,130] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:48:31,135] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 08:48:43,923] {scheduler_job.py:155} INFO - Started process (PID=72456) to work on /airflow/dags/download_data.py
[2022-02-18 08:48:43,929] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:48:43,931] {logging_mixin.py:112} INFO - [2022-02-18 08:48:43,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:48:44,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:48:44,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:48:44,417] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:48:44,422] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 08:48:57,218] {scheduler_job.py:155} INFO - Started process (PID=72482) to work on /airflow/dags/download_data.py
[2022-02-18 08:48:57,222] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:48:57,224] {logging_mixin.py:112} INFO - [2022-02-18 08:48:57,224] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:48:57,658] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:48:57,699] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:48:57,706] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:48:57,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 08:49:10,507] {scheduler_job.py:155} INFO - Started process (PID=72508) to work on /airflow/dags/download_data.py
[2022-02-18 08:49:10,512] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:49:10,514] {logging_mixin.py:112} INFO - [2022-02-18 08:49:10,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:49:10,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:49:10,999] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:49:11,007] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:49:11,013] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 08:49:23,748] {scheduler_job.py:155} INFO - Started process (PID=72534) to work on /airflow/dags/download_data.py
[2022-02-18 08:49:23,752] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:49:23,754] {logging_mixin.py:112} INFO - [2022-02-18 08:49:23,754] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:49:24,298] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:49:24,348] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:49:24,353] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:49:24,357] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-18 08:49:37,036] {scheduler_job.py:155} INFO - Started process (PID=72560) to work on /airflow/dags/download_data.py
[2022-02-18 08:49:37,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:49:37,046] {logging_mixin.py:112} INFO - [2022-02-18 08:49:37,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:49:37,478] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:49:37,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:49:37,538] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:49:37,543] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 08:49:50,326] {scheduler_job.py:155} INFO - Started process (PID=72586) to work on /airflow/dags/download_data.py
[2022-02-18 08:49:50,334] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:49:50,336] {logging_mixin.py:112} INFO - [2022-02-18 08:49:50,336] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:49:50,783] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:49:50,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:49:50,837] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:49:50,842] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 08:50:03,655] {scheduler_job.py:155} INFO - Started process (PID=72612) to work on /airflow/dags/download_data.py
[2022-02-18 08:50:03,662] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:50:03,664] {logging_mixin.py:112} INFO - [2022-02-18 08:50:03,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:50:04,107] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:50:04,149] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:50:04,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:50:04,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 08:50:16,966] {scheduler_job.py:155} INFO - Started process (PID=72638) to work on /airflow/dags/download_data.py
[2022-02-18 08:50:16,974] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:50:16,976] {logging_mixin.py:112} INFO - [2022-02-18 08:50:16,975] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:50:17,416] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:50:17,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:50:17,473] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:50:17,479] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 08:50:30,265] {scheduler_job.py:155} INFO - Started process (PID=72664) to work on /airflow/dags/download_data.py
[2022-02-18 08:50:30,274] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:50:30,276] {logging_mixin.py:112} INFO - [2022-02-18 08:50:30,276] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:50:30,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:50:30,761] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:50:30,772] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:50:30,779] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 08:50:43,551] {scheduler_job.py:155} INFO - Started process (PID=72690) to work on /airflow/dags/download_data.py
[2022-02-18 08:50:43,558] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:50:43,560] {logging_mixin.py:112} INFO - [2022-02-18 08:50:43,559] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:50:44,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:50:44,080] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:50:44,087] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:50:44,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 08:50:56,881] {scheduler_job.py:155} INFO - Started process (PID=72716) to work on /airflow/dags/download_data.py
[2022-02-18 08:50:56,892] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:50:56,894] {logging_mixin.py:112} INFO - [2022-02-18 08:50:56,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:50:57,328] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:50:57,380] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:50:57,389] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:50:57,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 08:51:10,184] {scheduler_job.py:155} INFO - Started process (PID=72742) to work on /airflow/dags/download_data.py
[2022-02-18 08:51:10,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:51:10,191] {logging_mixin.py:112} INFO - [2022-02-18 08:51:10,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:51:10,628] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:51:10,677] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:51:10,686] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:51:10,692] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 08:51:23,497] {scheduler_job.py:155} INFO - Started process (PID=72768) to work on /airflow/dags/download_data.py
[2022-02-18 08:51:23,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:51:23,504] {logging_mixin.py:112} INFO - [2022-02-18 08:51:23,504] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:51:23,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:51:24,007] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:51:24,015] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:51:24,020] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 08:51:36,777] {scheduler_job.py:155} INFO - Started process (PID=72794) to work on /airflow/dags/download_data.py
[2022-02-18 08:51:36,782] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:51:36,784] {logging_mixin.py:112} INFO - [2022-02-18 08:51:36,784] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:51:37,237] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:51:37,287] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:51:37,295] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:51:37,300] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 08:51:50,077] {scheduler_job.py:155} INFO - Started process (PID=72820) to work on /airflow/dags/download_data.py
[2022-02-18 08:51:50,081] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:51:50,084] {logging_mixin.py:112} INFO - [2022-02-18 08:51:50,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:51:50,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:51:50,590] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:51:50,597] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:51:50,602] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 08:52:03,353] {scheduler_job.py:155} INFO - Started process (PID=72846) to work on /airflow/dags/download_data.py
[2022-02-18 08:52:03,365] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:52:03,367] {logging_mixin.py:112} INFO - [2022-02-18 08:52:03,367] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:52:03,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:52:03,868] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:52:03,877] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:52:03,886] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 08:52:16,690] {scheduler_job.py:155} INFO - Started process (PID=72872) to work on /airflow/dags/download_data.py
[2022-02-18 08:52:16,699] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:52:16,702] {logging_mixin.py:112} INFO - [2022-02-18 08:52:16,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:52:17,145] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:52:17,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:52:17,205] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:52:17,210] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 08:52:29,951] {scheduler_job.py:155} INFO - Started process (PID=72898) to work on /airflow/dags/download_data.py
[2022-02-18 08:52:29,955] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:52:29,957] {logging_mixin.py:112} INFO - [2022-02-18 08:52:29,957] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:52:30,403] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:52:30,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:52:30,462] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:52:30,465] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 08:52:43,274] {scheduler_job.py:155} INFO - Started process (PID=72924) to work on /airflow/dags/download_data.py
[2022-02-18 08:52:43,280] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:52:43,281] {logging_mixin.py:112} INFO - [2022-02-18 08:52:43,281] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:52:43,716] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:52:43,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:52:43,769] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:52:43,775] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 08:52:56,547] {scheduler_job.py:155} INFO - Started process (PID=72950) to work on /airflow/dags/download_data.py
[2022-02-18 08:52:56,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:52:56,557] {logging_mixin.py:112} INFO - [2022-02-18 08:52:56,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:52:56,988] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:52:57,036] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:52:57,043] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:52:57,048] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 08:53:09,847] {scheduler_job.py:155} INFO - Started process (PID=72976) to work on /airflow/dags/download_data.py
[2022-02-18 08:53:09,851] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:53:09,852] {logging_mixin.py:112} INFO - [2022-02-18 08:53:09,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:53:10,286] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:53:10,338] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:53:10,349] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:53:10,353] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 08:53:23,133] {scheduler_job.py:155} INFO - Started process (PID=73002) to work on /airflow/dags/download_data.py
[2022-02-18 08:53:23,143] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:53:23,145] {logging_mixin.py:112} INFO - [2022-02-18 08:53:23,145] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:53:23,589] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:53:23,639] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:53:23,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:53:23,650] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 08:53:36,432] {scheduler_job.py:155} INFO - Started process (PID=73028) to work on /airflow/dags/download_data.py
[2022-02-18 08:53:36,439] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:53:36,441] {logging_mixin.py:112} INFO - [2022-02-18 08:53:36,441] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:53:36,872] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:53:36,916] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:53:36,921] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:53:36,925] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 08:53:49,734] {scheduler_job.py:155} INFO - Started process (PID=73054) to work on /airflow/dags/download_data.py
[2022-02-18 08:53:49,744] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:53:49,746] {logging_mixin.py:112} INFO - [2022-02-18 08:53:49,746] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:53:50,185] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:53:50,234] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:53:50,241] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:53:50,247] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 08:54:02,964] {scheduler_job.py:155} INFO - Started process (PID=73080) to work on /airflow/dags/download_data.py
[2022-02-18 08:54:02,972] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:54:02,974] {logging_mixin.py:112} INFO - [2022-02-18 08:54:02,974] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:54:03,430] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:54:03,491] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:54:03,499] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:54:03,504] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 08:54:16,307] {scheduler_job.py:155} INFO - Started process (PID=73106) to work on /airflow/dags/download_data.py
[2022-02-18 08:54:16,314] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:54:16,316] {logging_mixin.py:112} INFO - [2022-02-18 08:54:16,316] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:54:16,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:54:16,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:54:16,810] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:54:16,813] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 08:54:29,805] {scheduler_job.py:155} INFO - Started process (PID=73132) to work on /airflow/dags/download_data.py
[2022-02-18 08:54:29,813] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:54:29,815] {logging_mixin.py:112} INFO - [2022-02-18 08:54:29,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:54:30,245] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:54:30,299] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:54:30,308] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:54:30,315] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 08:54:43,136] {scheduler_job.py:155} INFO - Started process (PID=73158) to work on /airflow/dags/download_data.py
[2022-02-18 08:54:43,142] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:54:43,143] {logging_mixin.py:112} INFO - [2022-02-18 08:54:43,143] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:54:43,600] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:54:43,649] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:54:43,656] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:54:43,664] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 08:54:56,459] {scheduler_job.py:155} INFO - Started process (PID=73184) to work on /airflow/dags/download_data.py
[2022-02-18 08:54:56,467] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:54:56,472] {logging_mixin.py:112} INFO - [2022-02-18 08:54:56,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:54:56,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:54:56,959] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:54:56,964] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:54:56,968] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 08:55:09,754] {scheduler_job.py:155} INFO - Started process (PID=73210) to work on /airflow/dags/download_data.py
[2022-02-18 08:55:09,758] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:55:09,760] {logging_mixin.py:112} INFO - [2022-02-18 08:55:09,759] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:55:10,223] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:55:10,275] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:55:10,283] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:55:10,289] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 08:55:23,077] {scheduler_job.py:155} INFO - Started process (PID=73236) to work on /airflow/dags/download_data.py
[2022-02-18 08:55:23,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:55:23,101] {logging_mixin.py:112} INFO - [2022-02-18 08:55:23,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:55:23,557] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:55:23,615] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:55:23,623] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:55:23,628] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 08:55:36,354] {scheduler_job.py:155} INFO - Started process (PID=73262) to work on /airflow/dags/download_data.py
[2022-02-18 08:55:36,360] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:55:36,362] {logging_mixin.py:112} INFO - [2022-02-18 08:55:36,361] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:55:36,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:55:36,881] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:55:36,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:55:36,906] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 08:55:49,704] {scheduler_job.py:155} INFO - Started process (PID=73288) to work on /airflow/dags/download_data.py
[2022-02-18 08:55:49,710] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:55:49,713] {logging_mixin.py:112} INFO - [2022-02-18 08:55:49,712] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:55:50,151] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:55:50,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:55:50,205] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:55:50,209] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 08:56:02,970] {scheduler_job.py:155} INFO - Started process (PID=73314) to work on /airflow/dags/download_data.py
[2022-02-18 08:56:02,978] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:56:02,980] {logging_mixin.py:112} INFO - [2022-02-18 08:56:02,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:56:03,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:56:03,505] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:56:03,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:56:03,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 08:56:16,289] {scheduler_job.py:155} INFO - Started process (PID=73340) to work on /airflow/dags/download_data.py
[2022-02-18 08:56:16,293] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:56:16,296] {logging_mixin.py:112} INFO - [2022-02-18 08:56:16,296] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:56:16,755] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:56:16,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:56:16,816] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:56:16,820] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 08:56:29,560] {scheduler_job.py:155} INFO - Started process (PID=73366) to work on /airflow/dags/download_data.py
[2022-02-18 08:56:29,564] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:56:29,568] {logging_mixin.py:112} INFO - [2022-02-18 08:56:29,566] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:56:30,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:56:30,054] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:56:30,060] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:56:30,064] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 08:56:42,867] {scheduler_job.py:155} INFO - Started process (PID=73392) to work on /airflow/dags/download_data.py
[2022-02-18 08:56:42,871] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:56:42,873] {logging_mixin.py:112} INFO - [2022-02-18 08:56:42,873] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:56:43,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:56:43,356] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:56:43,366] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:56:43,372] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 08:56:56,181] {scheduler_job.py:155} INFO - Started process (PID=73418) to work on /airflow/dags/download_data.py
[2022-02-18 08:56:56,188] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:56:56,191] {logging_mixin.py:112} INFO - [2022-02-18 08:56:56,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:56:56,625] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:56:56,669] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:56:56,679] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:56:56,685] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 08:57:09,431] {scheduler_job.py:155} INFO - Started process (PID=73444) to work on /airflow/dags/download_data.py
[2022-02-18 08:57:09,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:57:09,437] {logging_mixin.py:112} INFO - [2022-02-18 08:57:09,436] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:57:09,884] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:57:09,937] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:57:09,947] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:57:09,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 08:57:22,744] {scheduler_job.py:155} INFO - Started process (PID=73470) to work on /airflow/dags/download_data.py
[2022-02-18 08:57:22,751] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:57:22,753] {logging_mixin.py:112} INFO - [2022-02-18 08:57:22,753] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:57:23,209] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:57:23,254] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:57:23,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:57:23,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 08:57:36,023] {scheduler_job.py:155} INFO - Started process (PID=73496) to work on /airflow/dags/download_data.py
[2022-02-18 08:57:36,036] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:57:36,038] {logging_mixin.py:112} INFO - [2022-02-18 08:57:36,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:57:36,478] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:57:36,519] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:57:36,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:57:36,532] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 08:57:49,296] {scheduler_job.py:155} INFO - Started process (PID=73522) to work on /airflow/dags/download_data.py
[2022-02-18 08:57:49,300] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:57:49,303] {logging_mixin.py:112} INFO - [2022-02-18 08:57:49,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:57:49,767] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:57:49,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:57:49,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:57:49,819] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 08:58:02,557] {scheduler_job.py:155} INFO - Started process (PID=73548) to work on /airflow/dags/download_data.py
[2022-02-18 08:58:02,564] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:58:02,567] {logging_mixin.py:112} INFO - [2022-02-18 08:58:02,566] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:58:03,006] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:58:03,048] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:58:03,058] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:58:03,064] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 08:58:15,872] {scheduler_job.py:155} INFO - Started process (PID=73574) to work on /airflow/dags/download_data.py
[2022-02-18 08:58:15,881] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:58:15,883] {logging_mixin.py:112} INFO - [2022-02-18 08:58:15,883] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:58:16,326] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:58:16,369] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:58:16,375] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:58:16,379] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 08:58:29,137] {scheduler_job.py:155} INFO - Started process (PID=73600) to work on /airflow/dags/download_data.py
[2022-02-18 08:58:29,141] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:58:29,144] {logging_mixin.py:112} INFO - [2022-02-18 08:58:29,144] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:58:29,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:58:29,625] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:58:29,631] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:58:29,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 08:58:42,467] {scheduler_job.py:155} INFO - Started process (PID=73626) to work on /airflow/dags/download_data.py
[2022-02-18 08:58:42,471] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:58:42,472] {logging_mixin.py:112} INFO - [2022-02-18 08:58:42,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:58:42,908] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:58:42,955] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:58:42,965] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:58:42,972] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 08:58:55,752] {scheduler_job.py:155} INFO - Started process (PID=73652) to work on /airflow/dags/download_data.py
[2022-02-18 08:58:55,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:58:55,765] {logging_mixin.py:112} INFO - [2022-02-18 08:58:55,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:58:56,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:58:56,256] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:58:56,266] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:58:56,272] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 08:59:09,018] {scheduler_job.py:155} INFO - Started process (PID=73678) to work on /airflow/dags/download_data.py
[2022-02-18 08:59:09,022] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:59:09,024] {logging_mixin.py:112} INFO - [2022-02-18 08:59:09,024] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:59:09,454] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:59:09,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:59:09,509] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:59:09,515] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 08:59:22,390] {scheduler_job.py:155} INFO - Started process (PID=73704) to work on /airflow/dags/download_data.py
[2022-02-18 08:59:22,398] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:59:22,399] {logging_mixin.py:112} INFO - [2022-02-18 08:59:22,399] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:59:22,830] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:59:22,871] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:59:22,880] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:59:22,884] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 08:59:35,637] {scheduler_job.py:155} INFO - Started process (PID=73730) to work on /airflow/dags/download_data.py
[2022-02-18 08:59:35,642] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:59:35,643] {logging_mixin.py:112} INFO - [2022-02-18 08:59:35,643] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:59:36,089] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:59:36,130] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:59:36,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:59:36,147] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 08:59:48,946] {scheduler_job.py:155} INFO - Started process (PID=73756) to work on /airflow/dags/download_data.py
[2022-02-18 08:59:48,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 08:59:48,955] {logging_mixin.py:112} INFO - [2022-02-18 08:59:48,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 08:59:49,392] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 08:59:49,445] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 08:59:49,454] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 08:59:49,462] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 10:00:00,302] {scheduler_job.py:155} INFO - Started process (PID=73782) to work on /airflow/dags/download_data.py
[2022-02-18 10:00:00,316] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:00:00,318] {logging_mixin.py:112} INFO - [2022-02-18 10:00:00,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:00:01,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:00:01,093] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:00:01,105] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:00:01,111] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.808 seconds
[2022-02-18 10:00:18,827] {scheduler_job.py:155} INFO - Started process (PID=73808) to work on /airflow/dags/download_data.py
[2022-02-18 10:00:18,831] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:00:18,832] {logging_mixin.py:112} INFO - [2022-02-18 10:00:18,832] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:00:19,276] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:00:19,327] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:00:19,335] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:00:19,340] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 10:00:32,115] {scheduler_job.py:155} INFO - Started process (PID=73834) to work on /airflow/dags/download_data.py
[2022-02-18 10:00:32,123] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:00:32,127] {logging_mixin.py:112} INFO - [2022-02-18 10:00:32,127] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:00:32,612] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:00:32,658] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:00:32,666] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:00:32,671] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 10:00:44,407] {scheduler_job.py:155} INFO - Started process (PID=73859) to work on /airflow/dags/download_data.py
[2022-02-18 10:00:44,415] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:00:44,417] {logging_mixin.py:112} INFO - [2022-02-18 10:00:44,417] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:00:44,847] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:00:44,899] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:00:44,910] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:00:44,913] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 10:00:57,695] {scheduler_job.py:155} INFO - Started process (PID=73885) to work on /airflow/dags/download_data.py
[2022-02-18 10:00:57,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:00:57,703] {logging_mixin.py:112} INFO - [2022-02-18 10:00:57,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:00:58,129] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:00:58,200] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:00:58,212] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:00:58,217] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 10:01:11,011] {scheduler_job.py:155} INFO - Started process (PID=73911) to work on /airflow/dags/download_data.py
[2022-02-18 10:01:11,015] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:01:11,017] {logging_mixin.py:112} INFO - [2022-02-18 10:01:11,017] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:01:11,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:01:11,513] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:01:11,520] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:01:11,525] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 10:01:24,325] {scheduler_job.py:155} INFO - Started process (PID=73937) to work on /airflow/dags/download_data.py
[2022-02-18 10:01:24,333] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:01:24,335] {logging_mixin.py:112} INFO - [2022-02-18 10:01:24,335] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:01:24,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:01:24,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:01:24,829] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:01:24,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 10:01:37,596] {scheduler_job.py:155} INFO - Started process (PID=73963) to work on /airflow/dags/download_data.py
[2022-02-18 10:01:37,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:01:37,606] {logging_mixin.py:112} INFO - [2022-02-18 10:01:37,606] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:01:38,068] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:01:38,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:01:38,133] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:01:38,140] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 10:01:50,936] {scheduler_job.py:155} INFO - Started process (PID=73989) to work on /airflow/dags/download_data.py
[2022-02-18 10:01:50,941] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:01:50,943] {logging_mixin.py:112} INFO - [2022-02-18 10:01:50,943] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:01:51,399] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:01:51,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:01:51,457] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:01:51,461] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 10:02:04,229] {scheduler_job.py:155} INFO - Started process (PID=74015) to work on /airflow/dags/download_data.py
[2022-02-18 10:02:04,234] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:02:04,237] {logging_mixin.py:112} INFO - [2022-02-18 10:02:04,237] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:02:04,676] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:02:04,722] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:02:04,729] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:02:04,736] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 10:02:17,519] {scheduler_job.py:155} INFO - Started process (PID=74041) to work on /airflow/dags/download_data.py
[2022-02-18 10:02:17,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:02:17,529] {logging_mixin.py:112} INFO - [2022-02-18 10:02:17,528] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:02:17,988] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:02:18,037] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:02:18,042] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:02:18,046] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 10:02:30,813] {scheduler_job.py:155} INFO - Started process (PID=74067) to work on /airflow/dags/download_data.py
[2022-02-18 10:02:30,827] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:02:30,835] {logging_mixin.py:112} INFO - [2022-02-18 10:02:30,835] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:02:31,290] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:02:31,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:02:31,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:02:31,361] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 10:02:44,119] {scheduler_job.py:155} INFO - Started process (PID=74093) to work on /airflow/dags/download_data.py
[2022-02-18 10:02:44,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:02:44,134] {logging_mixin.py:112} INFO - [2022-02-18 10:02:44,134] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:02:44,690] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:02:44,742] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:02:44,750] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:02:44,754] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-18 10:02:57,380] {scheduler_job.py:155} INFO - Started process (PID=74119) to work on /airflow/dags/download_data.py
[2022-02-18 10:02:57,384] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:02:57,386] {logging_mixin.py:112} INFO - [2022-02-18 10:02:57,386] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:02:57,824] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:02:57,866] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:02:57,876] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:02:57,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 10:03:10,702] {scheduler_job.py:155} INFO - Started process (PID=74145) to work on /airflow/dags/download_data.py
[2022-02-18 10:03:10,708] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:03:10,709] {logging_mixin.py:112} INFO - [2022-02-18 10:03:10,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:03:11,154] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:03:11,205] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:03:11,212] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:03:11,216] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 10:03:23,999] {scheduler_job.py:155} INFO - Started process (PID=74171) to work on /airflow/dags/download_data.py
[2022-02-18 10:03:24,004] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:03:24,005] {logging_mixin.py:112} INFO - [2022-02-18 10:03:24,005] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:03:24,464] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:03:24,514] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:03:24,521] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:03:24,524] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 10:03:37,241] {scheduler_job.py:155} INFO - Started process (PID=74197) to work on /airflow/dags/download_data.py
[2022-02-18 10:03:37,246] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:03:37,248] {logging_mixin.py:112} INFO - [2022-02-18 10:03:37,247] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:03:37,667] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:03:37,715] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:03:37,724] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:03:37,728] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.487 seconds
[2022-02-18 10:03:50,538] {scheduler_job.py:155} INFO - Started process (PID=74223) to work on /airflow/dags/download_data.py
[2022-02-18 10:03:50,543] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:03:50,544] {logging_mixin.py:112} INFO - [2022-02-18 10:03:50,544] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:03:50,997] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:03:51,048] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:03:51,054] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:03:51,057] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 10:04:03,852] {scheduler_job.py:155} INFO - Started process (PID=74249) to work on /airflow/dags/download_data.py
[2022-02-18 10:04:03,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:04:03,864] {logging_mixin.py:112} INFO - [2022-02-18 10:04:03,863] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:04:04,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:04:04,356] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:04:04,367] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:04:04,375] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 10:04:17,180] {scheduler_job.py:155} INFO - Started process (PID=74275) to work on /airflow/dags/download_data.py
[2022-02-18 10:04:17,186] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:04:17,189] {logging_mixin.py:112} INFO - [2022-02-18 10:04:17,188] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:04:17,622] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:04:17,669] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:04:17,675] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:04:17,680] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 10:04:30,395] {scheduler_job.py:155} INFO - Started process (PID=74301) to work on /airflow/dags/download_data.py
[2022-02-18 10:04:30,402] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:04:30,404] {logging_mixin.py:112} INFO - [2022-02-18 10:04:30,404] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:04:30,882] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:04:30,941] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:04:30,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:04:30,959] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 10:04:43,699] {scheduler_job.py:155} INFO - Started process (PID=74327) to work on /airflow/dags/download_data.py
[2022-02-18 10:04:43,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:04:43,710] {logging_mixin.py:112} INFO - [2022-02-18 10:04:43,710] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:04:44,142] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:04:44,188] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:04:44,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:04:44,200] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 10:04:56,986] {scheduler_job.py:155} INFO - Started process (PID=74353) to work on /airflow/dags/download_data.py
[2022-02-18 10:04:56,989] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:04:56,991] {logging_mixin.py:112} INFO - [2022-02-18 10:04:56,991] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:04:57,438] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:04:57,487] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:04:57,494] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:04:57,499] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 10:05:10,287] {scheduler_job.py:155} INFO - Started process (PID=74379) to work on /airflow/dags/download_data.py
[2022-02-18 10:05:10,292] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:05:10,294] {logging_mixin.py:112} INFO - [2022-02-18 10:05:10,294] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:05:10,763] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:05:10,816] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:05:10,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:05:10,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 10:05:23,567] {scheduler_job.py:155} INFO - Started process (PID=74405) to work on /airflow/dags/download_data.py
[2022-02-18 10:05:23,574] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:05:23,576] {logging_mixin.py:112} INFO - [2022-02-18 10:05:23,576] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:05:24,045] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:05:24,096] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:05:24,103] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:05:24,107] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 10:05:36,825] {scheduler_job.py:155} INFO - Started process (PID=74431) to work on /airflow/dags/download_data.py
[2022-02-18 10:05:36,831] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:05:36,834] {logging_mixin.py:112} INFO - [2022-02-18 10:05:36,834] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:05:37,295] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:05:37,347] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:05:37,353] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:05:37,358] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 10:05:50,140] {scheduler_job.py:155} INFO - Started process (PID=74457) to work on /airflow/dags/download_data.py
[2022-02-18 10:05:50,145] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:05:50,146] {logging_mixin.py:112} INFO - [2022-02-18 10:05:50,146] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:05:50,597] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:05:50,642] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:05:50,648] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:05:50,655] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 10:06:03,420] {scheduler_job.py:155} INFO - Started process (PID=74483) to work on /airflow/dags/download_data.py
[2022-02-18 10:06:03,431] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:06:03,433] {logging_mixin.py:112} INFO - [2022-02-18 10:06:03,433] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:06:03,860] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:06:03,908] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:06:03,916] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:06:03,920] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 10:06:16,695] {scheduler_job.py:155} INFO - Started process (PID=74509) to work on /airflow/dags/download_data.py
[2022-02-18 10:06:16,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:06:16,702] {logging_mixin.py:112} INFO - [2022-02-18 10:06:16,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:06:17,158] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:06:17,202] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:06:17,210] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:06:17,215] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 10:06:30,002] {scheduler_job.py:155} INFO - Started process (PID=74535) to work on /airflow/dags/download_data.py
[2022-02-18 10:06:30,010] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:06:30,012] {logging_mixin.py:112} INFO - [2022-02-18 10:06:30,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:06:30,461] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:06:30,519] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:06:30,533] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:06:30,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 10:06:43,289] {scheduler_job.py:155} INFO - Started process (PID=74561) to work on /airflow/dags/download_data.py
[2022-02-18 10:06:43,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:06:43,298] {logging_mixin.py:112} INFO - [2022-02-18 10:06:43,298] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:06:43,741] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:06:43,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:06:43,797] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:06:43,802] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 10:06:56,531] {scheduler_job.py:155} INFO - Started process (PID=74587) to work on /airflow/dags/download_data.py
[2022-02-18 10:06:56,535] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:06:56,537] {logging_mixin.py:112} INFO - [2022-02-18 10:06:56,537] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:06:56,991] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:06:57,045] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:06:57,055] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:06:57,061] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 10:07:09,813] {scheduler_job.py:155} INFO - Started process (PID=74613) to work on /airflow/dags/download_data.py
[2022-02-18 10:07:09,817] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:07:09,819] {logging_mixin.py:112} INFO - [2022-02-18 10:07:09,819] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:07:10,275] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:07:10,327] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:07:10,338] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:07:10,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 10:07:23,147] {scheduler_job.py:155} INFO - Started process (PID=74639) to work on /airflow/dags/download_data.py
[2022-02-18 10:07:23,154] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:07:23,156] {logging_mixin.py:112} INFO - [2022-02-18 10:07:23,156] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:07:23,598] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:07:23,650] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:07:23,658] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:07:23,663] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 10:07:36,403] {scheduler_job.py:155} INFO - Started process (PID=74665) to work on /airflow/dags/download_data.py
[2022-02-18 10:07:36,410] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:07:36,411] {logging_mixin.py:112} INFO - [2022-02-18 10:07:36,411] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:07:36,851] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:07:36,900] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:07:36,906] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:07:36,912] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 10:07:49,691] {scheduler_job.py:155} INFO - Started process (PID=74691) to work on /airflow/dags/download_data.py
[2022-02-18 10:07:49,699] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:07:49,702] {logging_mixin.py:112} INFO - [2022-02-18 10:07:49,701] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:07:50,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:07:50,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:07:50,186] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:07:50,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 10:08:02,930] {scheduler_job.py:155} INFO - Started process (PID=74717) to work on /airflow/dags/download_data.py
[2022-02-18 10:08:02,934] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:08:02,936] {logging_mixin.py:112} INFO - [2022-02-18 10:08:02,935] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:08:03,398] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:08:03,447] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:08:03,454] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:08:03,461] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 10:08:16,247] {scheduler_job.py:155} INFO - Started process (PID=74743) to work on /airflow/dags/download_data.py
[2022-02-18 10:08:16,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:08:16,255] {logging_mixin.py:112} INFO - [2022-02-18 10:08:16,255] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:08:16,701] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:08:16,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:08:16,752] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:08:16,755] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 10:08:29,516] {scheduler_job.py:155} INFO - Started process (PID=74769) to work on /airflow/dags/download_data.py
[2022-02-18 10:08:29,525] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:08:29,527] {logging_mixin.py:112} INFO - [2022-02-18 10:08:29,526] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:08:29,959] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:08:30,011] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:08:30,017] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:08:30,020] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 10:08:42,804] {scheduler_job.py:155} INFO - Started process (PID=74795) to work on /airflow/dags/download_data.py
[2022-02-18 10:08:42,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:08:42,811] {logging_mixin.py:112} INFO - [2022-02-18 10:08:42,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:08:43,258] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:08:43,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:08:43,313] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:08:43,319] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 10:08:56,098] {scheduler_job.py:155} INFO - Started process (PID=74821) to work on /airflow/dags/download_data.py
[2022-02-18 10:08:56,105] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:08:56,108] {logging_mixin.py:112} INFO - [2022-02-18 10:08:56,107] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:08:56,545] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:08:56,597] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:08:56,609] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:08:56,615] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 10:09:09,419] {scheduler_job.py:155} INFO - Started process (PID=74847) to work on /airflow/dags/download_data.py
[2022-02-18 10:09:09,426] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:09:09,434] {logging_mixin.py:112} INFO - [2022-02-18 10:09:09,433] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:09:09,881] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:09:09,933] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:09:09,938] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:09:09,942] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 10:09:22,686] {scheduler_job.py:155} INFO - Started process (PID=74873) to work on /airflow/dags/download_data.py
[2022-02-18 10:09:22,692] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:09:22,698] {logging_mixin.py:112} INFO - [2022-02-18 10:09:22,697] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:09:23,125] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:09:23,179] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:09:23,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:09:23,193] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 10:09:35,939] {scheduler_job.py:155} INFO - Started process (PID=74899) to work on /airflow/dags/download_data.py
[2022-02-18 10:09:35,945] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:09:35,947] {logging_mixin.py:112} INFO - [2022-02-18 10:09:35,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:09:36,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:09:36,436] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:09:36,444] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:09:36,449] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 10:09:49,237] {scheduler_job.py:155} INFO - Started process (PID=74925) to work on /airflow/dags/download_data.py
[2022-02-18 10:09:49,242] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:09:49,244] {logging_mixin.py:112} INFO - [2022-02-18 10:09:49,244] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:09:49,708] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:09:49,759] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:09:49,770] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:09:49,777] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 10:10:02,547] {scheduler_job.py:155} INFO - Started process (PID=74951) to work on /airflow/dags/download_data.py
[2022-02-18 10:10:02,553] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:10:02,554] {logging_mixin.py:112} INFO - [2022-02-18 10:10:02,554] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:10:03,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:10:03,086] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:10:03,099] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:10:03,104] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 10:10:15,873] {scheduler_job.py:155} INFO - Started process (PID=74976) to work on /airflow/dags/download_data.py
[2022-02-18 10:10:15,878] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:10:15,880] {logging_mixin.py:112} INFO - [2022-02-18 10:10:15,880] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:10:16,318] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:10:16,359] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:10:16,365] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:10:16,369] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 10:10:28,112] {scheduler_job.py:155} INFO - Started process (PID=75001) to work on /airflow/dags/download_data.py
[2022-02-18 10:10:28,120] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:10:28,122] {logging_mixin.py:112} INFO - [2022-02-18 10:10:28,122] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:10:28,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:10:28,602] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:10:28,608] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:10:28,614] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 10:10:41,429] {scheduler_job.py:155} INFO - Started process (PID=75027) to work on /airflow/dags/download_data.py
[2022-02-18 10:10:41,437] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:10:41,440] {logging_mixin.py:112} INFO - [2022-02-18 10:10:41,439] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:10:41,882] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:10:41,920] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:10:41,926] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:10:41,931] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 10:10:54,742] {scheduler_job.py:155} INFO - Started process (PID=75053) to work on /airflow/dags/download_data.py
[2022-02-18 10:10:54,749] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:10:54,751] {logging_mixin.py:112} INFO - [2022-02-18 10:10:54,751] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:10:55,180] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:10:55,230] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:10:55,239] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:10:55,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 10:11:08,019] {scheduler_job.py:155} INFO - Started process (PID=75079) to work on /airflow/dags/download_data.py
[2022-02-18 10:11:08,025] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:11:08,027] {logging_mixin.py:112} INFO - [2022-02-18 10:11:08,027] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:11:08,460] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:11:08,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:11:08,519] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:11:08,525] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 10:11:21,341] {scheduler_job.py:155} INFO - Started process (PID=75105) to work on /airflow/dags/download_data.py
[2022-02-18 10:11:21,349] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:11:21,352] {logging_mixin.py:112} INFO - [2022-02-18 10:11:21,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:11:21,783] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:11:21,836] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:11:21,842] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:11:21,847] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 10:11:34,599] {scheduler_job.py:155} INFO - Started process (PID=75131) to work on /airflow/dags/download_data.py
[2022-02-18 10:11:34,607] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:11:34,610] {logging_mixin.py:112} INFO - [2022-02-18 10:11:34,609] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:11:35,043] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:11:35,094] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:11:35,101] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:11:35,106] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 10:11:47,914] {scheduler_job.py:155} INFO - Started process (PID=75157) to work on /airflow/dags/download_data.py
[2022-02-18 10:11:47,919] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:11:47,921] {logging_mixin.py:112} INFO - [2022-02-18 10:11:47,921] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:11:48,379] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:11:48,423] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:11:48,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:11:48,433] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 10:12:01,172] {scheduler_job.py:155} INFO - Started process (PID=75183) to work on /airflow/dags/download_data.py
[2022-02-18 10:12:01,176] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:12:01,178] {logging_mixin.py:112} INFO - [2022-02-18 10:12:01,178] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:12:01,621] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:12:01,683] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:12:01,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:12:01,697] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 10:12:14,455] {scheduler_job.py:155} INFO - Started process (PID=75209) to work on /airflow/dags/download_data.py
[2022-02-18 10:12:14,461] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:12:14,463] {logging_mixin.py:112} INFO - [2022-02-18 10:12:14,463] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:12:14,891] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:12:14,941] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:12:14,947] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:12:14,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 10:12:27,737] {scheduler_job.py:155} INFO - Started process (PID=75235) to work on /airflow/dags/download_data.py
[2022-02-18 10:12:27,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:12:27,744] {logging_mixin.py:112} INFO - [2022-02-18 10:12:27,744] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:12:28,198] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:12:28,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:12:28,255] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:12:28,260] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 10:12:41,011] {scheduler_job.py:155} INFO - Started process (PID=75261) to work on /airflow/dags/download_data.py
[2022-02-18 10:12:41,015] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:12:41,017] {logging_mixin.py:112} INFO - [2022-02-18 10:12:41,017] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:12:41,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:12:41,492] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:12:41,500] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:12:41,503] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 10:12:54,303] {scheduler_job.py:155} INFO - Started process (PID=75287) to work on /airflow/dags/download_data.py
[2022-02-18 10:12:54,307] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:12:54,309] {logging_mixin.py:112} INFO - [2022-02-18 10:12:54,309] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:12:54,745] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:12:54,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:12:54,798] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:12:54,802] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 10:13:07,585] {scheduler_job.py:155} INFO - Started process (PID=75313) to work on /airflow/dags/download_data.py
[2022-02-18 10:13:07,589] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:13:07,591] {logging_mixin.py:112} INFO - [2022-02-18 10:13:07,590] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:13:08,040] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:13:08,093] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:13:08,102] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:13:08,109] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 10:13:20,930] {scheduler_job.py:155} INFO - Started process (PID=75339) to work on /airflow/dags/download_data.py
[2022-02-18 10:13:20,936] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:13:20,939] {logging_mixin.py:112} INFO - [2022-02-18 10:13:20,938] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:13:21,369] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:13:21,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:13:21,419] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:13:21,425] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 10:13:34,199] {scheduler_job.py:155} INFO - Started process (PID=75365) to work on /airflow/dags/download_data.py
[2022-02-18 10:13:34,204] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:13:34,206] {logging_mixin.py:112} INFO - [2022-02-18 10:13:34,206] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:13:34,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:13:34,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:13:34,692] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:13:34,698] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 10:13:47,519] {scheduler_job.py:155} INFO - Started process (PID=75391) to work on /airflow/dags/download_data.py
[2022-02-18 10:13:47,525] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:13:47,527] {logging_mixin.py:112} INFO - [2022-02-18 10:13:47,527] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:13:47,976] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:13:48,025] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:13:48,030] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:13:48,033] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 10:14:00,807] {scheduler_job.py:155} INFO - Started process (PID=75417) to work on /airflow/dags/download_data.py
[2022-02-18 10:14:00,812] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:14:00,814] {logging_mixin.py:112} INFO - [2022-02-18 10:14:00,814] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:14:01,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:14:01,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:14:01,315] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:14:01,319] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 10:14:14,104] {scheduler_job.py:155} INFO - Started process (PID=75443) to work on /airflow/dags/download_data.py
[2022-02-18 10:14:14,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:14:14,116] {logging_mixin.py:112} INFO - [2022-02-18 10:14:14,116] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:14:14,545] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:14:14,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:14:14,598] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:14:14,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 10:14:27,399] {scheduler_job.py:155} INFO - Started process (PID=75469) to work on /airflow/dags/download_data.py
[2022-02-18 10:14:27,404] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:14:27,406] {logging_mixin.py:112} INFO - [2022-02-18 10:14:27,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:14:27,840] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:14:27,892] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:14:27,899] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:14:27,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 10:14:41,216] {scheduler_job.py:155} INFO - Started process (PID=75495) to work on /airflow/dags/download_data.py
[2022-02-18 10:14:41,224] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:14:41,226] {logging_mixin.py:112} INFO - [2022-02-18 10:14:41,226] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:14:41,664] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:14:41,721] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:14:41,732] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:14:41,737] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 10:14:54,510] {scheduler_job.py:155} INFO - Started process (PID=75521) to work on /airflow/dags/download_data.py
[2022-02-18 10:14:54,515] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:14:54,516] {logging_mixin.py:112} INFO - [2022-02-18 10:14:54,516] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:14:54,973] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:14:55,024] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:14:55,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:14:55,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 10:15:07,814] {scheduler_job.py:155} INFO - Started process (PID=75547) to work on /airflow/dags/download_data.py
[2022-02-18 10:15:07,820] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:15:07,822] {logging_mixin.py:112} INFO - [2022-02-18 10:15:07,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:15:08,258] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:15:08,306] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:15:08,313] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:15:08,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 10:15:21,085] {scheduler_job.py:155} INFO - Started process (PID=75573) to work on /airflow/dags/download_data.py
[2022-02-18 10:15:21,090] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:15:21,091] {logging_mixin.py:112} INFO - [2022-02-18 10:15:21,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:15:21,527] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:15:21,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:15:21,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:15:21,592] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 10:15:34,379] {scheduler_job.py:155} INFO - Started process (PID=75599) to work on /airflow/dags/download_data.py
[2022-02-18 10:15:34,386] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:15:34,388] {logging_mixin.py:112} INFO - [2022-02-18 10:15:34,388] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:15:34,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:15:34,871] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:15:34,882] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:15:34,886] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 10:15:47,709] {scheduler_job.py:155} INFO - Started process (PID=75625) to work on /airflow/dags/download_data.py
[2022-02-18 10:15:47,713] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:15:47,715] {logging_mixin.py:112} INFO - [2022-02-18 10:15:47,715] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:15:48,177] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:15:48,243] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:15:48,252] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:15:48,256] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 10:16:01,006] {scheduler_job.py:155} INFO - Started process (PID=75651) to work on /airflow/dags/download_data.py
[2022-02-18 10:16:01,019] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:16:01,022] {logging_mixin.py:112} INFO - [2022-02-18 10:16:01,021] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:16:01,468] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:16:01,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:16:01,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:16:01,528] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 10:16:14,285] {scheduler_job.py:155} INFO - Started process (PID=75677) to work on /airflow/dags/download_data.py
[2022-02-18 10:16:14,292] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:16:14,294] {logging_mixin.py:112} INFO - [2022-02-18 10:16:14,294] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:16:14,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:16:14,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:16:14,787] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:16:14,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 10:16:27,560] {scheduler_job.py:155} INFO - Started process (PID=75703) to work on /airflow/dags/download_data.py
[2022-02-18 10:16:27,564] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:16:27,565] {logging_mixin.py:112} INFO - [2022-02-18 10:16:27,565] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:16:28,008] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:16:28,058] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:16:28,066] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:16:28,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 10:16:40,846] {scheduler_job.py:155} INFO - Started process (PID=75729) to work on /airflow/dags/download_data.py
[2022-02-18 10:16:40,854] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:16:40,856] {logging_mixin.py:112} INFO - [2022-02-18 10:16:40,856] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:16:41,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:16:41,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:16:41,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:16:41,358] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 10:16:54,152] {scheduler_job.py:155} INFO - Started process (PID=75755) to work on /airflow/dags/download_data.py
[2022-02-18 10:16:54,156] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:16:54,158] {logging_mixin.py:112} INFO - [2022-02-18 10:16:54,157] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:16:54,596] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:16:54,640] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:16:54,649] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:16:54,653] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 10:17:07,424] {scheduler_job.py:155} INFO - Started process (PID=75781) to work on /airflow/dags/download_data.py
[2022-02-18 10:17:07,428] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:17:07,429] {logging_mixin.py:112} INFO - [2022-02-18 10:17:07,429] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:17:07,872] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:17:07,925] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:17:07,933] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:17:07,938] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 10:17:20,756] {scheduler_job.py:155} INFO - Started process (PID=75807) to work on /airflow/dags/download_data.py
[2022-02-18 10:17:20,760] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:17:20,763] {logging_mixin.py:112} INFO - [2022-02-18 10:17:20,763] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:17:21,194] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:17:21,245] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:17:21,252] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:17:21,257] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 10:17:34,025] {scheduler_job.py:155} INFO - Started process (PID=75833) to work on /airflow/dags/download_data.py
[2022-02-18 10:17:34,035] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:17:34,037] {logging_mixin.py:112} INFO - [2022-02-18 10:17:34,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:17:34,485] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:17:34,539] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:17:34,550] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:17:34,555] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 10:17:47,333] {scheduler_job.py:155} INFO - Started process (PID=75859) to work on /airflow/dags/download_data.py
[2022-02-18 10:17:47,340] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:17:47,342] {logging_mixin.py:112} INFO - [2022-02-18 10:17:47,342] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:17:47,795] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:17:47,847] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:17:47,857] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:17:47,871] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 10:18:00,621] {scheduler_job.py:155} INFO - Started process (PID=75885) to work on /airflow/dags/download_data.py
[2022-02-18 10:18:00,631] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:18:00,635] {logging_mixin.py:112} INFO - [2022-02-18 10:18:00,634] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:18:01,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:18:01,149] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:18:01,158] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:18:01,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 10:18:13,922] {scheduler_job.py:155} INFO - Started process (PID=75911) to work on /airflow/dags/download_data.py
[2022-02-18 10:18:13,927] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:18:13,928] {logging_mixin.py:112} INFO - [2022-02-18 10:18:13,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:18:14,369] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:18:14,423] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:18:14,430] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:18:14,434] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 10:18:27,192] {scheduler_job.py:155} INFO - Started process (PID=75937) to work on /airflow/dags/download_data.py
[2022-02-18 10:18:27,196] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:18:27,198] {logging_mixin.py:112} INFO - [2022-02-18 10:18:27,198] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:18:27,640] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:18:27,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:18:27,693] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:18:27,698] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 10:18:40,484] {scheduler_job.py:155} INFO - Started process (PID=75963) to work on /airflow/dags/download_data.py
[2022-02-18 10:18:40,489] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:18:40,491] {logging_mixin.py:112} INFO - [2022-02-18 10:18:40,490] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:18:40,926] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:18:40,976] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:18:40,987] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:18:40,992] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 10:18:53,808] {scheduler_job.py:155} INFO - Started process (PID=75989) to work on /airflow/dags/download_data.py
[2022-02-18 10:18:53,815] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:18:53,817] {logging_mixin.py:112} INFO - [2022-02-18 10:18:53,817] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:18:54,260] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:18:54,313] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:18:54,321] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:18:54,325] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 10:19:07,082] {scheduler_job.py:155} INFO - Started process (PID=76015) to work on /airflow/dags/download_data.py
[2022-02-18 10:19:07,086] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:19:07,087] {logging_mixin.py:112} INFO - [2022-02-18 10:19:07,087] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:19:07,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:19:07,586] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:19:07,594] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:19:07,598] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 10:19:20,365] {scheduler_job.py:155} INFO - Started process (PID=76041) to work on /airflow/dags/download_data.py
[2022-02-18 10:19:20,372] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:19:20,374] {logging_mixin.py:112} INFO - [2022-02-18 10:19:20,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:19:20,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:19:20,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:19:20,855] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:19:20,861] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 10:19:33,605] {scheduler_job.py:155} INFO - Started process (PID=76067) to work on /airflow/dags/download_data.py
[2022-02-18 10:19:33,619] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:19:33,622] {logging_mixin.py:112} INFO - [2022-02-18 10:19:33,621] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:19:34,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:19:34,092] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:19:34,098] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:19:34,104] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 10:19:46,887] {scheduler_job.py:155} INFO - Started process (PID=76093) to work on /airflow/dags/download_data.py
[2022-02-18 10:19:46,894] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:19:46,896] {logging_mixin.py:112} INFO - [2022-02-18 10:19:46,895] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:19:47,379] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:19:47,431] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:19:47,443] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:19:47,448] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 10:20:00,185] {scheduler_job.py:155} INFO - Started process (PID=76119) to work on /airflow/dags/download_data.py
[2022-02-18 10:20:00,190] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:20:00,192] {logging_mixin.py:112} INFO - [2022-02-18 10:20:00,192] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:20:00,677] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:20:00,737] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:20:00,744] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:20:00,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 10:20:13,474] {scheduler_job.py:155} INFO - Started process (PID=76145) to work on /airflow/dags/download_data.py
[2022-02-18 10:20:13,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:20:13,480] {logging_mixin.py:112} INFO - [2022-02-18 10:20:13,479] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:20:13,910] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:20:13,961] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:20:13,968] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:20:13,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 10:20:26,771] {scheduler_job.py:155} INFO - Started process (PID=76171) to work on /airflow/dags/download_data.py
[2022-02-18 10:20:26,780] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:20:26,782] {logging_mixin.py:112} INFO - [2022-02-18 10:20:26,782] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:20:27,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:20:27,270] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:20:27,276] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:20:27,281] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 10:20:40,037] {scheduler_job.py:155} INFO - Started process (PID=76197) to work on /airflow/dags/download_data.py
[2022-02-18 10:20:40,042] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:20:40,044] {logging_mixin.py:112} INFO - [2022-02-18 10:20:40,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:20:40,495] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:20:40,548] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:20:40,560] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:20:40,566] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 10:20:53,331] {scheduler_job.py:155} INFO - Started process (PID=76223) to work on /airflow/dags/download_data.py
[2022-02-18 10:20:53,335] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:20:53,336] {logging_mixin.py:112} INFO - [2022-02-18 10:20:53,336] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:20:53,775] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:20:53,826] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:20:53,835] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:20:53,841] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 10:21:06,614] {scheduler_job.py:155} INFO - Started process (PID=76249) to work on /airflow/dags/download_data.py
[2022-02-18 10:21:06,621] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:21:06,622] {logging_mixin.py:112} INFO - [2022-02-18 10:21:06,622] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:21:07,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:21:07,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:21:07,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:21:07,115] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 10:21:19,923] {scheduler_job.py:155} INFO - Started process (PID=76275) to work on /airflow/dags/download_data.py
[2022-02-18 10:21:19,931] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:21:19,934] {logging_mixin.py:112} INFO - [2022-02-18 10:21:19,933] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:21:20,368] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:21:20,423] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:21:20,434] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:21:20,440] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 10:21:33,158] {scheduler_job.py:155} INFO - Started process (PID=76301) to work on /airflow/dags/download_data.py
[2022-02-18 10:21:33,167] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:21:33,169] {logging_mixin.py:112} INFO - [2022-02-18 10:21:33,169] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:21:33,607] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:21:33,665] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:21:33,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:21:33,677] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 10:21:46,454] {scheduler_job.py:155} INFO - Started process (PID=76327) to work on /airflow/dags/download_data.py
[2022-02-18 10:21:46,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:21:46,465] {logging_mixin.py:112} INFO - [2022-02-18 10:21:46,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:21:46,897] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:21:46,941] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:21:46,947] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:21:46,950] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 10:21:59,699] {scheduler_job.py:155} INFO - Started process (PID=76353) to work on /airflow/dags/download_data.py
[2022-02-18 10:21:59,703] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:21:59,705] {logging_mixin.py:112} INFO - [2022-02-18 10:21:59,704] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:22:00,163] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:22:00,215] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:22:00,221] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:22:00,225] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 10:22:12,996] {scheduler_job.py:155} INFO - Started process (PID=76379) to work on /airflow/dags/download_data.py
[2022-02-18 10:22:13,000] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:22:13,002] {logging_mixin.py:112} INFO - [2022-02-18 10:22:13,002] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:22:13,444] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:22:13,496] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:22:13,505] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:22:13,511] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 10:22:26,290] {scheduler_job.py:155} INFO - Started process (PID=76405) to work on /airflow/dags/download_data.py
[2022-02-18 10:22:26,295] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:22:26,297] {logging_mixin.py:112} INFO - [2022-02-18 10:22:26,297] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:22:26,739] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:22:26,790] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:22:26,796] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:22:26,799] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 10:22:39,605] {scheduler_job.py:155} INFO - Started process (PID=76431) to work on /airflow/dags/download_data.py
[2022-02-18 10:22:39,609] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:22:39,611] {logging_mixin.py:112} INFO - [2022-02-18 10:22:39,611] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:22:40,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:22:40,113] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:22:40,121] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:22:40,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 10:22:52,933] {scheduler_job.py:155} INFO - Started process (PID=76457) to work on /airflow/dags/download_data.py
[2022-02-18 10:22:52,945] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:22:52,947] {logging_mixin.py:112} INFO - [2022-02-18 10:22:52,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:22:53,395] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:22:53,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:22:53,450] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:22:53,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 10:23:06,161] {scheduler_job.py:155} INFO - Started process (PID=76483) to work on /airflow/dags/download_data.py
[2022-02-18 10:23:06,167] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:23:06,174] {logging_mixin.py:112} INFO - [2022-02-18 10:23:06,173] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:23:06,604] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:23:06,648] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:23:06,656] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:23:06,661] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 10:23:19,451] {scheduler_job.py:155} INFO - Started process (PID=76509) to work on /airflow/dags/download_data.py
[2022-02-18 10:23:19,457] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:23:19,459] {logging_mixin.py:112} INFO - [2022-02-18 10:23:19,459] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:23:19,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:23:19,945] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:23:19,952] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:23:19,957] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 10:23:32,737] {scheduler_job.py:155} INFO - Started process (PID=76535) to work on /airflow/dags/download_data.py
[2022-02-18 10:23:32,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:23:32,749] {logging_mixin.py:112} INFO - [2022-02-18 10:23:32,749] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:23:33,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:23:33,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:23:33,254] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:23:33,260] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 10:23:46,037] {scheduler_job.py:155} INFO - Started process (PID=76561) to work on /airflow/dags/download_data.py
[2022-02-18 10:23:46,041] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:23:46,043] {logging_mixin.py:112} INFO - [2022-02-18 10:23:46,042] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:23:46,495] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:23:46,548] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:23:46,554] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:23:46,558] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 10:23:59,318] {scheduler_job.py:155} INFO - Started process (PID=76587) to work on /airflow/dags/download_data.py
[2022-02-18 10:23:59,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:23:59,327] {logging_mixin.py:112} INFO - [2022-02-18 10:23:59,327] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:23:59,768] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:23:59,810] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:23:59,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:23:59,819] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 10:24:12,634] {scheduler_job.py:155} INFO - Started process (PID=76613) to work on /airflow/dags/download_data.py
[2022-02-18 10:24:12,638] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:24:12,639] {logging_mixin.py:112} INFO - [2022-02-18 10:24:12,639] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:24:13,078] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:24:13,125] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:24:13,135] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:24:13,139] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 10:24:25,946] {scheduler_job.py:155} INFO - Started process (PID=76639) to work on /airflow/dags/download_data.py
[2022-02-18 10:24:25,952] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:24:25,954] {logging_mixin.py:112} INFO - [2022-02-18 10:24:25,954] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:24:26,383] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:24:26,432] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:24:26,441] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:24:26,444] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 10:24:39,258] {scheduler_job.py:155} INFO - Started process (PID=76665) to work on /airflow/dags/download_data.py
[2022-02-18 10:24:39,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:24:39,268] {logging_mixin.py:112} INFO - [2022-02-18 10:24:39,268] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:24:39,783] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:24:39,835] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:24:39,843] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:24:39,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 10:24:52,531] {scheduler_job.py:155} INFO - Started process (PID=76691) to work on /airflow/dags/download_data.py
[2022-02-18 10:24:52,536] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:24:52,538] {logging_mixin.py:112} INFO - [2022-02-18 10:24:52,537] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:24:52,983] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:24:53,034] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:24:53,040] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:24:53,046] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 10:25:05,837] {scheduler_job.py:155} INFO - Started process (PID=76717) to work on /airflow/dags/download_data.py
[2022-02-18 10:25:05,841] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:25:05,842] {logging_mixin.py:112} INFO - [2022-02-18 10:25:05,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:25:06,274] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:25:06,325] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:25:06,332] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:25:06,338] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 10:25:19,149] {scheduler_job.py:155} INFO - Started process (PID=76743) to work on /airflow/dags/download_data.py
[2022-02-18 10:25:19,156] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:25:19,164] {logging_mixin.py:112} INFO - [2022-02-18 10:25:19,164] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:25:19,614] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:25:19,664] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:25:19,671] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:25:19,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 10:25:32,440] {scheduler_job.py:155} INFO - Started process (PID=76769) to work on /airflow/dags/download_data.py
[2022-02-18 10:25:32,445] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:25:32,446] {logging_mixin.py:112} INFO - [2022-02-18 10:25:32,446] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:25:32,915] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:25:32,964] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:25:32,972] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:25:32,978] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 10:25:45,746] {scheduler_job.py:155} INFO - Started process (PID=76795) to work on /airflow/dags/download_data.py
[2022-02-18 10:25:45,756] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:25:45,758] {logging_mixin.py:112} INFO - [2022-02-18 10:25:45,758] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:25:46,193] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:25:46,246] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:25:46,256] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:25:46,262] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 10:25:58,987] {scheduler_job.py:155} INFO - Started process (PID=76821) to work on /airflow/dags/download_data.py
[2022-02-18 10:25:58,994] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:25:58,997] {logging_mixin.py:112} INFO - [2022-02-18 10:25:58,996] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:25:59,433] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:25:59,486] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:25:59,494] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:25:59,500] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 10:26:12,296] {scheduler_job.py:155} INFO - Started process (PID=76847) to work on /airflow/dags/download_data.py
[2022-02-18 10:26:12,300] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:26:12,302] {logging_mixin.py:112} INFO - [2022-02-18 10:26:12,302] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:26:12,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:26:12,790] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:26:12,798] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:26:12,802] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 10:26:25,555] {scheduler_job.py:155} INFO - Started process (PID=76873) to work on /airflow/dags/download_data.py
[2022-02-18 10:26:25,559] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:26:25,561] {logging_mixin.py:112} INFO - [2022-02-18 10:26:25,561] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:26:25,993] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:26:26,040] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:26:26,048] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:26:26,053] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 10:26:38,897] {scheduler_job.py:155} INFO - Started process (PID=76899) to work on /airflow/dags/download_data.py
[2022-02-18 10:26:38,901] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:26:38,903] {logging_mixin.py:112} INFO - [2022-02-18 10:26:38,903] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:26:39,360] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:26:39,414] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:26:39,426] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:26:39,431] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 10:26:52,187] {scheduler_job.py:155} INFO - Started process (PID=76925) to work on /airflow/dags/download_data.py
[2022-02-18 10:26:52,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:26:52,193] {logging_mixin.py:112} INFO - [2022-02-18 10:26:52,193] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:26:52,637] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:26:52,682] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:26:52,688] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:26:52,693] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 10:27:05,502] {scheduler_job.py:155} INFO - Started process (PID=76951) to work on /airflow/dags/download_data.py
[2022-02-18 10:27:05,508] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:27:05,510] {logging_mixin.py:112} INFO - [2022-02-18 10:27:05,510] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:27:05,940] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:27:05,984] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:27:05,993] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:27:05,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 10:27:18,768] {scheduler_job.py:155} INFO - Started process (PID=76977) to work on /airflow/dags/download_data.py
[2022-02-18 10:27:18,773] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:27:18,774] {logging_mixin.py:112} INFO - [2022-02-18 10:27:18,774] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:27:19,223] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:27:19,264] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:27:19,271] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:27:19,274] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 10:27:32,048] {scheduler_job.py:155} INFO - Started process (PID=77003) to work on /airflow/dags/download_data.py
[2022-02-18 10:27:32,053] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:27:32,054] {logging_mixin.py:112} INFO - [2022-02-18 10:27:32,054] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:27:32,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:27:32,585] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:27:32,597] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:27:32,604] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 10:27:45,383] {scheduler_job.py:155} INFO - Started process (PID=77029) to work on /airflow/dags/download_data.py
[2022-02-18 10:27:45,389] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:27:45,391] {logging_mixin.py:112} INFO - [2022-02-18 10:27:45,391] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:27:45,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:27:45,874] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:27:45,882] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:27:45,887] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 10:27:58,676] {scheduler_job.py:155} INFO - Started process (PID=77055) to work on /airflow/dags/download_data.py
[2022-02-18 10:27:58,681] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:27:58,683] {logging_mixin.py:112} INFO - [2022-02-18 10:27:58,683] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:27:59,122] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:27:59,172] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:27:59,182] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:27:59,188] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 10:28:11,976] {scheduler_job.py:155} INFO - Started process (PID=77081) to work on /airflow/dags/download_data.py
[2022-02-18 10:28:11,982] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:28:11,983] {logging_mixin.py:112} INFO - [2022-02-18 10:28:11,983] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:28:12,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:28:12,460] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:28:12,470] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:28:12,476] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 10:28:25,239] {scheduler_job.py:155} INFO - Started process (PID=77107) to work on /airflow/dags/download_data.py
[2022-02-18 10:28:25,244] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:28:25,247] {logging_mixin.py:112} INFO - [2022-02-18 10:28:25,245] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:28:25,675] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:28:25,722] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:28:25,729] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:28:25,734] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 10:28:38,593] {scheduler_job.py:155} INFO - Started process (PID=77133) to work on /airflow/dags/download_data.py
[2022-02-18 10:28:38,598] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:28:38,600] {logging_mixin.py:112} INFO - [2022-02-18 10:28:38,599] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:28:39,042] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:28:39,076] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:28:39,081] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:28:39,085] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 10:28:51,860] {scheduler_job.py:155} INFO - Started process (PID=77159) to work on /airflow/dags/download_data.py
[2022-02-18 10:28:51,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:28:51,871] {logging_mixin.py:112} INFO - [2022-02-18 10:28:51,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:28:52,312] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:28:52,355] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:28:52,365] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:28:52,370] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 10:29:05,127] {scheduler_job.py:155} INFO - Started process (PID=77185) to work on /airflow/dags/download_data.py
[2022-02-18 10:29:05,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:29:05,133] {logging_mixin.py:112} INFO - [2022-02-18 10:29:05,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:29:05,570] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:29:05,621] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:29:05,631] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:29:05,634] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 10:29:18,443] {scheduler_job.py:155} INFO - Started process (PID=77211) to work on /airflow/dags/download_data.py
[2022-02-18 10:29:18,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:29:18,454] {logging_mixin.py:112} INFO - [2022-02-18 10:29:18,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:29:18,902] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:29:18,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:29:18,959] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:29:18,965] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 10:29:31,726] {scheduler_job.py:155} INFO - Started process (PID=77237) to work on /airflow/dags/download_data.py
[2022-02-18 10:29:31,738] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:29:31,740] {logging_mixin.py:112} INFO - [2022-02-18 10:29:31,739] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:29:32,191] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:29:32,249] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:29:32,262] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:29:32,270] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 10:29:45,012] {scheduler_job.py:155} INFO - Started process (PID=77263) to work on /airflow/dags/download_data.py
[2022-02-18 10:29:45,017] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:29:45,019] {logging_mixin.py:112} INFO - [2022-02-18 10:29:45,019] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:29:45,457] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:29:45,493] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:29:45,503] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:29:45,509] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 10:29:58,292] {scheduler_job.py:155} INFO - Started process (PID=77289) to work on /airflow/dags/download_data.py
[2022-02-18 10:29:58,305] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:29:58,308] {logging_mixin.py:112} INFO - [2022-02-18 10:29:58,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:30:00,200] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:30:00,341] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:30:00,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:30:00,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.064 seconds
[2022-02-18 10:30:15,035] {scheduler_job.py:155} INFO - Started process (PID=77315) to work on /airflow/dags/download_data.py
[2022-02-18 10:30:15,100] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 10:30:15,116] {logging_mixin.py:112} INFO - [2022-02-18 10:30:15,114] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 10:30:21,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 10:30:21,605] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 10:30:21,625] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 10:30:21,646] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 6.612 seconds
[2022-02-18 11:30:27,799] {scheduler_job.py:155} INFO - Started process (PID=77340) to work on /airflow/dags/download_data.py
[2022-02-18 11:30:27,804] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:30:27,805] {logging_mixin.py:112} INFO - [2022-02-18 11:30:27,805] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:30:28,268] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:30:28,318] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:30:28,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:30:28,333] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 11:30:41,096] {scheduler_job.py:155} INFO - Started process (PID=77366) to work on /airflow/dags/download_data.py
[2022-02-18 11:30:41,100] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:30:41,102] {logging_mixin.py:112} INFO - [2022-02-18 11:30:41,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:30:41,541] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:30:41,591] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:30:41,600] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:30:41,606] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 11:30:54,377] {scheduler_job.py:155} INFO - Started process (PID=77392) to work on /airflow/dags/download_data.py
[2022-02-18 11:30:54,385] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:30:54,387] {logging_mixin.py:112} INFO - [2022-02-18 11:30:54,387] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:30:54,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:30:54,868] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:30:54,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:30:54,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 11:31:07,701] {scheduler_job.py:155} INFO - Started process (PID=77418) to work on /airflow/dags/download_data.py
[2022-02-18 11:31:07,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:31:07,712] {logging_mixin.py:112} INFO - [2022-02-18 11:31:07,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:31:08,153] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:31:08,207] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:31:08,214] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:31:08,218] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 11:31:21,018] {scheduler_job.py:155} INFO - Started process (PID=77444) to work on /airflow/dags/download_data.py
[2022-02-18 11:31:21,029] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:31:21,031] {logging_mixin.py:112} INFO - [2022-02-18 11:31:21,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:31:21,454] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:31:21,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:31:21,513] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:31:21,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 11:31:34,290] {scheduler_job.py:155} INFO - Started process (PID=77470) to work on /airflow/dags/download_data.py
[2022-02-18 11:31:34,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:31:34,301] {logging_mixin.py:112} INFO - [2022-02-18 11:31:34,301] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:31:34,743] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:31:34,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:31:34,817] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:31:34,822] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 11:31:47,552] {scheduler_job.py:155} INFO - Started process (PID=77496) to work on /airflow/dags/download_data.py
[2022-02-18 11:31:47,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:31:47,558] {logging_mixin.py:112} INFO - [2022-02-18 11:31:47,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:31:48,023] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:31:48,099] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:31:48,109] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:31:48,118] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 11:32:00,812] {scheduler_job.py:155} INFO - Started process (PID=77522) to work on /airflow/dags/download_data.py
[2022-02-18 11:32:00,816] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:32:00,818] {logging_mixin.py:112} INFO - [2022-02-18 11:32:00,818] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:32:01,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:32:01,324] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:32:01,330] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:32:01,334] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 11:32:14,097] {scheduler_job.py:155} INFO - Started process (PID=77548) to work on /airflow/dags/download_data.py
[2022-02-18 11:32:14,102] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:32:14,103] {logging_mixin.py:112} INFO - [2022-02-18 11:32:14,103] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:32:14,542] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:32:14,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:32:14,595] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:32:14,602] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 11:32:27,397] {scheduler_job.py:155} INFO - Started process (PID=77574) to work on /airflow/dags/download_data.py
[2022-02-18 11:32:27,403] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:32:27,405] {logging_mixin.py:112} INFO - [2022-02-18 11:32:27,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:32:27,895] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:32:27,950] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:32:27,957] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:32:27,961] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 11:32:40,668] {scheduler_job.py:155} INFO - Started process (PID=77600) to work on /airflow/dags/download_data.py
[2022-02-18 11:32:40,672] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:32:40,674] {logging_mixin.py:112} INFO - [2022-02-18 11:32:40,673] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:32:41,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:32:41,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:32:41,164] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:32:41,169] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 11:32:53,902] {scheduler_job.py:155} INFO - Started process (PID=77626) to work on /airflow/dags/download_data.py
[2022-02-18 11:32:53,906] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:32:53,908] {logging_mixin.py:112} INFO - [2022-02-18 11:32:53,908] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:32:54,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:32:54,403] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:32:54,413] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:32:54,419] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 11:33:07,229] {scheduler_job.py:155} INFO - Started process (PID=77652) to work on /airflow/dags/download_data.py
[2022-02-18 11:33:07,241] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:33:07,243] {logging_mixin.py:112} INFO - [2022-02-18 11:33:07,242] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:33:07,686] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:33:07,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:33:07,745] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:33:07,749] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 11:33:20,531] {scheduler_job.py:155} INFO - Started process (PID=77678) to work on /airflow/dags/download_data.py
[2022-02-18 11:33:20,535] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:33:20,537] {logging_mixin.py:112} INFO - [2022-02-18 11:33:20,537] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:33:20,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:33:21,015] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:33:21,023] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:33:21,028] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 11:33:33,838] {scheduler_job.py:155} INFO - Started process (PID=77704) to work on /airflow/dags/download_data.py
[2022-02-18 11:33:33,842] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:33:33,844] {logging_mixin.py:112} INFO - [2022-02-18 11:33:33,843] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:33:34,280] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:33:34,331] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:33:34,340] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:33:34,344] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 11:33:47,157] {scheduler_job.py:155} INFO - Started process (PID=77730) to work on /airflow/dags/download_data.py
[2022-02-18 11:33:47,173] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:33:47,176] {logging_mixin.py:112} INFO - [2022-02-18 11:33:47,176] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:33:47,628] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:33:47,677] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:33:47,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:33:47,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 11:34:00,456] {scheduler_job.py:155} INFO - Started process (PID=77756) to work on /airflow/dags/download_data.py
[2022-02-18 11:34:00,461] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:34:00,462] {logging_mixin.py:112} INFO - [2022-02-18 11:34:00,462] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:34:00,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:34:00,958] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:34:00,969] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:34:00,975] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 11:34:13,713] {scheduler_job.py:155} INFO - Started process (PID=77782) to work on /airflow/dags/download_data.py
[2022-02-18 11:34:13,719] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:34:13,721] {logging_mixin.py:112} INFO - [2022-02-18 11:34:13,721] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:34:14,167] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:34:14,217] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:34:14,223] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:34:14,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 11:34:26,994] {scheduler_job.py:155} INFO - Started process (PID=77808) to work on /airflow/dags/download_data.py
[2022-02-18 11:34:26,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:34:27,000] {logging_mixin.py:112} INFO - [2022-02-18 11:34:27,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:34:27,461] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:34:27,526] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:34:27,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:34:27,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 11:34:40,316] {scheduler_job.py:155} INFO - Started process (PID=77834) to work on /airflow/dags/download_data.py
[2022-02-18 11:34:40,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:34:40,327] {logging_mixin.py:112} INFO - [2022-02-18 11:34:40,327] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:34:40,761] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:34:40,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:34:40,821] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:34:40,826] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 11:34:53,577] {scheduler_job.py:155} INFO - Started process (PID=77860) to work on /airflow/dags/download_data.py
[2022-02-18 11:34:53,581] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:34:53,583] {logging_mixin.py:112} INFO - [2022-02-18 11:34:53,583] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:34:54,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:34:54,083] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:34:54,091] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:34:54,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 11:35:06,897] {scheduler_job.py:155} INFO - Started process (PID=77886) to work on /airflow/dags/download_data.py
[2022-02-18 11:35:06,906] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:35:06,910] {logging_mixin.py:112} INFO - [2022-02-18 11:35:06,910] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:35:07,340] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:35:07,389] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:35:07,396] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:35:07,401] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 11:35:20,190] {scheduler_job.py:155} INFO - Started process (PID=77912) to work on /airflow/dags/download_data.py
[2022-02-18 11:35:20,195] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:35:20,196] {logging_mixin.py:112} INFO - [2022-02-18 11:35:20,196] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:35:20,643] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:35:20,693] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:35:20,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:35:20,710] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 11:35:33,478] {scheduler_job.py:155} INFO - Started process (PID=77938) to work on /airflow/dags/download_data.py
[2022-02-18 11:35:33,482] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:35:33,484] {logging_mixin.py:112} INFO - [2022-02-18 11:35:33,484] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:35:33,935] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:35:33,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:35:34,000] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:35:34,005] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 11:35:46,764] {scheduler_job.py:155} INFO - Started process (PID=77964) to work on /airflow/dags/download_data.py
[2022-02-18 11:35:46,769] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:35:46,771] {logging_mixin.py:112} INFO - [2022-02-18 11:35:46,771] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:35:47,208] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:35:47,255] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:35:47,262] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:35:47,268] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 11:36:00,049] {scheduler_job.py:155} INFO - Started process (PID=77990) to work on /airflow/dags/download_data.py
[2022-02-18 11:36:00,057] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:36:00,059] {logging_mixin.py:112} INFO - [2022-02-18 11:36:00,059] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:36:00,519] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:36:00,570] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:36:00,576] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:36:00,581] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 11:36:13,346] {scheduler_job.py:155} INFO - Started process (PID=78016) to work on /airflow/dags/download_data.py
[2022-02-18 11:36:13,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:36:13,352] {logging_mixin.py:112} INFO - [2022-02-18 11:36:13,352] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:36:13,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:36:13,849] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:36:13,858] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:36:13,864] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 11:36:26,610] {scheduler_job.py:155} INFO - Started process (PID=78042) to work on /airflow/dags/download_data.py
[2022-02-18 11:36:26,615] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:36:26,617] {logging_mixin.py:112} INFO - [2022-02-18 11:36:26,616] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:36:27,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:36:27,140] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:36:27,151] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:36:27,156] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 11:36:39,938] {scheduler_job.py:155} INFO - Started process (PID=78068) to work on /airflow/dags/download_data.py
[2022-02-18 11:36:39,947] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:36:39,949] {logging_mixin.py:112} INFO - [2022-02-18 11:36:39,949] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:36:40,405] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:36:40,459] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:36:40,471] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:36:40,476] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 11:36:53,226] {scheduler_job.py:155} INFO - Started process (PID=78094) to work on /airflow/dags/download_data.py
[2022-02-18 11:36:53,236] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:36:53,239] {logging_mixin.py:112} INFO - [2022-02-18 11:36:53,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:36:53,669] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:36:53,711] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:36:53,718] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:36:53,723] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 11:37:06,509] {scheduler_job.py:155} INFO - Started process (PID=78120) to work on /airflow/dags/download_data.py
[2022-02-18 11:37:06,520] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:37:06,522] {logging_mixin.py:112} INFO - [2022-02-18 11:37:06,522] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:37:06,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:37:07,000] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:37:07,008] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:37:07,013] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 11:37:19,788] {scheduler_job.py:155} INFO - Started process (PID=78146) to work on /airflow/dags/download_data.py
[2022-02-18 11:37:19,798] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:37:19,801] {logging_mixin.py:112} INFO - [2022-02-18 11:37:19,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:37:20,251] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:37:20,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:37:20,309] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:37:20,313] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 11:37:33,063] {scheduler_job.py:155} INFO - Started process (PID=78172) to work on /airflow/dags/download_data.py
[2022-02-18 11:37:33,067] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:37:33,069] {logging_mixin.py:112} INFO - [2022-02-18 11:37:33,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:37:33,510] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:37:33,553] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:37:33,561] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:37:33,566] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 11:37:46,375] {scheduler_job.py:155} INFO - Started process (PID=78198) to work on /airflow/dags/download_data.py
[2022-02-18 11:37:46,378] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:37:46,381] {logging_mixin.py:112} INFO - [2022-02-18 11:37:46,381] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:37:46,831] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:37:46,886] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:37:46,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:37:46,899] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 11:37:59,653] {scheduler_job.py:155} INFO - Started process (PID=78224) to work on /airflow/dags/download_data.py
[2022-02-18 11:37:59,662] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:37:59,664] {logging_mixin.py:112} INFO - [2022-02-18 11:37:59,664] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:38:00,142] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:38:00,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:38:00,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:38:00,193] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 11:38:12,953] {scheduler_job.py:155} INFO - Started process (PID=78250) to work on /airflow/dags/download_data.py
[2022-02-18 11:38:12,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:38:12,961] {logging_mixin.py:112} INFO - [2022-02-18 11:38:12,961] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:38:13,414] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:38:13,464] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:38:13,471] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:38:13,475] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 11:38:26,233] {scheduler_job.py:155} INFO - Started process (PID=78276) to work on /airflow/dags/download_data.py
[2022-02-18 11:38:26,238] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:38:26,240] {logging_mixin.py:112} INFO - [2022-02-18 11:38:26,240] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:38:26,686] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:38:26,735] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:38:26,746] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:38:26,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 11:38:39,596] {scheduler_job.py:155} INFO - Started process (PID=78302) to work on /airflow/dags/download_data.py
[2022-02-18 11:38:39,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:38:39,607] {logging_mixin.py:112} INFO - [2022-02-18 11:38:39,606] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:38:40,039] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:38:40,088] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:38:40,097] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:38:40,102] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 11:38:52,866] {scheduler_job.py:155} INFO - Started process (PID=78328) to work on /airflow/dags/download_data.py
[2022-02-18 11:38:52,871] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:38:52,872] {logging_mixin.py:112} INFO - [2022-02-18 11:38:52,872] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:38:53,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:38:53,360] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:38:53,368] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:38:53,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 11:39:06,179] {scheduler_job.py:155} INFO - Started process (PID=78354) to work on /airflow/dags/download_data.py
[2022-02-18 11:39:06,184] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:39:06,185] {logging_mixin.py:112} INFO - [2022-02-18 11:39:06,185] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:39:06,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:39:06,680] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:39:06,690] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:39:06,694] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 11:39:19,466] {scheduler_job.py:155} INFO - Started process (PID=78380) to work on /airflow/dags/download_data.py
[2022-02-18 11:39:19,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:39:19,472] {logging_mixin.py:112} INFO - [2022-02-18 11:39:19,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:39:19,906] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:39:19,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:39:19,961] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:39:19,966] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 11:39:32,688] {scheduler_job.py:155} INFO - Started process (PID=78406) to work on /airflow/dags/download_data.py
[2022-02-18 11:39:32,693] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:39:32,695] {logging_mixin.py:112} INFO - [2022-02-18 11:39:32,695] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:39:33,136] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:39:33,187] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:39:33,197] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:39:33,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 11:39:46,026] {scheduler_job.py:155} INFO - Started process (PID=78432) to work on /airflow/dags/download_data.py
[2022-02-18 11:39:46,030] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:39:46,033] {logging_mixin.py:112} INFO - [2022-02-18 11:39:46,032] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:39:46,468] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:39:46,514] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:39:46,520] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:39:46,524] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 11:39:59,302] {scheduler_job.py:155} INFO - Started process (PID=78458) to work on /airflow/dags/download_data.py
[2022-02-18 11:39:59,306] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:39:59,308] {logging_mixin.py:112} INFO - [2022-02-18 11:39:59,308] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:39:59,761] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:39:59,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:39:59,821] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:39:59,826] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 11:40:12,615] {scheduler_job.py:155} INFO - Started process (PID=78484) to work on /airflow/dags/download_data.py
[2022-02-18 11:40:12,622] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:40:12,624] {logging_mixin.py:112} INFO - [2022-02-18 11:40:12,624] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:40:13,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:40:13,118] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:40:13,126] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:40:13,131] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 11:40:25,911] {scheduler_job.py:155} INFO - Started process (PID=78510) to work on /airflow/dags/download_data.py
[2022-02-18 11:40:25,918] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:40:25,920] {logging_mixin.py:112} INFO - [2022-02-18 11:40:25,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:40:26,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:40:26,403] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:40:26,409] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:40:26,413] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 11:40:39,216] {scheduler_job.py:155} INFO - Started process (PID=78536) to work on /airflow/dags/download_data.py
[2022-02-18 11:40:39,221] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:40:39,223] {logging_mixin.py:112} INFO - [2022-02-18 11:40:39,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:40:39,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:40:39,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:40:39,713] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:40:39,717] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 11:40:52,453] {scheduler_job.py:155} INFO - Started process (PID=78562) to work on /airflow/dags/download_data.py
[2022-02-18 11:40:52,459] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:40:52,460] {logging_mixin.py:112} INFO - [2022-02-18 11:40:52,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:40:52,909] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:40:52,961] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:40:52,970] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:40:52,976] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 11:41:05,780] {scheduler_job.py:155} INFO - Started process (PID=78588) to work on /airflow/dags/download_data.py
[2022-02-18 11:41:05,789] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:41:05,792] {logging_mixin.py:112} INFO - [2022-02-18 11:41:05,791] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:41:06,237] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:41:06,285] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:41:06,294] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:41:06,298] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 11:41:19,050] {scheduler_job.py:155} INFO - Started process (PID=78614) to work on /airflow/dags/download_data.py
[2022-02-18 11:41:19,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:41:19,057] {logging_mixin.py:112} INFO - [2022-02-18 11:41:19,056] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:41:19,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:41:19,547] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:41:19,553] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:41:19,556] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 11:41:32,316] {scheduler_job.py:155} INFO - Started process (PID=78640) to work on /airflow/dags/download_data.py
[2022-02-18 11:41:32,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:41:32,325] {logging_mixin.py:112} INFO - [2022-02-18 11:41:32,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:41:32,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:41:32,810] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:41:32,817] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:41:32,824] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 11:41:45,662] {scheduler_job.py:155} INFO - Started process (PID=78666) to work on /airflow/dags/download_data.py
[2022-02-18 11:41:45,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:41:45,671] {logging_mixin.py:112} INFO - [2022-02-18 11:41:45,671] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:41:46,100] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:41:46,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:41:46,153] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:41:46,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 11:41:58,931] {scheduler_job.py:155} INFO - Started process (PID=78692) to work on /airflow/dags/download_data.py
[2022-02-18 11:41:58,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:41:58,936] {logging_mixin.py:112} INFO - [2022-02-18 11:41:58,936] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:41:59,399] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:41:59,451] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:41:59,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:41:59,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 11:42:12,260] {scheduler_job.py:155} INFO - Started process (PID=78718) to work on /airflow/dags/download_data.py
[2022-02-18 11:42:12,268] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:42:12,270] {logging_mixin.py:112} INFO - [2022-02-18 11:42:12,270] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:42:12,716] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:42:12,764] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:42:12,771] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:42:12,775] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 11:42:25,496] {scheduler_job.py:155} INFO - Started process (PID=78744) to work on /airflow/dags/download_data.py
[2022-02-18 11:42:25,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:42:25,505] {logging_mixin.py:112} INFO - [2022-02-18 11:42:25,505] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:42:25,940] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:42:25,985] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:42:25,993] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:42:25,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 11:42:38,816] {scheduler_job.py:155} INFO - Started process (PID=78770) to work on /airflow/dags/download_data.py
[2022-02-18 11:42:38,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:42:38,821] {logging_mixin.py:112} INFO - [2022-02-18 11:42:38,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:42:39,248] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:42:39,298] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:42:39,305] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:42:39,309] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 11:42:52,060] {scheduler_job.py:155} INFO - Started process (PID=78796) to work on /airflow/dags/download_data.py
[2022-02-18 11:42:52,065] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:42:52,067] {logging_mixin.py:112} INFO - [2022-02-18 11:42:52,067] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:42:52,529] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:42:52,571] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:42:52,579] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:42:52,585] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 11:43:05,336] {scheduler_job.py:155} INFO - Started process (PID=78822) to work on /airflow/dags/download_data.py
[2022-02-18 11:43:05,341] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:43:05,343] {logging_mixin.py:112} INFO - [2022-02-18 11:43:05,342] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:43:05,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:43:05,835] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:43:05,841] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:43:05,846] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 11:43:18,683] {scheduler_job.py:155} INFO - Started process (PID=78848) to work on /airflow/dags/download_data.py
[2022-02-18 11:43:18,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:43:18,692] {logging_mixin.py:112} INFO - [2022-02-18 11:43:18,692] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:43:19,149] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:43:19,189] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:43:19,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:43:19,201] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 11:43:31,931] {scheduler_job.py:155} INFO - Started process (PID=78874) to work on /airflow/dags/download_data.py
[2022-02-18 11:43:31,946] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:43:31,948] {logging_mixin.py:112} INFO - [2022-02-18 11:43:31,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:43:32,380] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:43:32,429] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:43:32,438] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:43:32,444] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 11:43:45,213] {scheduler_job.py:155} INFO - Started process (PID=78900) to work on /airflow/dags/download_data.py
[2022-02-18 11:43:45,220] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:43:45,225] {logging_mixin.py:112} INFO - [2022-02-18 11:43:45,225] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:43:45,650] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:43:45,699] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:43:45,706] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:43:45,710] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 11:43:58,450] {scheduler_job.py:155} INFO - Started process (PID=78926) to work on /airflow/dags/download_data.py
[2022-02-18 11:43:58,458] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:43:58,461] {logging_mixin.py:112} INFO - [2022-02-18 11:43:58,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:43:58,909] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:43:58,966] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:43:58,978] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:43:58,987] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 11:44:11,760] {scheduler_job.py:155} INFO - Started process (PID=78952) to work on /airflow/dags/download_data.py
[2022-02-18 11:44:11,765] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:44:11,767] {logging_mixin.py:112} INFO - [2022-02-18 11:44:11,767] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:44:12,195] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:44:12,245] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:44:12,253] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:44:12,258] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 11:44:24,999] {scheduler_job.py:155} INFO - Started process (PID=78978) to work on /airflow/dags/download_data.py
[2022-02-18 11:44:25,006] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:44:25,008] {logging_mixin.py:112} INFO - [2022-02-18 11:44:25,008] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:44:25,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:44:25,494] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:44:25,503] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:44:25,509] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 11:44:38,257] {scheduler_job.py:155} INFO - Started process (PID=79004) to work on /airflow/dags/download_data.py
[2022-02-18 11:44:38,261] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:44:38,263] {logging_mixin.py:112} INFO - [2022-02-18 11:44:38,262] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:44:38,691] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:44:38,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:44:38,751] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:44:38,756] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 11:44:51,536] {scheduler_job.py:155} INFO - Started process (PID=79030) to work on /airflow/dags/download_data.py
[2022-02-18 11:44:51,540] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:44:51,542] {logging_mixin.py:112} INFO - [2022-02-18 11:44:51,542] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:44:51,985] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:44:52,031] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:44:52,038] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:44:52,043] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 11:45:04,841] {scheduler_job.py:155} INFO - Started process (PID=79056) to work on /airflow/dags/download_data.py
[2022-02-18 11:45:04,845] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:45:04,847] {logging_mixin.py:112} INFO - [2022-02-18 11:45:04,847] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:45:05,290] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:45:05,330] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:45:05,336] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:45:05,340] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 11:45:18,182] {scheduler_job.py:155} INFO - Started process (PID=79082) to work on /airflow/dags/download_data.py
[2022-02-18 11:45:18,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:45:18,191] {logging_mixin.py:112} INFO - [2022-02-18 11:45:18,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:45:18,619] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:45:18,670] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:45:18,679] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:45:18,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 11:45:31,468] {scheduler_job.py:155} INFO - Started process (PID=79108) to work on /airflow/dags/download_data.py
[2022-02-18 11:45:31,474] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:45:31,476] {logging_mixin.py:112} INFO - [2022-02-18 11:45:31,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:45:31,925] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:45:31,968] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:45:31,980] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:45:31,985] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 11:45:44,788] {scheduler_job.py:155} INFO - Started process (PID=79134) to work on /airflow/dags/download_data.py
[2022-02-18 11:45:44,796] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:45:44,798] {logging_mixin.py:112} INFO - [2022-02-18 11:45:44,798] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:45:45,266] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:45:45,321] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:45:45,327] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:45:45,332] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 11:45:58,028] {scheduler_job.py:155} INFO - Started process (PID=79160) to work on /airflow/dags/download_data.py
[2022-02-18 11:45:58,034] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:45:58,036] {logging_mixin.py:112} INFO - [2022-02-18 11:45:58,036] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:45:58,490] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:45:58,547] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:45:58,560] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:45:58,568] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 11:46:11,347] {scheduler_job.py:155} INFO - Started process (PID=79186) to work on /airflow/dags/download_data.py
[2022-02-18 11:46:11,353] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:46:11,355] {logging_mixin.py:112} INFO - [2022-02-18 11:46:11,355] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:46:11,802] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:46:11,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:46:11,859] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:46:11,865] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 11:46:24,628] {scheduler_job.py:155} INFO - Started process (PID=79212) to work on /airflow/dags/download_data.py
[2022-02-18 11:46:24,636] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:46:24,637] {logging_mixin.py:112} INFO - [2022-02-18 11:46:24,637] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:46:25,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:46:25,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:46:25,128] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:46:25,132] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 11:46:37,893] {scheduler_job.py:155} INFO - Started process (PID=79238) to work on /airflow/dags/download_data.py
[2022-02-18 11:46:37,906] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:46:37,907] {logging_mixin.py:112} INFO - [2022-02-18 11:46:37,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:46:38,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:46:38,387] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:46:38,393] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:46:38,399] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 11:46:51,152] {scheduler_job.py:155} INFO - Started process (PID=79264) to work on /airflow/dags/download_data.py
[2022-02-18 11:46:51,160] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:46:51,162] {logging_mixin.py:112} INFO - [2022-02-18 11:46:51,162] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:46:51,611] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:46:51,664] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:46:51,675] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:46:51,679] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 11:47:04,443] {scheduler_job.py:155} INFO - Started process (PID=79290) to work on /airflow/dags/download_data.py
[2022-02-18 11:47:04,448] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:47:04,449] {logging_mixin.py:112} INFO - [2022-02-18 11:47:04,449] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:47:04,883] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:47:04,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:47:04,940] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:47:04,944] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 11:47:17,775] {scheduler_job.py:155} INFO - Started process (PID=79316) to work on /airflow/dags/download_data.py
[2022-02-18 11:47:17,781] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:47:17,783] {logging_mixin.py:112} INFO - [2022-02-18 11:47:17,783] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:47:18,212] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:47:18,252] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:47:18,258] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:47:18,262] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.487 seconds
[2022-02-18 11:47:31,076] {scheduler_job.py:155} INFO - Started process (PID=79342) to work on /airflow/dags/download_data.py
[2022-02-18 11:47:31,081] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:47:31,083] {logging_mixin.py:112} INFO - [2022-02-18 11:47:31,082] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:47:31,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:47:31,580] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:47:31,589] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:47:31,594] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 11:47:44,400] {scheduler_job.py:155} INFO - Started process (PID=79368) to work on /airflow/dags/download_data.py
[2022-02-18 11:47:44,409] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:47:44,411] {logging_mixin.py:112} INFO - [2022-02-18 11:47:44,411] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:47:44,845] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:47:44,896] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:47:44,906] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:47:44,913] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 11:47:57,659] {scheduler_job.py:155} INFO - Started process (PID=79394) to work on /airflow/dags/download_data.py
[2022-02-18 11:47:57,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:47:57,671] {logging_mixin.py:112} INFO - [2022-02-18 11:47:57,671] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:47:58,126] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:47:58,170] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:47:58,180] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:47:58,185] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 11:48:10,961] {scheduler_job.py:155} INFO - Started process (PID=79420) to work on /airflow/dags/download_data.py
[2022-02-18 11:48:10,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:48:10,972] {logging_mixin.py:112} INFO - [2022-02-18 11:48:10,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:48:11,398] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:48:11,440] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:48:11,446] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:48:11,449] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-18 11:48:24,263] {scheduler_job.py:155} INFO - Started process (PID=79446) to work on /airflow/dags/download_data.py
[2022-02-18 11:48:24,271] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:48:24,273] {logging_mixin.py:112} INFO - [2022-02-18 11:48:24,273] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:48:24,697] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:48:24,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:48:24,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:48:24,752] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-18 11:48:37,573] {scheduler_job.py:155} INFO - Started process (PID=79472) to work on /airflow/dags/download_data.py
[2022-02-18 11:48:37,580] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:48:37,582] {logging_mixin.py:112} INFO - [2022-02-18 11:48:37,582] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:48:38,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:48:38,080] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:48:38,086] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:48:38,092] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 11:48:50,880] {scheduler_job.py:155} INFO - Started process (PID=79498) to work on /airflow/dags/download_data.py
[2022-02-18 11:48:50,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:48:50,890] {logging_mixin.py:112} INFO - [2022-02-18 11:48:50,890] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:48:51,332] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:48:51,382] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:48:51,392] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:48:51,398] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 11:49:04,127] {scheduler_job.py:155} INFO - Started process (PID=79524) to work on /airflow/dags/download_data.py
[2022-02-18 11:49:04,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:49:04,134] {logging_mixin.py:112} INFO - [2022-02-18 11:49:04,133] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:49:04,580] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:49:04,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:49:04,636] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:49:04,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 11:49:17,433] {scheduler_job.py:155} INFO - Started process (PID=79550) to work on /airflow/dags/download_data.py
[2022-02-18 11:49:17,437] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:49:17,438] {logging_mixin.py:112} INFO - [2022-02-18 11:49:17,438] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:49:17,883] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:49:17,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:49:17,940] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:49:17,945] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 11:49:30,718] {scheduler_job.py:155} INFO - Started process (PID=79576) to work on /airflow/dags/download_data.py
[2022-02-18 11:49:30,726] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:49:30,728] {logging_mixin.py:112} INFO - [2022-02-18 11:49:30,727] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:49:31,166] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:49:31,212] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:49:31,218] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:49:31,223] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 11:49:44,016] {scheduler_job.py:155} INFO - Started process (PID=79602) to work on /airflow/dags/download_data.py
[2022-02-18 11:49:44,022] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:49:44,024] {logging_mixin.py:112} INFO - [2022-02-18 11:49:44,023] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:49:44,456] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:49:44,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:49:44,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:49:44,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 11:49:57,316] {scheduler_job.py:155} INFO - Started process (PID=79628) to work on /airflow/dags/download_data.py
[2022-02-18 11:49:57,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:49:57,326] {logging_mixin.py:112} INFO - [2022-02-18 11:49:57,326] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:49:57,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:49:57,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:49:57,901] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:49:57,907] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 11:50:10,617] {scheduler_job.py:155} INFO - Started process (PID=79654) to work on /airflow/dags/download_data.py
[2022-02-18 11:50:10,622] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:50:10,623] {logging_mixin.py:112} INFO - [2022-02-18 11:50:10,623] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:50:11,068] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:50:11,119] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:50:11,126] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:50:11,132] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 11:50:23,879] {scheduler_job.py:155} INFO - Started process (PID=79680) to work on /airflow/dags/download_data.py
[2022-02-18 11:50:23,883] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:50:23,884] {logging_mixin.py:112} INFO - [2022-02-18 11:50:23,884] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:50:24,321] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:50:24,371] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:50:24,379] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:50:24,383] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 11:50:37,159] {scheduler_job.py:155} INFO - Started process (PID=79706) to work on /airflow/dags/download_data.py
[2022-02-18 11:50:37,164] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:50:37,165] {logging_mixin.py:112} INFO - [2022-02-18 11:50:37,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:50:37,605] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:50:37,642] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:50:37,648] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:50:37,651] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 11:50:50,400] {scheduler_job.py:155} INFO - Started process (PID=79732) to work on /airflow/dags/download_data.py
[2022-02-18 11:50:50,406] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:50:50,408] {logging_mixin.py:112} INFO - [2022-02-18 11:50:50,408] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:50:50,857] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:50:50,908] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:50:50,915] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:50:50,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 11:51:03,704] {scheduler_job.py:155} INFO - Started process (PID=79758) to work on /airflow/dags/download_data.py
[2022-02-18 11:51:03,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:51:03,711] {logging_mixin.py:112} INFO - [2022-02-18 11:51:03,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:51:04,145] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:51:04,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:51:04,206] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:51:04,210] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 11:51:16,993] {scheduler_job.py:155} INFO - Started process (PID=79784) to work on /airflow/dags/download_data.py
[2022-02-18 11:51:16,997] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:51:16,999] {logging_mixin.py:112} INFO - [2022-02-18 11:51:16,999] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:51:17,455] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:51:17,495] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:51:17,501] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:51:17,504] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 11:51:30,299] {scheduler_job.py:155} INFO - Started process (PID=79810) to work on /airflow/dags/download_data.py
[2022-02-18 11:51:30,307] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:51:30,309] {logging_mixin.py:112} INFO - [2022-02-18 11:51:30,308] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:51:30,739] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:51:30,780] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:51:30,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:51:30,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 11:51:43,580] {scheduler_job.py:155} INFO - Started process (PID=79836) to work on /airflow/dags/download_data.py
[2022-02-18 11:51:43,588] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:51:43,590] {logging_mixin.py:112} INFO - [2022-02-18 11:51:43,590] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:51:44,021] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:51:44,069] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:51:44,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:51:44,078] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 11:51:56,845] {scheduler_job.py:155} INFO - Started process (PID=79862) to work on /airflow/dags/download_data.py
[2022-02-18 11:51:56,850] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:51:56,851] {logging_mixin.py:112} INFO - [2022-02-18 11:51:56,851] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:51:57,311] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:51:57,364] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:51:57,374] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:51:57,383] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 11:52:10,161] {scheduler_job.py:155} INFO - Started process (PID=79888) to work on /airflow/dags/download_data.py
[2022-02-18 11:52:10,167] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:52:10,168] {logging_mixin.py:112} INFO - [2022-02-18 11:52:10,168] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:52:10,611] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:52:10,653] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:52:10,659] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:52:10,662] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 11:52:23,436] {scheduler_job.py:155} INFO - Started process (PID=79914) to work on /airflow/dags/download_data.py
[2022-02-18 11:52:23,441] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:52:23,442] {logging_mixin.py:112} INFO - [2022-02-18 11:52:23,442] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:52:23,888] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:52:23,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:52:23,945] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:52:23,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 11:52:36,739] {scheduler_job.py:155} INFO - Started process (PID=79940) to work on /airflow/dags/download_data.py
[2022-02-18 11:52:36,744] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:52:36,746] {logging_mixin.py:112} INFO - [2022-02-18 11:52:36,746] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:52:37,189] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:52:37,238] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:52:37,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:52:37,257] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 11:52:49,978] {scheduler_job.py:155} INFO - Started process (PID=79966) to work on /airflow/dags/download_data.py
[2022-02-18 11:52:49,990] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:52:49,993] {logging_mixin.py:112} INFO - [2022-02-18 11:52:49,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:52:50,433] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:52:50,483] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:52:50,493] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:52:50,500] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 11:53:03,315] {scheduler_job.py:155} INFO - Started process (PID=79992) to work on /airflow/dags/download_data.py
[2022-02-18 11:53:03,319] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:53:03,321] {logging_mixin.py:112} INFO - [2022-02-18 11:53:03,321] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:53:03,761] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:53:03,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:53:03,811] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:53:03,816] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 11:53:16,628] {scheduler_job.py:155} INFO - Started process (PID=80018) to work on /airflow/dags/download_data.py
[2022-02-18 11:53:16,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:53:16,635] {logging_mixin.py:112} INFO - [2022-02-18 11:53:16,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:53:17,072] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:53:17,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:53:17,128] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:53:17,131] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 11:53:29,927] {scheduler_job.py:155} INFO - Started process (PID=80044) to work on /airflow/dags/download_data.py
[2022-02-18 11:53:29,934] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:53:29,936] {logging_mixin.py:112} INFO - [2022-02-18 11:53:29,936] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:53:30,376] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:53:30,438] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:53:30,446] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:53:30,451] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 11:53:43,233] {scheduler_job.py:155} INFO - Started process (PID=80070) to work on /airflow/dags/download_data.py
[2022-02-18 11:53:43,237] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:53:43,239] {logging_mixin.py:112} INFO - [2022-02-18 11:53:43,239] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:53:43,677] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:53:43,724] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:53:43,730] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:53:43,733] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 11:53:56,515] {scheduler_job.py:155} INFO - Started process (PID=80096) to work on /airflow/dags/download_data.py
[2022-02-18 11:53:56,521] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:53:56,522] {logging_mixin.py:112} INFO - [2022-02-18 11:53:56,522] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:53:56,960] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:53:57,006] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:53:57,015] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:53:57,021] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 11:54:09,816] {scheduler_job.py:155} INFO - Started process (PID=80122) to work on /airflow/dags/download_data.py
[2022-02-18 11:54:09,822] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:54:09,824] {logging_mixin.py:112} INFO - [2022-02-18 11:54:09,824] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:54:10,258] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:54:10,311] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:54:10,317] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:54:10,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 11:54:23,071] {scheduler_job.py:155} INFO - Started process (PID=80148) to work on /airflow/dags/download_data.py
[2022-02-18 11:54:23,083] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:54:23,086] {logging_mixin.py:112} INFO - [2022-02-18 11:54:23,085] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:54:23,535] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:54:23,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:54:23,585] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:54:23,591] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 11:54:36,346] {scheduler_job.py:155} INFO - Started process (PID=80174) to work on /airflow/dags/download_data.py
[2022-02-18 11:54:36,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:54:36,351] {logging_mixin.py:112} INFO - [2022-02-18 11:54:36,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:54:36,780] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:54:36,831] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:54:36,838] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:54:36,841] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 11:54:49,637] {scheduler_job.py:155} INFO - Started process (PID=80200) to work on /airflow/dags/download_data.py
[2022-02-18 11:54:49,642] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:54:49,643] {logging_mixin.py:112} INFO - [2022-02-18 11:54:49,643] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:54:50,044] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:54:50,096] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:54:50,105] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:54:50,109] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.472 seconds
[2022-02-18 11:55:02,924] {scheduler_job.py:155} INFO - Started process (PID=80226) to work on /airflow/dags/download_data.py
[2022-02-18 11:55:02,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:55:02,930] {logging_mixin.py:112} INFO - [2022-02-18 11:55:02,930] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:55:03,370] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:55:03,425] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:55:03,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:55:03,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 11:55:16,260] {scheduler_job.py:155} INFO - Started process (PID=80252) to work on /airflow/dags/download_data.py
[2022-02-18 11:55:16,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:55:16,266] {logging_mixin.py:112} INFO - [2022-02-18 11:55:16,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:55:16,689] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:55:16,729] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:55:16,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:55:16,739] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.479 seconds
[2022-02-18 11:55:29,567] {scheduler_job.py:155} INFO - Started process (PID=80278) to work on /airflow/dags/download_data.py
[2022-02-18 11:55:29,573] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:55:29,574] {logging_mixin.py:112} INFO - [2022-02-18 11:55:29,574] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:55:30,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:55:30,077] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:55:30,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:55:30,097] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 11:55:42,872] {scheduler_job.py:155} INFO - Started process (PID=80304) to work on /airflow/dags/download_data.py
[2022-02-18 11:55:42,877] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:55:42,878] {logging_mixin.py:112} INFO - [2022-02-18 11:55:42,878] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:55:43,322] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:55:43,370] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:55:43,376] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:55:43,381] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 11:55:56,165] {scheduler_job.py:155} INFO - Started process (PID=80330) to work on /airflow/dags/download_data.py
[2022-02-18 11:55:56,170] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:55:56,172] {logging_mixin.py:112} INFO - [2022-02-18 11:55:56,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:55:56,670] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:55:56,718] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:55:56,726] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:55:56,731] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 11:56:09,463] {scheduler_job.py:155} INFO - Started process (PID=80356) to work on /airflow/dags/download_data.py
[2022-02-18 11:56:09,473] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:56:09,477] {logging_mixin.py:112} INFO - [2022-02-18 11:56:09,476] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:56:09,949] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:56:09,994] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:56:10,003] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:56:10,008] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 11:56:22,760] {scheduler_job.py:155} INFO - Started process (PID=80382) to work on /airflow/dags/download_data.py
[2022-02-18 11:56:22,767] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:56:22,769] {logging_mixin.py:112} INFO - [2022-02-18 11:56:22,769] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:56:23,218] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:56:23,260] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:56:23,267] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:56:23,272] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 11:56:36,061] {scheduler_job.py:155} INFO - Started process (PID=80408) to work on /airflow/dags/download_data.py
[2022-02-18 11:56:36,066] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:56:36,067] {logging_mixin.py:112} INFO - [2022-02-18 11:56:36,067] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:56:36,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:56:36,570] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:56:36,577] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:56:36,586] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 11:56:49,330] {scheduler_job.py:155} INFO - Started process (PID=80434) to work on /airflow/dags/download_data.py
[2022-02-18 11:56:49,338] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:56:49,340] {logging_mixin.py:112} INFO - [2022-02-18 11:56:49,339] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:56:49,739] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:56:49,790] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:56:49,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:56:49,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.474 seconds
[2022-02-18 11:57:02,618] {scheduler_job.py:155} INFO - Started process (PID=80460) to work on /airflow/dags/download_data.py
[2022-02-18 11:57:02,625] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:57:02,627] {logging_mixin.py:112} INFO - [2022-02-18 11:57:02,627] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:57:03,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:57:03,102] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:57:03,108] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:57:03,113] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 11:57:15,908] {scheduler_job.py:155} INFO - Started process (PID=80486) to work on /airflow/dags/download_data.py
[2022-02-18 11:57:15,916] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:57:15,918] {logging_mixin.py:112} INFO - [2022-02-18 11:57:15,918] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:57:16,366] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:57:16,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:57:16,425] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:57:16,429] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 11:57:29,231] {scheduler_job.py:155} INFO - Started process (PID=80512) to work on /airflow/dags/download_data.py
[2022-02-18 11:57:29,236] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:57:29,237] {logging_mixin.py:112} INFO - [2022-02-18 11:57:29,237] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:57:29,708] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:57:29,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:57:29,766] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:57:29,770] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 11:57:42,544] {scheduler_job.py:155} INFO - Started process (PID=80538) to work on /airflow/dags/download_data.py
[2022-02-18 11:57:42,548] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:57:42,550] {logging_mixin.py:112} INFO - [2022-02-18 11:57:42,550] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:57:42,999] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:57:43,039] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:57:43,047] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:57:43,051] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 11:57:55,820] {scheduler_job.py:155} INFO - Started process (PID=80564) to work on /airflow/dags/download_data.py
[2022-02-18 11:57:55,825] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:57:55,827] {logging_mixin.py:112} INFO - [2022-02-18 11:57:55,826] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:57:56,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:57:56,315] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:57:56,325] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:57:56,331] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 11:58:09,147] {scheduler_job.py:155} INFO - Started process (PID=80590) to work on /airflow/dags/download_data.py
[2022-02-18 11:58:09,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:58:09,153] {logging_mixin.py:112} INFO - [2022-02-18 11:58:09,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:58:09,591] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:58:09,643] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:58:09,651] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:58:09,655] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 11:58:22,418] {scheduler_job.py:155} INFO - Started process (PID=80616) to work on /airflow/dags/download_data.py
[2022-02-18 11:58:22,422] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:58:22,424] {logging_mixin.py:112} INFO - [2022-02-18 11:58:22,424] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:58:22,858] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:58:22,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:58:22,905] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:58:22,910] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 11:58:35,746] {scheduler_job.py:155} INFO - Started process (PID=80642) to work on /airflow/dags/download_data.py
[2022-02-18 11:58:35,750] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:58:35,752] {logging_mixin.py:112} INFO - [2022-02-18 11:58:35,752] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:58:36,190] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:58:36,232] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:58:36,237] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:58:36,241] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 11:58:49,060] {scheduler_job.py:155} INFO - Started process (PID=80668) to work on /airflow/dags/download_data.py
[2022-02-18 11:58:49,065] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:58:49,066] {logging_mixin.py:112} INFO - [2022-02-18 11:58:49,066] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:58:49,518] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:58:49,566] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:58:49,576] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:58:49,582] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 11:59:02,370] {scheduler_job.py:155} INFO - Started process (PID=80694) to work on /airflow/dags/download_data.py
[2022-02-18 11:59:02,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:59:02,377] {logging_mixin.py:112} INFO - [2022-02-18 11:59:02,376] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:59:02,811] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:59:02,856] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:59:02,864] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:59:02,868] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 11:59:15,682] {scheduler_job.py:155} INFO - Started process (PID=80720) to work on /airflow/dags/download_data.py
[2022-02-18 11:59:15,686] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:59:15,688] {logging_mixin.py:112} INFO - [2022-02-18 11:59:15,688] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:59:16,131] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:59:16,171] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:59:16,181] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:59:16,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 11:59:28,959] {scheduler_job.py:155} INFO - Started process (PID=80746) to work on /airflow/dags/download_data.py
[2022-02-18 11:59:28,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:59:28,969] {logging_mixin.py:112} INFO - [2022-02-18 11:59:28,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:59:29,417] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:59:29,468] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:59:29,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:59:29,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 11:59:42,293] {scheduler_job.py:155} INFO - Started process (PID=80772) to work on /airflow/dags/download_data.py
[2022-02-18 11:59:42,298] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:59:42,300] {logging_mixin.py:112} INFO - [2022-02-18 11:59:42,300] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:59:42,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:59:42,785] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:59:42,792] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:59:42,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 11:59:55,574] {scheduler_job.py:155} INFO - Started process (PID=80798) to work on /airflow/dags/download_data.py
[2022-02-18 11:59:55,581] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 11:59:55,583] {logging_mixin.py:112} INFO - [2022-02-18 11:59:55,583] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 11:59:56,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 11:59:56,058] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 11:59:56,065] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 11:59:56,069] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 12:00:09,947] {scheduler_job.py:155} INFO - Started process (PID=80824) to work on /airflow/dags/download_data.py
[2022-02-18 12:00:09,951] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:00:09,953] {logging_mixin.py:112} INFO - [2022-02-18 12:00:09,953] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:00:10,429] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:00:10,482] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:00:10,492] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:00:10,498] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 12:30:22,042] {scheduler_job.py:155} INFO - Started process (PID=80850) to work on /airflow/dags/download_data.py
[2022-02-18 12:30:22,052] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:30:22,054] {logging_mixin.py:112} INFO - [2022-02-18 12:30:22,054] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:30:22,626] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:30:22,689] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:30:22,702] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:30:22,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-18 12:30:29,168] {scheduler_job.py:155} INFO - Started process (PID=80876) to work on /airflow/dags/download_data.py
[2022-02-18 12:30:29,175] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:30:29,177] {logging_mixin.py:112} INFO - [2022-02-18 12:30:29,177] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:30:29,637] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:30:29,688] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:30:29,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:30:29,701] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 12:30:37,235] {scheduler_job.py:155} INFO - Started process (PID=80903) to work on /airflow/dags/download_data.py
[2022-02-18 12:30:37,242] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:30:37,244] {logging_mixin.py:112} INFO - [2022-02-18 12:30:37,244] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:30:37,689] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:30:37,735] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:30:37,743] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:30:37,749] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 12:30:50,511] {scheduler_job.py:155} INFO - Started process (PID=80930) to work on /airflow/dags/download_data.py
[2022-02-18 12:30:50,517] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:30:50,518] {logging_mixin.py:112} INFO - [2022-02-18 12:30:50,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:30:50,958] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:30:51,007] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:30:51,014] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:30:51,018] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 12:31:03,813] {scheduler_job.py:155} INFO - Started process (PID=80956) to work on /airflow/dags/download_data.py
[2022-02-18 12:31:03,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:31:03,820] {logging_mixin.py:112} INFO - [2022-02-18 12:31:03,820] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:31:04,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:31:04,340] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:31:04,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:31:04,357] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 12:31:17,096] {scheduler_job.py:155} INFO - Started process (PID=80982) to work on /airflow/dags/download_data.py
[2022-02-18 12:31:17,101] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:31:17,103] {logging_mixin.py:112} INFO - [2022-02-18 12:31:17,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:31:17,530] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:31:17,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:31:17,576] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:31:17,581] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-18 12:31:30,415] {scheduler_job.py:155} INFO - Started process (PID=81008) to work on /airflow/dags/download_data.py
[2022-02-18 12:31:30,420] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:31:30,423] {logging_mixin.py:112} INFO - [2022-02-18 12:31:30,422] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:31:30,851] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:31:30,901] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:31:30,910] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:31:30,916] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 12:31:43,686] {scheduler_job.py:155} INFO - Started process (PID=81034) to work on /airflow/dags/download_data.py
[2022-02-18 12:31:43,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:31:43,692] {logging_mixin.py:112} INFO - [2022-02-18 12:31:43,692] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:31:44,099] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:31:44,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:31:44,155] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:31:44,159] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.473 seconds
[2022-02-18 12:31:56,965] {scheduler_job.py:155} INFO - Started process (PID=81060) to work on /airflow/dags/download_data.py
[2022-02-18 12:31:56,973] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:31:56,975] {logging_mixin.py:112} INFO - [2022-02-18 12:31:56,975] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:31:57,408] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:31:57,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:31:57,463] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:31:57,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 12:32:10,255] {scheduler_job.py:155} INFO - Started process (PID=81086) to work on /airflow/dags/download_data.py
[2022-02-18 12:32:10,259] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:32:10,261] {logging_mixin.py:112} INFO - [2022-02-18 12:32:10,261] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:32:10,725] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:32:10,775] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:32:10,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:32:10,793] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 12:32:23,513] {scheduler_job.py:155} INFO - Started process (PID=81112) to work on /airflow/dags/download_data.py
[2022-02-18 12:32:23,518] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:32:23,520] {logging_mixin.py:112} INFO - [2022-02-18 12:32:23,519] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:32:23,987] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:32:24,040] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:32:24,051] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:32:24,058] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 12:32:36,811] {scheduler_job.py:155} INFO - Started process (PID=81138) to work on /airflow/dags/download_data.py
[2022-02-18 12:32:36,817] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:32:36,820] {logging_mixin.py:112} INFO - [2022-02-18 12:32:36,819] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:32:37,326] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:32:37,373] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:32:37,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:32:37,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 12:32:50,117] {scheduler_job.py:155} INFO - Started process (PID=81164) to work on /airflow/dags/download_data.py
[2022-02-18 12:32:50,122] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:32:50,124] {logging_mixin.py:112} INFO - [2022-02-18 12:32:50,123] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:32:50,557] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:32:50,608] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:32:50,614] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:32:50,619] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 12:33:03,426] {scheduler_job.py:155} INFO - Started process (PID=81190) to work on /airflow/dags/download_data.py
[2022-02-18 12:33:03,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:33:03,432] {logging_mixin.py:112} INFO - [2022-02-18 12:33:03,432] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:33:03,884] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:33:03,928] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:33:03,939] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:33:03,944] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 12:33:16,706] {scheduler_job.py:155} INFO - Started process (PID=81216) to work on /airflow/dags/download_data.py
[2022-02-18 12:33:16,718] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:33:16,720] {logging_mixin.py:112} INFO - [2022-02-18 12:33:16,720] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:33:17,185] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:33:17,234] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:33:17,244] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:33:17,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 12:33:30,029] {scheduler_job.py:155} INFO - Started process (PID=81242) to work on /airflow/dags/download_data.py
[2022-02-18 12:33:30,036] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:33:30,037] {logging_mixin.py:112} INFO - [2022-02-18 12:33:30,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:33:30,461] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:33:30,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:33:30,517] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:33:30,522] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 12:33:43,355] {scheduler_job.py:155} INFO - Started process (PID=81268) to work on /airflow/dags/download_data.py
[2022-02-18 12:33:43,359] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:33:43,361] {logging_mixin.py:112} INFO - [2022-02-18 12:33:43,361] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:33:43,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:33:43,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:33:43,813] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:33:43,816] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.462 seconds
[2022-02-18 12:33:56,650] {scheduler_job.py:155} INFO - Started process (PID=81294) to work on /airflow/dags/download_data.py
[2022-02-18 12:33:56,655] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:33:56,656] {logging_mixin.py:112} INFO - [2022-02-18 12:33:56,656] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:33:57,088] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:33:57,139] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:33:57,146] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:33:57,151] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 12:34:09,955] {scheduler_job.py:155} INFO - Started process (PID=81320) to work on /airflow/dags/download_data.py
[2022-02-18 12:34:09,962] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:34:09,965] {logging_mixin.py:112} INFO - [2022-02-18 12:34:09,964] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:34:10,403] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:34:10,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:34:10,462] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:34:10,465] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 12:34:23,246] {scheduler_job.py:155} INFO - Started process (PID=81346) to work on /airflow/dags/download_data.py
[2022-02-18 12:34:23,252] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:34:23,254] {logging_mixin.py:112} INFO - [2022-02-18 12:34:23,253] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:34:23,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:34:23,773] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:34:23,781] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:34:23,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 12:34:36,540] {scheduler_job.py:155} INFO - Started process (PID=81372) to work on /airflow/dags/download_data.py
[2022-02-18 12:34:36,549] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:34:36,551] {logging_mixin.py:112} INFO - [2022-02-18 12:34:36,551] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:34:36,986] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:34:37,029] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:34:37,035] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:34:37,041] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 12:34:49,794] {scheduler_job.py:155} INFO - Started process (PID=81398) to work on /airflow/dags/download_data.py
[2022-02-18 12:34:49,800] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:34:49,801] {logging_mixin.py:112} INFO - [2022-02-18 12:34:49,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:34:50,633] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:34:50,705] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:34:50,715] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:34:50,720] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.926 seconds
[2022-02-18 12:35:03,110] {scheduler_job.py:155} INFO - Started process (PID=81424) to work on /airflow/dags/download_data.py
[2022-02-18 12:35:03,116] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:35:03,117] {logging_mixin.py:112} INFO - [2022-02-18 12:35:03,117] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:35:03,575] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:35:03,630] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:35:03,638] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:35:03,642] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 12:35:16,411] {scheduler_job.py:155} INFO - Started process (PID=81450) to work on /airflow/dags/download_data.py
[2022-02-18 12:35:16,422] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:35:16,424] {logging_mixin.py:112} INFO - [2022-02-18 12:35:16,424] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:35:16,860] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:35:16,899] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:35:16,905] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:35:16,908] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 12:35:29,698] {scheduler_job.py:155} INFO - Started process (PID=81476) to work on /airflow/dags/download_data.py
[2022-02-18 12:35:29,704] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:35:29,706] {logging_mixin.py:112} INFO - [2022-02-18 12:35:29,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:35:30,138] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:35:30,205] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:35:30,214] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:35:30,221] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 12:35:42,957] {scheduler_job.py:155} INFO - Started process (PID=81502) to work on /airflow/dags/download_data.py
[2022-02-18 12:35:42,964] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:35:42,967] {logging_mixin.py:112} INFO - [2022-02-18 12:35:42,966] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:35:43,414] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:35:43,458] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:35:43,465] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:35:43,471] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 12:35:56,230] {scheduler_job.py:155} INFO - Started process (PID=81528) to work on /airflow/dags/download_data.py
[2022-02-18 12:35:56,238] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:35:56,240] {logging_mixin.py:112} INFO - [2022-02-18 12:35:56,240] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:35:56,664] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:35:56,704] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:35:56,711] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:35:56,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.486 seconds
[2022-02-18 12:36:09,536] {scheduler_job.py:155} INFO - Started process (PID=81554) to work on /airflow/dags/download_data.py
[2022-02-18 12:36:09,541] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:36:09,546] {logging_mixin.py:112} INFO - [2022-02-18 12:36:09,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:36:09,979] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:36:10,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:36:10,036] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:36:10,041] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 12:36:22,818] {scheduler_job.py:155} INFO - Started process (PID=81580) to work on /airflow/dags/download_data.py
[2022-02-18 12:36:22,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:36:22,825] {logging_mixin.py:112} INFO - [2022-02-18 12:36:22,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:36:23,288] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:36:23,342] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:36:23,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:36:23,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 12:36:36,075] {scheduler_job.py:155} INFO - Started process (PID=81606) to work on /airflow/dags/download_data.py
[2022-02-18 12:36:36,080] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:36:36,087] {logging_mixin.py:112} INFO - [2022-02-18 12:36:36,087] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:36:36,559] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:36:36,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:36:36,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:36:36,625] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 12:36:49,315] {scheduler_job.py:155} INFO - Started process (PID=81632) to work on /airflow/dags/download_data.py
[2022-02-18 12:36:49,320] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:36:49,321] {logging_mixin.py:112} INFO - [2022-02-18 12:36:49,321] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:36:49,759] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:36:49,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:36:49,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:36:49,811] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 12:37:02,623] {scheduler_job.py:155} INFO - Started process (PID=81658) to work on /airflow/dags/download_data.py
[2022-02-18 12:37:02,627] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:37:02,629] {logging_mixin.py:112} INFO - [2022-02-18 12:37:02,629] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:37:03,055] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:37:03,105] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:37:03,116] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:37:03,123] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 12:37:15,897] {scheduler_job.py:155} INFO - Started process (PID=81684) to work on /airflow/dags/download_data.py
[2022-02-18 12:37:15,901] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:37:15,903] {logging_mixin.py:112} INFO - [2022-02-18 12:37:15,903] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:37:16,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:37:16,387] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:37:16,397] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:37:16,402] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 12:37:29,205] {scheduler_job.py:155} INFO - Started process (PID=81710) to work on /airflow/dags/download_data.py
[2022-02-18 12:37:29,210] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:37:29,211] {logging_mixin.py:112} INFO - [2022-02-18 12:37:29,211] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:37:29,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:37:29,698] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:37:29,705] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:37:29,710] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 12:37:42,501] {scheduler_job.py:155} INFO - Started process (PID=81736) to work on /airflow/dags/download_data.py
[2022-02-18 12:37:42,507] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:37:42,509] {logging_mixin.py:112} INFO - [2022-02-18 12:37:42,509] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:37:42,942] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:37:42,983] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:37:42,989] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:37:42,993] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 12:37:55,779] {scheduler_job.py:155} INFO - Started process (PID=81762) to work on /airflow/dags/download_data.py
[2022-02-18 12:37:55,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:37:55,786] {logging_mixin.py:112} INFO - [2022-02-18 12:37:55,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:37:56,237] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:37:56,286] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:37:56,295] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:37:56,301] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 12:38:09,083] {scheduler_job.py:155} INFO - Started process (PID=81788) to work on /airflow/dags/download_data.py
[2022-02-18 12:38:09,091] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:38:09,095] {logging_mixin.py:112} INFO - [2022-02-18 12:38:09,094] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:38:09,563] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:38:09,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:38:09,620] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:38:09,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 12:38:22,337] {scheduler_job.py:155} INFO - Started process (PID=81814) to work on /airflow/dags/download_data.py
[2022-02-18 12:38:22,341] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:38:22,343] {logging_mixin.py:112} INFO - [2022-02-18 12:38:22,343] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:38:22,801] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:38:22,856] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:38:22,863] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:38:22,868] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 12:38:35,636] {scheduler_job.py:155} INFO - Started process (PID=81840) to work on /airflow/dags/download_data.py
[2022-02-18 12:38:35,641] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:38:35,642] {logging_mixin.py:112} INFO - [2022-02-18 12:38:35,642] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:38:36,106] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:38:36,160] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:38:36,170] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:38:36,177] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 12:38:48,927] {scheduler_job.py:155} INFO - Started process (PID=81866) to work on /airflow/dags/download_data.py
[2022-02-18 12:38:48,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:38:48,937] {logging_mixin.py:112} INFO - [2022-02-18 12:38:48,937] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:38:49,390] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:38:49,445] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:38:49,455] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:38:49,460] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 12:39:02,216] {scheduler_job.py:155} INFO - Started process (PID=81892) to work on /airflow/dags/download_data.py
[2022-02-18 12:39:02,220] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:39:02,221] {logging_mixin.py:112} INFO - [2022-02-18 12:39:02,221] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:39:02,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:39:02,710] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:39:02,719] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:39:02,722] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 12:39:15,468] {scheduler_job.py:155} INFO - Started process (PID=81918) to work on /airflow/dags/download_data.py
[2022-02-18 12:39:15,472] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:39:15,473] {logging_mixin.py:112} INFO - [2022-02-18 12:39:15,473] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:39:15,911] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:39:15,960] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:39:15,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:39:15,972] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 12:39:28,760] {scheduler_job.py:155} INFO - Started process (PID=81944) to work on /airflow/dags/download_data.py
[2022-02-18 12:39:28,769] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:39:28,771] {logging_mixin.py:112} INFO - [2022-02-18 12:39:28,771] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:39:29,220] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:39:29,274] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:39:29,280] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:39:29,284] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 12:39:42,044] {scheduler_job.py:155} INFO - Started process (PID=81970) to work on /airflow/dags/download_data.py
[2022-02-18 12:39:42,048] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:39:42,050] {logging_mixin.py:112} INFO - [2022-02-18 12:39:42,049] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:39:42,509] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:39:42,561] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:39:42,567] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:39:42,571] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 12:39:55,305] {scheduler_job.py:155} INFO - Started process (PID=81996) to work on /airflow/dags/download_data.py
[2022-02-18 12:39:55,310] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:39:55,312] {logging_mixin.py:112} INFO - [2022-02-18 12:39:55,311] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:39:55,765] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:39:55,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:39:55,822] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:39:55,826] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 12:40:08,622] {scheduler_job.py:155} INFO - Started process (PID=82022) to work on /airflow/dags/download_data.py
[2022-02-18 12:40:08,632] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:40:08,635] {logging_mixin.py:112} INFO - [2022-02-18 12:40:08,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:40:09,065] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:40:09,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:40:09,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:40:09,124] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 12:40:21,904] {scheduler_job.py:155} INFO - Started process (PID=82048) to work on /airflow/dags/download_data.py
[2022-02-18 12:40:21,912] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:40:21,914] {logging_mixin.py:112} INFO - [2022-02-18 12:40:21,914] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:40:22,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:40:22,417] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:40:22,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:40:22,436] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 12:40:35,231] {scheduler_job.py:155} INFO - Started process (PID=82074) to work on /airflow/dags/download_data.py
[2022-02-18 12:40:35,239] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:40:35,241] {logging_mixin.py:112} INFO - [2022-02-18 12:40:35,241] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:40:35,671] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:40:35,720] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:40:35,726] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:40:35,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 12:40:48,475] {scheduler_job.py:155} INFO - Started process (PID=82100) to work on /airflow/dags/download_data.py
[2022-02-18 12:40:48,480] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:40:48,482] {logging_mixin.py:112} INFO - [2022-02-18 12:40:48,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:40:48,923] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:40:48,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:40:48,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:40:48,985] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 12:41:01,806] {scheduler_job.py:155} INFO - Started process (PID=82126) to work on /airflow/dags/download_data.py
[2022-02-18 12:41:01,813] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:41:01,815] {logging_mixin.py:112} INFO - [2022-02-18 12:41:01,814] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:41:02,249] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:41:02,298] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:41:02,308] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:41:02,314] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 12:41:15,087] {scheduler_job.py:155} INFO - Started process (PID=82152) to work on /airflow/dags/download_data.py
[2022-02-18 12:41:15,094] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:41:15,097] {logging_mixin.py:112} INFO - [2022-02-18 12:41:15,097] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:41:15,528] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:41:15,581] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:41:15,588] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:41:15,594] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 12:41:28,408] {scheduler_job.py:155} INFO - Started process (PID=82178) to work on /airflow/dags/download_data.py
[2022-02-18 12:41:28,414] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:41:28,416] {logging_mixin.py:112} INFO - [2022-02-18 12:41:28,416] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:41:28,854] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:41:28,905] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:41:28,913] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:41:28,919] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 12:41:41,666] {scheduler_job.py:155} INFO - Started process (PID=82204) to work on /airflow/dags/download_data.py
[2022-02-18 12:41:41,673] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:41:41,676] {logging_mixin.py:112} INFO - [2022-02-18 12:41:41,676] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:41:42,106] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:41:42,162] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:41:42,168] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:41:42,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 12:41:54,938] {scheduler_job.py:155} INFO - Started process (PID=82230) to work on /airflow/dags/download_data.py
[2022-02-18 12:41:54,942] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:41:54,943] {logging_mixin.py:112} INFO - [2022-02-18 12:41:54,943] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:41:55,377] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:41:55,428] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:41:55,438] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:41:55,444] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 12:42:08,250] {scheduler_job.py:155} INFO - Started process (PID=82256) to work on /airflow/dags/download_data.py
[2022-02-18 12:42:08,258] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:42:08,260] {logging_mixin.py:112} INFO - [2022-02-18 12:42:08,259] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:42:08,697] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:42:08,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:42:08,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:42:08,752] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 12:42:21,491] {scheduler_job.py:155} INFO - Started process (PID=82282) to work on /airflow/dags/download_data.py
[2022-02-18 12:42:21,496] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:42:21,498] {logging_mixin.py:112} INFO - [2022-02-18 12:42:21,498] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:42:21,950] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:42:21,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:42:22,005] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:42:22,008] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 12:42:34,818] {scheduler_job.py:155} INFO - Started process (PID=82308) to work on /airflow/dags/download_data.py
[2022-02-18 12:42:34,822] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:42:34,824] {logging_mixin.py:112} INFO - [2022-02-18 12:42:34,824] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:42:35,266] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:42:35,317] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:42:35,325] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:42:35,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 12:42:48,071] {scheduler_job.py:155} INFO - Started process (PID=82334) to work on /airflow/dags/download_data.py
[2022-02-18 12:42:48,076] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:42:48,077] {logging_mixin.py:112} INFO - [2022-02-18 12:42:48,077] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:42:48,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:42:48,587] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:42:48,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:42:48,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 12:43:01,360] {scheduler_job.py:155} INFO - Started process (PID=82360) to work on /airflow/dags/download_data.py
[2022-02-18 12:43:01,367] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:43:01,369] {logging_mixin.py:112} INFO - [2022-02-18 12:43:01,369] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:43:01,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:43:01,847] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:43:01,856] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:43:01,862] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 12:43:14,624] {scheduler_job.py:155} INFO - Started process (PID=82386) to work on /airflow/dags/download_data.py
[2022-02-18 12:43:14,629] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:43:14,630] {logging_mixin.py:112} INFO - [2022-02-18 12:43:14,630] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:43:15,081] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:43:15,136] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:43:15,145] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:43:15,150] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 12:43:27,931] {scheduler_job.py:155} INFO - Started process (PID=82412) to work on /airflow/dags/download_data.py
[2022-02-18 12:43:27,943] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:43:27,957] {logging_mixin.py:112} INFO - [2022-02-18 12:43:27,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:43:28,397] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:43:28,439] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:43:28,445] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:43:28,449] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 12:43:41,270] {scheduler_job.py:155} INFO - Started process (PID=82438) to work on /airflow/dags/download_data.py
[2022-02-18 12:43:41,280] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:43:41,282] {logging_mixin.py:112} INFO - [2022-02-18 12:43:41,282] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:43:41,727] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:43:41,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:43:41,783] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:43:41,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 12:43:54,557] {scheduler_job.py:155} INFO - Started process (PID=82464) to work on /airflow/dags/download_data.py
[2022-02-18 12:43:54,562] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:43:54,563] {logging_mixin.py:112} INFO - [2022-02-18 12:43:54,563] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:43:55,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:43:55,063] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:43:55,071] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:43:55,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 12:44:07,884] {scheduler_job.py:155} INFO - Started process (PID=82490) to work on /airflow/dags/download_data.py
[2022-02-18 12:44:07,893] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:44:07,895] {logging_mixin.py:112} INFO - [2022-02-18 12:44:07,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:44:08,327] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:44:08,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:44:08,390] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:44:08,397] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 12:44:21,138] {scheduler_job.py:155} INFO - Started process (PID=82516) to work on /airflow/dags/download_data.py
[2022-02-18 12:44:21,142] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:44:21,144] {logging_mixin.py:112} INFO - [2022-02-18 12:44:21,144] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:44:21,593] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:44:21,647] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:44:21,656] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:44:21,662] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 12:44:34,446] {scheduler_job.py:155} INFO - Started process (PID=82542) to work on /airflow/dags/download_data.py
[2022-02-18 12:44:34,459] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:44:34,461] {logging_mixin.py:112} INFO - [2022-02-18 12:44:34,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:44:34,900] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:44:34,950] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:44:34,958] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:44:34,962] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 12:44:47,755] {scheduler_job.py:155} INFO - Started process (PID=82568) to work on /airflow/dags/download_data.py
[2022-02-18 12:44:47,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:44:47,764] {logging_mixin.py:112} INFO - [2022-02-18 12:44:47,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:44:48,190] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:44:48,232] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:44:48,241] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:44:48,245] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 12:45:01,040] {scheduler_job.py:155} INFO - Started process (PID=82594) to work on /airflow/dags/download_data.py
[2022-02-18 12:45:01,044] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:45:01,046] {logging_mixin.py:112} INFO - [2022-02-18 12:45:01,046] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:45:01,504] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:45:01,549] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:45:01,556] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:45:01,562] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 12:45:14,304] {scheduler_job.py:155} INFO - Started process (PID=82620) to work on /airflow/dags/download_data.py
[2022-02-18 12:45:14,311] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:45:14,313] {logging_mixin.py:112} INFO - [2022-02-18 12:45:14,313] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:45:14,756] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:45:14,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:45:14,816] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:45:14,822] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 12:45:27,641] {scheduler_job.py:155} INFO - Started process (PID=82646) to work on /airflow/dags/download_data.py
[2022-02-18 12:45:27,651] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:45:27,653] {logging_mixin.py:112} INFO - [2022-02-18 12:45:27,653] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:45:28,082] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:45:28,138] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:45:28,148] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:45:28,154] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 12:45:40,945] {scheduler_job.py:155} INFO - Started process (PID=82672) to work on /airflow/dags/download_data.py
[2022-02-18 12:45:40,951] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:45:40,953] {logging_mixin.py:112} INFO - [2022-02-18 12:45:40,953] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:45:41,397] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:45:41,440] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:45:41,446] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:45:41,450] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 12:45:54,185] {scheduler_job.py:155} INFO - Started process (PID=82698) to work on /airflow/dags/download_data.py
[2022-02-18 12:45:54,191] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:45:54,192] {logging_mixin.py:112} INFO - [2022-02-18 12:45:54,192] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:45:54,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:45:54,692] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:45:54,698] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:45:54,704] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 12:46:07,507] {scheduler_job.py:155} INFO - Started process (PID=82724) to work on /airflow/dags/download_data.py
[2022-02-18 12:46:07,513] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:46:07,514] {logging_mixin.py:112} INFO - [2022-02-18 12:46:07,514] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:46:07,957] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:46:08,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:46:08,017] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:46:08,022] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 12:46:20,795] {scheduler_job.py:155} INFO - Started process (PID=82750) to work on /airflow/dags/download_data.py
[2022-02-18 12:46:20,800] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:46:20,802] {logging_mixin.py:112} INFO - [2022-02-18 12:46:20,802] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:46:21,239] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:46:21,284] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:46:21,293] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:46:21,299] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 12:46:34,098] {scheduler_job.py:155} INFO - Started process (PID=82776) to work on /airflow/dags/download_data.py
[2022-02-18 12:46:34,105] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:46:34,106] {logging_mixin.py:112} INFO - [2022-02-18 12:46:34,106] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:46:34,554] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:46:34,606] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:46:34,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:46:34,620] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 12:46:47,361] {scheduler_job.py:155} INFO - Started process (PID=82802) to work on /airflow/dags/download_data.py
[2022-02-18 12:46:47,367] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:46:47,369] {logging_mixin.py:112} INFO - [2022-02-18 12:46:47,369] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:46:47,811] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:46:47,864] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:46:47,869] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:46:47,873] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 12:47:00,680] {scheduler_job.py:155} INFO - Started process (PID=82828) to work on /airflow/dags/download_data.py
[2022-02-18 12:47:00,688] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:47:00,690] {logging_mixin.py:112} INFO - [2022-02-18 12:47:00,690] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:47:01,137] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:47:01,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:47:01,188] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:47:01,192] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 12:47:13,979] {scheduler_job.py:155} INFO - Started process (PID=82854) to work on /airflow/dags/download_data.py
[2022-02-18 12:47:13,988] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:47:13,991] {logging_mixin.py:112} INFO - [2022-02-18 12:47:13,990] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:47:14,425] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:47:14,468] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:47:14,475] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:47:14,479] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 12:47:27,301] {scheduler_job.py:155} INFO - Started process (PID=82880) to work on /airflow/dags/download_data.py
[2022-02-18 12:47:27,310] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:47:27,313] {logging_mixin.py:112} INFO - [2022-02-18 12:47:27,313] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:47:27,739] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:47:27,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:47:27,799] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:47:27,805] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 12:47:40,584] {scheduler_job.py:155} INFO - Started process (PID=82906) to work on /airflow/dags/download_data.py
[2022-02-18 12:47:40,588] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:47:40,590] {logging_mixin.py:112} INFO - [2022-02-18 12:47:40,590] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:47:41,022] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:47:41,075] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:47:41,082] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:47:41,087] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 12:47:53,845] {scheduler_job.py:155} INFO - Started process (PID=82932) to work on /airflow/dags/download_data.py
[2022-02-18 12:47:53,851] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:47:53,853] {logging_mixin.py:112} INFO - [2022-02-18 12:47:53,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:47:54,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:47:54,350] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:47:54,360] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:47:54,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 12:48:07,142] {scheduler_job.py:155} INFO - Started process (PID=82958) to work on /airflow/dags/download_data.py
[2022-02-18 12:48:07,146] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:48:07,148] {logging_mixin.py:112} INFO - [2022-02-18 12:48:07,148] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:48:07,586] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:48:07,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:48:07,635] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:48:07,640] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 12:48:20,433] {scheduler_job.py:155} INFO - Started process (PID=82984) to work on /airflow/dags/download_data.py
[2022-02-18 12:48:20,438] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:48:20,440] {logging_mixin.py:112} INFO - [2022-02-18 12:48:20,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:48:20,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:48:20,930] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:48:20,940] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:48:20,946] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 12:48:33,739] {scheduler_job.py:155} INFO - Started process (PID=83010) to work on /airflow/dags/download_data.py
[2022-02-18 12:48:33,746] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:48:33,748] {logging_mixin.py:112} INFO - [2022-02-18 12:48:33,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:48:34,191] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:48:34,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:48:34,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:48:34,252] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 12:48:46,981] {scheduler_job.py:155} INFO - Started process (PID=83036) to work on /airflow/dags/download_data.py
[2022-02-18 12:48:46,985] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:48:46,987] {logging_mixin.py:112} INFO - [2022-02-18 12:48:46,987] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:48:47,429] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:48:47,472] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:48:47,478] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:48:47,482] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 12:49:00,268] {scheduler_job.py:155} INFO - Started process (PID=83062) to work on /airflow/dags/download_data.py
[2022-02-18 12:49:00,272] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:49:00,274] {logging_mixin.py:112} INFO - [2022-02-18 12:49:00,274] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:49:00,718] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:49:00,770] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:49:00,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:49:00,781] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 12:49:13,559] {scheduler_job.py:155} INFO - Started process (PID=83088) to work on /airflow/dags/download_data.py
[2022-02-18 12:49:13,571] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:49:13,573] {logging_mixin.py:112} INFO - [2022-02-18 12:49:13,573] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:49:14,014] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:49:14,062] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:49:14,071] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:49:14,078] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 12:49:26,870] {scheduler_job.py:155} INFO - Started process (PID=83114) to work on /airflow/dags/download_data.py
[2022-02-18 12:49:26,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:49:26,876] {logging_mixin.py:112} INFO - [2022-02-18 12:49:26,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:49:27,326] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:49:27,379] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:49:27,388] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:49:27,394] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 12:49:40,188] {scheduler_job.py:155} INFO - Started process (PID=83140) to work on /airflow/dags/download_data.py
[2022-02-18 12:49:40,195] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:49:40,197] {logging_mixin.py:112} INFO - [2022-02-18 12:49:40,196] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:49:40,626] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:49:40,666] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:49:40,675] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:49:40,681] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 12:49:53,446] {scheduler_job.py:155} INFO - Started process (PID=83166) to work on /airflow/dags/download_data.py
[2022-02-18 12:49:53,452] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:49:53,455] {logging_mixin.py:112} INFO - [2022-02-18 12:49:53,455] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:49:53,894] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:49:53,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:49:53,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:49:53,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 12:50:06,735] {scheduler_job.py:155} INFO - Started process (PID=83192) to work on /airflow/dags/download_data.py
[2022-02-18 12:50:06,739] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:50:06,740] {logging_mixin.py:112} INFO - [2022-02-18 12:50:06,740] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:50:07,195] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:50:07,237] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:50:07,242] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:50:07,247] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 12:50:20,044] {scheduler_job.py:155} INFO - Started process (PID=83218) to work on /airflow/dags/download_data.py
[2022-02-18 12:50:20,050] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:50:20,051] {logging_mixin.py:112} INFO - [2022-02-18 12:50:20,051] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:50:20,492] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:50:20,535] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:50:20,541] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:50:20,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 12:50:33,412] {scheduler_job.py:155} INFO - Started process (PID=83244) to work on /airflow/dags/download_data.py
[2022-02-18 12:50:33,416] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:50:33,417] {logging_mixin.py:112} INFO - [2022-02-18 12:50:33,417] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:50:33,846] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:50:33,896] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:50:33,902] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:50:33,905] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 12:50:46,674] {scheduler_job.py:155} INFO - Started process (PID=83270) to work on /airflow/dags/download_data.py
[2022-02-18 12:50:46,682] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:50:46,684] {logging_mixin.py:112} INFO - [2022-02-18 12:50:46,684] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:50:47,114] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:50:47,169] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:50:47,178] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:50:47,184] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 12:50:59,976] {scheduler_job.py:155} INFO - Started process (PID=83296) to work on /airflow/dags/download_data.py
[2022-02-18 12:50:59,982] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:50:59,984] {logging_mixin.py:112} INFO - [2022-02-18 12:50:59,984] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:51:00,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:51:00,489] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:51:00,500] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:51:00,505] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 12:51:13,264] {scheduler_job.py:155} INFO - Started process (PID=83322) to work on /airflow/dags/download_data.py
[2022-02-18 12:51:13,273] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:51:13,275] {logging_mixin.py:112} INFO - [2022-02-18 12:51:13,275] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:51:13,709] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:51:13,757] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:51:13,766] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:51:13,771] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 12:51:26,626] {scheduler_job.py:155} INFO - Started process (PID=83348) to work on /airflow/dags/download_data.py
[2022-02-18 12:51:26,630] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:51:26,633] {logging_mixin.py:112} INFO - [2022-02-18 12:51:26,632] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:51:27,097] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:51:27,144] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:51:27,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:51:27,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 12:51:39,920] {scheduler_job.py:155} INFO - Started process (PID=83374) to work on /airflow/dags/download_data.py
[2022-02-18 12:51:39,925] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:51:39,927] {logging_mixin.py:112} INFO - [2022-02-18 12:51:39,926] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:51:40,368] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:51:40,411] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:51:40,419] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:51:40,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 12:51:53,194] {scheduler_job.py:155} INFO - Started process (PID=83400) to work on /airflow/dags/download_data.py
[2022-02-18 12:51:53,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:51:53,201] {logging_mixin.py:112} INFO - [2022-02-18 12:51:53,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:51:53,721] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:51:53,774] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:51:53,783] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:51:53,789] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 12:52:06,531] {scheduler_job.py:155} INFO - Started process (PID=83426) to work on /airflow/dags/download_data.py
[2022-02-18 12:52:06,537] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:52:06,539] {logging_mixin.py:112} INFO - [2022-02-18 12:52:06,538] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:52:06,981] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:52:07,026] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:52:07,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:52:07,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 12:52:19,797] {scheduler_job.py:155} INFO - Started process (PID=83452) to work on /airflow/dags/download_data.py
[2022-02-18 12:52:19,802] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:52:19,803] {logging_mixin.py:112} INFO - [2022-02-18 12:52:19,803] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:52:20,239] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:52:20,289] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:52:20,295] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:52:20,301] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 12:52:33,118] {scheduler_job.py:155} INFO - Started process (PID=83478) to work on /airflow/dags/download_data.py
[2022-02-18 12:52:33,124] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:52:33,127] {logging_mixin.py:112} INFO - [2022-02-18 12:52:33,126] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:52:33,554] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:52:33,604] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:52:33,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:52:33,619] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 12:52:46,361] {scheduler_job.py:155} INFO - Started process (PID=83504) to work on /airflow/dags/download_data.py
[2022-02-18 12:52:46,365] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:52:46,366] {logging_mixin.py:112} INFO - [2022-02-18 12:52:46,366] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:52:46,809] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:52:46,856] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:52:46,862] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:52:46,867] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 12:52:59,657] {scheduler_job.py:155} INFO - Started process (PID=83530) to work on /airflow/dags/download_data.py
[2022-02-18 12:52:59,661] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:52:59,662] {logging_mixin.py:112} INFO - [2022-02-18 12:52:59,662] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:53:00,118] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:53:00,174] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:53:00,180] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:53:00,184] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 12:53:12,919] {scheduler_job.py:155} INFO - Started process (PID=83556) to work on /airflow/dags/download_data.py
[2022-02-18 12:53:12,926] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:53:12,928] {logging_mixin.py:112} INFO - [2022-02-18 12:53:12,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:53:13,366] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:53:13,413] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:53:13,420] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:53:13,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 12:53:26,232] {scheduler_job.py:155} INFO - Started process (PID=83582) to work on /airflow/dags/download_data.py
[2022-02-18 12:53:26,241] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:53:26,243] {logging_mixin.py:112} INFO - [2022-02-18 12:53:26,243] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:53:26,682] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:53:26,724] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:53:26,732] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:53:26,740] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 12:53:39,551] {scheduler_job.py:155} INFO - Started process (PID=83608) to work on /airflow/dags/download_data.py
[2022-02-18 12:53:39,567] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:53:39,569] {logging_mixin.py:112} INFO - [2022-02-18 12:53:39,569] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:53:40,001] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:53:40,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:53:40,051] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:53:40,056] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 12:53:52,863] {scheduler_job.py:155} INFO - Started process (PID=83634) to work on /airflow/dags/download_data.py
[2022-02-18 12:53:52,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:53:52,871] {logging_mixin.py:112} INFO - [2022-02-18 12:53:52,871] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:53:53,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:53:53,395] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:53:53,403] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:53:53,408] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 12:54:06,165] {scheduler_job.py:155} INFO - Started process (PID=83660) to work on /airflow/dags/download_data.py
[2022-02-18 12:54:06,169] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:54:06,171] {logging_mixin.py:112} INFO - [2022-02-18 12:54:06,171] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:54:06,615] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:54:06,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:54:06,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:54:06,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 12:54:19,434] {scheduler_job.py:155} INFO - Started process (PID=83686) to work on /airflow/dags/download_data.py
[2022-02-18 12:54:19,444] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:54:19,446] {logging_mixin.py:112} INFO - [2022-02-18 12:54:19,446] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:54:19,885] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:54:19,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:54:19,942] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:54:19,946] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 12:54:32,748] {scheduler_job.py:155} INFO - Started process (PID=83712) to work on /airflow/dags/download_data.py
[2022-02-18 12:54:32,754] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:54:32,755] {logging_mixin.py:112} INFO - [2022-02-18 12:54:32,755] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:54:33,222] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:54:33,273] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:54:33,283] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:54:33,289] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 12:54:46,020] {scheduler_job.py:155} INFO - Started process (PID=83738) to work on /airflow/dags/download_data.py
[2022-02-18 12:54:46,026] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:54:46,028] {logging_mixin.py:112} INFO - [2022-02-18 12:54:46,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:54:46,469] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:54:46,518] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:54:46,524] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:54:46,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 12:54:59,344] {scheduler_job.py:155} INFO - Started process (PID=83764) to work on /airflow/dags/download_data.py
[2022-02-18 12:54:59,351] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:54:59,353] {logging_mixin.py:112} INFO - [2022-02-18 12:54:59,353] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:54:59,780] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:54:59,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:54:59,819] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:54:59,823] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.479 seconds
[2022-02-18 12:55:12,601] {scheduler_job.py:155} INFO - Started process (PID=83790) to work on /airflow/dags/download_data.py
[2022-02-18 12:55:12,609] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:55:12,611] {logging_mixin.py:112} INFO - [2022-02-18 12:55:12,610] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:55:13,038] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:55:13,080] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:55:13,087] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:55:13,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-18 12:55:25,959] {scheduler_job.py:155} INFO - Started process (PID=83816) to work on /airflow/dags/download_data.py
[2022-02-18 12:55:25,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:55:25,969] {logging_mixin.py:112} INFO - [2022-02-18 12:55:25,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:55:26,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:55:26,440] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:55:26,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:55:26,453] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 12:55:39,234] {scheduler_job.py:155} INFO - Started process (PID=83842) to work on /airflow/dags/download_data.py
[2022-02-18 12:55:39,249] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:55:39,250] {logging_mixin.py:112} INFO - [2022-02-18 12:55:39,250] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:55:39,698] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:55:39,750] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:55:39,758] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:55:39,764] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 12:55:52,516] {scheduler_job.py:155} INFO - Started process (PID=83868) to work on /airflow/dags/download_data.py
[2022-02-18 12:55:52,520] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:55:52,522] {logging_mixin.py:112} INFO - [2022-02-18 12:55:52,522] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:55:53,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:55:53,088] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:55:53,100] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:55:53,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 12:56:05,815] {scheduler_job.py:155} INFO - Started process (PID=83894) to work on /airflow/dags/download_data.py
[2022-02-18 12:56:05,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:56:05,821] {logging_mixin.py:112} INFO - [2022-02-18 12:56:05,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:56:06,258] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:56:06,309] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:56:06,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:56:06,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 12:56:19,082] {scheduler_job.py:155} INFO - Started process (PID=83920) to work on /airflow/dags/download_data.py
[2022-02-18 12:56:19,088] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:56:19,091] {logging_mixin.py:112} INFO - [2022-02-18 12:56:19,090] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:56:19,530] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:56:19,575] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:56:19,581] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:56:19,586] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 12:56:32,380] {scheduler_job.py:155} INFO - Started process (PID=83946) to work on /airflow/dags/download_data.py
[2022-02-18 12:56:32,385] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:56:32,388] {logging_mixin.py:112} INFO - [2022-02-18 12:56:32,388] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:56:32,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:56:32,877] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:56:32,888] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:56:32,892] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 12:56:45,663] {scheduler_job.py:155} INFO - Started process (PID=83972) to work on /airflow/dags/download_data.py
[2022-02-18 12:56:45,667] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:56:45,669] {logging_mixin.py:112} INFO - [2022-02-18 12:56:45,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:56:46,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:56:46,148] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:56:46,158] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:56:46,164] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 12:56:58,974] {scheduler_job.py:155} INFO - Started process (PID=83998) to work on /airflow/dags/download_data.py
[2022-02-18 12:56:58,979] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:56:58,983] {logging_mixin.py:112} INFO - [2022-02-18 12:56:58,982] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:56:59,429] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:56:59,469] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:56:59,475] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:56:59,479] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 12:57:12,272] {scheduler_job.py:155} INFO - Started process (PID=84024) to work on /airflow/dags/download_data.py
[2022-02-18 12:57:12,277] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:57:12,278] {logging_mixin.py:112} INFO - [2022-02-18 12:57:12,278] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:57:12,677] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:57:12,715] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:57:12,721] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:57:12,726] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.454 seconds
[2022-02-18 12:57:25,559] {scheduler_job.py:155} INFO - Started process (PID=84050) to work on /airflow/dags/download_data.py
[2022-02-18 12:57:25,566] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:57:25,569] {logging_mixin.py:112} INFO - [2022-02-18 12:57:25,568] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:57:26,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:57:26,059] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:57:26,067] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:57:26,073] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 12:57:38,897] {scheduler_job.py:155} INFO - Started process (PID=84076) to work on /airflow/dags/download_data.py
[2022-02-18 12:57:38,904] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:57:38,906] {logging_mixin.py:112} INFO - [2022-02-18 12:57:38,905] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:57:39,359] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:57:39,419] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:57:39,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:57:39,433] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 12:57:52,140] {scheduler_job.py:155} INFO - Started process (PID=84102) to work on /airflow/dags/download_data.py
[2022-02-18 12:57:52,151] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:57:52,154] {logging_mixin.py:112} INFO - [2022-02-18 12:57:52,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:57:52,612] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:57:52,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:57:52,678] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:57:52,682] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 12:58:05,473] {scheduler_job.py:155} INFO - Started process (PID=84128) to work on /airflow/dags/download_data.py
[2022-02-18 12:58:05,477] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:58:05,479] {logging_mixin.py:112} INFO - [2022-02-18 12:58:05,479] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:58:05,916] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:58:05,963] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:58:05,972] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:58:05,977] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 12:58:18,738] {scheduler_job.py:155} INFO - Started process (PID=84154) to work on /airflow/dags/download_data.py
[2022-02-18 12:58:18,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:58:18,750] {logging_mixin.py:112} INFO - [2022-02-18 12:58:18,749] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:58:19,177] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:58:19,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:58:19,226] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:58:19,229] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 12:58:32,082] {scheduler_job.py:155} INFO - Started process (PID=84180) to work on /airflow/dags/download_data.py
[2022-02-18 12:58:32,087] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:58:32,088] {logging_mixin.py:112} INFO - [2022-02-18 12:58:32,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:58:32,527] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:58:32,563] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:58:32,569] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:58:32,573] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 12:58:45,323] {scheduler_job.py:155} INFO - Started process (PID=84206) to work on /airflow/dags/download_data.py
[2022-02-18 12:58:45,328] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:58:45,330] {logging_mixin.py:112} INFO - [2022-02-18 12:58:45,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:58:45,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:58:45,841] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:58:45,850] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:58:45,856] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 12:58:58,637] {scheduler_job.py:155} INFO - Started process (PID=84232) to work on /airflow/dags/download_data.py
[2022-02-18 12:58:58,641] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:58:58,643] {logging_mixin.py:112} INFO - [2022-02-18 12:58:58,643] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:58:59,086] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:58:59,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:58:59,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:58:59,147] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 12:59:11,924] {scheduler_job.py:155} INFO - Started process (PID=84258) to work on /airflow/dags/download_data.py
[2022-02-18 12:59:11,932] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:59:11,934] {logging_mixin.py:112} INFO - [2022-02-18 12:59:11,934] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:59:12,332] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:59:12,382] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:59:12,389] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:59:12,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.472 seconds
[2022-02-18 12:59:25,190] {scheduler_job.py:155} INFO - Started process (PID=84284) to work on /airflow/dags/download_data.py
[2022-02-18 12:59:25,194] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:59:25,196] {logging_mixin.py:112} INFO - [2022-02-18 12:59:25,195] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:59:25,633] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:59:25,677] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:59:25,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:59:25,690] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 12:59:38,466] {scheduler_job.py:155} INFO - Started process (PID=84310) to work on /airflow/dags/download_data.py
[2022-02-18 12:59:38,471] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:59:38,473] {logging_mixin.py:112} INFO - [2022-02-18 12:59:38,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:59:38,923] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:59:38,985] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:59:38,993] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:59:38,998] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 12:59:51,736] {scheduler_job.py:155} INFO - Started process (PID=84336) to work on /airflow/dags/download_data.py
[2022-02-18 12:59:51,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 12:59:51,744] {logging_mixin.py:112} INFO - [2022-02-18 12:59:51,744] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 12:59:52,243] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 12:59:52,309] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 12:59:52,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 12:59:52,328] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 13:00:05,000] {scheduler_job.py:155} INFO - Started process (PID=84362) to work on /airflow/dags/download_data.py
[2022-02-18 13:00:05,005] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:00:05,007] {logging_mixin.py:112} INFO - [2022-02-18 13:00:05,007] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:00:05,436] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:00:05,476] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:00:05,482] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:00:05,485] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-18 13:00:18,318] {scheduler_job.py:155} INFO - Started process (PID=84388) to work on /airflow/dags/download_data.py
[2022-02-18 13:00:18,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:00:18,325] {logging_mixin.py:112} INFO - [2022-02-18 13:00:18,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:00:18,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:00:18,796] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:00:18,803] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:00:18,808] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-18 13:00:31,659] {scheduler_job.py:155} INFO - Started process (PID=84414) to work on /airflow/dags/download_data.py
[2022-02-18 13:00:31,664] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:00:31,666] {logging_mixin.py:112} INFO - [2022-02-18 13:00:31,666] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:00:32,116] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:00:32,158] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:00:32,166] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:00:32,169] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 13:00:44,923] {scheduler_job.py:155} INFO - Started process (PID=84440) to work on /airflow/dags/download_data.py
[2022-02-18 13:00:44,929] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:00:44,931] {logging_mixin.py:112} INFO - [2022-02-18 13:00:44,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:00:45,364] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:00:45,414] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:00:45,424] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:00:45,429] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 13:00:58,202] {scheduler_job.py:155} INFO - Started process (PID=84466) to work on /airflow/dags/download_data.py
[2022-02-18 13:00:58,207] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:00:58,209] {logging_mixin.py:112} INFO - [2022-02-18 13:00:58,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:00:58,655] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:00:58,706] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:00:58,716] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:00:58,723] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 13:01:11,493] {scheduler_job.py:155} INFO - Started process (PID=84492) to work on /airflow/dags/download_data.py
[2022-02-18 13:01:11,498] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:01:11,500] {logging_mixin.py:112} INFO - [2022-02-18 13:01:11,500] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:01:11,940] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:01:11,986] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:01:11,997] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:01:12,002] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 13:01:24,719] {scheduler_job.py:155} INFO - Started process (PID=84518) to work on /airflow/dags/download_data.py
[2022-02-18 13:01:24,723] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:01:24,724] {logging_mixin.py:112} INFO - [2022-02-18 13:01:24,724] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:01:25,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:01:25,201] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:01:25,207] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:01:25,210] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 13:01:38,027] {scheduler_job.py:155} INFO - Started process (PID=84544) to work on /airflow/dags/download_data.py
[2022-02-18 13:01:38,032] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:01:38,034] {logging_mixin.py:112} INFO - [2022-02-18 13:01:38,034] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:01:38,460] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:01:38,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:01:38,509] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:01:38,515] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-18 13:01:51,271] {scheduler_job.py:155} INFO - Started process (PID=84570) to work on /airflow/dags/download_data.py
[2022-02-18 13:01:51,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:01:51,281] {logging_mixin.py:112} INFO - [2022-02-18 13:01:51,280] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:01:51,731] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:01:51,784] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:01:51,792] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:01:51,796] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 13:02:04,614] {scheduler_job.py:155} INFO - Started process (PID=84596) to work on /airflow/dags/download_data.py
[2022-02-18 13:02:04,619] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:02:04,620] {logging_mixin.py:112} INFO - [2022-02-18 13:02:04,620] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:02:05,081] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:02:05,134] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:02:05,141] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:02:05,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 13:02:17,864] {scheduler_job.py:155} INFO - Started process (PID=84622) to work on /airflow/dags/download_data.py
[2022-02-18 13:02:17,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:02:17,869] {logging_mixin.py:112} INFO - [2022-02-18 13:02:17,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:02:18,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:02:18,356] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:02:18,363] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:02:18,369] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 13:02:31,183] {scheduler_job.py:155} INFO - Started process (PID=84648) to work on /airflow/dags/download_data.py
[2022-02-18 13:02:31,190] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:02:31,192] {logging_mixin.py:112} INFO - [2022-02-18 13:02:31,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:02:31,628] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:02:31,683] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:02:31,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:02:31,699] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 13:02:44,430] {scheduler_job.py:155} INFO - Started process (PID=84674) to work on /airflow/dags/download_data.py
[2022-02-18 13:02:44,434] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:02:44,436] {logging_mixin.py:112} INFO - [2022-02-18 13:02:44,435] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:02:44,882] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:02:44,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:02:44,939] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:02:44,943] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 13:02:57,737] {scheduler_job.py:155} INFO - Started process (PID=84700) to work on /airflow/dags/download_data.py
[2022-02-18 13:02:57,741] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:02:57,746] {logging_mixin.py:112} INFO - [2022-02-18 13:02:57,746] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:02:58,183] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:02:58,233] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:02:58,239] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:02:58,243] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 13:03:11,078] {scheduler_job.py:155} INFO - Started process (PID=84726) to work on /airflow/dags/download_data.py
[2022-02-18 13:03:11,089] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:03:11,091] {logging_mixin.py:112} INFO - [2022-02-18 13:03:11,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:03:11,526] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:03:11,576] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:03:11,586] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:03:11,592] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 13:03:24,330] {scheduler_job.py:155} INFO - Started process (PID=84752) to work on /airflow/dags/download_data.py
[2022-02-18 13:03:24,334] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:03:24,336] {logging_mixin.py:112} INFO - [2022-02-18 13:03:24,336] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:03:24,786] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:03:24,834] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:03:24,840] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:03:24,844] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 13:03:37,660] {scheduler_job.py:155} INFO - Started process (PID=84778) to work on /airflow/dags/download_data.py
[2022-02-18 13:03:37,667] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:03:37,670] {logging_mixin.py:112} INFO - [2022-02-18 13:03:37,669] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:03:38,098] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:03:38,145] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:03:38,152] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:03:38,156] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 13:03:50,926] {scheduler_job.py:155} INFO - Started process (PID=84804) to work on /airflow/dags/download_data.py
[2022-02-18 13:03:50,933] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:03:50,937] {logging_mixin.py:112} INFO - [2022-02-18 13:03:50,936] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:03:51,362] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:03:51,411] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:03:51,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:03:51,423] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 13:04:04,190] {scheduler_job.py:155} INFO - Started process (PID=84830) to work on /airflow/dags/download_data.py
[2022-02-18 13:04:04,194] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:04:04,196] {logging_mixin.py:112} INFO - [2022-02-18 13:04:04,195] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:04:04,653] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:04:04,708] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:04:04,717] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:04:04,723] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 13:04:17,456] {scheduler_job.py:155} INFO - Started process (PID=84856) to work on /airflow/dags/download_data.py
[2022-02-18 13:04:17,463] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:04:17,465] {logging_mixin.py:112} INFO - [2022-02-18 13:04:17,465] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:04:17,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:04:17,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:04:17,961] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:04:17,966] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 13:04:30,723] {scheduler_job.py:155} INFO - Started process (PID=84882) to work on /airflow/dags/download_data.py
[2022-02-18 13:04:30,727] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:04:30,729] {logging_mixin.py:112} INFO - [2022-02-18 13:04:30,729] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:04:31,165] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:04:31,207] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:04:31,213] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:04:31,216] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.494 seconds
[2022-02-18 13:04:43,991] {scheduler_job.py:155} INFO - Started process (PID=84908) to work on /airflow/dags/download_data.py
[2022-02-18 13:04:43,997] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:04:43,999] {logging_mixin.py:112} INFO - [2022-02-18 13:04:43,999] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:04:44,433] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:04:44,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:04:44,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:04:44,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 13:04:57,286] {scheduler_job.py:155} INFO - Started process (PID=84934) to work on /airflow/dags/download_data.py
[2022-02-18 13:04:57,295] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:04:57,297] {logging_mixin.py:112} INFO - [2022-02-18 13:04:57,297] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:04:57,725] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:04:57,778] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:04:57,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:04:57,791] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 13:05:10,549] {scheduler_job.py:155} INFO - Started process (PID=84960) to work on /airflow/dags/download_data.py
[2022-02-18 13:05:10,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:05:10,556] {logging_mixin.py:112} INFO - [2022-02-18 13:05:10,555] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:05:11,007] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:05:11,060] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:05:11,070] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:05:11,076] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 13:05:23,869] {scheduler_job.py:155} INFO - Started process (PID=84986) to work on /airflow/dags/download_data.py
[2022-02-18 13:05:23,873] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:05:23,876] {logging_mixin.py:112} INFO - [2022-02-18 13:05:23,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:05:24,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:05:24,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:05:24,392] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:05:24,399] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 13:05:37,114] {scheduler_job.py:155} INFO - Started process (PID=85012) to work on /airflow/dags/download_data.py
[2022-02-18 13:05:37,118] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:05:37,120] {logging_mixin.py:112} INFO - [2022-02-18 13:05:37,120] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:05:37,561] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:05:37,608] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:05:37,616] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:05:37,619] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 13:05:50,431] {scheduler_job.py:155} INFO - Started process (PID=85038) to work on /airflow/dags/download_data.py
[2022-02-18 13:05:50,437] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:05:50,439] {logging_mixin.py:112} INFO - [2022-02-18 13:05:50,439] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:05:50,883] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:05:50,925] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:05:50,936] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:05:50,942] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 13:06:03,737] {scheduler_job.py:155} INFO - Started process (PID=85064) to work on /airflow/dags/download_data.py
[2022-02-18 13:06:03,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:06:03,743] {logging_mixin.py:112} INFO - [2022-02-18 13:06:03,743] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:06:04,194] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:06:04,238] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:06:04,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:06:04,255] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 13:06:16,989] {scheduler_job.py:155} INFO - Started process (PID=85090) to work on /airflow/dags/download_data.py
[2022-02-18 13:06:16,993] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:06:16,995] {logging_mixin.py:112} INFO - [2022-02-18 13:06:16,995] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:06:17,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:06:17,479] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:06:17,489] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:06:17,494] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 13:06:30,269] {scheduler_job.py:155} INFO - Started process (PID=85116) to work on /airflow/dags/download_data.py
[2022-02-18 13:06:30,273] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:06:30,277] {logging_mixin.py:112} INFO - [2022-02-18 13:06:30,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:06:30,738] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:06:30,798] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:06:30,804] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:06:30,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 13:06:43,559] {scheduler_job.py:155} INFO - Started process (PID=85142) to work on /airflow/dags/download_data.py
[2022-02-18 13:06:43,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:06:43,571] {logging_mixin.py:112} INFO - [2022-02-18 13:06:43,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:06:43,999] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:06:44,049] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:06:44,058] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:06:44,064] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 13:06:56,869] {scheduler_job.py:155} INFO - Started process (PID=85168) to work on /airflow/dags/download_data.py
[2022-02-18 13:06:56,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:06:56,876] {logging_mixin.py:112} INFO - [2022-02-18 13:06:56,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:06:57,296] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:06:57,336] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:06:57,347] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:06:57,352] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.483 seconds
[2022-02-18 13:07:10,206] {scheduler_job.py:155} INFO - Started process (PID=85194) to work on /airflow/dags/download_data.py
[2022-02-18 13:07:10,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:07:10,215] {logging_mixin.py:112} INFO - [2022-02-18 13:07:10,215] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:07:10,642] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:07:10,689] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:07:10,697] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:07:10,702] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 13:07:23,472] {scheduler_job.py:155} INFO - Started process (PID=85220) to work on /airflow/dags/download_data.py
[2022-02-18 13:07:23,481] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:07:23,482] {logging_mixin.py:112} INFO - [2022-02-18 13:07:23,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:07:23,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:07:23,979] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:07:23,985] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:07:23,989] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 13:07:36,778] {scheduler_job.py:155} INFO - Started process (PID=85246) to work on /airflow/dags/download_data.py
[2022-02-18 13:07:36,782] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:07:36,784] {logging_mixin.py:112} INFO - [2022-02-18 13:07:36,783] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:07:37,230] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:07:37,279] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:07:37,287] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:07:37,296] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 13:07:50,064] {scheduler_job.py:155} INFO - Started process (PID=85272) to work on /airflow/dags/download_data.py
[2022-02-18 13:07:50,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:07:50,075] {logging_mixin.py:112} INFO - [2022-02-18 13:07:50,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:07:50,517] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:07:50,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:07:50,575] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:07:50,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 13:08:03,367] {scheduler_job.py:155} INFO - Started process (PID=85298) to work on /airflow/dags/download_data.py
[2022-02-18 13:08:03,371] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:08:03,373] {logging_mixin.py:112} INFO - [2022-02-18 13:08:03,372] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:08:03,821] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:08:03,874] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:08:03,881] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:08:03,885] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 13:08:16,652] {scheduler_job.py:155} INFO - Started process (PID=85324) to work on /airflow/dags/download_data.py
[2022-02-18 13:08:16,657] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:08:16,659] {logging_mixin.py:112} INFO - [2022-02-18 13:08:16,659] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:08:17,109] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:08:17,163] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:08:17,169] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:08:17,174] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 13:08:29,953] {scheduler_job.py:155} INFO - Started process (PID=85350) to work on /airflow/dags/download_data.py
[2022-02-18 13:08:29,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:08:29,961] {logging_mixin.py:112} INFO - [2022-02-18 13:08:29,961] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:08:30,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:08:30,440] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:08:30,446] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:08:30,450] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 13:08:43,242] {scheduler_job.py:155} INFO - Started process (PID=85376) to work on /airflow/dags/download_data.py
[2022-02-18 13:08:43,246] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:08:43,248] {logging_mixin.py:112} INFO - [2022-02-18 13:08:43,248] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:08:43,703] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:08:43,754] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:08:43,764] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:08:43,769] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 13:08:56,548] {scheduler_job.py:155} INFO - Started process (PID=85402) to work on /airflow/dags/download_data.py
[2022-02-18 13:08:56,555] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:08:56,558] {logging_mixin.py:112} INFO - [2022-02-18 13:08:56,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:08:56,985] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:08:57,030] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:08:57,041] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:08:57,047] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 13:09:09,849] {scheduler_job.py:155} INFO - Started process (PID=85428) to work on /airflow/dags/download_data.py
[2022-02-18 13:09:09,859] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:09:09,861] {logging_mixin.py:112} INFO - [2022-02-18 13:09:09,860] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:09:10,298] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:09:10,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:09:10,359] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:09:10,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 13:09:23,100] {scheduler_job.py:155} INFO - Started process (PID=85454) to work on /airflow/dags/download_data.py
[2022-02-18 13:09:23,105] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:09:23,107] {logging_mixin.py:112} INFO - [2022-02-18 13:09:23,107] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:09:23,560] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:09:23,609] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:09:23,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:09:23,630] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 13:09:36,384] {scheduler_job.py:155} INFO - Started process (PID=85480) to work on /airflow/dags/download_data.py
[2022-02-18 13:09:36,388] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:09:36,390] {logging_mixin.py:112} INFO - [2022-02-18 13:09:36,389] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:09:36,827] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:09:36,877] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:09:36,884] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:09:36,888] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 13:09:49,701] {scheduler_job.py:155} INFO - Started process (PID=85506) to work on /airflow/dags/download_data.py
[2022-02-18 13:09:49,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:09:49,711] {logging_mixin.py:112} INFO - [2022-02-18 13:09:49,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:09:50,148] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:09:50,200] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:09:50,207] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:09:50,213] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 13:10:03,013] {scheduler_job.py:155} INFO - Started process (PID=85532) to work on /airflow/dags/download_data.py
[2022-02-18 13:10:03,022] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:10:03,024] {logging_mixin.py:112} INFO - [2022-02-18 13:10:03,024] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:10:03,477] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:10:03,524] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:10:03,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:10:03,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 13:10:16,287] {scheduler_job.py:155} INFO - Started process (PID=85558) to work on /airflow/dags/download_data.py
[2022-02-18 13:10:16,292] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:10:16,294] {logging_mixin.py:112} INFO - [2022-02-18 13:10:16,293] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:10:16,742] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:10:16,794] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:10:16,799] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:10:16,803] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 13:10:29,621] {scheduler_job.py:155} INFO - Started process (PID=85584) to work on /airflow/dags/download_data.py
[2022-02-18 13:10:29,625] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:10:29,628] {logging_mixin.py:112} INFO - [2022-02-18 13:10:29,627] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:10:30,076] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:10:30,117] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:10:30,125] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:10:30,131] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 13:10:42,928] {scheduler_job.py:155} INFO - Started process (PID=85610) to work on /airflow/dags/download_data.py
[2022-02-18 13:10:42,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:10:42,941] {logging_mixin.py:112} INFO - [2022-02-18 13:10:42,941] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:10:43,391] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:10:43,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:10:43,452] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:10:43,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 13:10:56,212] {scheduler_job.py:155} INFO - Started process (PID=85636) to work on /airflow/dags/download_data.py
[2022-02-18 13:10:56,217] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:10:56,218] {logging_mixin.py:112} INFO - [2022-02-18 13:10:56,218] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:10:56,638] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:10:56,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:10:56,694] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:10:56,698] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.486 seconds
[2022-02-18 13:11:09,483] {scheduler_job.py:155} INFO - Started process (PID=85662) to work on /airflow/dags/download_data.py
[2022-02-18 13:11:09,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:11:09,489] {logging_mixin.py:112} INFO - [2022-02-18 13:11:09,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:11:09,938] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:11:09,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:11:09,996] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:11:10,000] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 13:11:22,804] {scheduler_job.py:155} INFO - Started process (PID=85688) to work on /airflow/dags/download_data.py
[2022-02-18 13:11:22,814] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:11:22,816] {logging_mixin.py:112} INFO - [2022-02-18 13:11:22,816] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:11:23,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:11:23,327] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:11:23,335] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:11:23,344] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 13:11:36,106] {scheduler_job.py:155} INFO - Started process (PID=85714) to work on /airflow/dags/download_data.py
[2022-02-18 13:11:36,111] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:11:36,113] {logging_mixin.py:112} INFO - [2022-02-18 13:11:36,113] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:11:36,569] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:11:36,616] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:11:36,624] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:11:36,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 13:11:49,372] {scheduler_job.py:155} INFO - Started process (PID=85740) to work on /airflow/dags/download_data.py
[2022-02-18 13:11:49,377] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:11:49,380] {logging_mixin.py:112} INFO - [2022-02-18 13:11:49,380] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:11:49,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:11:49,875] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:11:49,885] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:11:49,890] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 13:12:02,679] {scheduler_job.py:155} INFO - Started process (PID=85766) to work on /airflow/dags/download_data.py
[2022-02-18 13:12:02,686] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:12:02,688] {logging_mixin.py:112} INFO - [2022-02-18 13:12:02,688] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:12:03,136] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:12:03,192] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:12:03,202] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:12:03,208] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 13:12:15,944] {scheduler_job.py:155} INFO - Started process (PID=85792) to work on /airflow/dags/download_data.py
[2022-02-18 13:12:15,948] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:12:15,950] {logging_mixin.py:112} INFO - [2022-02-18 13:12:15,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:12:16,385] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:12:16,434] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:12:16,443] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:12:16,449] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 13:12:29,275] {scheduler_job.py:155} INFO - Started process (PID=85818) to work on /airflow/dags/download_data.py
[2022-02-18 13:12:29,280] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:12:29,281] {logging_mixin.py:112} INFO - [2022-02-18 13:12:29,281] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:12:29,724] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:12:29,775] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:12:29,783] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:12:29,789] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 13:12:42,543] {scheduler_job.py:155} INFO - Started process (PID=85844) to work on /airflow/dags/download_data.py
[2022-02-18 13:12:42,552] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:12:42,554] {logging_mixin.py:112} INFO - [2022-02-18 13:12:42,554] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:12:43,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:12:43,054] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:12:43,064] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:12:43,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 13:12:55,805] {scheduler_job.py:155} INFO - Started process (PID=85870) to work on /airflow/dags/download_data.py
[2022-02-18 13:12:55,810] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:12:55,812] {logging_mixin.py:112} INFO - [2022-02-18 13:12:55,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:12:56,253] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:12:56,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:12:56,314] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:12:56,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 13:13:09,105] {scheduler_job.py:155} INFO - Started process (PID=85896) to work on /airflow/dags/download_data.py
[2022-02-18 13:13:09,109] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:13:09,110] {logging_mixin.py:112} INFO - [2022-02-18 13:13:09,110] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:13:09,576] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:13:09,627] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:13:09,634] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:13:09,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 13:13:22,384] {scheduler_job.py:155} INFO - Started process (PID=85922) to work on /airflow/dags/download_data.py
[2022-02-18 13:13:22,389] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:13:22,391] {logging_mixin.py:112} INFO - [2022-02-18 13:13:22,391] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:13:22,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:13:22,915] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:13:22,923] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:13:22,929] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 13:13:35,703] {scheduler_job.py:155} INFO - Started process (PID=85948) to work on /airflow/dags/download_data.py
[2022-02-18 13:13:35,708] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:13:35,710] {logging_mixin.py:112} INFO - [2022-02-18 13:13:35,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:13:36,145] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:13:36,196] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:13:36,203] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:13:36,208] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 13:13:49,002] {scheduler_job.py:155} INFO - Started process (PID=85974) to work on /airflow/dags/download_data.py
[2022-02-18 13:13:49,007] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:13:49,009] {logging_mixin.py:112} INFO - [2022-02-18 13:13:49,008] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:13:49,464] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:13:49,511] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:13:49,520] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:13:49,524] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 13:14:02,281] {scheduler_job.py:155} INFO - Started process (PID=86000) to work on /airflow/dags/download_data.py
[2022-02-18 13:14:02,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:14:02,289] {logging_mixin.py:112} INFO - [2022-02-18 13:14:02,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:14:02,724] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:14:02,775] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:14:02,785] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:14:02,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 13:14:15,562] {scheduler_job.py:155} INFO - Started process (PID=86026) to work on /airflow/dags/download_data.py
[2022-02-18 13:14:15,566] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:14:15,568] {logging_mixin.py:112} INFO - [2022-02-18 13:14:15,568] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:14:16,003] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:14:16,056] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:14:16,064] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:14:16,067] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 13:14:28,890] {scheduler_job.py:155} INFO - Started process (PID=86052) to work on /airflow/dags/download_data.py
[2022-02-18 13:14:28,896] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:14:28,897] {logging_mixin.py:112} INFO - [2022-02-18 13:14:28,897] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:14:29,375] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:14:29,419] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:14:29,425] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:14:29,432] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 13:14:42,136] {scheduler_job.py:155} INFO - Started process (PID=86078) to work on /airflow/dags/download_data.py
[2022-02-18 13:14:42,141] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:14:42,143] {logging_mixin.py:112} INFO - [2022-02-18 13:14:42,143] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:14:42,609] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:14:42,661] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:14:42,670] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:14:42,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 13:14:55,444] {scheduler_job.py:155} INFO - Started process (PID=86104) to work on /airflow/dags/download_data.py
[2022-02-18 13:14:55,452] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:14:55,454] {logging_mixin.py:112} INFO - [2022-02-18 13:14:55,454] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:14:55,891] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:14:55,931] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:14:55,937] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:14:55,942] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 13:15:08,728] {scheduler_job.py:155} INFO - Started process (PID=86130) to work on /airflow/dags/download_data.py
[2022-02-18 13:15:08,740] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:15:08,742] {logging_mixin.py:112} INFO - [2022-02-18 13:15:08,741] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:15:09,175] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:15:09,223] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:15:09,230] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:15:09,236] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 13:15:22,035] {scheduler_job.py:155} INFO - Started process (PID=86156) to work on /airflow/dags/download_data.py
[2022-02-18 13:15:22,040] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:15:22,041] {logging_mixin.py:112} INFO - [2022-02-18 13:15:22,041] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:15:22,489] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:15:22,538] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:15:22,549] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:15:22,555] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 13:15:35,346] {scheduler_job.py:155} INFO - Started process (PID=86182) to work on /airflow/dags/download_data.py
[2022-02-18 13:15:35,350] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:15:35,352] {logging_mixin.py:112} INFO - [2022-02-18 13:15:35,352] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:15:35,794] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:15:35,844] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:15:35,852] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:15:35,857] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 13:15:48,654] {scheduler_job.py:155} INFO - Started process (PID=86208) to work on /airflow/dags/download_data.py
[2022-02-18 13:15:48,659] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:15:48,660] {logging_mixin.py:112} INFO - [2022-02-18 13:15:48,660] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:15:49,101] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:15:49,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:15:49,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:15:49,162] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 13:16:01,962] {scheduler_job.py:155} INFO - Started process (PID=86234) to work on /airflow/dags/download_data.py
[2022-02-18 13:16:01,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:16:01,971] {logging_mixin.py:112} INFO - [2022-02-18 13:16:01,971] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:16:02,417] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:16:02,460] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:16:02,467] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:16:02,472] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 13:16:15,201] {scheduler_job.py:155} INFO - Started process (PID=86260) to work on /airflow/dags/download_data.py
[2022-02-18 13:16:15,214] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:16:15,219] {logging_mixin.py:112} INFO - [2022-02-18 13:16:15,219] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:16:15,653] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:16:15,697] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:16:15,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:16:15,706] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 13:16:28,517] {scheduler_job.py:155} INFO - Started process (PID=86286) to work on /airflow/dags/download_data.py
[2022-02-18 13:16:28,521] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:16:28,523] {logging_mixin.py:112} INFO - [2022-02-18 13:16:28,523] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:16:28,975] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:16:29,022] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:16:29,030] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:16:29,036] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 13:16:41,774] {scheduler_job.py:155} INFO - Started process (PID=86312) to work on /airflow/dags/download_data.py
[2022-02-18 13:16:41,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:16:41,788] {logging_mixin.py:112} INFO - [2022-02-18 13:16:41,788] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:16:42,213] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:16:42,259] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:16:42,266] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:16:42,272] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 13:16:55,117] {scheduler_job.py:155} INFO - Started process (PID=86338) to work on /airflow/dags/download_data.py
[2022-02-18 13:16:55,123] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:16:55,128] {logging_mixin.py:112} INFO - [2022-02-18 13:16:55,127] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:16:55,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:16:55,610] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:16:55,619] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:16:55,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 13:17:08,429] {scheduler_job.py:155} INFO - Started process (PID=86364) to work on /airflow/dags/download_data.py
[2022-02-18 13:17:08,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:17:08,438] {logging_mixin.py:112} INFO - [2022-02-18 13:17:08,437] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:17:08,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:17:08,921] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:17:08,932] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:17:08,938] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 13:17:21,722] {scheduler_job.py:155} INFO - Started process (PID=86390) to work on /airflow/dags/download_data.py
[2022-02-18 13:17:21,728] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:17:21,730] {logging_mixin.py:112} INFO - [2022-02-18 13:17:21,730] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:17:22,208] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:17:22,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:17:22,260] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:17:22,267] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 13:17:34,998] {scheduler_job.py:155} INFO - Started process (PID=86416) to work on /airflow/dags/download_data.py
[2022-02-18 13:17:35,007] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:17:35,009] {logging_mixin.py:112} INFO - [2022-02-18 13:17:35,008] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:17:35,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:17:35,508] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:17:35,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:17:35,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 13:17:48,241] {scheduler_job.py:155} INFO - Started process (PID=86442) to work on /airflow/dags/download_data.py
[2022-02-18 13:17:48,245] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:17:48,246] {logging_mixin.py:112} INFO - [2022-02-18 13:17:48,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:17:48,681] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:17:48,731] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:17:48,740] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:17:48,745] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 13:18:01,586] {scheduler_job.py:155} INFO - Started process (PID=86468) to work on /airflow/dags/download_data.py
[2022-02-18 13:18:01,594] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:18:01,596] {logging_mixin.py:112} INFO - [2022-02-18 13:18:01,596] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:18:02,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:18:02,083] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:18:02,091] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:18:02,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 13:18:14,880] {scheduler_job.py:155} INFO - Started process (PID=86494) to work on /airflow/dags/download_data.py
[2022-02-18 13:18:14,889] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:18:14,901] {logging_mixin.py:112} INFO - [2022-02-18 13:18:14,900] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:18:15,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:18:15,393] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:18:15,401] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:18:15,405] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 13:18:28,164] {scheduler_job.py:155} INFO - Started process (PID=86520) to work on /airflow/dags/download_data.py
[2022-02-18 13:18:28,171] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:18:28,173] {logging_mixin.py:112} INFO - [2022-02-18 13:18:28,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:18:28,606] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:18:28,661] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:18:28,667] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:18:28,674] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 13:18:41,442] {scheduler_job.py:155} INFO - Started process (PID=86546) to work on /airflow/dags/download_data.py
[2022-02-18 13:18:41,453] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:18:41,455] {logging_mixin.py:112} INFO - [2022-02-18 13:18:41,455] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:18:41,877] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:18:41,926] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:18:41,935] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:18:41,941] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 13:18:54,742] {scheduler_job.py:155} INFO - Started process (PID=86572) to work on /airflow/dags/download_data.py
[2022-02-18 13:18:54,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:18:54,748] {logging_mixin.py:112} INFO - [2022-02-18 13:18:54,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:18:55,193] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:18:55,228] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:18:55,235] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:18:55,239] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 13:19:08,044] {scheduler_job.py:155} INFO - Started process (PID=86598) to work on /airflow/dags/download_data.py
[2022-02-18 13:19:08,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:19:08,057] {logging_mixin.py:112} INFO - [2022-02-18 13:19:08,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:19:08,505] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:19:08,549] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:19:08,561] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:19:08,567] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 13:19:21,327] {scheduler_job.py:155} INFO - Started process (PID=86624) to work on /airflow/dags/download_data.py
[2022-02-18 13:19:21,337] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:19:21,339] {logging_mixin.py:112} INFO - [2022-02-18 13:19:21,338] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:19:21,792] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:19:21,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:19:21,862] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:19:21,867] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 13:19:34,665] {scheduler_job.py:155} INFO - Started process (PID=86650) to work on /airflow/dags/download_data.py
[2022-02-18 13:19:34,671] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:19:34,674] {logging_mixin.py:112} INFO - [2022-02-18 13:19:34,673] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:19:35,105] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:19:35,154] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:19:35,162] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:19:35,167] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 13:19:47,908] {scheduler_job.py:155} INFO - Started process (PID=86676) to work on /airflow/dags/download_data.py
[2022-02-18 13:19:47,914] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:19:47,915] {logging_mixin.py:112} INFO - [2022-02-18 13:19:47,915] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:19:48,360] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:19:48,404] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:19:48,414] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:19:48,420] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 13:20:01,212] {scheduler_job.py:155} INFO - Started process (PID=86702) to work on /airflow/dags/download_data.py
[2022-02-18 13:20:01,219] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:20:01,221] {logging_mixin.py:112} INFO - [2022-02-18 13:20:01,221] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:20:01,667] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:20:01,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:20:01,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:20:01,731] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 13:20:14,471] {scheduler_job.py:155} INFO - Started process (PID=86728) to work on /airflow/dags/download_data.py
[2022-02-18 13:20:14,480] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:20:14,482] {logging_mixin.py:112} INFO - [2022-02-18 13:20:14,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:20:14,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:20:14,958] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:20:14,966] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:20:14,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 13:20:27,822] {scheduler_job.py:155} INFO - Started process (PID=86754) to work on /airflow/dags/download_data.py
[2022-02-18 13:20:27,829] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:20:27,831] {logging_mixin.py:112} INFO - [2022-02-18 13:20:27,831] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:20:28,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:20:28,319] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:20:28,331] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:20:28,337] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 13:20:41,066] {scheduler_job.py:155} INFO - Started process (PID=86780) to work on /airflow/dags/download_data.py
[2022-02-18 13:20:41,070] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:20:41,072] {logging_mixin.py:112} INFO - [2022-02-18 13:20:41,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:20:41,521] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:20:41,571] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:20:41,581] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:20:41,587] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 13:20:54,369] {scheduler_job.py:155} INFO - Started process (PID=86806) to work on /airflow/dags/download_data.py
[2022-02-18 13:20:54,374] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:20:54,375] {logging_mixin.py:112} INFO - [2022-02-18 13:20:54,375] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:20:54,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:20:54,858] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:20:54,865] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:20:54,869] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 13:21:07,700] {scheduler_job.py:155} INFO - Started process (PID=86832) to work on /airflow/dags/download_data.py
[2022-02-18 13:21:07,704] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:21:07,706] {logging_mixin.py:112} INFO - [2022-02-18 13:21:07,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:21:08,162] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:21:08,205] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:21:08,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:21:08,215] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 13:21:20,960] {scheduler_job.py:155} INFO - Started process (PID=86858) to work on /airflow/dags/download_data.py
[2022-02-18 13:21:20,965] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:21:20,967] {logging_mixin.py:112} INFO - [2022-02-18 13:21:20,967] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:21:21,414] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:21:21,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:21:21,470] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:21:21,476] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 13:21:34,242] {scheduler_job.py:155} INFO - Started process (PID=86884) to work on /airflow/dags/download_data.py
[2022-02-18 13:21:34,247] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:21:34,249] {logging_mixin.py:112} INFO - [2022-02-18 13:21:34,249] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:21:34,700] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:21:34,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:21:34,755] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:21:34,758] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 13:21:47,509] {scheduler_job.py:155} INFO - Started process (PID=86910) to work on /airflow/dags/download_data.py
[2022-02-18 13:21:47,515] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:21:47,517] {logging_mixin.py:112} INFO - [2022-02-18 13:21:47,517] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:21:47,961] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:21:48,015] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:21:48,023] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:21:48,028] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 13:22:00,816] {scheduler_job.py:155} INFO - Started process (PID=86936) to work on /airflow/dags/download_data.py
[2022-02-18 13:22:00,820] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:22:00,822] {logging_mixin.py:112} INFO - [2022-02-18 13:22:00,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:22:01,289] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:22:01,343] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:22:01,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:22:01,357] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 13:22:14,065] {scheduler_job.py:155} INFO - Started process (PID=86962) to work on /airflow/dags/download_data.py
[2022-02-18 13:22:14,070] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:22:14,072] {logging_mixin.py:112} INFO - [2022-02-18 13:22:14,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:22:14,509] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:22:14,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:22:14,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:22:14,568] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 13:22:27,359] {scheduler_job.py:155} INFO - Started process (PID=86988) to work on /airflow/dags/download_data.py
[2022-02-18 13:22:27,363] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:22:27,364] {logging_mixin.py:112} INFO - [2022-02-18 13:22:27,364] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:22:27,811] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:22:27,861] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:22:27,869] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:22:27,874] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 13:22:40,636] {scheduler_job.py:155} INFO - Started process (PID=87014) to work on /airflow/dags/download_data.py
[2022-02-18 13:22:40,643] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:22:40,645] {logging_mixin.py:112} INFO - [2022-02-18 13:22:40,645] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:22:41,049] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:22:41,092] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:22:41,099] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:22:41,102] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.466 seconds
[2022-02-18 13:22:53,900] {scheduler_job.py:155} INFO - Started process (PID=87040) to work on /airflow/dags/download_data.py
[2022-02-18 13:22:53,907] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:22:53,909] {logging_mixin.py:112} INFO - [2022-02-18 13:22:53,909] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:22:54,347] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:22:54,390] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:22:54,400] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:22:54,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 13:23:07,221] {scheduler_job.py:155} INFO - Started process (PID=87066) to work on /airflow/dags/download_data.py
[2022-02-18 13:23:07,226] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:23:07,228] {logging_mixin.py:112} INFO - [2022-02-18 13:23:07,228] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:23:07,671] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:23:07,723] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:23:07,733] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:23:07,740] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 13:23:20,477] {scheduler_job.py:155} INFO - Started process (PID=87092) to work on /airflow/dags/download_data.py
[2022-02-18 13:23:20,481] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:23:20,482] {logging_mixin.py:112} INFO - [2022-02-18 13:23:20,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:23:20,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:23:20,980] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:23:20,989] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:23:20,995] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 13:23:33,800] {scheduler_job.py:155} INFO - Started process (PID=87118) to work on /airflow/dags/download_data.py
[2022-02-18 13:23:33,806] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:23:33,808] {logging_mixin.py:112} INFO - [2022-02-18 13:23:33,808] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:23:34,252] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:23:34,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:23:34,315] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:23:34,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 13:23:47,076] {scheduler_job.py:155} INFO - Started process (PID=87144) to work on /airflow/dags/download_data.py
[2022-02-18 13:23:47,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:23:47,083] {logging_mixin.py:112} INFO - [2022-02-18 13:23:47,083] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:23:47,538] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:23:47,591] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:23:47,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:23:47,602] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 13:24:00,372] {scheduler_job.py:155} INFO - Started process (PID=87170) to work on /airflow/dags/download_data.py
[2022-02-18 13:24:00,376] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:24:00,378] {logging_mixin.py:112} INFO - [2022-02-18 13:24:00,377] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:24:00,820] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:24:00,873] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:24:00,880] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:24:00,883] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 13:24:13,648] {scheduler_job.py:155} INFO - Started process (PID=87196) to work on /airflow/dags/download_data.py
[2022-02-18 13:24:13,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:24:13,655] {logging_mixin.py:112} INFO - [2022-02-18 13:24:13,655] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:24:14,096] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:24:14,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:24:14,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:24:14,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 13:24:26,952] {scheduler_job.py:155} INFO - Started process (PID=87222) to work on /airflow/dags/download_data.py
[2022-02-18 13:24:26,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:24:26,961] {logging_mixin.py:112} INFO - [2022-02-18 13:24:26,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:24:27,402] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:24:27,451] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:24:27,458] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:24:27,462] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 13:24:40,224] {scheduler_job.py:155} INFO - Started process (PID=87248) to work on /airflow/dags/download_data.py
[2022-02-18 13:24:40,232] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:24:40,234] {logging_mixin.py:112} INFO - [2022-02-18 13:24:40,234] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:24:40,664] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:24:40,715] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:24:40,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:24:40,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 13:24:53,503] {scheduler_job.py:155} INFO - Started process (PID=87274) to work on /airflow/dags/download_data.py
[2022-02-18 13:24:53,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:24:53,514] {logging_mixin.py:112} INFO - [2022-02-18 13:24:53,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:24:53,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:24:54,010] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:24:54,021] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:24:54,027] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 13:25:06,801] {scheduler_job.py:155} INFO - Started process (PID=87300) to work on /airflow/dags/download_data.py
[2022-02-18 13:25:06,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:25:06,811] {logging_mixin.py:112} INFO - [2022-02-18 13:25:06,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:25:07,239] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:25:07,282] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:25:07,287] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:25:07,292] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 13:25:20,082] {scheduler_job.py:155} INFO - Started process (PID=87326) to work on /airflow/dags/download_data.py
[2022-02-18 13:25:20,093] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:25:20,095] {logging_mixin.py:112} INFO - [2022-02-18 13:25:20,095] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:25:20,540] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:25:20,595] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:25:20,600] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:25:20,604] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 13:25:33,436] {scheduler_job.py:155} INFO - Started process (PID=87352) to work on /airflow/dags/download_data.py
[2022-02-18 13:25:33,443] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:25:33,445] {logging_mixin.py:112} INFO - [2022-02-18 13:25:33,444] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:25:33,908] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:25:33,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:25:33,963] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:25:33,967] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 13:25:46,705] {scheduler_job.py:155} INFO - Started process (PID=87378) to work on /airflow/dags/download_data.py
[2022-02-18 13:25:46,713] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:25:46,715] {logging_mixin.py:112} INFO - [2022-02-18 13:25:46,715] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:25:47,189] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:25:47,239] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:25:47,245] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:25:47,252] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 13:26:00,015] {scheduler_job.py:155} INFO - Started process (PID=87404) to work on /airflow/dags/download_data.py
[2022-02-18 13:26:00,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:26:00,026] {logging_mixin.py:112} INFO - [2022-02-18 13:26:00,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:26:00,489] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:26:00,528] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:26:00,536] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:26:00,540] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 13:26:13,292] {scheduler_job.py:155} INFO - Started process (PID=87430) to work on /airflow/dags/download_data.py
[2022-02-18 13:26:13,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:26:13,297] {logging_mixin.py:112} INFO - [2022-02-18 13:26:13,297] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:26:13,738] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:26:13,790] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:26:13,796] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:26:13,801] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 13:26:26,580] {scheduler_job.py:155} INFO - Started process (PID=87456) to work on /airflow/dags/download_data.py
[2022-02-18 13:26:26,587] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:26:26,589] {logging_mixin.py:112} INFO - [2022-02-18 13:26:26,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:26:27,026] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:26:27,075] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:26:27,083] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:26:27,088] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 13:26:39,876] {scheduler_job.py:155} INFO - Started process (PID=87482) to work on /airflow/dags/download_data.py
[2022-02-18 13:26:39,883] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:26:39,885] {logging_mixin.py:112} INFO - [2022-02-18 13:26:39,885] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:26:40,322] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:26:40,372] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:26:40,380] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:26:40,385] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 13:26:53,123] {scheduler_job.py:155} INFO - Started process (PID=87508) to work on /airflow/dags/download_data.py
[2022-02-18 13:26:53,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:26:53,129] {logging_mixin.py:112} INFO - [2022-02-18 13:26:53,129] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:26:53,584] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:26:53,635] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:26:53,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:26:53,651] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 13:27:06,454] {scheduler_job.py:155} INFO - Started process (PID=87534) to work on /airflow/dags/download_data.py
[2022-02-18 13:27:06,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:27:06,464] {logging_mixin.py:112} INFO - [2022-02-18 13:27:06,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:27:06,893] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:27:06,933] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:27:06,941] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:27:06,946] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 13:27:19,727] {scheduler_job.py:155} INFO - Started process (PID=87560) to work on /airflow/dags/download_data.py
[2022-02-18 13:27:19,734] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:27:19,736] {logging_mixin.py:112} INFO - [2022-02-18 13:27:19,736] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:27:20,168] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:27:20,208] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:27:20,213] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:27:20,217] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 13:27:33,053] {scheduler_job.py:155} INFO - Started process (PID=87586) to work on /airflow/dags/download_data.py
[2022-02-18 13:27:33,058] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:27:33,060] {logging_mixin.py:112} INFO - [2022-02-18 13:27:33,060] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:27:33,519] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:27:33,573] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:27:33,583] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:27:33,587] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 13:27:46,321] {scheduler_job.py:155} INFO - Started process (PID=87612) to work on /airflow/dags/download_data.py
[2022-02-18 13:27:46,326] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:27:46,328] {logging_mixin.py:112} INFO - [2022-02-18 13:27:46,328] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:27:46,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:27:46,814] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:27:46,822] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:27:46,827] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 13:27:59,630] {scheduler_job.py:155} INFO - Started process (PID=87638) to work on /airflow/dags/download_data.py
[2022-02-18 13:27:59,634] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:27:59,636] {logging_mixin.py:112} INFO - [2022-02-18 13:27:59,636] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:28:00,093] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:28:00,143] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:28:00,149] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:28:00,155] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 13:28:12,897] {scheduler_job.py:155} INFO - Started process (PID=87664) to work on /airflow/dags/download_data.py
[2022-02-18 13:28:12,905] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:28:12,907] {logging_mixin.py:112} INFO - [2022-02-18 13:28:12,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:28:13,357] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:28:13,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:28:13,409] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:28:13,412] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 13:28:26,222] {scheduler_job.py:155} INFO - Started process (PID=87690) to work on /airflow/dags/download_data.py
[2022-02-18 13:28:26,232] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:28:26,236] {logging_mixin.py:112} INFO - [2022-02-18 13:28:26,235] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:28:26,683] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:28:26,734] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:28:26,745] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:28:26,750] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 13:28:39,525] {scheduler_job.py:155} INFO - Started process (PID=87716) to work on /airflow/dags/download_data.py
[2022-02-18 13:28:39,531] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:28:39,533] {logging_mixin.py:112} INFO - [2022-02-18 13:28:39,532] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:28:39,966] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:28:40,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:28:40,026] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:28:40,030] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 13:28:52,803] {scheduler_job.py:155} INFO - Started process (PID=87742) to work on /airflow/dags/download_data.py
[2022-02-18 13:28:52,807] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:28:52,809] {logging_mixin.py:112} INFO - [2022-02-18 13:28:52,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:28:53,270] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:28:53,323] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:28:53,330] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:28:53,336] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 13:29:06,108] {scheduler_job.py:155} INFO - Started process (PID=87768) to work on /airflow/dags/download_data.py
[2022-02-18 13:29:06,116] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:29:06,118] {logging_mixin.py:112} INFO - [2022-02-18 13:29:06,117] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:29:06,563] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:29:06,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:29:06,622] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:29:06,627] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 13:29:19,392] {scheduler_job.py:155} INFO - Started process (PID=87794) to work on /airflow/dags/download_data.py
[2022-02-18 13:29:19,396] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:29:19,398] {logging_mixin.py:112} INFO - [2022-02-18 13:29:19,398] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:29:19,861] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:29:19,913] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:29:19,922] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:29:19,925] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 13:29:32,676] {scheduler_job.py:155} INFO - Started process (PID=87820) to work on /airflow/dags/download_data.py
[2022-02-18 13:29:32,683] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:29:32,685] {logging_mixin.py:112} INFO - [2022-02-18 13:29:32,685] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:29:33,130] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:29:33,180] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:29:33,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:29:33,195] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 13:29:45,979] {scheduler_job.py:155} INFO - Started process (PID=87846) to work on /airflow/dags/download_data.py
[2022-02-18 13:29:45,984] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:29:45,986] {logging_mixin.py:112} INFO - [2022-02-18 13:29:45,986] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:29:46,435] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:29:46,476] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:29:46,485] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:29:46,490] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 13:29:59,328] {scheduler_job.py:155} INFO - Started process (PID=87872) to work on /airflow/dags/download_data.py
[2022-02-18 13:29:59,335] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 13:29:59,337] {logging_mixin.py:112} INFO - [2022-02-18 13:29:59,337] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 13:29:59,795] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 13:29:59,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 13:29:59,855] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 13:29:59,859] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 14:24:11,248] {scheduler_job.py:155} INFO - Started process (PID=87898) to work on /airflow/dags/download_data.py
[2022-02-18 14:24:11,254] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:24:11,256] {logging_mixin.py:112} INFO - [2022-02-18 14:24:11,256] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:24:11,716] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:24:11,768] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:24:11,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:24:11,781] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 14:24:29,779] {scheduler_job.py:155} INFO - Started process (PID=87924) to work on /airflow/dags/download_data.py
[2022-02-18 14:24:29,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:24:29,789] {logging_mixin.py:112} INFO - [2022-02-18 14:24:29,788] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:24:30,261] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:24:30,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:24:30,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:24:30,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 14:24:43,067] {scheduler_job.py:155} INFO - Started process (PID=87950) to work on /airflow/dags/download_data.py
[2022-02-18 14:24:43,071] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:24:43,073] {logging_mixin.py:112} INFO - [2022-02-18 14:24:43,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:24:43,507] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:24:43,547] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:24:43,557] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:24:43,562] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 14:24:56,388] {scheduler_job.py:155} INFO - Started process (PID=87976) to work on /airflow/dags/download_data.py
[2022-02-18 14:24:56,392] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:24:56,395] {logging_mixin.py:112} INFO - [2022-02-18 14:24:56,394] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:24:56,839] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:24:56,889] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:24:56,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:24:56,903] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 14:25:09,635] {scheduler_job.py:155} INFO - Started process (PID=88002) to work on /airflow/dags/download_data.py
[2022-02-18 14:25:09,639] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:25:09,641] {logging_mixin.py:112} INFO - [2022-02-18 14:25:09,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:25:10,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:25:10,135] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:25:10,147] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:25:10,151] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 14:25:22,990] {scheduler_job.py:155} INFO - Started process (PID=88028) to work on /airflow/dags/download_data.py
[2022-02-18 14:25:22,997] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:25:23,000] {logging_mixin.py:112} INFO - [2022-02-18 14:25:22,999] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:25:23,441] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:25:23,492] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:25:23,500] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:25:23,505] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 14:25:36,312] {scheduler_job.py:155} INFO - Started process (PID=88054) to work on /airflow/dags/download_data.py
[2022-02-18 14:25:36,319] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:25:36,321] {logging_mixin.py:112} INFO - [2022-02-18 14:25:36,321] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:25:36,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:25:36,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:25:36,808] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:25:36,813] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 14:25:49,629] {scheduler_job.py:155} INFO - Started process (PID=88080) to work on /airflow/dags/download_data.py
[2022-02-18 14:25:49,635] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:25:49,637] {logging_mixin.py:112} INFO - [2022-02-18 14:25:49,637] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:25:50,094] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:25:50,145] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:25:50,159] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:25:50,163] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 14:26:03,018] {scheduler_job.py:155} INFO - Started process (PID=88106) to work on /airflow/dags/download_data.py
[2022-02-18 14:26:03,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:26:03,025] {logging_mixin.py:112} INFO - [2022-02-18 14:26:03,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:26:03,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:26:03,502] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:26:03,511] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:26:03,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 14:26:16,303] {scheduler_job.py:155} INFO - Started process (PID=88132) to work on /airflow/dags/download_data.py
[2022-02-18 14:26:16,307] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:26:16,308] {logging_mixin.py:112} INFO - [2022-02-18 14:26:16,308] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:26:16,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:26:16,803] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:26:16,810] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:26:16,813] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 14:26:29,607] {scheduler_job.py:155} INFO - Started process (PID=88158) to work on /airflow/dags/download_data.py
[2022-02-18 14:26:29,612] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:26:29,614] {logging_mixin.py:112} INFO - [2022-02-18 14:26:29,613] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:26:30,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:26:30,095] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:26:30,101] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:26:30,106] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 14:26:42,862] {scheduler_job.py:155} INFO - Started process (PID=88184) to work on /airflow/dags/download_data.py
[2022-02-18 14:26:42,866] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:26:42,867] {logging_mixin.py:112} INFO - [2022-02-18 14:26:42,867] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:26:43,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:26:43,385] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:26:43,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:26:43,399] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 14:26:56,162] {scheduler_job.py:155} INFO - Started process (PID=88210) to work on /airflow/dags/download_data.py
[2022-02-18 14:26:56,169] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:26:56,171] {logging_mixin.py:112} INFO - [2022-02-18 14:26:56,171] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:26:56,599] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:26:56,648] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:26:56,655] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:26:56,660] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 14:27:09,458] {scheduler_job.py:155} INFO - Started process (PID=88236) to work on /airflow/dags/download_data.py
[2022-02-18 14:27:09,464] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:27:09,466] {logging_mixin.py:112} INFO - [2022-02-18 14:27:09,466] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:27:09,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:27:09,944] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:27:09,950] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:27:09,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 14:27:22,709] {scheduler_job.py:155} INFO - Started process (PID=88262) to work on /airflow/dags/download_data.py
[2022-02-18 14:27:22,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:27:22,718] {logging_mixin.py:112} INFO - [2022-02-18 14:27:22,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:27:23,163] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:27:23,215] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:27:23,222] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:27:23,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 14:27:36,028] {scheduler_job.py:155} INFO - Started process (PID=88288) to work on /airflow/dags/download_data.py
[2022-02-18 14:27:36,034] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:27:36,036] {logging_mixin.py:112} INFO - [2022-02-18 14:27:36,036] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:27:36,469] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:27:36,521] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:27:36,529] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:27:36,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 14:27:49,325] {scheduler_job.py:155} INFO - Started process (PID=88314) to work on /airflow/dags/download_data.py
[2022-02-18 14:27:49,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:27:49,334] {logging_mixin.py:112} INFO - [2022-02-18 14:27:49,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:27:49,755] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:27:49,807] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:27:49,814] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:27:49,819] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 14:28:02,629] {scheduler_job.py:155} INFO - Started process (PID=88340) to work on /airflow/dags/download_data.py
[2022-02-18 14:28:02,634] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:28:02,635] {logging_mixin.py:112} INFO - [2022-02-18 14:28:02,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:28:03,062] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:28:03,101] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:28:03,107] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:28:03,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.483 seconds
[2022-02-18 14:28:15,889] {scheduler_job.py:155} INFO - Started process (PID=88366) to work on /airflow/dags/download_data.py
[2022-02-18 14:28:15,899] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:28:15,901] {logging_mixin.py:112} INFO - [2022-02-18 14:28:15,901] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:28:16,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:28:16,385] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:28:16,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:28:16,401] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 14:28:29,200] {scheduler_job.py:155} INFO - Started process (PID=88392) to work on /airflow/dags/download_data.py
[2022-02-18 14:28:29,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:28:29,208] {logging_mixin.py:112} INFO - [2022-02-18 14:28:29,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:28:29,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:28:29,699] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:28:29,710] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:28:29,715] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 14:28:42,479] {scheduler_job.py:155} INFO - Started process (PID=88418) to work on /airflow/dags/download_data.py
[2022-02-18 14:28:42,489] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:28:42,492] {logging_mixin.py:112} INFO - [2022-02-18 14:28:42,491] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:28:42,937] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:28:42,984] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:28:42,994] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:28:42,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 14:28:55,809] {scheduler_job.py:155} INFO - Started process (PID=88444) to work on /airflow/dags/download_data.py
[2022-02-18 14:28:55,814] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:28:55,816] {logging_mixin.py:112} INFO - [2022-02-18 14:28:55,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:28:56,248] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:28:56,296] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:28:56,304] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:28:56,308] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 14:29:09,078] {scheduler_job.py:155} INFO - Started process (PID=88470) to work on /airflow/dags/download_data.py
[2022-02-18 14:29:09,083] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:29:09,085] {logging_mixin.py:112} INFO - [2022-02-18 14:29:09,085] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:29:09,521] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:29:09,562] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:29:09,567] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:29:09,571] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 14:29:22,417] {scheduler_job.py:155} INFO - Started process (PID=88496) to work on /airflow/dags/download_data.py
[2022-02-18 14:29:22,428] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:29:22,431] {logging_mixin.py:112} INFO - [2022-02-18 14:29:22,430] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:29:22,888] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:29:22,939] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:29:22,945] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:29:22,949] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 14:29:35,704] {scheduler_job.py:155} INFO - Started process (PID=88522) to work on /airflow/dags/download_data.py
[2022-02-18 14:29:35,710] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:29:35,711] {logging_mixin.py:112} INFO - [2022-02-18 14:29:35,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:29:36,138] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:29:36,189] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:29:36,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:29:36,202] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 14:29:48,994] {scheduler_job.py:155} INFO - Started process (PID=88548) to work on /airflow/dags/download_data.py
[2022-02-18 14:29:49,000] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:29:49,002] {logging_mixin.py:112} INFO - [2022-02-18 14:29:49,002] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:29:49,442] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:29:49,485] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:29:49,495] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:29:49,500] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 14:30:02,249] {scheduler_job.py:155} INFO - Started process (PID=88574) to work on /airflow/dags/download_data.py
[2022-02-18 14:30:02,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:30:02,255] {logging_mixin.py:112} INFO - [2022-02-18 14:30:02,255] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:30:02,705] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:30:02,739] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:30:02,747] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:30:02,753] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 14:30:15,523] {scheduler_job.py:155} INFO - Started process (PID=88600) to work on /airflow/dags/download_data.py
[2022-02-18 14:30:15,530] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:30:15,532] {logging_mixin.py:112} INFO - [2022-02-18 14:30:15,532] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:30:15,962] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:30:16,003] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:30:16,010] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:30:16,013] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-18 14:30:28,840] {scheduler_job.py:155} INFO - Started process (PID=88626) to work on /airflow/dags/download_data.py
[2022-02-18 14:30:28,846] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:30:28,848] {logging_mixin.py:112} INFO - [2022-02-18 14:30:28,848] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:30:29,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:30:29,323] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:30:29,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:30:29,342] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 14:30:42,123] {scheduler_job.py:155} INFO - Started process (PID=88652) to work on /airflow/dags/download_data.py
[2022-02-18 14:30:42,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:30:42,129] {logging_mixin.py:112} INFO - [2022-02-18 14:30:42,128] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:30:42,578] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:30:42,631] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:30:42,640] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:30:42,646] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 14:30:55,442] {scheduler_job.py:155} INFO - Started process (PID=88678) to work on /airflow/dags/download_data.py
[2022-02-18 14:30:55,449] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:30:55,451] {logging_mixin.py:112} INFO - [2022-02-18 14:30:55,451] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:30:55,882] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:30:55,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:30:55,939] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:30:55,945] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 14:31:08,721] {scheduler_job.py:155} INFO - Started process (PID=88704) to work on /airflow/dags/download_data.py
[2022-02-18 14:31:08,737] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:31:08,742] {logging_mixin.py:112} INFO - [2022-02-18 14:31:08,742] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:31:09,201] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:31:09,251] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:31:09,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:31:09,267] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 14:31:22,017] {scheduler_job.py:155} INFO - Started process (PID=88730) to work on /airflow/dags/download_data.py
[2022-02-18 14:31:22,022] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:31:22,027] {logging_mixin.py:112} INFO - [2022-02-18 14:31:22,027] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:31:22,485] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:31:22,539] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:31:22,548] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:31:22,554] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 14:31:35,325] {scheduler_job.py:155} INFO - Started process (PID=88756) to work on /airflow/dags/download_data.py
[2022-02-18 14:31:35,331] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:31:35,334] {logging_mixin.py:112} INFO - [2022-02-18 14:31:35,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:31:35,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:31:35,816] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:31:35,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:31:35,828] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 14:31:48,575] {scheduler_job.py:155} INFO - Started process (PID=88782) to work on /airflow/dags/download_data.py
[2022-02-18 14:31:48,579] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:31:48,581] {logging_mixin.py:112} INFO - [2022-02-18 14:31:48,581] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:31:49,004] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:31:49,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:31:49,051] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:31:49,056] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.481 seconds
[2022-02-18 14:32:01,874] {scheduler_job.py:155} INFO - Started process (PID=88808) to work on /airflow/dags/download_data.py
[2022-02-18 14:32:01,878] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:32:01,880] {logging_mixin.py:112} INFO - [2022-02-18 14:32:01,880] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:32:02,317] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:32:02,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:32:02,368] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:32:02,373] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 14:32:15,121] {scheduler_job.py:155} INFO - Started process (PID=88834) to work on /airflow/dags/download_data.py
[2022-02-18 14:32:15,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:32:15,130] {logging_mixin.py:112} INFO - [2022-02-18 14:32:15,129] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:32:15,559] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:32:15,610] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:32:15,616] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:32:15,621] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 14:32:28,446] {scheduler_job.py:155} INFO - Started process (PID=88860) to work on /airflow/dags/download_data.py
[2022-02-18 14:32:28,450] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:32:28,453] {logging_mixin.py:112} INFO - [2022-02-18 14:32:28,452] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:32:28,902] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:32:28,955] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:32:28,965] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:32:28,972] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 14:32:41,725] {scheduler_job.py:155} INFO - Started process (PID=88886) to work on /airflow/dags/download_data.py
[2022-02-18 14:32:41,731] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:32:41,733] {logging_mixin.py:112} INFO - [2022-02-18 14:32:41,733] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:32:42,170] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:32:42,222] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:32:42,229] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:32:42,235] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 14:32:55,025] {scheduler_job.py:155} INFO - Started process (PID=88912) to work on /airflow/dags/download_data.py
[2022-02-18 14:32:55,029] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:32:55,030] {logging_mixin.py:112} INFO - [2022-02-18 14:32:55,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:32:55,469] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:32:55,521] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:32:55,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:32:55,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 14:33:08,260] {scheduler_job.py:155} INFO - Started process (PID=88938) to work on /airflow/dags/download_data.py
[2022-02-18 14:33:08,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:33:08,266] {logging_mixin.py:112} INFO - [2022-02-18 14:33:08,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:33:08,694] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:33:08,746] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:33:08,755] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:33:08,761] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 14:33:21,574] {scheduler_job.py:155} INFO - Started process (PID=88964) to work on /airflow/dags/download_data.py
[2022-02-18 14:33:21,584] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:33:21,586] {logging_mixin.py:112} INFO - [2022-02-18 14:33:21,586] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:33:22,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:33:22,095] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:33:22,105] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:33:22,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 14:33:34,853] {scheduler_job.py:155} INFO - Started process (PID=88990) to work on /airflow/dags/download_data.py
[2022-02-18 14:33:34,857] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:33:34,859] {logging_mixin.py:112} INFO - [2022-02-18 14:33:34,858] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:33:35,296] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:33:35,340] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:33:35,348] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:33:35,352] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 14:33:48,128] {scheduler_job.py:155} INFO - Started process (PID=89016) to work on /airflow/dags/download_data.py
[2022-02-18 14:33:48,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:33:48,134] {logging_mixin.py:112} INFO - [2022-02-18 14:33:48,134] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:33:48,575] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:33:48,618] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:33:48,624] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:33:48,628] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 14:34:01,445] {scheduler_job.py:155} INFO - Started process (PID=89042) to work on /airflow/dags/download_data.py
[2022-02-18 14:34:01,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:34:01,452] {logging_mixin.py:112} INFO - [2022-02-18 14:34:01,452] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:34:01,893] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:34:01,941] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:34:01,951] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:34:01,957] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 14:34:14,770] {scheduler_job.py:155} INFO - Started process (PID=89068) to work on /airflow/dags/download_data.py
[2022-02-18 14:34:14,779] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:34:14,781] {logging_mixin.py:112} INFO - [2022-02-18 14:34:14,781] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:34:15,205] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:34:15,255] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:34:15,262] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:34:15,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 14:34:28,090] {scheduler_job.py:155} INFO - Started process (PID=89094) to work on /airflow/dags/download_data.py
[2022-02-18 14:34:28,095] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:34:28,096] {logging_mixin.py:112} INFO - [2022-02-18 14:34:28,096] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:34:28,533] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:34:28,572] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:34:28,581] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:34:28,585] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 14:34:41,364] {scheduler_job.py:155} INFO - Started process (PID=89120) to work on /airflow/dags/download_data.py
[2022-02-18 14:34:41,368] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:34:41,370] {logging_mixin.py:112} INFO - [2022-02-18 14:34:41,369] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:34:41,815] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:34:41,870] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:34:41,878] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:34:41,883] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 14:34:54,670] {scheduler_job.py:155} INFO - Started process (PID=89146) to work on /airflow/dags/download_data.py
[2022-02-18 14:34:54,674] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:34:54,676] {logging_mixin.py:112} INFO - [2022-02-18 14:34:54,675] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:34:55,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:34:55,175] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:34:55,181] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:34:55,187] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 14:35:07,962] {scheduler_job.py:155} INFO - Started process (PID=89172) to work on /airflow/dags/download_data.py
[2022-02-18 14:35:07,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:35:07,969] {logging_mixin.py:112} INFO - [2022-02-18 14:35:07,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:35:08,368] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:35:08,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:35:08,416] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:35:08,419] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.457 seconds
[2022-02-18 14:35:21,223] {scheduler_job.py:155} INFO - Started process (PID=89198) to work on /airflow/dags/download_data.py
[2022-02-18 14:35:21,231] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:35:21,233] {logging_mixin.py:112} INFO - [2022-02-18 14:35:21,233] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:35:21,681] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:35:21,734] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:35:21,743] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:35:21,750] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 14:35:34,525] {scheduler_job.py:155} INFO - Started process (PID=89224) to work on /airflow/dags/download_data.py
[2022-02-18 14:35:34,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:35:34,535] {logging_mixin.py:112} INFO - [2022-02-18 14:35:34,535] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:35:35,077] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:35:35,129] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:35:35,136] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:35:35,143] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-18 14:35:47,813] {scheduler_job.py:155} INFO - Started process (PID=89250) to work on /airflow/dags/download_data.py
[2022-02-18 14:35:47,821] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:35:47,823] {logging_mixin.py:112} INFO - [2022-02-18 14:35:47,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:35:48,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:35:48,294] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:35:48,303] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:35:48,308] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 14:36:01,092] {scheduler_job.py:155} INFO - Started process (PID=89276) to work on /airflow/dags/download_data.py
[2022-02-18 14:36:01,096] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:36:01,098] {logging_mixin.py:112} INFO - [2022-02-18 14:36:01,097] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:36:01,551] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:36:01,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:36:01,611] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:36:01,616] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 14:36:14,366] {scheduler_job.py:155} INFO - Started process (PID=89302) to work on /airflow/dags/download_data.py
[2022-02-18 14:36:14,371] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:36:14,372] {logging_mixin.py:112} INFO - [2022-02-18 14:36:14,372] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:36:14,831] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:36:14,872] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:36:14,878] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:36:14,882] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 14:36:27,661] {scheduler_job.py:155} INFO - Started process (PID=89328) to work on /airflow/dags/download_data.py
[2022-02-18 14:36:27,666] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:36:27,667] {logging_mixin.py:112} INFO - [2022-02-18 14:36:27,667] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:36:28,103] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:36:28,154] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:36:28,164] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:36:28,170] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 14:36:40,913] {scheduler_job.py:155} INFO - Started process (PID=89354) to work on /airflow/dags/download_data.py
[2022-02-18 14:36:40,919] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:36:40,921] {logging_mixin.py:112} INFO - [2022-02-18 14:36:40,921] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:36:41,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:36:41,404] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:36:41,412] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:36:41,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 14:36:54,216] {scheduler_job.py:155} INFO - Started process (PID=89380) to work on /airflow/dags/download_data.py
[2022-02-18 14:36:54,222] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:36:54,224] {logging_mixin.py:112} INFO - [2022-02-18 14:36:54,224] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:36:54,675] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:36:54,725] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:36:54,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:36:54,741] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 14:37:07,523] {scheduler_job.py:155} INFO - Started process (PID=89406) to work on /airflow/dags/download_data.py
[2022-02-18 14:37:07,529] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:37:07,531] {logging_mixin.py:112} INFO - [2022-02-18 14:37:07,531] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:37:07,932] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:37:07,973] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:37:07,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:37:07,990] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.467 seconds
[2022-02-18 14:37:20,803] {scheduler_job.py:155} INFO - Started process (PID=89432) to work on /airflow/dags/download_data.py
[2022-02-18 14:37:20,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:37:20,811] {logging_mixin.py:112} INFO - [2022-02-18 14:37:20,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:37:21,267] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:37:21,324] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:37:21,331] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:37:21,335] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 14:37:34,101] {scheduler_job.py:155} INFO - Started process (PID=89458) to work on /airflow/dags/download_data.py
[2022-02-18 14:37:34,105] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:37:34,106] {logging_mixin.py:112} INFO - [2022-02-18 14:37:34,106] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:37:34,535] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:37:34,577] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:37:34,584] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:37:34,590] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-18 14:37:47,404] {scheduler_job.py:155} INFO - Started process (PID=89484) to work on /airflow/dags/download_data.py
[2022-02-18 14:37:47,408] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:37:47,409] {logging_mixin.py:112} INFO - [2022-02-18 14:37:47,409] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:37:47,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:37:47,901] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:37:47,908] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:37:47,914] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 14:38:00,694] {scheduler_job.py:155} INFO - Started process (PID=89510) to work on /airflow/dags/download_data.py
[2022-02-18 14:38:00,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:38:00,702] {logging_mixin.py:112} INFO - [2022-02-18 14:38:00,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:38:01,166] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:38:01,201] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:38:01,206] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:38:01,209] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 14:38:13,975] {scheduler_job.py:155} INFO - Started process (PID=89536) to work on /airflow/dags/download_data.py
[2022-02-18 14:38:13,979] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:38:13,981] {logging_mixin.py:112} INFO - [2022-02-18 14:38:13,981] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:38:14,416] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:38:14,465] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:38:14,475] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:38:14,482] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 14:38:27,244] {scheduler_job.py:155} INFO - Started process (PID=89562) to work on /airflow/dags/download_data.py
[2022-02-18 14:38:27,248] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:38:27,250] {logging_mixin.py:112} INFO - [2022-02-18 14:38:27,249] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:38:27,692] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:38:27,740] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:38:27,746] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:38:27,750] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 14:38:40,521] {scheduler_job.py:155} INFO - Started process (PID=89588) to work on /airflow/dags/download_data.py
[2022-02-18 14:38:40,525] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:38:40,527] {logging_mixin.py:112} INFO - [2022-02-18 14:38:40,527] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:38:40,953] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:38:41,007] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:38:41,013] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:38:41,017] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 14:38:53,848] {scheduler_job.py:155} INFO - Started process (PID=89614) to work on /airflow/dags/download_data.py
[2022-02-18 14:38:53,853] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:38:53,854] {logging_mixin.py:112} INFO - [2022-02-18 14:38:53,854] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:38:54,298] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:38:54,353] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:38:54,362] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:38:54,369] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 14:39:07,157] {scheduler_job.py:155} INFO - Started process (PID=89640) to work on /airflow/dags/download_data.py
[2022-02-18 14:39:07,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:39:07,165] {logging_mixin.py:112} INFO - [2022-02-18 14:39:07,164] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:39:07,611] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:39:07,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:39:07,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:39:07,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 14:39:20,452] {scheduler_job.py:155} INFO - Started process (PID=89666) to work on /airflow/dags/download_data.py
[2022-02-18 14:39:20,459] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:39:20,461] {logging_mixin.py:112} INFO - [2022-02-18 14:39:20,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:39:20,920] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:39:20,981] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:39:20,991] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:39:20,995] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 14:39:33,766] {scheduler_job.py:155} INFO - Started process (PID=89692) to work on /airflow/dags/download_data.py
[2022-02-18 14:39:33,772] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:39:33,774] {logging_mixin.py:112} INFO - [2022-02-18 14:39:33,773] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:39:34,203] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:39:34,256] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:39:34,266] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:39:34,272] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 14:39:47,068] {scheduler_job.py:155} INFO - Started process (PID=89718) to work on /airflow/dags/download_data.py
[2022-02-18 14:39:47,076] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:39:47,078] {logging_mixin.py:112} INFO - [2022-02-18 14:39:47,078] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:39:47,528] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:39:47,580] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:39:47,590] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:39:47,596] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 14:40:00,329] {scheduler_job.py:155} INFO - Started process (PID=89744) to work on /airflow/dags/download_data.py
[2022-02-18 14:40:00,333] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:40:00,335] {logging_mixin.py:112} INFO - [2022-02-18 14:40:00,335] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:40:00,782] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:40:00,833] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:40:00,840] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:40:00,845] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 14:40:13,885] {scheduler_job.py:155} INFO - Started process (PID=89770) to work on /airflow/dags/download_data.py
[2022-02-18 14:40:13,890] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:40:13,892] {logging_mixin.py:112} INFO - [2022-02-18 14:40:13,891] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:40:14,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:40:14,387] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:40:14,396] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:40:14,401] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 14:40:27,189] {scheduler_job.py:155} INFO - Started process (PID=89796) to work on /airflow/dags/download_data.py
[2022-02-18 14:40:27,195] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:40:27,197] {logging_mixin.py:112} INFO - [2022-02-18 14:40:27,197] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:40:27,624] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:40:27,666] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:40:27,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:40:27,678] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-18 14:40:40,471] {scheduler_job.py:155} INFO - Started process (PID=89822) to work on /airflow/dags/download_data.py
[2022-02-18 14:40:40,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:40:40,480] {logging_mixin.py:112} INFO - [2022-02-18 14:40:40,480] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:40:40,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:40:40,951] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:40:40,958] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:40:40,962] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 14:40:53,751] {scheduler_job.py:155} INFO - Started process (PID=89848) to work on /airflow/dags/download_data.py
[2022-02-18 14:40:53,755] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:40:53,756] {logging_mixin.py:112} INFO - [2022-02-18 14:40:53,756] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:40:54,189] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:40:54,231] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:40:54,237] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:40:54,241] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-18 14:41:07,014] {scheduler_job.py:155} INFO - Started process (PID=89874) to work on /airflow/dags/download_data.py
[2022-02-18 14:41:07,019] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:41:07,020] {logging_mixin.py:112} INFO - [2022-02-18 14:41:07,020] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:41:07,469] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:41:07,515] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:41:07,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:41:07,527] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 14:41:20,318] {scheduler_job.py:155} INFO - Started process (PID=89900) to work on /airflow/dags/download_data.py
[2022-02-18 14:41:20,329] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:41:20,331] {logging_mixin.py:112} INFO - [2022-02-18 14:41:20,331] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:41:20,773] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:41:20,817] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:41:20,826] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:41:20,834] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 14:41:33,641] {scheduler_job.py:155} INFO - Started process (PID=89926) to work on /airflow/dags/download_data.py
[2022-02-18 14:41:33,648] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:41:33,650] {logging_mixin.py:112} INFO - [2022-02-18 14:41:33,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:41:34,076] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:41:34,118] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:41:34,125] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:41:34,129] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-18 14:41:46,872] {scheduler_job.py:155} INFO - Started process (PID=89952) to work on /airflow/dags/download_data.py
[2022-02-18 14:41:46,876] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:41:46,877] {logging_mixin.py:112} INFO - [2022-02-18 14:41:46,877] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:41:47,315] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:41:47,365] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:41:47,375] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:41:47,381] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 14:42:00,187] {scheduler_job.py:155} INFO - Started process (PID=89978) to work on /airflow/dags/download_data.py
[2022-02-18 14:42:00,194] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:42:00,196] {logging_mixin.py:112} INFO - [2022-02-18 14:42:00,196] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:42:00,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:42:00,680] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:42:00,689] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:42:00,693] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 14:42:13,450] {scheduler_job.py:155} INFO - Started process (PID=90004) to work on /airflow/dags/download_data.py
[2022-02-18 14:42:13,455] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:42:13,457] {logging_mixin.py:112} INFO - [2022-02-18 14:42:13,456] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:42:13,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:42:13,950] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:42:13,960] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:42:13,965] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 14:42:26,754] {scheduler_job.py:155} INFO - Started process (PID=90030) to work on /airflow/dags/download_data.py
[2022-02-18 14:42:26,759] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:42:26,760] {logging_mixin.py:112} INFO - [2022-02-18 14:42:26,760] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:42:27,195] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:42:27,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:42:27,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:42:27,267] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 14:42:40,024] {scheduler_job.py:155} INFO - Started process (PID=90056) to work on /airflow/dags/download_data.py
[2022-02-18 14:42:40,028] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:42:40,029] {logging_mixin.py:112} INFO - [2022-02-18 14:42:40,029] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:42:40,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:42:40,522] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:42:40,529] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:42:40,534] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 14:42:53,351] {scheduler_job.py:155} INFO - Started process (PID=90082) to work on /airflow/dags/download_data.py
[2022-02-18 14:42:53,358] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:42:53,360] {logging_mixin.py:112} INFO - [2022-02-18 14:42:53,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:42:53,788] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:42:53,838] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:42:53,847] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:42:53,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 14:43:06,683] {scheduler_job.py:155} INFO - Started process (PID=90108) to work on /airflow/dags/download_data.py
[2022-02-18 14:43:06,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:43:06,692] {logging_mixin.py:112} INFO - [2022-02-18 14:43:06,692] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:43:07,146] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:43:07,204] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:43:07,216] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:43:07,221] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 14:43:19,926] {scheduler_job.py:155} INFO - Started process (PID=90134) to work on /airflow/dags/download_data.py
[2022-02-18 14:43:19,931] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:43:19,933] {logging_mixin.py:112} INFO - [2022-02-18 14:43:19,933] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:43:20,433] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:43:20,474] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:43:20,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:43:20,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 14:43:33,246] {scheduler_job.py:155} INFO - Started process (PID=90160) to work on /airflow/dags/download_data.py
[2022-02-18 14:43:33,251] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:43:33,252] {logging_mixin.py:112} INFO - [2022-02-18 14:43:33,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:43:33,684] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:43:33,733] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:43:33,741] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:43:33,747] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 14:43:46,505] {scheduler_job.py:155} INFO - Started process (PID=90186) to work on /airflow/dags/download_data.py
[2022-02-18 14:43:46,510] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:43:46,512] {logging_mixin.py:112} INFO - [2022-02-18 14:43:46,512] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:43:46,941] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:43:46,992] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:43:46,999] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:43:47,004] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 14:43:59,820] {scheduler_job.py:155} INFO - Started process (PID=90212) to work on /airflow/dags/download_data.py
[2022-02-18 14:43:59,824] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:43:59,827] {logging_mixin.py:112} INFO - [2022-02-18 14:43:59,827] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:44:00,280] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:44:00,330] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:44:00,338] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:44:00,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 14:44:13,140] {scheduler_job.py:155} INFO - Started process (PID=90238) to work on /airflow/dags/download_data.py
[2022-02-18 14:44:13,150] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:44:13,152] {logging_mixin.py:112} INFO - [2022-02-18 14:44:13,151] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:44:13,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:44:13,627] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:44:13,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:44:13,639] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 14:44:26,421] {scheduler_job.py:155} INFO - Started process (PID=90264) to work on /airflow/dags/download_data.py
[2022-02-18 14:44:26,426] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:44:26,428] {logging_mixin.py:112} INFO - [2022-02-18 14:44:26,428] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:44:26,870] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:44:26,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:44:26,934] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:44:26,940] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 14:44:39,672] {scheduler_job.py:155} INFO - Started process (PID=90290) to work on /airflow/dags/download_data.py
[2022-02-18 14:44:39,677] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:44:39,680] {logging_mixin.py:112} INFO - [2022-02-18 14:44:39,680] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:44:40,283] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:44:40,329] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:44:40,337] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:44:40,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.671 seconds
[2022-02-18 14:44:53,053] {scheduler_job.py:155} INFO - Started process (PID=90316) to work on /airflow/dags/download_data.py
[2022-02-18 14:44:53,061] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:44:53,063] {logging_mixin.py:112} INFO - [2022-02-18 14:44:53,063] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:44:53,492] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:44:53,541] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:44:53,552] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:44:53,558] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 14:45:06,320] {scheduler_job.py:155} INFO - Started process (PID=90342) to work on /airflow/dags/download_data.py
[2022-02-18 14:45:06,324] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:45:06,326] {logging_mixin.py:112} INFO - [2022-02-18 14:45:06,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:45:06,756] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:45:06,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:45:06,813] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:45:06,817] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 14:45:19,626] {scheduler_job.py:155} INFO - Started process (PID=90368) to work on /airflow/dags/download_data.py
[2022-02-18 14:45:19,630] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:45:19,632] {logging_mixin.py:112} INFO - [2022-02-18 14:45:19,632] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:45:20,094] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:45:20,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:45:20,167] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:45:20,174] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 14:45:32,928] {scheduler_job.py:155} INFO - Started process (PID=90394) to work on /airflow/dags/download_data.py
[2022-02-18 14:45:32,934] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:45:32,936] {logging_mixin.py:112} INFO - [2022-02-18 14:45:32,936] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:45:33,381] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:45:33,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:45:33,427] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:45:33,432] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 14:45:46,162] {scheduler_job.py:155} INFO - Started process (PID=90420) to work on /airflow/dags/download_data.py
[2022-02-18 14:45:46,166] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:45:46,167] {logging_mixin.py:112} INFO - [2022-02-18 14:45:46,167] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:45:46,609] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:45:46,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:45:46,663] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:45:46,667] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 14:45:59,448] {scheduler_job.py:155} INFO - Started process (PID=90446) to work on /airflow/dags/download_data.py
[2022-02-18 14:45:59,452] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:45:59,454] {logging_mixin.py:112} INFO - [2022-02-18 14:45:59,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:45:59,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:45:59,952] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:45:59,957] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:45:59,961] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 14:46:12,713] {scheduler_job.py:155} INFO - Started process (PID=90472) to work on /airflow/dags/download_data.py
[2022-02-18 14:46:12,717] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:46:12,719] {logging_mixin.py:112} INFO - [2022-02-18 14:46:12,719] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:46:13,172] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:46:13,214] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:46:13,220] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:46:13,224] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 14:46:26,026] {scheduler_job.py:155} INFO - Started process (PID=90498) to work on /airflow/dags/download_data.py
[2022-02-18 14:46:26,035] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:46:26,037] {logging_mixin.py:112} INFO - [2022-02-18 14:46:26,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:46:26,474] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:46:26,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:46:26,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:46:26,525] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 14:46:39,299] {scheduler_job.py:155} INFO - Started process (PID=90524) to work on /airflow/dags/download_data.py
[2022-02-18 14:46:39,308] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:46:39,310] {logging_mixin.py:112} INFO - [2022-02-18 14:46:39,310] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:46:39,739] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:46:39,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:46:39,797] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:46:39,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 14:46:52,591] {scheduler_job.py:155} INFO - Started process (PID=90550) to work on /airflow/dags/download_data.py
[2022-02-18 14:46:52,595] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:46:52,597] {logging_mixin.py:112} INFO - [2022-02-18 14:46:52,597] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:46:53,029] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:46:53,069] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:46:53,075] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:46:53,079] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-18 14:47:05,879] {scheduler_job.py:155} INFO - Started process (PID=90576) to work on /airflow/dags/download_data.py
[2022-02-18 14:47:05,884] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:47:05,885] {logging_mixin.py:112} INFO - [2022-02-18 14:47:05,885] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:47:06,340] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:47:06,385] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:47:06,392] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:47:06,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 14:47:19,116] {scheduler_job.py:155} INFO - Started process (PID=90602) to work on /airflow/dags/download_data.py
[2022-02-18 14:47:19,130] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:47:19,132] {logging_mixin.py:112} INFO - [2022-02-18 14:47:19,131] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:47:19,568] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:47:19,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:47:19,623] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:47:19,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 14:47:32,455] {scheduler_job.py:155} INFO - Started process (PID=90628) to work on /airflow/dags/download_data.py
[2022-02-18 14:47:32,460] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:47:32,461] {logging_mixin.py:112} INFO - [2022-02-18 14:47:32,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:47:32,898] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:47:32,943] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:47:32,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:47:32,953] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 14:47:45,729] {scheduler_job.py:155} INFO - Started process (PID=90654) to work on /airflow/dags/download_data.py
[2022-02-18 14:47:45,736] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:47:45,740] {logging_mixin.py:112} INFO - [2022-02-18 14:47:45,740] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:47:46,167] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:47:46,214] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:47:46,223] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:47:46,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 14:47:59,042] {scheduler_job.py:155} INFO - Started process (PID=90680) to work on /airflow/dags/download_data.py
[2022-02-18 14:47:59,053] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:47:59,056] {logging_mixin.py:112} INFO - [2022-02-18 14:47:59,056] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:47:59,486] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:47:59,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:47:59,543] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:47:59,549] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 14:48:12,278] {scheduler_job.py:155} INFO - Started process (PID=90706) to work on /airflow/dags/download_data.py
[2022-02-18 14:48:12,282] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:48:12,284] {logging_mixin.py:112} INFO - [2022-02-18 14:48:12,283] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:48:12,726] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:48:12,773] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:48:12,781] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:48:12,786] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 14:48:25,602] {scheduler_job.py:155} INFO - Started process (PID=90732) to work on /airflow/dags/download_data.py
[2022-02-18 14:48:25,607] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:48:25,609] {logging_mixin.py:112} INFO - [2022-02-18 14:48:25,608] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:48:26,051] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:48:26,099] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:48:26,107] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:48:26,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 14:48:38,868] {scheduler_job.py:155} INFO - Started process (PID=90758) to work on /airflow/dags/download_data.py
[2022-02-18 14:48:38,872] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:48:38,873] {logging_mixin.py:112} INFO - [2022-02-18 14:48:38,873] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:48:39,309] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:48:39,353] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:48:39,359] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:48:39,363] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.495 seconds
[2022-02-18 14:48:52,182] {scheduler_job.py:155} INFO - Started process (PID=90784) to work on /airflow/dags/download_data.py
[2022-02-18 14:48:52,188] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:48:52,189] {logging_mixin.py:112} INFO - [2022-02-18 14:48:52,189] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:48:52,628] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:48:52,679] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:48:52,688] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:48:52,695] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 14:49:05,502] {scheduler_job.py:155} INFO - Started process (PID=90810) to work on /airflow/dags/download_data.py
[2022-02-18 14:49:05,510] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:49:05,512] {logging_mixin.py:112} INFO - [2022-02-18 14:49:05,511] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:49:05,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:49:05,999] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:49:06,007] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:49:06,013] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 14:49:18,831] {scheduler_job.py:155} INFO - Started process (PID=90836) to work on /airflow/dags/download_data.py
[2022-02-18 14:49:18,840] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:49:18,850] {logging_mixin.py:112} INFO - [2022-02-18 14:49:18,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:49:19,290] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:49:19,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:49:19,369] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:49:19,373] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 14:49:32,093] {scheduler_job.py:155} INFO - Started process (PID=90862) to work on /airflow/dags/download_data.py
[2022-02-18 14:49:32,102] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:49:32,105] {logging_mixin.py:112} INFO - [2022-02-18 14:49:32,104] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:49:32,538] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:49:32,591] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:49:32,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:49:32,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 14:49:45,359] {scheduler_job.py:155} INFO - Started process (PID=90888) to work on /airflow/dags/download_data.py
[2022-02-18 14:49:45,364] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:49:45,366] {logging_mixin.py:112} INFO - [2022-02-18 14:49:45,366] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:49:45,799] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:49:45,842] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:49:45,847] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:49:45,850] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 14:49:58,656] {scheduler_job.py:155} INFO - Started process (PID=90914) to work on /airflow/dags/download_data.py
[2022-02-18 14:49:58,660] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:49:58,661] {logging_mixin.py:112} INFO - [2022-02-18 14:49:58,661] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:49:59,112] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:49:59,163] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:49:59,169] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:49:59,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 14:50:11,967] {scheduler_job.py:155} INFO - Started process (PID=90940) to work on /airflow/dags/download_data.py
[2022-02-18 14:50:11,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:50:11,979] {logging_mixin.py:112} INFO - [2022-02-18 14:50:11,978] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:50:12,426] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:50:12,478] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:50:12,488] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:50:12,493] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 14:50:25,271] {scheduler_job.py:155} INFO - Started process (PID=90966) to work on /airflow/dags/download_data.py
[2022-02-18 14:50:25,276] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:50:25,277] {logging_mixin.py:112} INFO - [2022-02-18 14:50:25,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:50:25,736] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:50:25,785] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:50:25,792] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:50:25,797] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 14:50:38,538] {scheduler_job.py:155} INFO - Started process (PID=90992) to work on /airflow/dags/download_data.py
[2022-02-18 14:50:38,543] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:50:38,544] {logging_mixin.py:112} INFO - [2022-02-18 14:50:38,544] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:50:38,989] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:50:39,039] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:50:39,048] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:50:39,054] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 14:50:51,854] {scheduler_job.py:155} INFO - Started process (PID=91018) to work on /airflow/dags/download_data.py
[2022-02-18 14:50:51,858] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:50:51,860] {logging_mixin.py:112} INFO - [2022-02-18 14:50:51,860] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:50:52,292] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:50:52,343] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:50:52,349] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:50:52,353] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 14:51:05,163] {scheduler_job.py:155} INFO - Started process (PID=91044) to work on /airflow/dags/download_data.py
[2022-02-18 14:51:05,167] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:51:05,169] {logging_mixin.py:112} INFO - [2022-02-18 14:51:05,169] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:51:05,612] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:51:05,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:51:05,670] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:51:05,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 14:51:18,421] {scheduler_job.py:155} INFO - Started process (PID=91070) to work on /airflow/dags/download_data.py
[2022-02-18 14:51:18,425] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:51:18,427] {logging_mixin.py:112} INFO - [2022-02-18 14:51:18,427] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:51:18,861] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:51:18,923] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:51:18,928] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:51:18,932] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 14:51:31,739] {scheduler_job.py:155} INFO - Started process (PID=91096) to work on /airflow/dags/download_data.py
[2022-02-18 14:51:31,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:51:31,746] {logging_mixin.py:112} INFO - [2022-02-18 14:51:31,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:51:32,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:51:32,229] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:51:32,236] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:51:32,241] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 14:51:45,020] {scheduler_job.py:155} INFO - Started process (PID=91122) to work on /airflow/dags/download_data.py
[2022-02-18 14:51:45,025] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:51:45,027] {logging_mixin.py:112} INFO - [2022-02-18 14:51:45,027] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:51:45,482] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:51:45,532] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:51:45,541] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:51:45,545] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 14:51:58,332] {scheduler_job.py:155} INFO - Started process (PID=91148) to work on /airflow/dags/download_data.py
[2022-02-18 14:51:58,339] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:51:58,341] {logging_mixin.py:112} INFO - [2022-02-18 14:51:58,341] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:51:58,800] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:51:58,841] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:51:58,847] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:51:58,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 14:52:11,606] {scheduler_job.py:155} INFO - Started process (PID=91174) to work on /airflow/dags/download_data.py
[2022-02-18 14:52:11,612] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:52:11,614] {logging_mixin.py:112} INFO - [2022-02-18 14:52:11,614] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:52:12,051] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:52:12,101] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:52:12,108] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:52:12,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 14:52:24,904] {scheduler_job.py:155} INFO - Started process (PID=91200) to work on /airflow/dags/download_data.py
[2022-02-18 14:52:24,908] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:52:24,910] {logging_mixin.py:112} INFO - [2022-02-18 14:52:24,910] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:52:25,331] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:52:25,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:52:25,389] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:52:25,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.489 seconds
[2022-02-18 14:52:38,224] {scheduler_job.py:155} INFO - Started process (PID=91226) to work on /airflow/dags/download_data.py
[2022-02-18 14:52:38,231] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:52:38,233] {logging_mixin.py:112} INFO - [2022-02-18 14:52:38,232] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:52:38,674] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:52:38,723] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:52:38,733] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:52:38,740] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 14:52:51,522] {scheduler_job.py:155} INFO - Started process (PID=91252) to work on /airflow/dags/download_data.py
[2022-02-18 14:52:51,531] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:52:51,533] {logging_mixin.py:112} INFO - [2022-02-18 14:52:51,532] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:52:51,984] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:52:52,036] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:52:52,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:52:52,051] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 14:53:04,812] {scheduler_job.py:155} INFO - Started process (PID=91278) to work on /airflow/dags/download_data.py
[2022-02-18 14:53:04,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:53:04,820] {logging_mixin.py:112} INFO - [2022-02-18 14:53:04,820] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:53:05,249] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:53:05,290] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:53:05,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:53:05,300] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-18 14:53:18,068] {scheduler_job.py:155} INFO - Started process (PID=91304) to work on /airflow/dags/download_data.py
[2022-02-18 14:53:18,071] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:53:18,073] {logging_mixin.py:112} INFO - [2022-02-18 14:53:18,073] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:53:18,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:53:18,549] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:53:18,555] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:53:18,559] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 14:53:31,461] {scheduler_job.py:155} INFO - Started process (PID=91330) to work on /airflow/dags/download_data.py
[2022-02-18 14:53:31,466] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:53:31,468] {logging_mixin.py:112} INFO - [2022-02-18 14:53:31,468] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:53:31,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:53:31,945] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:53:31,954] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:53:31,959] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 14:53:44,711] {scheduler_job.py:155} INFO - Started process (PID=91356) to work on /airflow/dags/download_data.py
[2022-02-18 14:53:44,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:53:44,718] {logging_mixin.py:112} INFO - [2022-02-18 14:53:44,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:53:45,164] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:53:45,213] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:53:45,222] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:53:45,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 14:53:57,986] {scheduler_job.py:155} INFO - Started process (PID=91382) to work on /airflow/dags/download_data.py
[2022-02-18 14:53:57,991] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:53:57,992] {logging_mixin.py:112} INFO - [2022-02-18 14:53:57,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:53:58,431] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:53:58,472] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:53:58,480] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:53:58,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 14:54:11,291] {scheduler_job.py:155} INFO - Started process (PID=91408) to work on /airflow/dags/download_data.py
[2022-02-18 14:54:11,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:54:11,298] {logging_mixin.py:112} INFO - [2022-02-18 14:54:11,297] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:54:11,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:54:11,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:54:11,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:54:11,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 14:54:25,301] {scheduler_job.py:155} INFO - Started process (PID=91434) to work on /airflow/dags/download_data.py
[2022-02-18 14:54:25,305] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 14:54:25,306] {logging_mixin.py:112} INFO - [2022-02-18 14:54:25,306] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 14:54:25,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 14:54:25,912] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 14:54:25,999] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 14:54:26,111] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.810 seconds
[2022-02-18 15:15:31,974] {scheduler_job.py:155} INFO - Started process (PID=91460) to work on /airflow/dags/download_data.py
[2022-02-18 15:15:31,979] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 15:15:31,980] {logging_mixin.py:112} INFO - [2022-02-18 15:15:31,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 15:15:32,421] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 15:15:32,472] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 15:15:32,479] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 15:15:32,483] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 15:15:45,265] {scheduler_job.py:155} INFO - Started process (PID=91486) to work on /airflow/dags/download_data.py
[2022-02-18 15:15:45,273] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 15:15:45,276] {logging_mixin.py:112} INFO - [2022-02-18 15:15:45,275] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 15:15:45,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 15:15:45,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 15:15:45,796] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 15:15:45,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 15:15:59,941] {scheduler_job.py:155} INFO - Started process (PID=91512) to work on /airflow/dags/download_data.py
[2022-02-18 15:15:59,947] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 15:15:59,950] {logging_mixin.py:112} INFO - [2022-02-18 15:15:59,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 15:16:00,418] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 15:16:00,467] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 15:16:00,473] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 15:16:00,479] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 15:16:19,016] {scheduler_job.py:155} INFO - Started process (PID=91538) to work on /airflow/dags/download_data.py
[2022-02-18 15:16:19,031] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 15:16:19,034] {logging_mixin.py:112} INFO - [2022-02-18 15:16:19,033] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 15:16:19,550] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 15:16:19,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 15:16:19,608] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 15:16:19,614] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 15:24:31,533] {scheduler_job.py:155} INFO - Started process (PID=91564) to work on /airflow/dags/download_data.py
[2022-02-18 15:24:31,537] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 15:24:31,540] {logging_mixin.py:112} INFO - [2022-02-18 15:24:31,539] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 15:24:32,057] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 15:24:32,103] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 15:24:32,111] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 15:24:32,116] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 15:24:44,848] {scheduler_job.py:155} INFO - Started process (PID=91590) to work on /airflow/dags/download_data.py
[2022-02-18 15:24:44,852] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 15:24:44,854] {logging_mixin.py:112} INFO - [2022-02-18 15:24:44,854] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 15:24:45,297] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 15:24:45,348] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 15:24:45,364] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 15:24:45,371] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 15:46:13,279] {scheduler_job.py:155} INFO - Started process (PID=91616) to work on /airflow/dags/download_data.py
[2022-02-18 15:46:13,285] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 15:46:13,286] {logging_mixin.py:112} INFO - [2022-02-18 15:46:13,286] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 15:46:13,734] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 15:46:13,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 15:46:13,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 15:46:13,793] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 15:46:31,621] {scheduler_job.py:155} INFO - Started process (PID=91642) to work on /airflow/dags/download_data.py
[2022-02-18 15:46:31,630] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 15:46:31,632] {logging_mixin.py:112} INFO - [2022-02-18 15:46:31,632] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 15:46:32,058] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 15:46:32,107] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 15:46:32,117] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 15:46:32,122] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 15:46:43,892] {scheduler_job.py:155} INFO - Started process (PID=91667) to work on /airflow/dags/download_data.py
[2022-02-18 15:46:43,898] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 15:46:43,899] {logging_mixin.py:112} INFO - [2022-02-18 15:46:43,899] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 15:46:44,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 15:46:44,391] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 15:46:44,397] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 15:46:44,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 15:46:57,910] {scheduler_job.py:155} INFO - Started process (PID=91693) to work on /airflow/dags/download_data.py
[2022-02-18 15:46:57,918] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 15:46:57,920] {logging_mixin.py:112} INFO - [2022-02-18 15:46:57,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 15:46:58,598] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 15:46:58,660] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 15:46:58,669] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 15:46:58,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.765 seconds
[2022-02-18 16:28:29,547] {scheduler_job.py:155} INFO - Started process (PID=91719) to work on /airflow/dags/download_data.py
[2022-02-18 16:28:29,553] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:28:29,556] {logging_mixin.py:112} INFO - [2022-02-18 16:28:29,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:28:30,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:28:30,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:28:30,433] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:28:30,441] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.894 seconds
[2022-02-18 16:28:42,835] {scheduler_job.py:155} INFO - Started process (PID=91745) to work on /airflow/dags/download_data.py
[2022-02-18 16:28:42,844] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:28:42,847] {logging_mixin.py:112} INFO - [2022-02-18 16:28:42,847] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:28:43,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:28:43,516] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:28:43,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:28:43,534] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.699 seconds
[2022-02-18 16:28:57,495] {scheduler_job.py:155} INFO - Started process (PID=91771) to work on /airflow/dags/download_data.py
[2022-02-18 16:28:57,507] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:28:57,509] {logging_mixin.py:112} INFO - [2022-02-18 16:28:57,509] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:28:58,128] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:28:58,176] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:28:58,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:28:58,196] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.701 seconds
[2022-02-18 16:29:10,782] {scheduler_job.py:155} INFO - Started process (PID=91797) to work on /airflow/dags/download_data.py
[2022-02-18 16:29:10,788] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:29:10,791] {logging_mixin.py:112} INFO - [2022-02-18 16:29:10,791] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:29:11,296] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:29:11,343] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:29:11,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:29:11,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-18 16:29:24,099] {scheduler_job.py:155} INFO - Started process (PID=91823) to work on /airflow/dags/download_data.py
[2022-02-18 16:29:24,105] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:29:24,107] {logging_mixin.py:112} INFO - [2022-02-18 16:29:24,107] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:29:25,014] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:29:25,063] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:29:25,080] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:29:25,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.992 seconds
[2022-02-18 16:29:38,392] {scheduler_job.py:155} INFO - Started process (PID=91849) to work on /airflow/dags/download_data.py
[2022-02-18 16:29:38,401] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:29:38,404] {logging_mixin.py:112} INFO - [2022-02-18 16:29:38,403] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:29:38,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:29:38,928] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:29:38,938] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:29:38,945] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 16:29:50,676] {scheduler_job.py:155} INFO - Started process (PID=91874) to work on /airflow/dags/download_data.py
[2022-02-18 16:29:50,682] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:29:50,685] {logging_mixin.py:112} INFO - [2022-02-18 16:29:50,684] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:29:51,185] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:29:51,236] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:29:51,246] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:29:51,252] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 16:30:03,931] {scheduler_job.py:155} INFO - Started process (PID=91900) to work on /airflow/dags/download_data.py
[2022-02-18 16:30:03,939] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:30:03,942] {logging_mixin.py:112} INFO - [2022-02-18 16:30:03,941] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:30:04,413] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:30:04,473] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:30:04,486] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:30:04,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 16:30:17,209] {scheduler_job.py:155} INFO - Started process (PID=91926) to work on /airflow/dags/download_data.py
[2022-02-18 16:30:17,217] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:30:17,219] {logging_mixin.py:112} INFO - [2022-02-18 16:30:17,219] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:30:17,690] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:30:17,740] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:30:17,750] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:30:17,757] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 16:30:30,445] {scheduler_job.py:155} INFO - Started process (PID=91952) to work on /airflow/dags/download_data.py
[2022-02-18 16:30:30,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:30:30,453] {logging_mixin.py:112} INFO - [2022-02-18 16:30:30,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:30:31,005] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:30:31,049] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:30:31,059] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:30:31,063] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-18 16:30:43,721] {scheduler_job.py:155} INFO - Started process (PID=91978) to work on /airflow/dags/download_data.py
[2022-02-18 16:30:43,725] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:30:43,727] {logging_mixin.py:112} INFO - [2022-02-18 16:30:43,727] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:30:44,194] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:30:44,244] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:30:44,251] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:30:44,257] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 16:30:56,970] {scheduler_job.py:155} INFO - Started process (PID=92004) to work on /airflow/dags/download_data.py
[2022-02-18 16:30:56,974] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:30:56,976] {logging_mixin.py:112} INFO - [2022-02-18 16:30:56,976] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:30:57,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:30:57,477] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:30:57,483] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:30:57,488] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 16:31:10,260] {scheduler_job.py:155} INFO - Started process (PID=92030) to work on /airflow/dags/download_data.py
[2022-02-18 16:31:10,265] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:31:10,267] {logging_mixin.py:112} INFO - [2022-02-18 16:31:10,267] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:31:10,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:31:10,841] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:31:10,850] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:31:10,855] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 16:31:23,550] {scheduler_job.py:155} INFO - Started process (PID=92056) to work on /airflow/dags/download_data.py
[2022-02-18 16:31:23,558] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:31:23,561] {logging_mixin.py:112} INFO - [2022-02-18 16:31:23,560] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:31:24,044] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:31:24,102] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:31:24,109] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:31:24,119] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-18 16:31:36,798] {scheduler_job.py:155} INFO - Started process (PID=92082) to work on /airflow/dags/download_data.py
[2022-02-18 16:31:36,806] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:31:36,810] {logging_mixin.py:112} INFO - [2022-02-18 16:31:36,810] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:31:37,323] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:31:37,373] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:31:37,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:31:37,388] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 16:31:50,077] {scheduler_job.py:155} INFO - Started process (PID=92108) to work on /airflow/dags/download_data.py
[2022-02-18 16:31:50,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:31:50,084] {logging_mixin.py:112} INFO - [2022-02-18 16:31:50,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:31:50,564] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:31:50,606] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:31:50,617] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:31:50,621] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 16:32:03,352] {scheduler_job.py:155} INFO - Started process (PID=92134) to work on /airflow/dags/download_data.py
[2022-02-18 16:32:03,367] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:32:03,369] {logging_mixin.py:112} INFO - [2022-02-18 16:32:03,369] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:32:03,861] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:32:03,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:32:03,933] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:32:03,941] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 16:32:16,640] {scheduler_job.py:155} INFO - Started process (PID=92160) to work on /airflow/dags/download_data.py
[2022-02-18 16:32:16,651] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:32:16,654] {logging_mixin.py:112} INFO - [2022-02-18 16:32:16,654] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:32:17,114] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:32:17,166] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:32:17,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:32:17,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 16:32:29,889] {scheduler_job.py:155} INFO - Started process (PID=92186) to work on /airflow/dags/download_data.py
[2022-02-18 16:32:29,896] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:32:29,898] {logging_mixin.py:112} INFO - [2022-02-18 16:32:29,898] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:32:30,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:32:30,487] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:32:30,497] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:32:30,504] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-18 16:32:43,471] {scheduler_job.py:155} INFO - Started process (PID=92212) to work on /airflow/dags/download_data.py
[2022-02-18 16:32:43,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:32:43,481] {logging_mixin.py:112} INFO - [2022-02-18 16:32:43,481] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:32:44,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:32:44,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:32:44,076] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:32:44,082] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 16:32:56,697] {scheduler_job.py:155} INFO - Started process (PID=92238) to work on /airflow/dags/download_data.py
[2022-02-18 16:32:56,703] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:32:56,704] {logging_mixin.py:112} INFO - [2022-02-18 16:32:56,704] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:32:57,216] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:32:57,252] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:32:57,259] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:32:57,264] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 16:33:09,980] {scheduler_job.py:155} INFO - Started process (PID=92264) to work on /airflow/dags/download_data.py
[2022-02-18 16:33:09,988] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:33:09,994] {logging_mixin.py:112} INFO - [2022-02-18 16:33:09,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:33:10,503] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:33:10,559] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:33:10,569] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:33:10,573] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 16:33:23,257] {scheduler_job.py:155} INFO - Started process (PID=92290) to work on /airflow/dags/download_data.py
[2022-02-18 16:33:23,262] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:33:23,263] {logging_mixin.py:112} INFO - [2022-02-18 16:33:23,263] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:33:23,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:33:23,838] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:33:23,845] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:33:23,852] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 16:33:36,560] {scheduler_job.py:155} INFO - Started process (PID=92316) to work on /airflow/dags/download_data.py
[2022-02-18 16:33:36,569] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:33:36,572] {logging_mixin.py:112} INFO - [2022-02-18 16:33:36,571] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:33:37,101] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:33:37,165] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:33:37,174] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:33:37,181] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-18 16:33:49,851] {scheduler_job.py:155} INFO - Started process (PID=92342) to work on /airflow/dags/download_data.py
[2022-02-18 16:33:49,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:33:49,863] {logging_mixin.py:112} INFO - [2022-02-18 16:33:49,863] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:33:50,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:33:50,439] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:33:50,451] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:33:50,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 16:34:03,109] {scheduler_job.py:155} INFO - Started process (PID=92368) to work on /airflow/dags/download_data.py
[2022-02-18 16:34:03,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:34:03,115] {logging_mixin.py:112} INFO - [2022-02-18 16:34:03,114] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:34:03,584] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:34:03,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:34:03,639] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:34:03,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 16:34:16,399] {scheduler_job.py:155} INFO - Started process (PID=92394) to work on /airflow/dags/download_data.py
[2022-02-18 16:34:16,403] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:34:16,405] {logging_mixin.py:112} INFO - [2022-02-18 16:34:16,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:34:16,897] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:34:16,940] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:34:16,952] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:34:16,957] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 16:34:29,676] {scheduler_job.py:155} INFO - Started process (PID=92420) to work on /airflow/dags/download_data.py
[2022-02-18 16:34:29,685] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:34:29,687] {logging_mixin.py:112} INFO - [2022-02-18 16:34:29,687] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:34:30,130] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:34:30,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:34:30,191] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:34:30,195] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 16:34:42,944] {scheduler_job.py:155} INFO - Started process (PID=92446) to work on /airflow/dags/download_data.py
[2022-02-18 16:34:42,949] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:34:42,951] {logging_mixin.py:112} INFO - [2022-02-18 16:34:42,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:34:43,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:34:43,455] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:34:43,465] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:34:43,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 16:34:56,197] {scheduler_job.py:155} INFO - Started process (PID=92472) to work on /airflow/dags/download_data.py
[2022-02-18 16:34:56,211] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:34:56,240] {logging_mixin.py:112} INFO - [2022-02-18 16:34:56,240] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:34:56,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:34:56,772] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:34:56,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:34:56,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 16:35:09,488] {scheduler_job.py:155} INFO - Started process (PID=92498) to work on /airflow/dags/download_data.py
[2022-02-18 16:35:09,494] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:35:09,495] {logging_mixin.py:112} INFO - [2022-02-18 16:35:09,495] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:35:09,968] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:35:10,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:35:10,049] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:35:10,059] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 16:35:22,787] {scheduler_job.py:155} INFO - Started process (PID=92524) to work on /airflow/dags/download_data.py
[2022-02-18 16:35:22,799] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:35:22,801] {logging_mixin.py:112} INFO - [2022-02-18 16:35:22,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:35:23,350] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:35:23,399] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:35:23,410] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:35:23,417] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-18 16:35:35,998] {scheduler_job.py:155} INFO - Started process (PID=92550) to work on /airflow/dags/download_data.py
[2022-02-18 16:35:36,004] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:35:36,005] {logging_mixin.py:112} INFO - [2022-02-18 16:35:36,005] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:35:36,470] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:35:36,530] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:35:36,541] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:35:36,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 16:35:49,336] {scheduler_job.py:155} INFO - Started process (PID=92576) to work on /airflow/dags/download_data.py
[2022-02-18 16:35:49,341] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:35:49,344] {logging_mixin.py:112} INFO - [2022-02-18 16:35:49,344] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:35:49,776] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:35:49,824] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:35:49,829] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:35:49,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 16:36:02,553] {scheduler_job.py:155} INFO - Started process (PID=92602) to work on /airflow/dags/download_data.py
[2022-02-18 16:36:02,558] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:36:02,560] {logging_mixin.py:112} INFO - [2022-02-18 16:36:02,560] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:36:03,121] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:36:03,199] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:36:03,212] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:36:03,218] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.665 seconds
[2022-02-18 16:36:15,822] {scheduler_job.py:155} INFO - Started process (PID=92628) to work on /airflow/dags/download_data.py
[2022-02-18 16:36:15,826] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:36:15,828] {logging_mixin.py:112} INFO - [2022-02-18 16:36:15,828] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:36:16,330] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:36:16,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:36:16,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:36:16,401] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 16:36:29,087] {scheduler_job.py:155} INFO - Started process (PID=92654) to work on /airflow/dags/download_data.py
[2022-02-18 16:36:29,092] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:36:29,093] {logging_mixin.py:112} INFO - [2022-02-18 16:36:29,093] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:36:29,616] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:36:29,668] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:36:29,673] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:36:29,680] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 16:36:42,399] {scheduler_job.py:155} INFO - Started process (PID=92680) to work on /airflow/dags/download_data.py
[2022-02-18 16:36:42,405] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:36:42,408] {logging_mixin.py:112} INFO - [2022-02-18 16:36:42,408] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:36:42,957] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:36:43,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:36:43,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:36:43,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.640 seconds
[2022-02-18 16:36:55,651] {scheduler_job.py:155} INFO - Started process (PID=92706) to work on /airflow/dags/download_data.py
[2022-02-18 16:36:55,661] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:36:55,664] {logging_mixin.py:112} INFO - [2022-02-18 16:36:55,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:36:56,128] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:36:56,186] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:36:56,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:36:56,218] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 16:37:08,940] {scheduler_job.py:155} INFO - Started process (PID=92732) to work on /airflow/dags/download_data.py
[2022-02-18 16:37:08,950] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:37:08,953] {logging_mixin.py:112} INFO - [2022-02-18 16:37:08,953] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:37:09,448] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:37:09,491] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:37:09,498] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:37:09,502] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 16:37:22,231] {scheduler_job.py:155} INFO - Started process (PID=92758) to work on /airflow/dags/download_data.py
[2022-02-18 16:37:22,240] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:37:22,245] {logging_mixin.py:112} INFO - [2022-02-18 16:37:22,244] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:37:22,694] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:37:22,745] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:37:22,753] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:37:22,758] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 16:37:35,495] {scheduler_job.py:155} INFO - Started process (PID=92784) to work on /airflow/dags/download_data.py
[2022-02-18 16:37:35,503] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:37:35,506] {logging_mixin.py:112} INFO - [2022-02-18 16:37:35,505] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:37:35,961] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:37:36,009] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:37:36,018] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:37:36,025] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 16:37:48,776] {scheduler_job.py:155} INFO - Started process (PID=92810) to work on /airflow/dags/download_data.py
[2022-02-18 16:37:48,780] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:37:48,782] {logging_mixin.py:112} INFO - [2022-02-18 16:37:48,782] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:37:49,225] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:37:49,272] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:37:49,278] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:37:49,283] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 16:38:02,044] {scheduler_job.py:155} INFO - Started process (PID=92836) to work on /airflow/dags/download_data.py
[2022-02-18 16:38:02,048] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:38:02,050] {logging_mixin.py:112} INFO - [2022-02-18 16:38:02,050] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:38:02,489] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:38:02,536] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:38:02,549] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:38:02,553] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 16:38:15,357] {scheduler_job.py:155} INFO - Started process (PID=92862) to work on /airflow/dags/download_data.py
[2022-02-18 16:38:15,363] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:38:15,364] {logging_mixin.py:112} INFO - [2022-02-18 16:38:15,364] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:38:15,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:38:15,972] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:38:15,988] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:38:15,996] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.639 seconds
[2022-02-18 16:38:28,639] {scheduler_job.py:155} INFO - Started process (PID=92888) to work on /airflow/dags/download_data.py
[2022-02-18 16:38:28,647] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:38:28,651] {logging_mixin.py:112} INFO - [2022-02-18 16:38:28,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:38:29,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:38:29,954] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:38:29,964] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:38:29,973] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.333 seconds
[2022-02-18 16:38:42,997] {scheduler_job.py:155} INFO - Started process (PID=92914) to work on /airflow/dags/download_data.py
[2022-02-18 16:38:43,020] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:38:43,022] {logging_mixin.py:112} INFO - [2022-02-18 16:38:43,022] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:38:43,495] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:38:43,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:38:43,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:38:43,567] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 16:38:55,230] {scheduler_job.py:155} INFO - Started process (PID=92939) to work on /airflow/dags/download_data.py
[2022-02-18 16:38:55,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:38:55,237] {logging_mixin.py:112} INFO - [2022-02-18 16:38:55,236] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:38:55,702] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:38:55,755] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:38:55,767] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:38:55,771] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 16:39:08,501] {scheduler_job.py:155} INFO - Started process (PID=92965) to work on /airflow/dags/download_data.py
[2022-02-18 16:39:08,507] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:39:08,509] {logging_mixin.py:112} INFO - [2022-02-18 16:39:08,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:39:09,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:39:09,054] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:39:09,068] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:39:09,075] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-18 16:39:21,816] {scheduler_job.py:155} INFO - Started process (PID=92991) to work on /airflow/dags/download_data.py
[2022-02-18 16:39:21,828] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:39:21,832] {logging_mixin.py:112} INFO - [2022-02-18 16:39:21,831] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:39:22,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:39:22,413] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:39:22,421] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:39:22,431] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-18 16:39:35,057] {scheduler_job.py:155} INFO - Started process (PID=93017) to work on /airflow/dags/download_data.py
[2022-02-18 16:39:35,064] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:39:35,066] {logging_mixin.py:112} INFO - [2022-02-18 16:39:35,065] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:39:35,598] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:39:35,644] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:39:35,655] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:39:35,661] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 16:39:48,427] {scheduler_job.py:155} INFO - Started process (PID=93043) to work on /airflow/dags/download_data.py
[2022-02-18 16:39:48,434] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:39:48,436] {logging_mixin.py:112} INFO - [2022-02-18 16:39:48,436] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:39:49,247] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:39:49,388] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:39:49,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:39:49,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.998 seconds
[2022-02-18 16:39:58,645] {scheduler_job.py:155} INFO - Started process (PID=93069) to work on /airflow/dags/download_data.py
[2022-02-18 16:39:58,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:39:58,657] {logging_mixin.py:112} INFO - [2022-02-18 16:39:58,656] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:39:59,137] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:39:59,193] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:39:59,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:39:59,206] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 16:40:11,934] {scheduler_job.py:155} INFO - Started process (PID=93095) to work on /airflow/dags/download_data.py
[2022-02-18 16:40:11,946] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:40:11,947] {logging_mixin.py:112} INFO - [2022-02-18 16:40:11,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:40:12,423] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:40:12,466] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:40:12,476] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:40:12,481] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 16:40:25,240] {scheduler_job.py:155} INFO - Started process (PID=93121) to work on /airflow/dags/download_data.py
[2022-02-18 16:40:25,248] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:40:25,250] {logging_mixin.py:112} INFO - [2022-02-18 16:40:25,250] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:40:25,841] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:40:25,886] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:40:25,896] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:40:25,902] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.663 seconds
[2022-02-18 16:40:38,544] {scheduler_job.py:155} INFO - Started process (PID=93147) to work on /airflow/dags/download_data.py
[2022-02-18 16:40:38,550] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:40:38,553] {logging_mixin.py:112} INFO - [2022-02-18 16:40:38,552] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:40:39,312] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:40:39,364] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:40:39,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:40:39,378] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.834 seconds
[2022-02-18 16:40:51,825] {scheduler_job.py:155} INFO - Started process (PID=93173) to work on /airflow/dags/download_data.py
[2022-02-18 16:40:51,829] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:40:51,830] {logging_mixin.py:112} INFO - [2022-02-18 16:40:51,830] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:40:52,286] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:40:52,334] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:40:52,342] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:40:52,347] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 16:41:05,090] {scheduler_job.py:155} INFO - Started process (PID=93199) to work on /airflow/dags/download_data.py
[2022-02-18 16:41:05,100] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:41:05,101] {logging_mixin.py:112} INFO - [2022-02-18 16:41:05,101] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:41:05,616] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:41:05,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:41:05,682] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:41:05,686] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 16:41:18,435] {scheduler_job.py:155} INFO - Started process (PID=93225) to work on /airflow/dags/download_data.py
[2022-02-18 16:41:18,439] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:41:18,441] {logging_mixin.py:112} INFO - [2022-02-18 16:41:18,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:41:18,975] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:41:19,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:41:19,041] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:41:19,046] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 16:41:31,668] {scheduler_job.py:155} INFO - Started process (PID=93251) to work on /airflow/dags/download_data.py
[2022-02-18 16:41:31,680] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:41:31,681] {logging_mixin.py:112} INFO - [2022-02-18 16:41:31,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:41:32,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:41:32,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:41:32,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:41:32,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.756 seconds
[2022-02-18 16:41:44,948] {scheduler_job.py:155} INFO - Started process (PID=93277) to work on /airflow/dags/download_data.py
[2022-02-18 16:41:44,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:41:44,957] {logging_mixin.py:112} INFO - [2022-02-18 16:41:44,957] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:41:45,454] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:41:45,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:41:45,519] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:41:45,525] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 16:41:58,243] {scheduler_job.py:155} INFO - Started process (PID=93303) to work on /airflow/dags/download_data.py
[2022-02-18 16:41:58,248] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:41:58,253] {logging_mixin.py:112} INFO - [2022-02-18 16:41:58,253] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:41:58,727] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:41:58,776] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:41:58,783] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:41:58,788] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 16:42:11,538] {scheduler_job.py:155} INFO - Started process (PID=93329) to work on /airflow/dags/download_data.py
[2022-02-18 16:42:11,547] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:42:11,554] {logging_mixin.py:112} INFO - [2022-02-18 16:42:11,551] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:42:12,020] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:42:12,074] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:42:12,086] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:42:12,092] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 16:42:24,805] {scheduler_job.py:155} INFO - Started process (PID=93355) to work on /airflow/dags/download_data.py
[2022-02-18 16:42:24,811] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:42:24,812] {logging_mixin.py:112} INFO - [2022-02-18 16:42:24,812] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:42:25,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:42:25,290] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:42:25,298] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:42:25,305] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 16:42:38,051] {scheduler_job.py:155} INFO - Started process (PID=93381) to work on /airflow/dags/download_data.py
[2022-02-18 16:42:38,061] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:42:38,065] {logging_mixin.py:112} INFO - [2022-02-18 16:42:38,063] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:42:38,585] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:42:38,636] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:42:38,646] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:42:38,654] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 16:42:51,326] {scheduler_job.py:155} INFO - Started process (PID=93407) to work on /airflow/dags/download_data.py
[2022-02-18 16:42:51,330] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:42:51,332] {logging_mixin.py:112} INFO - [2022-02-18 16:42:51,332] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:42:51,793] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:42:51,845] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:42:51,851] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:42:51,855] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 16:43:04,551] {scheduler_job.py:155} INFO - Started process (PID=93433) to work on /airflow/dags/download_data.py
[2022-02-18 16:43:04,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:43:04,558] {logging_mixin.py:112} INFO - [2022-02-18 16:43:04,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:43:05,017] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:43:05,068] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:43:05,079] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:43:05,083] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 16:43:17,832] {scheduler_job.py:155} INFO - Started process (PID=93459) to work on /airflow/dags/download_data.py
[2022-02-18 16:43:17,843] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:43:17,846] {logging_mixin.py:112} INFO - [2022-02-18 16:43:17,845] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:43:18,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:43:18,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:43:18,368] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:43:18,373] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 16:43:31,097] {scheduler_job.py:155} INFO - Started process (PID=93485) to work on /airflow/dags/download_data.py
[2022-02-18 16:43:31,105] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:43:31,108] {logging_mixin.py:112} INFO - [2022-02-18 16:43:31,107] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:43:31,557] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:43:31,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:43:31,606] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:43:31,610] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 16:43:44,364] {scheduler_job.py:155} INFO - Started process (PID=93511) to work on /airflow/dags/download_data.py
[2022-02-18 16:43:44,369] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:43:44,371] {logging_mixin.py:112} INFO - [2022-02-18 16:43:44,371] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:43:44,824] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:43:44,873] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:43:44,878] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:43:44,882] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 16:43:57,631] {scheduler_job.py:155} INFO - Started process (PID=93537) to work on /airflow/dags/download_data.py
[2022-02-18 16:43:57,635] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:43:57,637] {logging_mixin.py:112} INFO - [2022-02-18 16:43:57,637] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:43:58,085] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:43:58,130] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:43:58,139] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:43:58,144] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 16:44:10,913] {scheduler_job.py:155} INFO - Started process (PID=93563) to work on /airflow/dags/download_data.py
[2022-02-18 16:44:10,918] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:44:10,920] {logging_mixin.py:112} INFO - [2022-02-18 16:44:10,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:44:11,388] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:44:11,435] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:44:11,443] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:44:11,450] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 16:45:52,852] {scheduler_job.py:155} INFO - Started process (PID=93589) to work on /airflow/dags/download_data.py
[2022-02-18 16:45:52,857] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:45:52,859] {logging_mixin.py:112} INFO - [2022-02-18 16:45:52,859] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:45:53,470] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:45:53,515] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:45:53,523] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:45:53,529] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.676 seconds
[2022-02-18 16:46:06,156] {scheduler_job.py:155} INFO - Started process (PID=93615) to work on /airflow/dags/download_data.py
[2022-02-18 16:46:06,162] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:46:06,164] {logging_mixin.py:112} INFO - [2022-02-18 16:46:06,164] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:46:06,697] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:46:06,755] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:46:06,764] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:46:06,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-18 16:46:19,440] {scheduler_job.py:155} INFO - Started process (PID=93641) to work on /airflow/dags/download_data.py
[2022-02-18 16:46:19,452] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:46:19,454] {logging_mixin.py:112} INFO - [2022-02-18 16:46:19,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:46:19,970] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:46:20,047] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:46:20,066] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:46:20,074] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.634 seconds
[2022-02-18 16:46:32,686] {scheduler_job.py:155} INFO - Started process (PID=93667) to work on /airflow/dags/download_data.py
[2022-02-18 16:46:32,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:46:32,692] {logging_mixin.py:112} INFO - [2022-02-18 16:46:32,692] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:46:33,254] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:46:33,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:46:33,333] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:46:33,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-18 16:46:45,965] {scheduler_job.py:155} INFO - Started process (PID=93693) to work on /airflow/dags/download_data.py
[2022-02-18 16:46:45,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:46:45,971] {logging_mixin.py:112} INFO - [2022-02-18 16:46:45,971] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:46:46,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:46:46,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:46:46,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:46:46,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 16:46:59,215] {scheduler_job.py:155} INFO - Started process (PID=93719) to work on /airflow/dags/download_data.py
[2022-02-18 16:46:59,221] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:46:59,223] {logging_mixin.py:112} INFO - [2022-02-18 16:46:59,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:46:59,800] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:46:59,875] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:46:59,882] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:46:59,887] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-18 16:47:12,506] {scheduler_job.py:155} INFO - Started process (PID=93745) to work on /airflow/dags/download_data.py
[2022-02-18 16:47:12,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:47:12,519] {logging_mixin.py:112} INFO - [2022-02-18 16:47:12,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:47:13,064] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:47:13,107] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:47:13,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:47:13,123] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-18 16:47:25,756] {scheduler_job.py:155} INFO - Started process (PID=93771) to work on /airflow/dags/download_data.py
[2022-02-18 16:47:25,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:47:25,763] {logging_mixin.py:112} INFO - [2022-02-18 16:47:25,763] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:47:26,383] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:47:26,432] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:47:26,441] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:47:26,447] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.692 seconds
[2022-02-18 16:47:39,049] {scheduler_job.py:155} INFO - Started process (PID=93797) to work on /airflow/dags/download_data.py
[2022-02-18 16:47:39,057] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:47:39,060] {logging_mixin.py:112} INFO - [2022-02-18 16:47:39,059] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:47:39,557] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:47:39,606] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:47:39,617] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:47:39,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-18 16:47:52,312] {scheduler_job.py:155} INFO - Started process (PID=93823) to work on /airflow/dags/download_data.py
[2022-02-18 16:47:52,321] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:47:52,323] {logging_mixin.py:112} INFO - [2022-02-18 16:47:52,322] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:47:52,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:47:52,850] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:47:52,861] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:47:52,868] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 16:48:05,587] {scheduler_job.py:155} INFO - Started process (PID=93849) to work on /airflow/dags/download_data.py
[2022-02-18 16:48:05,591] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:48:05,595] {logging_mixin.py:112} INFO - [2022-02-18 16:48:05,594] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:48:07,472] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:48:07,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:48:07,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:48:07,672] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.085 seconds
[2022-02-18 16:48:19,939] {scheduler_job.py:155} INFO - Started process (PID=93875) to work on /airflow/dags/download_data.py
[2022-02-18 16:48:19,943] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:48:19,946] {logging_mixin.py:112} INFO - [2022-02-18 16:48:19,945] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:48:20,414] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:48:20,456] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:48:20,463] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:48:20,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 16:48:33,247] {scheduler_job.py:155} INFO - Started process (PID=93901) to work on /airflow/dags/download_data.py
[2022-02-18 16:48:33,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:48:33,255] {logging_mixin.py:112} INFO - [2022-02-18 16:48:33,255] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:48:33,694] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:48:33,745] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:48:33,751] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:48:33,757] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 16:48:46,512] {scheduler_job.py:155} INFO - Started process (PID=93927) to work on /airflow/dags/download_data.py
[2022-02-18 16:48:46,517] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:48:46,518] {logging_mixin.py:112} INFO - [2022-02-18 16:48:46,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:48:46,983] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:48:47,031] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:48:47,039] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:48:47,045] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 16:48:59,777] {scheduler_job.py:155} INFO - Started process (PID=93953) to work on /airflow/dags/download_data.py
[2022-02-18 16:48:59,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:48:59,786] {logging_mixin.py:112} INFO - [2022-02-18 16:48:59,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:49:00,280] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:49:00,326] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:49:00,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:49:00,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 16:49:13,060] {scheduler_job.py:155} INFO - Started process (PID=93979) to work on /airflow/dags/download_data.py
[2022-02-18 16:49:13,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:49:13,070] {logging_mixin.py:112} INFO - [2022-02-18 16:49:13,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:49:13,516] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:49:13,567] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:49:13,579] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:49:13,588] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 16:49:26,286] {scheduler_job.py:155} INFO - Started process (PID=94005) to work on /airflow/dags/download_data.py
[2022-02-18 16:49:26,291] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:49:26,293] {logging_mixin.py:112} INFO - [2022-02-18 16:49:26,292] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:49:26,757] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:49:26,810] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:49:26,818] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:49:26,821] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 16:49:39,601] {scheduler_job.py:155} INFO - Started process (PID=94031) to work on /airflow/dags/download_data.py
[2022-02-18 16:49:39,607] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:49:39,609] {logging_mixin.py:112} INFO - [2022-02-18 16:49:39,609] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:49:40,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:49:40,228] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:49:40,237] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:49:40,242] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 16:49:52,856] {scheduler_job.py:155} INFO - Started process (PID=94057) to work on /airflow/dags/download_data.py
[2022-02-18 16:49:52,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:49:52,864] {logging_mixin.py:112} INFO - [2022-02-18 16:49:52,863] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:49:53,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:49:53,412] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:49:53,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:49:53,425] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-18 16:50:06,142] {scheduler_job.py:155} INFO - Started process (PID=94083) to work on /airflow/dags/download_data.py
[2022-02-18 16:50:06,155] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:50:06,160] {logging_mixin.py:112} INFO - [2022-02-18 16:50:06,160] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:50:06,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:50:06,876] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:50:06,887] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:50:06,892] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.750 seconds
[2022-02-18 16:50:19,413] {scheduler_job.py:155} INFO - Started process (PID=94109) to work on /airflow/dags/download_data.py
[2022-02-18 16:50:19,418] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:50:19,422] {logging_mixin.py:112} INFO - [2022-02-18 16:50:19,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:50:19,872] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:50:19,915] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:50:19,922] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:50:19,927] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 16:50:32,701] {scheduler_job.py:155} INFO - Started process (PID=94135) to work on /airflow/dags/download_data.py
[2022-02-18 16:50:32,708] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:50:32,711] {logging_mixin.py:112} INFO - [2022-02-18 16:50:32,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:50:33,172] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:50:33,216] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:50:33,226] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:50:33,232] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 16:50:46,001] {scheduler_job.py:155} INFO - Started process (PID=94161) to work on /airflow/dags/download_data.py
[2022-02-18 16:50:46,006] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:50:46,009] {logging_mixin.py:112} INFO - [2022-02-18 16:50:46,008] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:50:46,456] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:50:46,505] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:50:46,511] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:50:46,514] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 16:50:59,231] {scheduler_job.py:155} INFO - Started process (PID=94187) to work on /airflow/dags/download_data.py
[2022-02-18 16:50:59,238] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:50:59,240] {logging_mixin.py:112} INFO - [2022-02-18 16:50:59,239] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:50:59,694] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:50:59,744] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:50:59,758] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:50:59,761] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 16:51:12,483] {scheduler_job.py:155} INFO - Started process (PID=94213) to work on /airflow/dags/download_data.py
[2022-02-18 16:51:12,498] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:51:12,500] {logging_mixin.py:112} INFO - [2022-02-18 16:51:12,499] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:51:13,020] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:51:13,071] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:51:13,081] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:51:13,085] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 16:51:25,727] {scheduler_job.py:155} INFO - Started process (PID=94239) to work on /airflow/dags/download_data.py
[2022-02-18 16:51:25,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:51:25,744] {logging_mixin.py:112} INFO - [2022-02-18 16:51:25,744] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:51:26,198] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:51:26,244] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:51:26,252] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:51:26,257] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 16:51:39,022] {scheduler_job.py:155} INFO - Started process (PID=94265) to work on /airflow/dags/download_data.py
[2022-02-18 16:51:39,043] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:51:39,048] {logging_mixin.py:112} INFO - [2022-02-18 16:51:39,047] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:51:39,562] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:51:39,622] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:51:39,635] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:51:39,640] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-18 16:51:52,334] {scheduler_job.py:155} INFO - Started process (PID=94291) to work on /airflow/dags/download_data.py
[2022-02-18 16:51:52,343] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:51:52,346] {logging_mixin.py:112} INFO - [2022-02-18 16:51:52,345] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:51:52,852] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:51:52,906] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:51:52,916] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:51:52,922] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 16:52:05,642] {scheduler_job.py:155} INFO - Started process (PID=94317) to work on /airflow/dags/download_data.py
[2022-02-18 16:52:05,652] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:52:05,654] {logging_mixin.py:112} INFO - [2022-02-18 16:52:05,654] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:52:07,045] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:52:07,117] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:52:07,131] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:52:07,136] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.495 seconds
[2022-02-18 16:52:19,939] {scheduler_job.py:155} INFO - Started process (PID=94343) to work on /airflow/dags/download_data.py
[2022-02-18 16:52:19,944] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:52:19,946] {logging_mixin.py:112} INFO - [2022-02-18 16:52:19,946] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:52:20,418] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:52:20,467] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:52:20,484] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:52:20,492] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 16:52:32,188] {scheduler_job.py:155} INFO - Started process (PID=94368) to work on /airflow/dags/download_data.py
[2022-02-18 16:52:32,195] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:52:32,197] {logging_mixin.py:112} INFO - [2022-02-18 16:52:32,196] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:52:32,697] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:52:32,746] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:52:32,753] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:52:32,759] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 16:52:45,501] {scheduler_job.py:155} INFO - Started process (PID=94394) to work on /airflow/dags/download_data.py
[2022-02-18 16:52:45,509] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:52:45,513] {logging_mixin.py:112} INFO - [2022-02-18 16:52:45,511] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:52:46,000] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:52:46,044] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:52:46,053] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:52:46,059] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 16:52:58,744] {scheduler_job.py:155} INFO - Started process (PID=94420) to work on /airflow/dags/download_data.py
[2022-02-18 16:52:58,749] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:52:58,751] {logging_mixin.py:112} INFO - [2022-02-18 16:52:58,750] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:52:59,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:52:59,256] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:52:59,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:52:59,268] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 16:53:12,054] {scheduler_job.py:155} INFO - Started process (PID=94446) to work on /airflow/dags/download_data.py
[2022-02-18 16:53:12,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:53:12,070] {logging_mixin.py:112} INFO - [2022-02-18 16:53:12,070] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:53:12,550] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:53:12,602] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:53:12,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:53:12,620] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 16:53:25,251] {scheduler_job.py:155} INFO - Started process (PID=94472) to work on /airflow/dags/download_data.py
[2022-02-18 16:53:25,256] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:53:25,258] {logging_mixin.py:112} INFO - [2022-02-18 16:53:25,258] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:53:25,727] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:53:25,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:53:25,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:53:25,793] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 16:53:38,571] {scheduler_job.py:155} INFO - Started process (PID=94498) to work on /airflow/dags/download_data.py
[2022-02-18 16:53:38,582] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:53:38,585] {logging_mixin.py:112} INFO - [2022-02-18 16:53:38,585] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:53:39,054] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:53:39,108] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:53:39,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:53:39,123] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 16:53:51,802] {scheduler_job.py:155} INFO - Started process (PID=94524) to work on /airflow/dags/download_data.py
[2022-02-18 16:53:51,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:53:51,821] {logging_mixin.py:112} INFO - [2022-02-18 16:53:51,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:53:52,289] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:53:52,345] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:53:52,353] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:53:52,361] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 16:54:05,107] {scheduler_job.py:155} INFO - Started process (PID=94550) to work on /airflow/dags/download_data.py
[2022-02-18 16:54:05,111] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:54:05,114] {logging_mixin.py:112} INFO - [2022-02-18 16:54:05,112] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:54:05,611] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:54:05,666] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:54:05,677] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:54:05,683] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 16:54:18,366] {scheduler_job.py:155} INFO - Started process (PID=94576) to work on /airflow/dags/download_data.py
[2022-02-18 16:54:18,370] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:54:18,372] {logging_mixin.py:112} INFO - [2022-02-18 16:54:18,372] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:54:18,833] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:54:18,881] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:54:18,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:54:18,901] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 16:54:31,618] {scheduler_job.py:155} INFO - Started process (PID=94602) to work on /airflow/dags/download_data.py
[2022-02-18 16:54:31,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:54:31,629] {logging_mixin.py:112} INFO - [2022-02-18 16:54:31,628] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:54:32,090] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:54:32,138] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:54:32,144] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:54:32,148] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 16:54:44,979] {scheduler_job.py:155} INFO - Started process (PID=94628) to work on /airflow/dags/download_data.py
[2022-02-18 16:54:44,986] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:54:44,988] {logging_mixin.py:112} INFO - [2022-02-18 16:54:44,988] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:54:45,475] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:54:45,527] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:54:45,537] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:54:45,543] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 16:54:58,217] {scheduler_job.py:155} INFO - Started process (PID=94654) to work on /airflow/dags/download_data.py
[2022-02-18 16:54:58,225] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:54:58,228] {logging_mixin.py:112} INFO - [2022-02-18 16:54:58,227] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:54:58,698] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:54:58,756] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:54:58,763] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:54:58,769] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 16:55:11,505] {scheduler_job.py:155} INFO - Started process (PID=94680) to work on /airflow/dags/download_data.py
[2022-02-18 16:55:11,510] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:55:11,511] {logging_mixin.py:112} INFO - [2022-02-18 16:55:11,511] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:55:11,992] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:55:12,051] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:55:12,061] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:55:12,065] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 16:55:24,752] {scheduler_job.py:155} INFO - Started process (PID=94706) to work on /airflow/dags/download_data.py
[2022-02-18 16:55:24,757] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:55:24,758] {logging_mixin.py:112} INFO - [2022-02-18 16:55:24,758] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:55:25,222] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:55:25,272] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:55:25,280] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:55:25,286] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 16:55:38,065] {scheduler_job.py:155} INFO - Started process (PID=94732) to work on /airflow/dags/download_data.py
[2022-02-18 16:55:38,070] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:55:38,072] {logging_mixin.py:112} INFO - [2022-02-18 16:55:38,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:55:38,562] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:55:38,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:55:38,642] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:55:38,649] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 16:55:51,350] {scheduler_job.py:155} INFO - Started process (PID=94758) to work on /airflow/dags/download_data.py
[2022-02-18 16:55:51,355] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:55:51,357] {logging_mixin.py:112} INFO - [2022-02-18 16:55:51,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:55:51,772] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:55:51,820] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:55:51,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:55:51,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.480 seconds
[2022-02-18 16:56:04,616] {scheduler_job.py:155} INFO - Started process (PID=94784) to work on /airflow/dags/download_data.py
[2022-02-18 16:56:04,624] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:56:04,627] {logging_mixin.py:112} INFO - [2022-02-18 16:56:04,626] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:56:05,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:56:05,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:56:05,228] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:56:05,232] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-18 16:56:17,939] {scheduler_job.py:155} INFO - Started process (PID=94810) to work on /airflow/dags/download_data.py
[2022-02-18 16:56:17,949] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:56:17,954] {logging_mixin.py:112} INFO - [2022-02-18 16:56:17,954] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:56:18,553] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:56:18,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:56:18,609] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:56:18,614] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.675 seconds
[2022-02-18 16:56:31,156] {scheduler_job.py:155} INFO - Started process (PID=94836) to work on /airflow/dags/download_data.py
[2022-02-18 16:56:31,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:56:31,165] {logging_mixin.py:112} INFO - [2022-02-18 16:56:31,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:56:31,656] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:56:31,721] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:56:31,733] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:56:31,738] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 16:56:44,455] {scheduler_job.py:155} INFO - Started process (PID=94862) to work on /airflow/dags/download_data.py
[2022-02-18 16:56:44,461] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:56:44,464] {logging_mixin.py:112} INFO - [2022-02-18 16:56:44,463] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:56:44,952] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:56:44,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:56:45,010] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:56:45,021] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 16:56:57,728] {scheduler_job.py:155} INFO - Started process (PID=94888) to work on /airflow/dags/download_data.py
[2022-02-18 16:56:57,733] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:56:57,735] {logging_mixin.py:112} INFO - [2022-02-18 16:56:57,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:56:58,263] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:56:58,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:56:58,328] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:56:58,333] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 16:57:11,009] {scheduler_job.py:155} INFO - Started process (PID=94914) to work on /airflow/dags/download_data.py
[2022-02-18 16:57:11,020] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:57:11,027] {logging_mixin.py:112} INFO - [2022-02-18 16:57:11,027] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:57:11,579] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:57:11,638] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:57:11,649] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:57:11,656] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-18 16:57:24,218] {scheduler_job.py:155} INFO - Started process (PID=94940) to work on /airflow/dags/download_data.py
[2022-02-18 16:57:24,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:57:24,229] {logging_mixin.py:112} INFO - [2022-02-18 16:57:24,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:57:24,710] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:57:24,766] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:57:24,775] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:57:24,780] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 16:57:37,522] {scheduler_job.py:155} INFO - Started process (PID=94966) to work on /airflow/dags/download_data.py
[2022-02-18 16:57:37,536] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:57:37,549] {logging_mixin.py:112} INFO - [2022-02-18 16:57:37,549] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:57:37,994] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:57:38,048] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:57:38,056] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:57:38,061] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 16:57:50,817] {scheduler_job.py:155} INFO - Started process (PID=94992) to work on /airflow/dags/download_data.py
[2022-02-18 16:57:50,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:57:50,825] {logging_mixin.py:112} INFO - [2022-02-18 16:57:50,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:57:51,297] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:57:51,350] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:57:51,361] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:57:51,372] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 16:58:04,074] {scheduler_job.py:155} INFO - Started process (PID=95018) to work on /airflow/dags/download_data.py
[2022-02-18 16:58:04,085] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:58:04,088] {logging_mixin.py:112} INFO - [2022-02-18 16:58:04,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:58:04,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:58:04,630] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:58:04,642] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:58:04,648] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-18 16:58:17,378] {scheduler_job.py:155} INFO - Started process (PID=95044) to work on /airflow/dags/download_data.py
[2022-02-18 16:58:17,387] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:58:17,389] {logging_mixin.py:112} INFO - [2022-02-18 16:58:17,389] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:58:17,913] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:58:17,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:58:17,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:58:17,986] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 16:58:30,694] {scheduler_job.py:155} INFO - Started process (PID=95070) to work on /airflow/dags/download_data.py
[2022-02-18 16:58:30,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:58:30,717] {logging_mixin.py:112} INFO - [2022-02-18 16:58:30,717] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:58:31,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:58:31,302] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:58:31,308] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:58:31,315] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-18 16:58:43,974] {scheduler_job.py:155} INFO - Started process (PID=95096) to work on /airflow/dags/download_data.py
[2022-02-18 16:58:43,981] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:58:43,985] {logging_mixin.py:112} INFO - [2022-02-18 16:58:43,985] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:58:44,536] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:58:44,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:58:44,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:58:44,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-18 16:58:57,210] {scheduler_job.py:155} INFO - Started process (PID=95122) to work on /airflow/dags/download_data.py
[2022-02-18 16:58:57,215] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:58:57,217] {logging_mixin.py:112} INFO - [2022-02-18 16:58:57,217] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:58:57,733] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:58:57,782] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:58:57,799] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:58:57,806] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 16:59:10,529] {scheduler_job.py:155} INFO - Started process (PID=95148) to work on /airflow/dags/download_data.py
[2022-02-18 16:59:10,534] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:59:10,535] {logging_mixin.py:112} INFO - [2022-02-18 16:59:10,535] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:59:10,988] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:59:11,039] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:59:11,049] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:59:11,056] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 16:59:23,777] {scheduler_job.py:155} INFO - Started process (PID=95174) to work on /airflow/dags/download_data.py
[2022-02-18 16:59:23,781] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:59:23,782] {logging_mixin.py:112} INFO - [2022-02-18 16:59:23,782] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:59:24,253] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:59:24,306] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:59:24,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:59:24,323] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 16:59:37,061] {scheduler_job.py:155} INFO - Started process (PID=95200) to work on /airflow/dags/download_data.py
[2022-02-18 16:59:37,075] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:59:37,079] {logging_mixin.py:112} INFO - [2022-02-18 16:59:37,078] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:59:37,535] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:59:37,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:59:37,588] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:59:37,593] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 16:59:50,368] {scheduler_job.py:155} INFO - Started process (PID=95226) to work on /airflow/dags/download_data.py
[2022-02-18 16:59:50,380] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 16:59:50,385] {logging_mixin.py:112} INFO - [2022-02-18 16:59:50,385] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 16:59:50,843] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 16:59:50,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 16:59:50,907] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 16:59:50,912] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 17:00:03,625] {scheduler_job.py:155} INFO - Started process (PID=95252) to work on /airflow/dags/download_data.py
[2022-02-18 17:00:03,636] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:00:03,642] {logging_mixin.py:112} INFO - [2022-02-18 17:00:03,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:00:04,881] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:00:04,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:00:04,987] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:00:04,992] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.367 seconds
[2022-02-18 17:00:17,900] {scheduler_job.py:155} INFO - Started process (PID=95278) to work on /airflow/dags/download_data.py
[2022-02-18 17:00:17,905] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:00:17,907] {logging_mixin.py:112} INFO - [2022-02-18 17:00:17,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:00:18,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:00:18,426] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:00:18,434] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:00:18,440] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 17:00:30,156] {scheduler_job.py:155} INFO - Started process (PID=95303) to work on /airflow/dags/download_data.py
[2022-02-18 17:00:30,161] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:00:30,167] {logging_mixin.py:112} INFO - [2022-02-18 17:00:30,163] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:00:30,611] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:00:30,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:00:30,669] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:00:30,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 17:00:43,441] {scheduler_job.py:155} INFO - Started process (PID=95329) to work on /airflow/dags/download_data.py
[2022-02-18 17:00:43,450] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:00:43,453] {logging_mixin.py:112} INFO - [2022-02-18 17:00:43,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:00:43,892] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:00:43,945] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:00:43,955] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:00:43,959] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 17:00:56,696] {scheduler_job.py:155} INFO - Started process (PID=95355) to work on /airflow/dags/download_data.py
[2022-02-18 17:00:56,701] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:00:56,703] {logging_mixin.py:112} INFO - [2022-02-18 17:00:56,703] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:00:57,200] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:00:57,254] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:00:57,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:00:57,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 17:01:09,980] {scheduler_job.py:155} INFO - Started process (PID=95381) to work on /airflow/dags/download_data.py
[2022-02-18 17:01:09,988] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:01:09,990] {logging_mixin.py:112} INFO - [2022-02-18 17:01:09,989] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:01:10,513] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:01:10,566] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:01:10,577] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:01:10,581] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-18 17:01:23,272] {scheduler_job.py:155} INFO - Started process (PID=95407) to work on /airflow/dags/download_data.py
[2022-02-18 17:01:23,283] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:01:23,300] {logging_mixin.py:112} INFO - [2022-02-18 17:01:23,299] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:01:23,957] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:01:24,014] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:01:24,024] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:01:24,029] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.757 seconds
[2022-02-18 17:01:36,558] {scheduler_job.py:155} INFO - Started process (PID=95433) to work on /airflow/dags/download_data.py
[2022-02-18 17:01:36,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:01:36,572] {logging_mixin.py:112} INFO - [2022-02-18 17:01:36,571] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:01:37,121] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:01:37,170] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:01:37,177] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:01:37,184] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-18 17:01:49,846] {scheduler_job.py:155} INFO - Started process (PID=95459) to work on /airflow/dags/download_data.py
[2022-02-18 17:01:49,851] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:01:49,853] {logging_mixin.py:112} INFO - [2022-02-18 17:01:49,853] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:01:50,342] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:01:50,387] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:01:50,394] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:01:50,398] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 17:02:03,120] {scheduler_job.py:155} INFO - Started process (PID=95485) to work on /airflow/dags/download_data.py
[2022-02-18 17:02:03,125] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:02:03,126] {logging_mixin.py:112} INFO - [2022-02-18 17:02:03,126] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:02:03,582] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:02:03,626] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:02:03,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:02:03,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 17:02:16,446] {scheduler_job.py:155} INFO - Started process (PID=95511) to work on /airflow/dags/download_data.py
[2022-02-18 17:02:16,453] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:02:16,456] {logging_mixin.py:112} INFO - [2022-02-18 17:02:16,455] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:02:16,899] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:02:16,951] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:02:16,962] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:02:16,968] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 17:02:29,682] {scheduler_job.py:155} INFO - Started process (PID=95537) to work on /airflow/dags/download_data.py
[2022-02-18 17:02:29,686] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:02:29,688] {logging_mixin.py:112} INFO - [2022-02-18 17:02:29,688] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:02:30,131] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:02:30,172] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:02:30,179] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:02:30,182] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 17:02:42,960] {scheduler_job.py:155} INFO - Started process (PID=95563) to work on /airflow/dags/download_data.py
[2022-02-18 17:02:42,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:02:42,972] {logging_mixin.py:112} INFO - [2022-02-18 17:02:42,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:02:43,420] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:02:43,472] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:02:43,484] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:02:43,488] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 17:02:56,231] {scheduler_job.py:155} INFO - Started process (PID=95589) to work on /airflow/dags/download_data.py
[2022-02-18 17:02:56,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:02:56,237] {logging_mixin.py:112} INFO - [2022-02-18 17:02:56,236] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:02:56,689] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:02:56,743] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:02:56,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:02:56,753] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 17:03:09,530] {scheduler_job.py:155} INFO - Started process (PID=95615) to work on /airflow/dags/download_data.py
[2022-02-18 17:03:09,535] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:03:09,538] {logging_mixin.py:112} INFO - [2022-02-18 17:03:09,537] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:03:09,996] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:03:10,046] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:03:10,056] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:03:10,061] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 17:03:22,800] {scheduler_job.py:155} INFO - Started process (PID=95641) to work on /airflow/dags/download_data.py
[2022-02-18 17:03:22,807] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:03:22,809] {logging_mixin.py:112} INFO - [2022-02-18 17:03:22,809] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:03:23,246] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:03:23,293] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:03:23,303] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:03:23,308] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 17:03:36,090] {scheduler_job.py:155} INFO - Started process (PID=95667) to work on /airflow/dags/download_data.py
[2022-02-18 17:03:36,098] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:03:36,102] {logging_mixin.py:112} INFO - [2022-02-18 17:03:36,101] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:03:36,570] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:03:36,630] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:03:36,642] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:03:36,649] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 17:03:49,366] {scheduler_job.py:155} INFO - Started process (PID=95693) to work on /airflow/dags/download_data.py
[2022-02-18 17:03:49,370] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:03:49,372] {logging_mixin.py:112} INFO - [2022-02-18 17:03:49,371] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:03:49,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:03:49,872] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:03:49,884] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:03:49,888] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 17:04:02,614] {scheduler_job.py:155} INFO - Started process (PID=95719) to work on /airflow/dags/download_data.py
[2022-02-18 17:04:02,624] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:04:02,632] {logging_mixin.py:112} INFO - [2022-02-18 17:04:02,630] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:04:03,239] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:04:03,293] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:04:03,301] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:04:03,306] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.693 seconds
[2022-02-18 17:04:15,909] {scheduler_job.py:155} INFO - Started process (PID=95745) to work on /airflow/dags/download_data.py
[2022-02-18 17:04:15,924] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:04:15,927] {logging_mixin.py:112} INFO - [2022-02-18 17:04:15,927] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:04:16,515] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:04:16,575] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:04:16,589] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:04:16,598] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.690 seconds
[2022-02-18 17:04:29,187] {scheduler_job.py:155} INFO - Started process (PID=95771) to work on /airflow/dags/download_data.py
[2022-02-18 17:04:29,197] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:04:29,199] {logging_mixin.py:112} INFO - [2022-02-18 17:04:29,199] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:04:29,705] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:04:29,763] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:04:29,769] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:04:29,774] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 17:04:42,444] {scheduler_job.py:155} INFO - Started process (PID=95797) to work on /airflow/dags/download_data.py
[2022-02-18 17:04:42,449] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:04:42,451] {logging_mixin.py:112} INFO - [2022-02-18 17:04:42,450] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:04:42,964] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:04:43,022] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:04:43,032] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:04:43,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 17:04:55,736] {scheduler_job.py:155} INFO - Started process (PID=95823) to work on /airflow/dags/download_data.py
[2022-02-18 17:04:55,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:04:55,745] {logging_mixin.py:112} INFO - [2022-02-18 17:04:55,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:04:56,214] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:04:56,272] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:04:56,280] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:04:56,286] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 17:05:09,042] {scheduler_job.py:155} INFO - Started process (PID=95849) to work on /airflow/dags/download_data.py
[2022-02-18 17:05:09,048] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:05:09,050] {logging_mixin.py:112} INFO - [2022-02-18 17:05:09,050] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:05:09,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:05:09,589] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:05:09,595] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:05:09,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 17:05:22,317] {scheduler_job.py:155} INFO - Started process (PID=95875) to work on /airflow/dags/download_data.py
[2022-02-18 17:05:22,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:05:22,328] {logging_mixin.py:112} INFO - [2022-02-18 17:05:22,328] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:05:22,818] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:05:22,861] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:05:22,867] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:05:22,871] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 17:05:35,603] {scheduler_job.py:155} INFO - Started process (PID=95901) to work on /airflow/dags/download_data.py
[2022-02-18 17:05:35,610] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:05:35,613] {logging_mixin.py:112} INFO - [2022-02-18 17:05:35,613] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:05:36,118] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:05:36,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:05:36,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:05:36,202] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 17:05:48,893] {scheduler_job.py:155} INFO - Started process (PID=95927) to work on /airflow/dags/download_data.py
[2022-02-18 17:05:48,900] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:05:48,901] {logging_mixin.py:112} INFO - [2022-02-18 17:05:48,901] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:05:49,366] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:05:49,420] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:05:49,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:05:49,433] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 17:06:02,121] {scheduler_job.py:155} INFO - Started process (PID=95953) to work on /airflow/dags/download_data.py
[2022-02-18 17:06:02,126] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:06:02,128] {logging_mixin.py:112} INFO - [2022-02-18 17:06:02,127] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:06:02,599] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:06:02,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:06:02,667] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:06:02,673] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 17:06:15,413] {scheduler_job.py:155} INFO - Started process (PID=95979) to work on /airflow/dags/download_data.py
[2022-02-18 17:06:15,418] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:06:15,419] {logging_mixin.py:112} INFO - [2022-02-18 17:06:15,419] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:06:15,911] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:06:15,963] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:06:15,971] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:06:15,977] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 17:06:28,695] {scheduler_job.py:155} INFO - Started process (PID=96005) to work on /airflow/dags/download_data.py
[2022-02-18 17:06:28,699] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:06:28,701] {logging_mixin.py:112} INFO - [2022-02-18 17:06:28,701] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:06:29,170] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:06:29,222] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:06:29,229] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:06:29,233] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 17:06:41,985] {scheduler_job.py:155} INFO - Started process (PID=96031) to work on /airflow/dags/download_data.py
[2022-02-18 17:06:41,990] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:06:41,992] {logging_mixin.py:112} INFO - [2022-02-18 17:06:41,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:06:42,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:06:42,495] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:06:42,503] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:06:42,508] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 17:06:55,252] {scheduler_job.py:155} INFO - Started process (PID=96057) to work on /airflow/dags/download_data.py
[2022-02-18 17:06:55,259] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:06:55,261] {logging_mixin.py:112} INFO - [2022-02-18 17:06:55,261] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:06:55,694] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:06:55,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:06:55,750] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:06:55,756] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 17:07:08,530] {scheduler_job.py:155} INFO - Started process (PID=96083) to work on /airflow/dags/download_data.py
[2022-02-18 17:07:08,537] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:07:08,539] {logging_mixin.py:112} INFO - [2022-02-18 17:07:08,539] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:07:09,023] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:07:09,074] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:07:09,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:07:09,092] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 17:07:21,792] {scheduler_job.py:155} INFO - Started process (PID=96109) to work on /airflow/dags/download_data.py
[2022-02-18 17:07:21,796] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:07:21,799] {logging_mixin.py:112} INFO - [2022-02-18 17:07:21,799] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:07:22,260] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:07:22,304] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:07:22,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:07:22,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 17:07:35,078] {scheduler_job.py:155} INFO - Started process (PID=96135) to work on /airflow/dags/download_data.py
[2022-02-18 17:07:35,084] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:07:35,092] {logging_mixin.py:112} INFO - [2022-02-18 17:07:35,092] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:07:35,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:07:35,684] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:07:35,696] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:07:35,701] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-18 17:07:48,345] {scheduler_job.py:155} INFO - Started process (PID=96161) to work on /airflow/dags/download_data.py
[2022-02-18 17:07:48,351] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:07:48,353] {logging_mixin.py:112} INFO - [2022-02-18 17:07:48,353] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:07:48,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:07:48,921] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:07:48,929] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:07:48,934] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 17:08:01,598] {scheduler_job.py:155} INFO - Started process (PID=96187) to work on /airflow/dags/download_data.py
[2022-02-18 17:08:01,602] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:08:01,603] {logging_mixin.py:112} INFO - [2022-02-18 17:08:01,603] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:08:02,069] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:08:02,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:08:02,118] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:08:02,124] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 17:08:14,863] {scheduler_job.py:155} INFO - Started process (PID=96213) to work on /airflow/dags/download_data.py
[2022-02-18 17:08:14,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:08:14,869] {logging_mixin.py:112} INFO - [2022-02-18 17:08:14,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:08:15,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:08:15,388] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:08:15,407] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:08:15,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 17:08:28,145] {scheduler_job.py:155} INFO - Started process (PID=96239) to work on /airflow/dags/download_data.py
[2022-02-18 17:08:28,152] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:08:28,154] {logging_mixin.py:112} INFO - [2022-02-18 17:08:28,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:08:28,603] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:08:28,651] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:08:28,658] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:08:28,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 17:08:41,425] {scheduler_job.py:155} INFO - Started process (PID=96265) to work on /airflow/dags/download_data.py
[2022-02-18 17:08:41,431] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:08:41,434] {logging_mixin.py:112} INFO - [2022-02-18 17:08:41,434] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:08:41,903] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:08:41,952] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:08:41,963] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:08:41,968] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 17:08:54,685] {scheduler_job.py:155} INFO - Started process (PID=96291) to work on /airflow/dags/download_data.py
[2022-02-18 17:08:54,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:08:54,692] {logging_mixin.py:112} INFO - [2022-02-18 17:08:54,692] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:08:55,200] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:08:55,256] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:08:55,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:08:55,269] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 17:09:07,967] {scheduler_job.py:155} INFO - Started process (PID=96317) to work on /airflow/dags/download_data.py
[2022-02-18 17:09:07,971] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:09:07,973] {logging_mixin.py:112} INFO - [2022-02-18 17:09:07,973] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:09:08,516] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:09:08,580] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:09:08,591] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:09:08,595] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-18 17:09:21,199] {scheduler_job.py:155} INFO - Started process (PID=96343) to work on /airflow/dags/download_data.py
[2022-02-18 17:09:21,204] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:09:21,207] {logging_mixin.py:112} INFO - [2022-02-18 17:09:21,207] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:09:21,672] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:09:21,724] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:09:21,733] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:09:21,738] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 17:09:34,465] {scheduler_job.py:155} INFO - Started process (PID=96369) to work on /airflow/dags/download_data.py
[2022-02-18 17:09:34,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:09:34,471] {logging_mixin.py:112} INFO - [2022-02-18 17:09:34,471] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:09:34,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:09:35,026] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:09:35,038] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:09:35,044] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 17:09:47,757] {scheduler_job.py:155} INFO - Started process (PID=96395) to work on /airflow/dags/download_data.py
[2022-02-18 17:09:47,765] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:09:47,768] {logging_mixin.py:112} INFO - [2022-02-18 17:09:47,767] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:09:48,214] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:09:48,257] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:09:48,270] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:09:48,276] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 17:10:01,000] {scheduler_job.py:155} INFO - Started process (PID=96421) to work on /airflow/dags/download_data.py
[2022-02-18 17:10:01,005] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:10:01,006] {logging_mixin.py:112} INFO - [2022-02-18 17:10:01,006] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:10:01,451] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:10:01,501] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:10:01,509] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:10:01,514] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 17:10:14,273] {scheduler_job.py:155} INFO - Started process (PID=96447) to work on /airflow/dags/download_data.py
[2022-02-18 17:10:14,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:10:14,280] {logging_mixin.py:112} INFO - [2022-02-18 17:10:14,279] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:10:14,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:10:14,772] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:10:14,778] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:10:14,782] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 17:10:27,530] {scheduler_job.py:155} INFO - Started process (PID=96473) to work on /airflow/dags/download_data.py
[2022-02-18 17:10:27,535] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:10:27,536] {logging_mixin.py:112} INFO - [2022-02-18 17:10:27,536] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:10:27,998] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:10:28,052] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:10:28,060] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:10:28,064] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 17:10:40,805] {scheduler_job.py:155} INFO - Started process (PID=96499) to work on /airflow/dags/download_data.py
[2022-02-18 17:10:40,814] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:10:40,816] {logging_mixin.py:112} INFO - [2022-02-18 17:10:40,816] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:10:41,285] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:10:41,338] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:10:41,348] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:10:41,353] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 17:10:54,091] {scheduler_job.py:155} INFO - Started process (PID=96525) to work on /airflow/dags/download_data.py
[2022-02-18 17:10:54,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:10:54,102] {logging_mixin.py:112} INFO - [2022-02-18 17:10:54,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:10:54,562] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:10:54,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:10:54,624] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:10:54,628] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 17:11:07,382] {scheduler_job.py:155} INFO - Started process (PID=96551) to work on /airflow/dags/download_data.py
[2022-02-18 17:11:07,394] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:11:07,396] {logging_mixin.py:112} INFO - [2022-02-18 17:11:07,395] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:11:07,851] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:11:07,913] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:11:07,921] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:11:07,930] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 17:11:20,628] {scheduler_job.py:155} INFO - Started process (PID=96577) to work on /airflow/dags/download_data.py
[2022-02-18 17:11:20,634] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:11:20,635] {logging_mixin.py:112} INFO - [2022-02-18 17:11:20,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:11:21,091] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:11:21,142] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:11:21,152] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:11:21,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 17:11:33,892] {scheduler_job.py:155} INFO - Started process (PID=96603) to work on /airflow/dags/download_data.py
[2022-02-18 17:11:33,901] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:11:33,906] {logging_mixin.py:112} INFO - [2022-02-18 17:11:33,905] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:11:34,436] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:11:34,490] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:11:34,496] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:11:34,500] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 17:11:47,159] {scheduler_job.py:155} INFO - Started process (PID=96629) to work on /airflow/dags/download_data.py
[2022-02-18 17:11:47,166] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:11:47,167] {logging_mixin.py:112} INFO - [2022-02-18 17:11:47,167] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:11:47,620] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:11:47,671] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:11:47,678] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:11:47,683] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 17:12:00,425] {scheduler_job.py:155} INFO - Started process (PID=96655) to work on /airflow/dags/download_data.py
[2022-02-18 17:12:00,434] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:12:00,437] {logging_mixin.py:112} INFO - [2022-02-18 17:12:00,437] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:12:00,976] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:12:01,099] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:12:01,114] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:12:01,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.750 seconds
[2022-02-18 17:12:13,737] {scheduler_job.py:155} INFO - Started process (PID=96681) to work on /airflow/dags/download_data.py
[2022-02-18 17:12:13,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:12:13,746] {logging_mixin.py:112} INFO - [2022-02-18 17:12:13,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:12:14,238] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:12:14,273] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:12:14,284] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:12:14,291] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 17:12:26,962] {scheduler_job.py:155} INFO - Started process (PID=96707) to work on /airflow/dags/download_data.py
[2022-02-18 17:12:26,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:12:26,968] {logging_mixin.py:112} INFO - [2022-02-18 17:12:26,968] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:12:27,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:12:27,558] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:12:27,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:12:27,568] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-18 17:12:40,267] {scheduler_job.py:155} INFO - Started process (PID=96733) to work on /airflow/dags/download_data.py
[2022-02-18 17:12:40,275] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:12:40,290] {logging_mixin.py:112} INFO - [2022-02-18 17:12:40,290] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:12:40,740] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:12:40,790] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:12:40,799] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:12:40,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 17:12:53,492] {scheduler_job.py:155} INFO - Started process (PID=96759) to work on /airflow/dags/download_data.py
[2022-02-18 17:12:53,497] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:12:53,498] {logging_mixin.py:112} INFO - [2022-02-18 17:12:53,498] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:12:53,990] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:12:54,035] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:12:54,044] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:12:54,050] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 17:13:06,779] {scheduler_job.py:155} INFO - Started process (PID=96785) to work on /airflow/dags/download_data.py
[2022-02-18 17:13:06,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:13:06,786] {logging_mixin.py:112} INFO - [2022-02-18 17:13:06,786] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:13:07,263] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:13:07,323] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:13:07,349] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:13:07,363] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 17:13:20,042] {scheduler_job.py:155} INFO - Started process (PID=96811) to work on /airflow/dags/download_data.py
[2022-02-18 17:13:20,048] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:13:20,049] {logging_mixin.py:112} INFO - [2022-02-18 17:13:20,049] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:13:20,530] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:13:20,571] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:13:20,548] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:13:20,553] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 17:13:33,324] {scheduler_job.py:155} INFO - Started process (PID=96837) to work on /airflow/dags/download_data.py
[2022-02-18 17:13:33,331] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:13:33,334] {logging_mixin.py:112} INFO - [2022-02-18 17:13:33,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:13:33,804] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:13:33,861] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:13:33,867] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:13:33,873] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 17:13:46,606] {scheduler_job.py:155} INFO - Started process (PID=96863) to work on /airflow/dags/download_data.py
[2022-02-18 17:13:46,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:13:46,617] {logging_mixin.py:112} INFO - [2022-02-18 17:13:46,617] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:13:47,089] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:13:47,129] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:13:47,136] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:13:47,139] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 17:13:59,884] {scheduler_job.py:155} INFO - Started process (PID=96889) to work on /airflow/dags/download_data.py
[2022-02-18 17:13:59,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:13:59,890] {logging_mixin.py:112} INFO - [2022-02-18 17:13:59,890] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:14:00,367] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:14:00,411] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:14:00,421] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:14:00,425] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 17:14:13,170] {scheduler_job.py:155} INFO - Started process (PID=96915) to work on /airflow/dags/download_data.py
[2022-02-18 17:14:13,180] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:14:13,182] {logging_mixin.py:112} INFO - [2022-02-18 17:14:13,182] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:14:13,633] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:14:13,687] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:14:13,699] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:14:13,706] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 17:14:26,407] {scheduler_job.py:155} INFO - Started process (PID=96941) to work on /airflow/dags/download_data.py
[2022-02-18 17:14:26,416] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:14:26,418] {logging_mixin.py:112} INFO - [2022-02-18 17:14:26,418] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:14:26,885] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:14:26,936] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:14:26,944] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:14:26,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 17:14:39,738] {scheduler_job.py:155} INFO - Started process (PID=96967) to work on /airflow/dags/download_data.py
[2022-02-18 17:14:39,746] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:14:39,749] {logging_mixin.py:112} INFO - [2022-02-18 17:14:39,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:14:40,325] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:14:40,393] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:14:40,400] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:14:40,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-18 17:14:52,954] {scheduler_job.py:155} INFO - Started process (PID=96993) to work on /airflow/dags/download_data.py
[2022-02-18 17:14:52,960] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:14:52,962] {logging_mixin.py:112} INFO - [2022-02-18 17:14:52,962] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:14:53,476] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:14:53,528] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:14:53,537] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:14:53,541] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 17:15:06,264] {scheduler_job.py:155} INFO - Started process (PID=97019) to work on /airflow/dags/download_data.py
[2022-02-18 17:15:06,270] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:15:06,271] {logging_mixin.py:112} INFO - [2022-02-18 17:15:06,271] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:15:06,757] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:15:06,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:15:06,829] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:15:06,836] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 17:15:19,545] {scheduler_job.py:155} INFO - Started process (PID=97045) to work on /airflow/dags/download_data.py
[2022-02-18 17:15:19,550] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:15:19,552] {logging_mixin.py:112} INFO - [2022-02-18 17:15:19,551] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:15:20,053] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:15:20,114] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:15:20,126] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:15:20,130] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 17:15:32,767] {scheduler_job.py:155} INFO - Started process (PID=97071) to work on /airflow/dags/download_data.py
[2022-02-18 17:15:32,772] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:15:32,773] {logging_mixin.py:112} INFO - [2022-02-18 17:15:32,773] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:15:33,233] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:15:33,283] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:15:33,291] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:15:33,296] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 17:15:46,075] {scheduler_job.py:155} INFO - Started process (PID=97097) to work on /airflow/dags/download_data.py
[2022-02-18 17:15:46,084] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:15:46,088] {logging_mixin.py:112} INFO - [2022-02-18 17:15:46,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:15:46,595] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:15:46,647] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:15:46,657] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:15:46,661] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 17:15:59,311] {scheduler_job.py:155} INFO - Started process (PID=97123) to work on /airflow/dags/download_data.py
[2022-02-18 17:15:59,321] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:15:59,323] {logging_mixin.py:112} INFO - [2022-02-18 17:15:59,322] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:15:59,838] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:15:59,898] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:15:59,908] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:15:59,921] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 17:16:12,618] {scheduler_job.py:155} INFO - Started process (PID=97149) to work on /airflow/dags/download_data.py
[2022-02-18 17:16:12,624] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:16:12,626] {logging_mixin.py:112} INFO - [2022-02-18 17:16:12,626] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:16:13,057] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:16:13,106] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:16:13,116] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:16:13,123] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 17:16:25,852] {scheduler_job.py:155} INFO - Started process (PID=97175) to work on /airflow/dags/download_data.py
[2022-02-18 17:16:25,857] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:16:25,858] {logging_mixin.py:112} INFO - [2022-02-18 17:16:25,858] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:16:26,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:16:26,353] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:16:26,360] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:16:26,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 17:16:39,154] {scheduler_job.py:155} INFO - Started process (PID=97201) to work on /airflow/dags/download_data.py
[2022-02-18 17:16:39,160] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:16:39,162] {logging_mixin.py:112} INFO - [2022-02-18 17:16:39,162] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:16:39,749] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:16:39,799] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:16:39,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:16:39,815] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.661 seconds
[2022-02-18 17:16:52,468] {scheduler_job.py:155} INFO - Started process (PID=97227) to work on /airflow/dags/download_data.py
[2022-02-18 17:16:52,518] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:16:52,523] {logging_mixin.py:112} INFO - [2022-02-18 17:16:52,522] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:16:53,214] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:16:53,268] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:16:53,277] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:16:53,284] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.816 seconds
[2022-02-18 17:17:05,729] {scheduler_job.py:155} INFO - Started process (PID=97253) to work on /airflow/dags/download_data.py
[2022-02-18 17:17:05,734] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:17:05,735] {logging_mixin.py:112} INFO - [2022-02-18 17:17:05,735] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:17:06,237] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:17:06,294] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:17:06,307] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:17:06,313] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-18 17:17:18,978] {scheduler_job.py:155} INFO - Started process (PID=97279) to work on /airflow/dags/download_data.py
[2022-02-18 17:17:18,983] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:17:18,984] {logging_mixin.py:112} INFO - [2022-02-18 17:17:18,984] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:17:19,418] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:17:19,454] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:17:19,459] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:17:19,464] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-18 17:17:32,253] {scheduler_job.py:155} INFO - Started process (PID=97305) to work on /airflow/dags/download_data.py
[2022-02-18 17:17:32,259] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:17:32,261] {logging_mixin.py:112} INFO - [2022-02-18 17:17:32,261] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:17:32,744] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:17:32,794] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:17:32,801] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:17:32,805] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 17:17:45,541] {scheduler_job.py:155} INFO - Started process (PID=97331) to work on /airflow/dags/download_data.py
[2022-02-18 17:17:45,549] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:17:45,552] {logging_mixin.py:112} INFO - [2022-02-18 17:17:45,551] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:17:46,029] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:17:46,082] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:17:46,096] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:17:46,104] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 17:17:58,878] {scheduler_job.py:155} INFO - Started process (PID=97357) to work on /airflow/dags/download_data.py
[2022-02-18 17:17:58,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:17:58,890] {logging_mixin.py:112} INFO - [2022-02-18 17:17:58,890] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:17:59,382] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:17:59,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:17:59,452] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:17:59,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 17:18:12,179] {scheduler_job.py:155} INFO - Started process (PID=97383) to work on /airflow/dags/download_data.py
[2022-02-18 17:18:12,184] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:18:12,186] {logging_mixin.py:112} INFO - [2022-02-18 17:18:12,185] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:18:12,675] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:18:12,724] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:18:12,730] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:18:12,735] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 17:18:25,431] {scheduler_job.py:155} INFO - Started process (PID=97409) to work on /airflow/dags/download_data.py
[2022-02-18 17:18:25,438] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:18:25,440] {logging_mixin.py:112} INFO - [2022-02-18 17:18:25,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:18:25,870] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:18:25,919] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:18:25,925] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:18:25,928] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 17:18:38,692] {scheduler_job.py:155} INFO - Started process (PID=97435) to work on /airflow/dags/download_data.py
[2022-02-18 17:18:38,696] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:18:38,698] {logging_mixin.py:112} INFO - [2022-02-18 17:18:38,697] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:18:39,158] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:18:39,230] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:18:39,240] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:18:39,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 17:18:51,929] {scheduler_job.py:155} INFO - Started process (PID=97461) to work on /airflow/dags/download_data.py
[2022-02-18 17:18:51,933] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:18:51,935] {logging_mixin.py:112} INFO - [2022-02-18 17:18:51,935] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:18:52,410] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:18:52,458] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:18:52,465] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:18:52,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 17:19:05,221] {scheduler_job.py:155} INFO - Started process (PID=97487) to work on /airflow/dags/download_data.py
[2022-02-18 17:19:05,225] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:19:05,227] {logging_mixin.py:112} INFO - [2022-02-18 17:19:05,226] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:19:05,683] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:19:05,732] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:19:05,738] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:19:05,741] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 17:19:18,495] {scheduler_job.py:155} INFO - Started process (PID=97513) to work on /airflow/dags/download_data.py
[2022-02-18 17:19:18,500] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:19:18,502] {logging_mixin.py:112} INFO - [2022-02-18 17:19:18,501] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:19:18,940] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:19:18,985] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:19:18,995] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:19:19,001] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 17:19:31,765] {scheduler_job.py:155} INFO - Started process (PID=97539) to work on /airflow/dags/download_data.py
[2022-02-18 17:19:31,776] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:19:31,778] {logging_mixin.py:112} INFO - [2022-02-18 17:19:31,777] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:19:32,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:19:32,256] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:19:32,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:19:32,267] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 17:19:45,021] {scheduler_job.py:155} INFO - Started process (PID=97565) to work on /airflow/dags/download_data.py
[2022-02-18 17:19:45,028] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:19:45,029] {logging_mixin.py:112} INFO - [2022-02-18 17:19:45,029] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:19:45,473] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:19:45,522] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:19:45,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:19:45,536] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 17:19:58,276] {scheduler_job.py:155} INFO - Started process (PID=97591) to work on /airflow/dags/download_data.py
[2022-02-18 17:19:58,285] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:19:58,287] {logging_mixin.py:112} INFO - [2022-02-18 17:19:58,287] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:19:58,723] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:19:58,766] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:19:58,774] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:19:58,778] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 17:20:11,557] {scheduler_job.py:155} INFO - Started process (PID=97617) to work on /airflow/dags/download_data.py
[2022-02-18 17:20:11,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:20:11,570] {logging_mixin.py:112} INFO - [2022-02-18 17:20:11,570] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:20:12,039] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:20:12,095] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:20:12,104] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:20:12,109] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 17:20:24,784] {scheduler_job.py:155} INFO - Started process (PID=97643) to work on /airflow/dags/download_data.py
[2022-02-18 17:20:24,789] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:20:24,790] {logging_mixin.py:112} INFO - [2022-02-18 17:20:24,790] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:20:25,245] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:20:25,287] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:20:25,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:20:25,301] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 17:20:38,087] {scheduler_job.py:155} INFO - Started process (PID=97669) to work on /airflow/dags/download_data.py
[2022-02-18 17:20:38,092] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:20:38,094] {logging_mixin.py:112} INFO - [2022-02-18 17:20:38,094] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:20:38,556] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:20:38,602] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:20:38,609] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:20:38,613] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 17:20:51,355] {scheduler_job.py:155} INFO - Started process (PID=97695) to work on /airflow/dags/download_data.py
[2022-02-18 17:20:51,363] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:20:51,365] {logging_mixin.py:112} INFO - [2022-02-18 17:20:51,365] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:20:51,797] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:20:51,846] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:20:51,853] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:20:51,858] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 17:21:04,585] {scheduler_job.py:155} INFO - Started process (PID=97721) to work on /airflow/dags/download_data.py
[2022-02-18 17:21:04,589] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:21:04,591] {logging_mixin.py:112} INFO - [2022-02-18 17:21:04,591] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:21:05,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:21:05,069] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:21:05,077] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:21:05,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 17:21:17,909] {scheduler_job.py:155} INFO - Started process (PID=97747) to work on /airflow/dags/download_data.py
[2022-02-18 17:21:17,916] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:21:17,918] {logging_mixin.py:112} INFO - [2022-02-18 17:21:17,918] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:21:18,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:21:18,446] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:21:18,456] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:21:18,463] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 17:21:31,150] {scheduler_job.py:155} INFO - Started process (PID=97773) to work on /airflow/dags/download_data.py
[2022-02-18 17:21:31,157] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:21:31,159] {logging_mixin.py:112} INFO - [2022-02-18 17:21:31,159] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:21:31,593] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:21:31,645] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:21:31,655] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:21:31,662] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 17:21:44,430] {scheduler_job.py:155} INFO - Started process (PID=97799) to work on /airflow/dags/download_data.py
[2022-02-18 17:21:44,439] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:21:44,441] {logging_mixin.py:112} INFO - [2022-02-18 17:21:44,441] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:21:44,906] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:21:44,960] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:21:44,970] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:21:44,974] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 17:21:57,693] {scheduler_job.py:155} INFO - Started process (PID=97825) to work on /airflow/dags/download_data.py
[2022-02-18 17:21:57,702] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:21:57,705] {logging_mixin.py:112} INFO - [2022-02-18 17:21:57,705] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:21:58,146] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:21:58,185] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:21:58,195] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:21:58,201] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 17:22:10,985] {scheduler_job.py:155} INFO - Started process (PID=97851) to work on /airflow/dags/download_data.py
[2022-02-18 17:22:10,992] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:22:10,995] {logging_mixin.py:112} INFO - [2022-02-18 17:22:10,994] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:22:11,470] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:22:11,520] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:22:11,531] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:22:11,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 17:22:24,228] {scheduler_job.py:155} INFO - Started process (PID=97877) to work on /airflow/dags/download_data.py
[2022-02-18 17:22:24,232] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:22:24,234] {logging_mixin.py:112} INFO - [2022-02-18 17:22:24,234] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:22:24,768] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:22:24,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:22:24,838] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:22:24,843] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-18 17:22:37,508] {scheduler_job.py:155} INFO - Started process (PID=97903) to work on /airflow/dags/download_data.py
[2022-02-18 17:22:37,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:22:37,521] {logging_mixin.py:112} INFO - [2022-02-18 17:22:37,519] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:22:38,032] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:22:38,099] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:22:38,109] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:22:38,116] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 17:22:50,775] {scheduler_job.py:155} INFO - Started process (PID=97929) to work on /airflow/dags/download_data.py
[2022-02-18 17:22:50,781] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:22:50,788] {logging_mixin.py:112} INFO - [2022-02-18 17:22:50,786] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:22:51,277] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:22:51,337] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:22:51,345] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:22:51,351] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 17:23:04,045] {scheduler_job.py:155} INFO - Started process (PID=97955) to work on /airflow/dags/download_data.py
[2022-02-18 17:23:04,054] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:23:04,057] {logging_mixin.py:112} INFO - [2022-02-18 17:23:04,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:23:04,493] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:23:04,543] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:23:04,553] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:23:04,559] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 17:23:17,349] {scheduler_job.py:155} INFO - Started process (PID=97981) to work on /airflow/dags/download_data.py
[2022-02-18 17:23:17,354] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:23:17,358] {logging_mixin.py:112} INFO - [2022-02-18 17:23:17,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:23:17,843] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:23:17,895] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:23:17,901] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:23:17,905] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 17:23:30,627] {scheduler_job.py:155} INFO - Started process (PID=98007) to work on /airflow/dags/download_data.py
[2022-02-18 17:23:30,632] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:23:30,634] {logging_mixin.py:112} INFO - [2022-02-18 17:23:30,634] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:23:31,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:23:31,166] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:23:31,175] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:23:31,180] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 17:23:43,930] {scheduler_job.py:155} INFO - Started process (PID=98033) to work on /airflow/dags/download_data.py
[2022-02-18 17:23:43,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:23:43,937] {logging_mixin.py:112} INFO - [2022-02-18 17:23:43,936] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:23:44,517] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:23:44,582] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:23:44,591] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:23:44,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-18 17:23:57,196] {scheduler_job.py:155} INFO - Started process (PID=98059) to work on /airflow/dags/download_data.py
[2022-02-18 17:23:57,204] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:23:57,207] {logging_mixin.py:112} INFO - [2022-02-18 17:23:57,207] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:23:57,700] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:23:57,747] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:23:57,754] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:23:57,760] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 17:24:10,458] {scheduler_job.py:155} INFO - Started process (PID=98085) to work on /airflow/dags/download_data.py
[2022-02-18 17:24:10,464] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:24:10,466] {logging_mixin.py:112} INFO - [2022-02-18 17:24:10,465] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:24:10,926] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:24:10,982] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:24:10,991] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:24:10,996] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 17:24:23,759] {scheduler_job.py:155} INFO - Started process (PID=98111) to work on /airflow/dags/download_data.py
[2022-02-18 17:24:23,765] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:24:23,767] {logging_mixin.py:112} INFO - [2022-02-18 17:24:23,766] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:24:24,252] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:24:24,317] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:24:24,329] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:24:24,336] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 17:24:37,017] {scheduler_job.py:155} INFO - Started process (PID=98137) to work on /airflow/dags/download_data.py
[2022-02-18 17:24:37,028] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:24:37,037] {logging_mixin.py:112} INFO - [2022-02-18 17:24:37,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:24:37,516] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:24:37,560] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:24:37,571] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:24:37,575] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 17:24:50,301] {scheduler_job.py:155} INFO - Started process (PID=98163) to work on /airflow/dags/download_data.py
[2022-02-18 17:24:50,312] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:24:50,314] {logging_mixin.py:112} INFO - [2022-02-18 17:24:50,314] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:24:50,865] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:24:50,922] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:24:50,927] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:24:50,930] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-18 17:25:03,551] {scheduler_job.py:155} INFO - Started process (PID=98189) to work on /airflow/dags/download_data.py
[2022-02-18 17:25:03,556] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:25:03,558] {logging_mixin.py:112} INFO - [2022-02-18 17:25:03,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:25:04,021] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:25:04,072] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:25:04,080] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:25:04,086] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 17:25:16,845] {scheduler_job.py:155} INFO - Started process (PID=98215) to work on /airflow/dags/download_data.py
[2022-02-18 17:25:16,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:25:16,850] {logging_mixin.py:112} INFO - [2022-02-18 17:25:16,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:25:17,308] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:25:17,394] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:25:17,407] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:25:17,414] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 17:25:30,089] {scheduler_job.py:155} INFO - Started process (PID=98241) to work on /airflow/dags/download_data.py
[2022-02-18 17:25:30,097] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:25:30,099] {logging_mixin.py:112} INFO - [2022-02-18 17:25:30,099] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:25:30,642] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:25:30,702] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:25:30,709] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:25:30,715] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-18 17:25:43,421] {scheduler_job.py:155} INFO - Started process (PID=98267) to work on /airflow/dags/download_data.py
[2022-02-18 17:25:43,428] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:25:43,430] {logging_mixin.py:112} INFO - [2022-02-18 17:25:43,430] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:25:43,970] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:25:44,036] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:25:44,053] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:25:44,058] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-18 17:25:56,661] {scheduler_job.py:155} INFO - Started process (PID=98293) to work on /airflow/dags/download_data.py
[2022-02-18 17:25:56,666] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:25:56,668] {logging_mixin.py:112} INFO - [2022-02-18 17:25:56,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:25:57,119] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:25:57,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:25:57,182] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:25:57,188] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 17:26:09,947] {scheduler_job.py:155} INFO - Started process (PID=98319) to work on /airflow/dags/download_data.py
[2022-02-18 17:26:09,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:26:09,956] {logging_mixin.py:112} INFO - [2022-02-18 17:26:09,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:26:10,391] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:26:10,439] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:26:10,445] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:26:10,450] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 17:26:23,208] {scheduler_job.py:155} INFO - Started process (PID=98345) to work on /airflow/dags/download_data.py
[2022-02-18 17:26:23,219] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:26:23,221] {logging_mixin.py:112} INFO - [2022-02-18 17:26:23,220] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:26:23,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:26:23,704] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:26:23,712] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:26:23,717] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 17:26:36,480] {scheduler_job.py:155} INFO - Started process (PID=98371) to work on /airflow/dags/download_data.py
[2022-02-18 17:26:36,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:26:36,488] {logging_mixin.py:112} INFO - [2022-02-18 17:26:36,488] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:26:36,967] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:26:37,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:26:37,037] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:26:37,044] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 17:26:49,779] {scheduler_job.py:155} INFO - Started process (PID=98397) to work on /airflow/dags/download_data.py
[2022-02-18 17:26:49,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:26:49,788] {logging_mixin.py:112} INFO - [2022-02-18 17:26:49,788] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:26:50,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:26:50,272] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:26:50,280] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:26:50,286] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 17:27:03,009] {scheduler_job.py:155} INFO - Started process (PID=98423) to work on /airflow/dags/download_data.py
[2022-02-18 17:27:03,014] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:27:03,016] {logging_mixin.py:112} INFO - [2022-02-18 17:27:03,015] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:27:03,461] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:27:03,508] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:27:03,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:27:03,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 17:27:16,292] {scheduler_job.py:155} INFO - Started process (PID=98449) to work on /airflow/dags/download_data.py
[2022-02-18 17:27:16,300] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:27:16,305] {logging_mixin.py:112} INFO - [2022-02-18 17:27:16,305] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:27:16,740] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:27:16,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:27:16,811] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:27:16,818] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 17:27:29,537] {scheduler_job.py:155} INFO - Started process (PID=98475) to work on /airflow/dags/download_data.py
[2022-02-18 17:27:29,544] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:27:29,546] {logging_mixin.py:112} INFO - [2022-02-18 17:27:29,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:27:29,981] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:27:30,033] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:27:30,039] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:27:30,042] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 17:27:42,815] {scheduler_job.py:155} INFO - Started process (PID=98501) to work on /airflow/dags/download_data.py
[2022-02-18 17:27:42,822] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:27:42,825] {logging_mixin.py:112} INFO - [2022-02-18 17:27:42,824] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:27:43,264] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:27:43,303] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:27:43,312] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:27:43,317] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 17:27:56,056] {scheduler_job.py:155} INFO - Started process (PID=98527) to work on /airflow/dags/download_data.py
[2022-02-18 17:27:56,063] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:27:56,065] {logging_mixin.py:112} INFO - [2022-02-18 17:27:56,065] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:27:56,496] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:27:56,539] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:27:56,550] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:27:56,557] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 17:28:09,333] {scheduler_job.py:155} INFO - Started process (PID=98553) to work on /airflow/dags/download_data.py
[2022-02-18 17:28:09,337] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:28:09,339] {logging_mixin.py:112} INFO - [2022-02-18 17:28:09,338] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:28:09,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:28:09,833] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:28:09,842] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:28:09,847] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 17:28:22,571] {scheduler_job.py:155} INFO - Started process (PID=98579) to work on /airflow/dags/download_data.py
[2022-02-18 17:28:22,575] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:28:22,577] {logging_mixin.py:112} INFO - [2022-02-18 17:28:22,577] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:28:23,015] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:28:23,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:28:23,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:28:23,078] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 17:28:36,455] {scheduler_job.py:155} INFO - Started process (PID=98605) to work on /airflow/dags/download_data.py
[2022-02-18 17:28:36,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:28:36,464] {logging_mixin.py:112} INFO - [2022-02-18 17:28:36,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:28:36,912] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:28:36,970] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:28:36,983] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:28:36,988] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 17:29:37,146] {scheduler_job.py:155} INFO - Started process (PID=98631) to work on /airflow/dags/download_data.py
[2022-02-18 17:29:37,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:29:37,169] {logging_mixin.py:112} INFO - [2022-02-18 17:29:37,168] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:29:38,356] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:29:38,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:29:38,471] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:29:38,475] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.329 seconds
[2022-02-18 17:29:51,502] {scheduler_job.py:155} INFO - Started process (PID=98657) to work on /airflow/dags/download_data.py
[2022-02-18 17:29:51,506] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:29:51,508] {logging_mixin.py:112} INFO - [2022-02-18 17:29:51,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:29:51,993] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:29:52,052] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:29:52,059] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:29:52,063] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 17:30:03,764] {scheduler_job.py:155} INFO - Started process (PID=98682) to work on /airflow/dags/download_data.py
[2022-02-18 17:30:03,769] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:30:03,771] {logging_mixin.py:112} INFO - [2022-02-18 17:30:03,770] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:30:04,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:30:04,289] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:30:04,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:30:04,300] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 17:30:17,429] {scheduler_job.py:155} INFO - Started process (PID=98708) to work on /airflow/dags/download_data.py
[2022-02-18 17:30:17,436] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:30:17,439] {logging_mixin.py:112} INFO - [2022-02-18 17:30:17,438] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:30:17,887] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:30:17,934] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:30:17,941] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:30:17,946] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 17:30:30,711] {scheduler_job.py:155} INFO - Started process (PID=98734) to work on /airflow/dags/download_data.py
[2022-02-18 17:30:30,715] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:30:30,717] {logging_mixin.py:112} INFO - [2022-02-18 17:30:30,716] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:30:31,164] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:30:31,213] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:30:31,221] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:30:31,226] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 17:30:43,927] {scheduler_job.py:155} INFO - Started process (PID=98760) to work on /airflow/dags/download_data.py
[2022-02-18 17:30:43,933] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:30:43,935] {logging_mixin.py:112} INFO - [2022-02-18 17:30:43,935] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:30:44,383] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:30:44,425] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:30:44,432] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:30:44,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 17:30:57,194] {scheduler_job.py:155} INFO - Started process (PID=98786) to work on /airflow/dags/download_data.py
[2022-02-18 17:30:57,204] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:30:57,207] {logging_mixin.py:112} INFO - [2022-02-18 17:30:57,206] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:30:57,751] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:30:57,797] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:30:57,808] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:30:57,815] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-18 17:31:10,458] {scheduler_job.py:155} INFO - Started process (PID=98812) to work on /airflow/dags/download_data.py
[2022-02-18 17:31:10,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:31:10,473] {logging_mixin.py:112} INFO - [2022-02-18 17:31:10,472] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:31:10,961] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:31:11,013] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:31:11,020] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:31:11,024] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 17:31:23,710] {scheduler_job.py:155} INFO - Started process (PID=98838) to work on /airflow/dags/download_data.py
[2022-02-18 17:31:23,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:31:23,718] {logging_mixin.py:112} INFO - [2022-02-18 17:31:23,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:31:24,252] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:31:24,305] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:31:24,316] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:31:24,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 17:31:36,969] {scheduler_job.py:155} INFO - Started process (PID=98864) to work on /airflow/dags/download_data.py
[2022-02-18 17:31:36,976] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:31:36,979] {logging_mixin.py:112} INFO - [2022-02-18 17:31:36,978] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:31:37,425] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:31:37,470] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:31:37,476] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:31:37,480] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 17:31:50,252] {scheduler_job.py:155} INFO - Started process (PID=98890) to work on /airflow/dags/download_data.py
[2022-02-18 17:31:50,257] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:31:50,258] {logging_mixin.py:112} INFO - [2022-02-18 17:31:50,258] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:31:50,774] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:31:50,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:31:50,838] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:31:50,843] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 17:32:03,536] {scheduler_job.py:155} INFO - Started process (PID=98916) to work on /airflow/dags/download_data.py
[2022-02-18 17:32:03,544] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:32:03,546] {logging_mixin.py:112} INFO - [2022-02-18 17:32:03,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:32:03,976] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:32:04,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:32:04,033] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:32:04,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 17:32:16,820] {scheduler_job.py:155} INFO - Started process (PID=98942) to work on /airflow/dags/download_data.py
[2022-02-18 17:32:16,831] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:32:16,833] {logging_mixin.py:112} INFO - [2022-02-18 17:32:16,833] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:32:17,296] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:32:17,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:32:17,352] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:32:17,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 17:32:30,112] {scheduler_job.py:155} INFO - Started process (PID=98968) to work on /airflow/dags/download_data.py
[2022-02-18 17:32:30,119] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:32:30,121] {logging_mixin.py:112} INFO - [2022-02-18 17:32:30,121] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:32:30,589] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:32:30,638] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:32:30,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:32:30,652] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 17:32:43,397] {scheduler_job.py:155} INFO - Started process (PID=98994) to work on /airflow/dags/download_data.py
[2022-02-18 17:32:43,403] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:32:43,406] {logging_mixin.py:112} INFO - [2022-02-18 17:32:43,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:32:43,846] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:32:43,885] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:32:43,891] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:32:43,895] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 17:32:56,698] {scheduler_job.py:155} INFO - Started process (PID=99020) to work on /airflow/dags/download_data.py
[2022-02-18 17:32:56,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:32:56,712] {logging_mixin.py:112} INFO - [2022-02-18 17:32:56,711] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:32:57,163] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:32:57,214] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:32:57,219] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:32:57,223] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 17:33:09,902] {scheduler_job.py:155} INFO - Started process (PID=99046) to work on /airflow/dags/download_data.py
[2022-02-18 17:33:09,906] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:33:09,908] {logging_mixin.py:112} INFO - [2022-02-18 17:33:09,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:33:10,361] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:33:10,412] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:33:10,419] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:33:10,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 17:33:23,191] {scheduler_job.py:155} INFO - Started process (PID=99072) to work on /airflow/dags/download_data.py
[2022-02-18 17:33:23,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:33:23,201] {logging_mixin.py:112} INFO - [2022-02-18 17:33:23,201] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:33:23,772] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:33:23,842] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:33:23,848] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:33:23,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.662 seconds
[2022-02-18 17:33:36,455] {scheduler_job.py:155} INFO - Started process (PID=99098) to work on /airflow/dags/download_data.py
[2022-02-18 17:33:36,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:33:36,463] {logging_mixin.py:112} INFO - [2022-02-18 17:33:36,463] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:33:36,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:33:36,976] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:33:36,985] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:33:36,991] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 17:33:49,735] {scheduler_job.py:155} INFO - Started process (PID=99124) to work on /airflow/dags/download_data.py
[2022-02-18 17:33:49,741] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:33:49,744] {logging_mixin.py:112} INFO - [2022-02-18 17:33:49,743] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:33:50,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:33:50,241] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:33:50,252] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:33:50,257] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 17:34:03,030] {scheduler_job.py:155} INFO - Started process (PID=99150) to work on /airflow/dags/download_data.py
[2022-02-18 17:34:03,041] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:34:03,043] {logging_mixin.py:112} INFO - [2022-02-18 17:34:03,043] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:34:03,482] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:34:03,529] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:34:03,536] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:34:03,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 17:34:16,276] {scheduler_job.py:155} INFO - Started process (PID=99176) to work on /airflow/dags/download_data.py
[2022-02-18 17:34:16,281] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:34:16,283] {logging_mixin.py:112} INFO - [2022-02-18 17:34:16,283] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:34:16,735] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:34:16,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:34:16,785] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:34:16,789] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 17:34:29,509] {scheduler_job.py:155} INFO - Started process (PID=99202) to work on /airflow/dags/download_data.py
[2022-02-18 17:34:29,514] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:34:29,516] {logging_mixin.py:112} INFO - [2022-02-18 17:34:29,516] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:34:29,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:34:30,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:34:30,037] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:34:30,042] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 17:34:42,775] {scheduler_job.py:155} INFO - Started process (PID=99228) to work on /airflow/dags/download_data.py
[2022-02-18 17:34:42,787] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:34:42,791] {logging_mixin.py:112} INFO - [2022-02-18 17:34:42,790] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:34:43,235] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:34:43,294] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:34:43,303] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:34:43,308] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 17:34:56,083] {scheduler_job.py:155} INFO - Started process (PID=99254) to work on /airflow/dags/download_data.py
[2022-02-18 17:34:56,100] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:34:56,102] {logging_mixin.py:112} INFO - [2022-02-18 17:34:56,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:34:56,556] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:34:56,605] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:34:56,613] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:34:56,617] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 17:35:09,297] {scheduler_job.py:155} INFO - Started process (PID=99280) to work on /airflow/dags/download_data.py
[2022-02-18 17:35:09,301] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:35:09,303] {logging_mixin.py:112} INFO - [2022-02-18 17:35:09,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:35:09,738] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:35:09,833] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:35:09,840] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:35:09,846] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 17:35:22,573] {scheduler_job.py:155} INFO - Started process (PID=99306) to work on /airflow/dags/download_data.py
[2022-02-18 17:35:22,577] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:35:22,579] {logging_mixin.py:112} INFO - [2022-02-18 17:35:22,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:35:23,036] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:35:23,078] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:35:23,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:35:23,089] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 17:35:35,871] {scheduler_job.py:155} INFO - Started process (PID=99332) to work on /airflow/dags/download_data.py
[2022-02-18 17:35:35,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:35:35,877] {logging_mixin.py:112} INFO - [2022-02-18 17:35:35,877] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:35:36,292] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:35:36,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:35:36,354] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:35:36,361] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-18 17:35:49,130] {scheduler_job.py:155} INFO - Started process (PID=99358) to work on /airflow/dags/download_data.py
[2022-02-18 17:35:49,135] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:35:49,137] {logging_mixin.py:112} INFO - [2022-02-18 17:35:49,137] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:35:49,592] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:35:49,644] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:35:49,663] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:35:49,670] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 17:36:02,404] {scheduler_job.py:155} INFO - Started process (PID=99384) to work on /airflow/dags/download_data.py
[2022-02-18 17:36:02,409] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:36:02,411] {logging_mixin.py:112} INFO - [2022-02-18 17:36:02,410] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:36:02,866] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:36:02,908] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:36:02,918] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:36:02,922] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 17:36:15,978] {scheduler_job.py:155} INFO - Started process (PID=99410) to work on /airflow/dags/download_data.py
[2022-02-18 17:36:15,982] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:36:15,984] {logging_mixin.py:112} INFO - [2022-02-18 17:36:15,984] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:36:16,437] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:36:16,477] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:36:16,484] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:36:16,488] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 17:36:30,730] {scheduler_job.py:155} INFO - Started process (PID=99436) to work on /airflow/dags/download_data.py
[2022-02-18 17:36:30,737] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:36:30,739] {logging_mixin.py:112} INFO - [2022-02-18 17:36:30,739] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:36:31,475] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:36:31,526] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:36:31,535] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:36:31,538] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.809 seconds
[2022-02-18 17:37:22,888] {scheduler_job.py:155} INFO - Started process (PID=99462) to work on /airflow/dags/download_data.py
[2022-02-18 17:37:22,892] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:37:22,894] {logging_mixin.py:112} INFO - [2022-02-18 17:37:22,894] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:37:23,359] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:37:23,409] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:37:23,416] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:37:23,421] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 17:37:36,201] {scheduler_job.py:155} INFO - Started process (PID=99488) to work on /airflow/dags/download_data.py
[2022-02-18 17:37:36,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:37:36,208] {logging_mixin.py:112} INFO - [2022-02-18 17:37:36,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:37:36,664] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:37:36,723] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:37:36,730] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:37:36,736] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 17:37:49,455] {scheduler_job.py:155} INFO - Started process (PID=99514) to work on /airflow/dags/download_data.py
[2022-02-18 17:37:49,463] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:37:49,466] {logging_mixin.py:112} INFO - [2022-02-18 17:37:49,465] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:37:49,968] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:37:50,008] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:37:50,013] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:37:50,016] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 17:38:02,735] {scheduler_job.py:155} INFO - Started process (PID=99540) to work on /airflow/dags/download_data.py
[2022-02-18 17:38:02,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:38:02,745] {logging_mixin.py:112} INFO - [2022-02-18 17:38:02,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:38:03,213] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:38:03,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:38:03,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:38:03,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 17:38:15,961] {scheduler_job.py:155} INFO - Started process (PID=99566) to work on /airflow/dags/download_data.py
[2022-02-18 17:38:15,965] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:38:15,969] {logging_mixin.py:112} INFO - [2022-02-18 17:38:15,969] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:38:16,434] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:38:16,475] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:38:16,480] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:38:16,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 17:38:29,301] {scheduler_job.py:155} INFO - Started process (PID=99592) to work on /airflow/dags/download_data.py
[2022-02-18 17:38:29,310] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:38:29,312] {logging_mixin.py:112} INFO - [2022-02-18 17:38:29,311] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:38:29,754] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:38:29,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:38:29,810] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:38:29,815] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 17:38:43,565] {scheduler_job.py:155} INFO - Started process (PID=99618) to work on /airflow/dags/download_data.py
[2022-02-18 17:38:43,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:38:43,579] {logging_mixin.py:112} INFO - [2022-02-18 17:38:43,579] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:38:44,088] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:38:44,135] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:38:44,141] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:38:44,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 17:38:55,802] {scheduler_job.py:155} INFO - Started process (PID=99643) to work on /airflow/dags/download_data.py
[2022-02-18 17:38:55,812] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:38:55,819] {logging_mixin.py:112} INFO - [2022-02-18 17:38:55,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:38:56,326] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:38:56,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:38:56,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:38:56,384] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 17:39:09,096] {scheduler_job.py:155} INFO - Started process (PID=99669) to work on /airflow/dags/download_data.py
[2022-02-18 17:39:09,101] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:39:09,102] {logging_mixin.py:112} INFO - [2022-02-18 17:39:09,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:39:09,571] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:39:09,619] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:39:09,628] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:39:09,633] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 17:39:22,368] {scheduler_job.py:155} INFO - Started process (PID=99695) to work on /airflow/dags/download_data.py
[2022-02-18 17:39:22,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:39:22,375] {logging_mixin.py:112} INFO - [2022-02-18 17:39:22,375] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:39:22,842] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:39:22,895] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:39:22,907] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:39:22,912] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 17:39:35,631] {scheduler_job.py:155} INFO - Started process (PID=99721) to work on /airflow/dags/download_data.py
[2022-02-18 17:39:35,636] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:39:35,637] {logging_mixin.py:112} INFO - [2022-02-18 17:39:35,637] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:39:36,094] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:39:36,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:39:36,152] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:39:36,157] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 17:39:48,866] {scheduler_job.py:155} INFO - Started process (PID=99747) to work on /airflow/dags/download_data.py
[2022-02-18 17:39:48,870] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:39:48,873] {logging_mixin.py:112} INFO - [2022-02-18 17:39:48,872] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:39:49,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:39:49,450] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:39:49,457] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:39:49,461] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 17:40:02,112] {scheduler_job.py:155} INFO - Started process (PID=99773) to work on /airflow/dags/download_data.py
[2022-02-18 17:40:02,117] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:40:02,118] {logging_mixin.py:112} INFO - [2022-02-18 17:40:02,118] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:40:02,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:40:02,695] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:40:02,711] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:40:02,718] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 17:40:15,363] {scheduler_job.py:155} INFO - Started process (PID=99799) to work on /airflow/dags/download_data.py
[2022-02-18 17:40:15,367] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:40:15,369] {logging_mixin.py:112} INFO - [2022-02-18 17:40:15,369] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:40:15,876] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:40:15,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:40:15,946] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:40:15,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 17:40:28,667] {scheduler_job.py:155} INFO - Started process (PID=99825) to work on /airflow/dags/download_data.py
[2022-02-18 17:40:28,671] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:40:28,676] {logging_mixin.py:112} INFO - [2022-02-18 17:40:28,676] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:40:29,137] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:40:29,185] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:40:29,195] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:40:29,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 17:40:41,918] {scheduler_job.py:155} INFO - Started process (PID=99851) to work on /airflow/dags/download_data.py
[2022-02-18 17:40:41,925] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:40:41,928] {logging_mixin.py:112} INFO - [2022-02-18 17:40:41,927] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:40:42,399] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:40:42,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:40:42,460] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:40:42,466] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 17:40:55,182] {scheduler_job.py:155} INFO - Started process (PID=99877) to work on /airflow/dags/download_data.py
[2022-02-18 17:40:55,186] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:40:55,188] {logging_mixin.py:112} INFO - [2022-02-18 17:40:55,188] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:40:55,654] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:40:55,704] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:40:55,713] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:40:55,721] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 17:41:08,479] {scheduler_job.py:155} INFO - Started process (PID=99903) to work on /airflow/dags/download_data.py
[2022-02-18 17:41:08,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:41:08,489] {logging_mixin.py:112} INFO - [2022-02-18 17:41:08,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:41:08,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:41:08,995] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:41:09,005] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:41:09,011] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 17:41:21,750] {scheduler_job.py:155} INFO - Started process (PID=99929) to work on /airflow/dags/download_data.py
[2022-02-18 17:41:21,757] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:41:21,759] {logging_mixin.py:112} INFO - [2022-02-18 17:41:21,759] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:41:22,205] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:41:22,256] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:41:22,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:41:22,270] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 17:41:35,024] {scheduler_job.py:155} INFO - Started process (PID=99955) to work on /airflow/dags/download_data.py
[2022-02-18 17:41:35,029] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:41:35,031] {logging_mixin.py:112} INFO - [2022-02-18 17:41:35,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:41:35,500] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:41:35,554] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:41:35,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:41:35,569] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 17:41:48,279] {scheduler_job.py:155} INFO - Started process (PID=99981) to work on /airflow/dags/download_data.py
[2022-02-18 17:41:48,288] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:41:48,290] {logging_mixin.py:112} INFO - [2022-02-18 17:41:48,290] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:41:48,742] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:41:48,795] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:41:48,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:41:48,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 17:42:01,573] {scheduler_job.py:155} INFO - Started process (PID=308) to work on /airflow/dags/download_data.py
[2022-02-18 17:42:01,582] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:42:01,584] {logging_mixin.py:112} INFO - [2022-02-18 17:42:01,584] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:42:02,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:42:02,086] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:42:02,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:42:02,097] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 17:42:14,854] {scheduler_job.py:155} INFO - Started process (PID=334) to work on /airflow/dags/download_data.py
[2022-02-18 17:42:14,860] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:42:14,863] {logging_mixin.py:112} INFO - [2022-02-18 17:42:14,862] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:42:15,374] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:42:15,434] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:42:15,447] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:42:15,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 17:42:28,135] {scheduler_job.py:155} INFO - Started process (PID=360) to work on /airflow/dags/download_data.py
[2022-02-18 17:42:28,139] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:42:28,143] {logging_mixin.py:112} INFO - [2022-02-18 17:42:28,143] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:42:28,668] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:42:28,728] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:42:28,738] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:42:28,746] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 17:42:41,414] {scheduler_job.py:155} INFO - Started process (PID=386) to work on /airflow/dags/download_data.py
[2022-02-18 17:42:41,418] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:42:41,420] {logging_mixin.py:112} INFO - [2022-02-18 17:42:41,419] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:42:41,884] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:42:41,939] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:42:41,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:42:41,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 17:42:54,676] {scheduler_job.py:155} INFO - Started process (PID=412) to work on /airflow/dags/download_data.py
[2022-02-18 17:42:54,684] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:42:54,686] {logging_mixin.py:112} INFO - [2022-02-18 17:42:54,686] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:42:55,132] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:42:55,184] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:42:55,193] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:42:55,200] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 17:43:07,968] {scheduler_job.py:155} INFO - Started process (PID=438) to work on /airflow/dags/download_data.py
[2022-02-18 17:43:07,975] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:43:07,977] {logging_mixin.py:112} INFO - [2022-02-18 17:43:07,977] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:43:08,444] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:43:08,497] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:43:08,505] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:43:08,515] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 17:43:21,202] {scheduler_job.py:155} INFO - Started process (PID=464) to work on /airflow/dags/download_data.py
[2022-02-18 17:43:21,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:43:21,209] {logging_mixin.py:112} INFO - [2022-02-18 17:43:21,208] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:43:21,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:43:21,745] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:43:21,751] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:43:21,755] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 17:43:34,570] {scheduler_job.py:155} INFO - Started process (PID=490) to work on /airflow/dags/download_data.py
[2022-02-18 17:43:34,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:43:34,580] {logging_mixin.py:112} INFO - [2022-02-18 17:43:34,580] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:43:35,241] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:43:35,292] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:43:35,303] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:43:35,310] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.740 seconds
[2022-02-18 17:43:47,814] {scheduler_job.py:155} INFO - Started process (PID=516) to work on /airflow/dags/download_data.py
[2022-02-18 17:43:47,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:43:47,823] {logging_mixin.py:112} INFO - [2022-02-18 17:43:47,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:43:48,334] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:43:48,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:43:48,393] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:43:48,402] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 17:44:01,138] {scheduler_job.py:155} INFO - Started process (PID=542) to work on /airflow/dags/download_data.py
[2022-02-18 17:44:01,145] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:44:01,147] {logging_mixin.py:112} INFO - [2022-02-18 17:44:01,147] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:44:01,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:44:01,691] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:44:01,703] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:44:01,711] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 17:44:14,420] {scheduler_job.py:155} INFO - Started process (PID=568) to work on /airflow/dags/download_data.py
[2022-02-18 17:44:14,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:44:14,432] {logging_mixin.py:112} INFO - [2022-02-18 17:44:14,432] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:44:14,906] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:44:14,964] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:44:14,975] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:44:14,982] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 17:44:27,694] {scheduler_job.py:155} INFO - Started process (PID=594) to work on /airflow/dags/download_data.py
[2022-02-18 17:44:27,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:44:27,711] {logging_mixin.py:112} INFO - [2022-02-18 17:44:27,710] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:44:28,205] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:44:28,267] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:44:28,278] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:44:28,286] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 17:44:40,990] {scheduler_job.py:155} INFO - Started process (PID=620) to work on /airflow/dags/download_data.py
[2022-02-18 17:44:40,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:44:41,001] {logging_mixin.py:112} INFO - [2022-02-18 17:44:41,001] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:44:41,480] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:44:41,522] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:44:41,532] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:44:41,537] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 17:44:54,234] {scheduler_job.py:155} INFO - Started process (PID=646) to work on /airflow/dags/download_data.py
[2022-02-18 17:44:54,240] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:44:54,243] {logging_mixin.py:112} INFO - [2022-02-18 17:44:54,243] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:44:54,800] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:44:54,857] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:44:54,862] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:44:54,872] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-18 17:45:07,549] {scheduler_job.py:155} INFO - Started process (PID=672) to work on /airflow/dags/download_data.py
[2022-02-18 17:45:07,557] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:45:07,559] {logging_mixin.py:112} INFO - [2022-02-18 17:45:07,559] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:45:08,019] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:45:08,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:45:08,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:45:08,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 17:45:20,783] {scheduler_job.py:155} INFO - Started process (PID=698) to work on /airflow/dags/download_data.py
[2022-02-18 17:45:20,787] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:45:20,789] {logging_mixin.py:112} INFO - [2022-02-18 17:45:20,789] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:45:21,217] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:45:21,257] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:45:21,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:45:21,268] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-18 17:45:34,097] {scheduler_job.py:155} INFO - Started process (PID=724) to work on /airflow/dags/download_data.py
[2022-02-18 17:45:34,109] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:45:34,112] {logging_mixin.py:112} INFO - [2022-02-18 17:45:34,111] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:45:34,576] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:45:34,628] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:45:34,639] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:45:34,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 17:45:47,322] {scheduler_job.py:155} INFO - Started process (PID=750) to work on /airflow/dags/download_data.py
[2022-02-18 17:45:47,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:45:47,334] {logging_mixin.py:112} INFO - [2022-02-18 17:45:47,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:45:47,767] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:45:47,824] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:45:47,829] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:45:47,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 17:46:00,615] {scheduler_job.py:155} INFO - Started process (PID=776) to work on /airflow/dags/download_data.py
[2022-02-18 17:46:00,621] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:46:00,623] {logging_mixin.py:112} INFO - [2022-02-18 17:46:00,622] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:46:01,185] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:46:01,242] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:46:01,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:46:01,257] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-18 17:46:13,883] {scheduler_job.py:155} INFO - Started process (PID=802) to work on /airflow/dags/download_data.py
[2022-02-18 17:46:13,890] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:46:13,892] {logging_mixin.py:112} INFO - [2022-02-18 17:46:13,892] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:46:14,450] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:46:14,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:46:14,520] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:46:14,525] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 17:46:27,124] {scheduler_job.py:155} INFO - Started process (PID=828) to work on /airflow/dags/download_data.py
[2022-02-18 17:46:27,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:46:27,133] {logging_mixin.py:112} INFO - [2022-02-18 17:46:27,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:46:27,590] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:46:27,642] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:46:27,650] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:46:27,655] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 17:46:40,390] {scheduler_job.py:155} INFO - Started process (PID=854) to work on /airflow/dags/download_data.py
[2022-02-18 17:46:40,395] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:46:40,397] {logging_mixin.py:112} INFO - [2022-02-18 17:46:40,396] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:46:40,834] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:46:40,882] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:46:40,890] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:46:40,895] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 17:46:53,619] {scheduler_job.py:155} INFO - Started process (PID=880) to work on /airflow/dags/download_data.py
[2022-02-18 17:46:53,624] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:46:53,626] {logging_mixin.py:112} INFO - [2022-02-18 17:46:53,626] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:46:54,063] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:46:54,115] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:46:54,123] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:46:54,127] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 17:47:06,903] {scheduler_job.py:155} INFO - Started process (PID=906) to work on /airflow/dags/download_data.py
[2022-02-18 17:47:06,908] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:47:06,910] {logging_mixin.py:112} INFO - [2022-02-18 17:47:06,910] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:47:07,359] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:47:07,407] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:47:07,413] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:47:07,417] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 17:47:20,142] {scheduler_job.py:155} INFO - Started process (PID=932) to work on /airflow/dags/download_data.py
[2022-02-18 17:47:20,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:47:20,149] {logging_mixin.py:112} INFO - [2022-02-18 17:47:20,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:47:20,607] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:47:20,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:47:20,663] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:47:20,668] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 17:47:33,416] {scheduler_job.py:155} INFO - Started process (PID=958) to work on /airflow/dags/download_data.py
[2022-02-18 17:47:33,421] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:47:33,423] {logging_mixin.py:112} INFO - [2022-02-18 17:47:33,422] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:47:33,906] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:47:33,963] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:47:33,974] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:47:33,978] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 17:47:46,651] {scheduler_job.py:155} INFO - Started process (PID=984) to work on /airflow/dags/download_data.py
[2022-02-18 17:47:46,657] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:47:46,659] {logging_mixin.py:112} INFO - [2022-02-18 17:47:46,659] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:47:47,097] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:47:47,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:47:47,162] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:47:47,168] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 17:47:59,933] {scheduler_job.py:155} INFO - Started process (PID=1010) to work on /airflow/dags/download_data.py
[2022-02-18 17:47:59,937] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:47:59,939] {logging_mixin.py:112} INFO - [2022-02-18 17:47:59,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:48:00,372] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:48:00,421] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:48:00,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:48:00,434] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 17:48:13,219] {scheduler_job.py:155} INFO - Started process (PID=1036) to work on /airflow/dags/download_data.py
[2022-02-18 17:48:13,225] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:48:13,227] {logging_mixin.py:112} INFO - [2022-02-18 17:48:13,227] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:48:13,683] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:48:13,743] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:48:13,755] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:48:13,761] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 17:48:26,450] {scheduler_job.py:155} INFO - Started process (PID=1062) to work on /airflow/dags/download_data.py
[2022-02-18 17:48:26,455] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:48:26,460] {logging_mixin.py:112} INFO - [2022-02-18 17:48:26,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:48:26,918] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:48:26,965] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:48:26,974] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:48:26,979] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 17:48:39,781] {scheduler_job.py:155} INFO - Started process (PID=1088) to work on /airflow/dags/download_data.py
[2022-02-18 17:48:39,787] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:48:39,788] {logging_mixin.py:112} INFO - [2022-02-18 17:48:39,788] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:48:40,235] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:48:40,278] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:48:40,286] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:48:40,291] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 17:48:54,448] {scheduler_job.py:155} INFO - Started process (PID=1114) to work on /airflow/dags/download_data.py
[2022-02-18 17:48:54,500] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:48:54,505] {logging_mixin.py:112} INFO - [2022-02-18 17:48:54,505] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:48:55,087] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:48:55,166] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:48:55,176] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:48:55,183] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.735 seconds
[2022-02-18 17:49:07,762] {scheduler_job.py:155} INFO - Started process (PID=1140) to work on /airflow/dags/download_data.py
[2022-02-18 17:49:07,771] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:49:07,773] {logging_mixin.py:112} INFO - [2022-02-18 17:49:07,772] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:49:08,224] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:49:08,279] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:49:08,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:49:08,294] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 17:49:32,950] {scheduler_job.py:155} INFO - Started process (PID=1166) to work on /airflow/dags/download_data.py
[2022-02-18 17:49:32,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:49:32,955] {logging_mixin.py:112} INFO - [2022-02-18 17:49:32,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:49:33,422] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:49:33,472] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:49:33,480] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:49:33,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 17:49:46,243] {scheduler_job.py:155} INFO - Started process (PID=1192) to work on /airflow/dags/download_data.py
[2022-02-18 17:49:46,249] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:49:46,251] {logging_mixin.py:112} INFO - [2022-02-18 17:49:46,250] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:49:46,780] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:49:46,833] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:49:46,841] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:49:46,845] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 17:49:59,512] {scheduler_job.py:155} INFO - Started process (PID=1218) to work on /airflow/dags/download_data.py
[2022-02-18 17:49:59,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:49:59,518] {logging_mixin.py:112} INFO - [2022-02-18 17:49:59,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:49:59,955] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:50:00,005] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:50:00,017] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:50:00,023] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 17:50:12,780] {scheduler_job.py:155} INFO - Started process (PID=1244) to work on /airflow/dags/download_data.py
[2022-02-18 17:50:12,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:50:12,787] {logging_mixin.py:112} INFO - [2022-02-18 17:50:12,787] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:50:13,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:50:13,280] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:50:13,287] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:50:13,292] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 17:50:26,046] {scheduler_job.py:155} INFO - Started process (PID=1270) to work on /airflow/dags/download_data.py
[2022-02-18 17:50:26,060] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:50:26,065] {logging_mixin.py:112} INFO - [2022-02-18 17:50:26,064] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:50:26,513] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:50:26,554] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:50:26,560] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:50:26,564] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 17:50:39,307] {scheduler_job.py:155} INFO - Started process (PID=1296) to work on /airflow/dags/download_data.py
[2022-02-18 17:50:39,312] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:50:39,314] {logging_mixin.py:112} INFO - [2022-02-18 17:50:39,314] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:50:39,761] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:50:39,811] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:50:39,817] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:50:39,823] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 17:50:52,588] {scheduler_job.py:155} INFO - Started process (PID=1322) to work on /airflow/dags/download_data.py
[2022-02-18 17:50:52,593] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:50:52,594] {logging_mixin.py:112} INFO - [2022-02-18 17:50:52,594] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:50:53,080] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:50:53,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:50:53,134] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:50:53,141] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 17:51:05,831] {scheduler_job.py:155} INFO - Started process (PID=1348) to work on /airflow/dags/download_data.py
[2022-02-18 17:51:05,834] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:51:05,837] {logging_mixin.py:112} INFO - [2022-02-18 17:51:05,837] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:51:06,283] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:51:06,324] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:51:06,330] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:51:06,334] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 17:51:19,132] {scheduler_job.py:155} INFO - Started process (PID=1374) to work on /airflow/dags/download_data.py
[2022-02-18 17:51:19,137] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:51:19,140] {logging_mixin.py:112} INFO - [2022-02-18 17:51:19,140] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:51:19,573] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:51:19,623] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:51:19,629] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:51:19,635] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 17:51:32,369] {scheduler_job.py:155} INFO - Started process (PID=1400) to work on /airflow/dags/download_data.py
[2022-02-18 17:51:32,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:51:32,374] {logging_mixin.py:112} INFO - [2022-02-18 17:51:32,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:51:32,824] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:51:32,871] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:51:32,877] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:51:32,881] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 17:51:45,649] {scheduler_job.py:155} INFO - Started process (PID=1426) to work on /airflow/dags/download_data.py
[2022-02-18 17:51:45,654] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:51:45,656] {logging_mixin.py:112} INFO - [2022-02-18 17:51:45,655] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:51:46,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:51:46,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:51:46,184] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:51:46,189] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 17:51:58,867] {scheduler_job.py:155} INFO - Started process (PID=1452) to work on /airflow/dags/download_data.py
[2022-02-18 17:51:58,872] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:51:58,874] {logging_mixin.py:112} INFO - [2022-02-18 17:51:58,874] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:51:59,408] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:51:59,448] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:51:59,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:51:59,468] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-18 17:52:12,189] {scheduler_job.py:155} INFO - Started process (PID=1478) to work on /airflow/dags/download_data.py
[2022-02-18 17:52:12,194] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:52:12,196] {logging_mixin.py:112} INFO - [2022-02-18 17:52:12,196] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:52:12,640] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:52:12,689] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:52:12,695] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:52:12,702] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 17:52:25,474] {scheduler_job.py:155} INFO - Started process (PID=1504) to work on /airflow/dags/download_data.py
[2022-02-18 17:52:25,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:52:25,480] {logging_mixin.py:112} INFO - [2022-02-18 17:52:25,480] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:52:25,946] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:52:25,996] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:52:26,003] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:52:26,009] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 17:52:38,951] {scheduler_job.py:155} INFO - Started process (PID=1530) to work on /airflow/dags/download_data.py
[2022-02-18 17:52:38,955] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:52:38,957] {logging_mixin.py:112} INFO - [2022-02-18 17:52:38,957] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:52:39,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:52:39,451] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:52:39,458] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:52:39,464] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 17:52:53,448] {scheduler_job.py:155} INFO - Started process (PID=1556) to work on /airflow/dags/download_data.py
[2022-02-18 17:52:53,453] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:52:53,455] {logging_mixin.py:112} INFO - [2022-02-18 17:52:53,454] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:52:53,895] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:52:53,942] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:52:53,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:52:53,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 17:53:12,774] {scheduler_job.py:155} INFO - Started process (PID=1582) to work on /airflow/dags/download_data.py
[2022-02-18 17:53:12,783] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:53:12,786] {logging_mixin.py:112} INFO - [2022-02-18 17:53:12,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:53:13,223] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:53:13,270] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:53:13,280] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:53:13,285] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 17:53:26,032] {scheduler_job.py:155} INFO - Started process (PID=1608) to work on /airflow/dags/download_data.py
[2022-02-18 17:53:26,036] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:53:26,038] {logging_mixin.py:112} INFO - [2022-02-18 17:53:26,038] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:53:26,480] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:53:26,532] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:53:26,538] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:53:26,546] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 17:53:39,328] {scheduler_job.py:155} INFO - Started process (PID=1634) to work on /airflow/dags/download_data.py
[2022-02-18 17:53:39,344] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:53:39,349] {logging_mixin.py:112} INFO - [2022-02-18 17:53:39,349] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:53:39,795] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:53:39,838] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:53:39,848] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:53:39,854] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 17:53:52,600] {scheduler_job.py:155} INFO - Started process (PID=1660) to work on /airflow/dags/download_data.py
[2022-02-18 17:53:52,607] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:53:52,608] {logging_mixin.py:112} INFO - [2022-02-18 17:53:52,608] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:53:53,148] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:53:53,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:53:53,208] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:53:53,213] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 17:54:05,842] {scheduler_job.py:155} INFO - Started process (PID=1686) to work on /airflow/dags/download_data.py
[2022-02-18 17:54:05,847] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:54:05,849] {logging_mixin.py:112} INFO - [2022-02-18 17:54:05,849] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:54:06,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:54:06,333] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:54:06,341] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:54:06,346] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 17:54:19,120] {scheduler_job.py:155} INFO - Started process (PID=1712) to work on /airflow/dags/download_data.py
[2022-02-18 17:54:19,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:54:19,132] {logging_mixin.py:112} INFO - [2022-02-18 17:54:19,131] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:54:19,590] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:54:19,630] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:54:19,635] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:54:19,639] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 17:54:32,412] {scheduler_job.py:155} INFO - Started process (PID=1738) to work on /airflow/dags/download_data.py
[2022-02-18 17:54:32,416] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:54:32,419] {logging_mixin.py:112} INFO - [2022-02-18 17:54:32,418] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:54:32,873] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:54:32,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:54:32,937] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:54:32,942] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 17:54:45,681] {scheduler_job.py:155} INFO - Started process (PID=1764) to work on /airflow/dags/download_data.py
[2022-02-18 17:54:45,688] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:54:45,690] {logging_mixin.py:112} INFO - [2022-02-18 17:54:45,690] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:54:46,256] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:54:46,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:54:46,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:54:46,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-18 17:54:58,956] {scheduler_job.py:155} INFO - Started process (PID=1790) to work on /airflow/dags/download_data.py
[2022-02-18 17:54:58,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:54:58,963] {logging_mixin.py:112} INFO - [2022-02-18 17:54:58,962] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:54:59,403] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:54:59,455] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:54:59,462] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:54:59,469] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 17:55:12,219] {scheduler_job.py:155} INFO - Started process (PID=1816) to work on /airflow/dags/download_data.py
[2022-02-18 17:55:12,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:55:12,229] {logging_mixin.py:112} INFO - [2022-02-18 17:55:12,229] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:55:12,677] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:55:12,722] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:55:12,733] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:55:12,740] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 17:55:25,512] {scheduler_job.py:155} INFO - Started process (PID=1842) to work on /airflow/dags/download_data.py
[2022-02-18 17:55:25,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:55:25,518] {logging_mixin.py:112} INFO - [2022-02-18 17:55:25,518] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:55:26,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:55:26,061] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:55:26,068] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:55:26,073] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 17:55:38,817] {scheduler_job.py:155} INFO - Started process (PID=1868) to work on /airflow/dags/download_data.py
[2022-02-18 17:55:38,826] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:55:38,828] {logging_mixin.py:112} INFO - [2022-02-18 17:55:38,827] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:55:39,288] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:55:39,330] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:55:39,341] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:55:39,346] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 17:55:52,083] {scheduler_job.py:155} INFO - Started process (PID=1894) to work on /airflow/dags/download_data.py
[2022-02-18 17:55:52,087] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:55:52,090] {logging_mixin.py:112} INFO - [2022-02-18 17:55:52,089] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:55:52,589] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:55:52,652] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:55:52,666] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:55:52,676] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 17:56:05,322] {scheduler_job.py:155} INFO - Started process (PID=1920) to work on /airflow/dags/download_data.py
[2022-02-18 17:56:05,328] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:56:05,330] {logging_mixin.py:112} INFO - [2022-02-18 17:56:05,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:56:05,809] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:56:05,861] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:56:05,870] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:56:05,876] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 17:56:18,597] {scheduler_job.py:155} INFO - Started process (PID=1946) to work on /airflow/dags/download_data.py
[2022-02-18 17:56:18,602] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:56:18,604] {logging_mixin.py:112} INFO - [2022-02-18 17:56:18,604] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:56:19,131] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:56:19,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:56:19,190] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:56:19,195] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 17:56:31,883] {scheduler_job.py:155} INFO - Started process (PID=1972) to work on /airflow/dags/download_data.py
[2022-02-18 17:56:31,891] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:56:31,894] {logging_mixin.py:112} INFO - [2022-02-18 17:56:31,893] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:56:32,413] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:56:32,467] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:56:32,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:56:32,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 17:56:45,140] {scheduler_job.py:155} INFO - Started process (PID=1998) to work on /airflow/dags/download_data.py
[2022-02-18 17:56:45,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:56:45,149] {logging_mixin.py:112} INFO - [2022-02-18 17:56:45,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:56:45,678] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:56:45,735] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:56:45,746] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:56:45,755] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-18 17:56:58,425] {scheduler_job.py:155} INFO - Started process (PID=2024) to work on /airflow/dags/download_data.py
[2022-02-18 17:56:58,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:56:58,432] {logging_mixin.py:112} INFO - [2022-02-18 17:56:58,432] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:56:58,926] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:56:58,976] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:56:58,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:56:58,989] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 17:57:11,674] {scheduler_job.py:155} INFO - Started process (PID=2050) to work on /airflow/dags/download_data.py
[2022-02-18 17:57:11,678] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:57:11,680] {logging_mixin.py:112} INFO - [2022-02-18 17:57:11,679] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:57:12,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:57:12,216] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:57:12,224] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:57:12,229] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 17:57:24,951] {scheduler_job.py:155} INFO - Started process (PID=2076) to work on /airflow/dags/download_data.py
[2022-02-18 17:57:24,962] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:57:24,965] {logging_mixin.py:112} INFO - [2022-02-18 17:57:24,965] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:57:25,475] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:57:25,540] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:57:25,552] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:57:25,559] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 17:57:38,192] {scheduler_job.py:155} INFO - Started process (PID=2102) to work on /airflow/dags/download_data.py
[2022-02-18 17:57:38,197] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:57:38,198] {logging_mixin.py:112} INFO - [2022-02-18 17:57:38,198] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:57:38,662] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:57:38,727] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:57:38,734] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:57:38,739] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 17:57:51,481] {scheduler_job.py:155} INFO - Started process (PID=2128) to work on /airflow/dags/download_data.py
[2022-02-18 17:57:51,490] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:57:51,492] {logging_mixin.py:112} INFO - [2022-02-18 17:57:51,492] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:57:51,980] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:57:52,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:57:52,031] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:57:52,036] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 17:58:04,730] {scheduler_job.py:155} INFO - Started process (PID=2154) to work on /airflow/dags/download_data.py
[2022-02-18 17:58:04,734] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:58:04,736] {logging_mixin.py:112} INFO - [2022-02-18 17:58:04,736] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:58:05,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:58:05,293] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:58:05,300] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:58:05,304] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-18 17:58:18,019] {scheduler_job.py:155} INFO - Started process (PID=2180) to work on /airflow/dags/download_data.py
[2022-02-18 17:58:18,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:58:18,029] {logging_mixin.py:112} INFO - [2022-02-18 17:58:18,029] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:58:18,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:58:18,521] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:58:18,533] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:58:18,540] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 17:58:31,328] {scheduler_job.py:155} INFO - Started process (PID=2206) to work on /airflow/dags/download_data.py
[2022-02-18 17:58:31,336] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:58:31,339] {logging_mixin.py:112} INFO - [2022-02-18 17:58:31,339] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:58:31,779] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:58:31,831] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:58:31,838] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:58:31,843] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 17:58:44,601] {scheduler_job.py:155} INFO - Started process (PID=2232) to work on /airflow/dags/download_data.py
[2022-02-18 17:58:44,607] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:58:44,610] {logging_mixin.py:112} INFO - [2022-02-18 17:58:44,609] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:58:45,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:58:45,092] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:58:45,099] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:58:45,105] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 17:58:57,870] {scheduler_job.py:155} INFO - Started process (PID=2258) to work on /airflow/dags/download_data.py
[2022-02-18 17:58:57,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:58:57,877] {logging_mixin.py:112} INFO - [2022-02-18 17:58:57,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:58:58,316] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:58:58,363] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:58:58,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:58:58,376] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 17:59:11,117] {scheduler_job.py:155} INFO - Started process (PID=2284) to work on /airflow/dags/download_data.py
[2022-02-18 17:59:11,126] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:59:11,128] {logging_mixin.py:112} INFO - [2022-02-18 17:59:11,128] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:59:11,570] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:59:11,620] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:59:11,629] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:59:11,635] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 17:59:24,431] {scheduler_job.py:155} INFO - Started process (PID=2310) to work on /airflow/dags/download_data.py
[2022-02-18 17:59:24,441] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:59:24,443] {logging_mixin.py:112} INFO - [2022-02-18 17:59:24,442] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:59:24,884] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:59:24,925] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:59:24,930] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:59:24,934] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 17:59:37,652] {scheduler_job.py:155} INFO - Started process (PID=2336) to work on /airflow/dags/download_data.py
[2022-02-18 17:59:37,657] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:59:37,658] {logging_mixin.py:112} INFO - [2022-02-18 17:59:37,658] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:59:38,106] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:59:38,153] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:59:38,165] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:59:38,170] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 17:59:51,001] {scheduler_job.py:155} INFO - Started process (PID=2362) to work on /airflow/dags/download_data.py
[2022-02-18 17:59:51,014] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 17:59:51,017] {logging_mixin.py:112} INFO - [2022-02-18 17:59:51,017] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 17:59:51,541] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 17:59:51,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 17:59:51,621] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 17:59:51,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-18 18:00:04,261] {scheduler_job.py:155} INFO - Started process (PID=2388) to work on /airflow/dags/download_data.py
[2022-02-18 18:00:04,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:00:04,268] {logging_mixin.py:112} INFO - [2022-02-18 18:00:04,267] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:00:04,732] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:00:04,774] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:00:04,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:00:04,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 18:00:17,568] {scheduler_job.py:155} INFO - Started process (PID=2414) to work on /airflow/dags/download_data.py
[2022-02-18 18:00:17,575] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:00:17,577] {logging_mixin.py:112} INFO - [2022-02-18 18:00:17,577] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:00:18,015] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:00:18,067] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:00:18,079] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:00:18,083] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 18:00:30,847] {scheduler_job.py:155} INFO - Started process (PID=2440) to work on /airflow/dags/download_data.py
[2022-02-18 18:00:30,855] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:00:30,858] {logging_mixin.py:112} INFO - [2022-02-18 18:00:30,858] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:00:31,332] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:00:31,388] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:00:31,396] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:00:31,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 18:00:44,093] {scheduler_job.py:155} INFO - Started process (PID=2466) to work on /airflow/dags/download_data.py
[2022-02-18 18:00:44,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:00:44,101] {logging_mixin.py:112} INFO - [2022-02-18 18:00:44,101] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:00:44,546] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:00:44,593] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:00:44,602] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:00:44,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 18:00:57,356] {scheduler_job.py:155} INFO - Started process (PID=2492) to work on /airflow/dags/download_data.py
[2022-02-18 18:00:57,361] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:00:57,363] {logging_mixin.py:112} INFO - [2022-02-18 18:00:57,363] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:00:57,859] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:00:57,910] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:00:57,921] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:00:57,928] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 18:01:10,582] {scheduler_job.py:155} INFO - Started process (PID=2518) to work on /airflow/dags/download_data.py
[2022-02-18 18:01:10,587] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:01:10,589] {logging_mixin.py:112} INFO - [2022-02-18 18:01:10,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:01:11,048] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:01:11,101] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:01:11,110] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:01:11,116] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 18:01:23,876] {scheduler_job.py:155} INFO - Started process (PID=2544) to work on /airflow/dags/download_data.py
[2022-02-18 18:01:23,880] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:01:23,882] {logging_mixin.py:112} INFO - [2022-02-18 18:01:23,882] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:01:24,382] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:01:24,432] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:01:24,439] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:01:24,443] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 18:01:37,121] {scheduler_job.py:155} INFO - Started process (PID=2570) to work on /airflow/dags/download_data.py
[2022-02-18 18:01:37,126] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:01:37,127] {logging_mixin.py:112} INFO - [2022-02-18 18:01:37,127] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:01:37,581] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:01:37,630] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:01:37,636] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:01:37,641] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 18:01:50,397] {scheduler_job.py:155} INFO - Started process (PID=2596) to work on /airflow/dags/download_data.py
[2022-02-18 18:01:50,405] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:01:50,408] {logging_mixin.py:112} INFO - [2022-02-18 18:01:50,407] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:01:50,891] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:01:50,952] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:01:50,961] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:01:50,965] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 18:02:03,655] {scheduler_job.py:155} INFO - Started process (PID=2622) to work on /airflow/dags/download_data.py
[2022-02-18 18:02:03,659] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:02:03,661] {logging_mixin.py:112} INFO - [2022-02-18 18:02:03,661] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:02:04,101] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:02:04,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:02:04,164] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:02:04,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 18:02:16,941] {scheduler_job.py:155} INFO - Started process (PID=2648) to work on /airflow/dags/download_data.py
[2022-02-18 18:02:16,948] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:02:16,950] {logging_mixin.py:112} INFO - [2022-02-18 18:02:16,950] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:02:17,442] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:02:17,494] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:02:17,503] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:02:17,507] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 18:02:30,224] {scheduler_job.py:155} INFO - Started process (PID=2674) to work on /airflow/dags/download_data.py
[2022-02-18 18:02:30,234] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:02:30,236] {logging_mixin.py:112} INFO - [2022-02-18 18:02:30,236] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:02:30,718] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:02:30,773] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:02:30,781] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:02:30,784] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 18:02:43,439] {scheduler_job.py:155} INFO - Started process (PID=2700) to work on /airflow/dags/download_data.py
[2022-02-18 18:02:43,444] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:02:43,445] {logging_mixin.py:112} INFO - [2022-02-18 18:02:43,445] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:02:43,930] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:02:43,980] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:02:43,988] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:02:43,992] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 18:02:56,736] {scheduler_job.py:155} INFO - Started process (PID=2726) to work on /airflow/dags/download_data.py
[2022-02-18 18:02:56,741] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:02:56,743] {logging_mixin.py:112} INFO - [2022-02-18 18:02:56,743] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:02:57,194] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:02:57,245] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:02:57,253] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:02:57,257] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 18:03:09,975] {scheduler_job.py:155} INFO - Started process (PID=2752) to work on /airflow/dags/download_data.py
[2022-02-18 18:03:09,980] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:03:09,986] {logging_mixin.py:112} INFO - [2022-02-18 18:03:09,985] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:03:10,419] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:03:10,468] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:03:10,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:03:10,488] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 18:03:23,261] {scheduler_job.py:155} INFO - Started process (PID=2778) to work on /airflow/dags/download_data.py
[2022-02-18 18:03:23,272] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:03:23,276] {logging_mixin.py:112} INFO - [2022-02-18 18:03:23,275] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:03:23,805] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:03:23,860] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:03:23,876] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:03:23,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-18 18:03:36,534] {scheduler_job.py:155} INFO - Started process (PID=2804) to work on /airflow/dags/download_data.py
[2022-02-18 18:03:36,538] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:03:36,540] {logging_mixin.py:112} INFO - [2022-02-18 18:03:36,540] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:03:37,031] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:03:37,090] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:03:37,097] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:03:37,103] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-18 18:03:49,810] {scheduler_job.py:155} INFO - Started process (PID=2830) to work on /airflow/dags/download_data.py
[2022-02-18 18:03:49,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:03:49,820] {logging_mixin.py:112} INFO - [2022-02-18 18:03:49,819] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:03:50,278] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:03:50,333] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:03:50,338] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:03:50,342] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 18:04:03,074] {scheduler_job.py:155} INFO - Started process (PID=2856) to work on /airflow/dags/download_data.py
[2022-02-18 18:04:03,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:04:03,085] {logging_mixin.py:112} INFO - [2022-02-18 18:04:03,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:04:03,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:04:03,593] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:04:03,604] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:04:03,610] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 18:04:16,366] {scheduler_job.py:155} INFO - Started process (PID=2882) to work on /airflow/dags/download_data.py
[2022-02-18 18:04:16,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:04:16,375] {logging_mixin.py:112} INFO - [2022-02-18 18:04:16,375] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:04:16,821] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:04:16,869] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:04:16,879] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:04:16,884] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 18:04:29,646] {scheduler_job.py:155} INFO - Started process (PID=2908) to work on /airflow/dags/download_data.py
[2022-02-18 18:04:29,650] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:04:29,651] {logging_mixin.py:112} INFO - [2022-02-18 18:04:29,651] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:04:30,088] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:04:30,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:04:30,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:04:30,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 18:04:42,895] {scheduler_job.py:155} INFO - Started process (PID=2934) to work on /airflow/dags/download_data.py
[2022-02-18 18:04:42,900] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:04:42,902] {logging_mixin.py:112} INFO - [2022-02-18 18:04:42,901] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:04:43,443] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:04:43,498] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:04:43,508] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:04:43,512] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-18 18:04:56,231] {scheduler_job.py:155} INFO - Started process (PID=2960) to work on /airflow/dags/download_data.py
[2022-02-18 18:04:56,239] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:04:56,242] {logging_mixin.py:112} INFO - [2022-02-18 18:04:56,241] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:04:56,678] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:04:56,731] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:04:56,738] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:04:56,742] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 18:05:09,484] {scheduler_job.py:155} INFO - Started process (PID=2986) to work on /airflow/dags/download_data.py
[2022-02-18 18:05:09,491] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:05:09,492] {logging_mixin.py:112} INFO - [2022-02-18 18:05:09,492] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:05:09,975] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:05:10,025] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:05:10,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:05:10,040] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 18:05:22,792] {scheduler_job.py:155} INFO - Started process (PID=3012) to work on /airflow/dags/download_data.py
[2022-02-18 18:05:22,796] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:05:22,797] {logging_mixin.py:112} INFO - [2022-02-18 18:05:22,797] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:05:23,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:05:23,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:05:23,320] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:05:23,326] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 18:05:36,019] {scheduler_job.py:155} INFO - Started process (PID=3038) to work on /airflow/dags/download_data.py
[2022-02-18 18:05:36,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:05:36,025] {logging_mixin.py:112} INFO - [2022-02-18 18:05:36,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:05:36,487] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:05:36,542] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:05:36,550] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:05:36,555] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 18:05:49,308] {scheduler_job.py:155} INFO - Started process (PID=3064) to work on /airflow/dags/download_data.py
[2022-02-18 18:05:49,316] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:05:49,319] {logging_mixin.py:112} INFO - [2022-02-18 18:05:49,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:05:49,778] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:05:49,833] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:05:49,839] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:05:49,842] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 18:06:02,577] {scheduler_job.py:155} INFO - Started process (PID=3090) to work on /airflow/dags/download_data.py
[2022-02-18 18:06:02,586] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:06:02,590] {logging_mixin.py:112} INFO - [2022-02-18 18:06:02,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:06:03,184] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:06:03,237] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:06:03,243] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:06:03,254] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-18 18:06:15,849] {scheduler_job.py:155} INFO - Started process (PID=3116) to work on /airflow/dags/download_data.py
[2022-02-18 18:06:15,856] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:06:15,858] {logging_mixin.py:112} INFO - [2022-02-18 18:06:15,858] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:06:16,350] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:06:16,403] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:06:16,410] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:06:16,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-18 18:06:29,129] {scheduler_job.py:155} INFO - Started process (PID=3142) to work on /airflow/dags/download_data.py
[2022-02-18 18:06:29,136] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:06:29,138] {logging_mixin.py:112} INFO - [2022-02-18 18:06:29,138] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:06:29,613] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:06:29,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:06:29,677] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:06:29,683] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 18:06:42,430] {scheduler_job.py:155} INFO - Started process (PID=3168) to work on /airflow/dags/download_data.py
[2022-02-18 18:06:42,436] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:06:42,443] {logging_mixin.py:112} INFO - [2022-02-18 18:06:42,442] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:06:42,956] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:06:43,012] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:06:43,022] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:06:43,027] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-18 18:06:55,726] {scheduler_job.py:155} INFO - Started process (PID=3194) to work on /airflow/dags/download_data.py
[2022-02-18 18:06:55,731] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:06:55,733] {logging_mixin.py:112} INFO - [2022-02-18 18:06:55,733] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:06:56,169] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:06:56,220] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:06:56,231] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:06:56,237] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 18:07:08,939] {scheduler_job.py:155} INFO - Started process (PID=3220) to work on /airflow/dags/download_data.py
[2022-02-18 18:07:08,945] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:07:08,946] {logging_mixin.py:112} INFO - [2022-02-18 18:07:08,946] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:07:09,431] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:07:09,498] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:07:09,505] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:07:09,510] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 18:07:22,235] {scheduler_job.py:155} INFO - Started process (PID=3246) to work on /airflow/dags/download_data.py
[2022-02-18 18:07:22,256] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:07:22,258] {logging_mixin.py:112} INFO - [2022-02-18 18:07:22,258] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:07:22,871] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:07:22,937] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:07:22,944] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:07:22,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.713 seconds
[2022-02-18 18:07:35,454] {scheduler_job.py:155} INFO - Started process (PID=3272) to work on /airflow/dags/download_data.py
[2022-02-18 18:07:35,458] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:07:35,461] {logging_mixin.py:112} INFO - [2022-02-18 18:07:35,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:07:35,920] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:07:35,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:07:35,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:07:35,991] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 18:07:48,757] {scheduler_job.py:155} INFO - Started process (PID=3298) to work on /airflow/dags/download_data.py
[2022-02-18 18:07:48,764] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:07:48,766] {logging_mixin.py:112} INFO - [2022-02-18 18:07:48,766] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:07:49,243] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:07:49,291] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:07:49,300] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:07:49,305] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 18:08:02,036] {scheduler_job.py:155} INFO - Started process (PID=3324) to work on /airflow/dags/download_data.py
[2022-02-18 18:08:02,042] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:08:02,043] {logging_mixin.py:112} INFO - [2022-02-18 18:08:02,043] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:08:02,488] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:08:02,535] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:08:02,542] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:08:02,547] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 18:08:15,290] {scheduler_job.py:155} INFO - Started process (PID=3350) to work on /airflow/dags/download_data.py
[2022-02-18 18:08:15,303] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:08:15,308] {logging_mixin.py:112} INFO - [2022-02-18 18:08:15,308] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:08:15,807] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:08:15,853] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:08:15,863] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:08:15,867] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 18:08:28,613] {scheduler_job.py:155} INFO - Started process (PID=3376) to work on /airflow/dags/download_data.py
[2022-02-18 18:08:28,621] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:08:28,625] {logging_mixin.py:112} INFO - [2022-02-18 18:08:28,625] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:08:29,112] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:08:29,161] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:08:29,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:08:29,183] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 18:08:41,873] {scheduler_job.py:155} INFO - Started process (PID=3402) to work on /airflow/dags/download_data.py
[2022-02-18 18:08:41,880] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:08:41,883] {logging_mixin.py:112} INFO - [2022-02-18 18:08:41,882] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:08:42,385] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:08:42,445] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:08:42,456] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:08:42,462] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 18:08:55,164] {scheduler_job.py:155} INFO - Started process (PID=3428) to work on /airflow/dags/download_data.py
[2022-02-18 18:08:55,183] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:08:55,184] {logging_mixin.py:112} INFO - [2022-02-18 18:08:55,184] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:08:55,685] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:08:55,734] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:08:55,745] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:08:55,750] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 18:09:08,403] {scheduler_job.py:155} INFO - Started process (PID=3454) to work on /airflow/dags/download_data.py
[2022-02-18 18:09:08,409] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:09:08,411] {logging_mixin.py:112} INFO - [2022-02-18 18:09:08,411] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:09:08,918] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:09:08,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:09:08,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:09:08,990] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 18:09:21,670] {scheduler_job.py:155} INFO - Started process (PID=3480) to work on /airflow/dags/download_data.py
[2022-02-18 18:09:21,676] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:09:21,678] {logging_mixin.py:112} INFO - [2022-02-18 18:09:21,678] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:09:22,212] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:09:22,261] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:09:22,269] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:09:22,273] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 18:09:35,066] {scheduler_job.py:155} INFO - Started process (PID=3506) to work on /airflow/dags/download_data.py
[2022-02-18 18:09:35,071] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:09:35,073] {logging_mixin.py:112} INFO - [2022-02-18 18:09:35,072] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:09:35,542] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:09:35,591] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:09:35,599] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:09:35,602] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 18:09:48,349] {scheduler_job.py:155} INFO - Started process (PID=3532) to work on /airflow/dags/download_data.py
[2022-02-18 18:09:48,360] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:09:48,363] {logging_mixin.py:112} INFO - [2022-02-18 18:09:48,362] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:09:48,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:09:48,868] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:09:48,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:09:48,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 18:10:01,658] {scheduler_job.py:155} INFO - Started process (PID=3558) to work on /airflow/dags/download_data.py
[2022-02-18 18:10:01,666] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:10:01,669] {logging_mixin.py:112} INFO - [2022-02-18 18:10:01,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:10:02,145] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:10:02,205] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:10:02,212] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:10:02,217] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 18:10:14,910] {scheduler_job.py:155} INFO - Started process (PID=3584) to work on /airflow/dags/download_data.py
[2022-02-18 18:10:14,920] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:10:14,925] {logging_mixin.py:112} INFO - [2022-02-18 18:10:14,924] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:10:15,374] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:10:15,428] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:10:15,438] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:10:15,446] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 18:10:28,201] {scheduler_job.py:155} INFO - Started process (PID=3610) to work on /airflow/dags/download_data.py
[2022-02-18 18:10:28,206] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:10:28,207] {logging_mixin.py:112} INFO - [2022-02-18 18:10:28,207] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:10:28,693] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:10:28,751] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:10:28,759] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:10:28,765] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 18:10:41,433] {scheduler_job.py:155} INFO - Started process (PID=3636) to work on /airflow/dags/download_data.py
[2022-02-18 18:10:41,442] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:10:41,444] {logging_mixin.py:112} INFO - [2022-02-18 18:10:41,444] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:10:41,904] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:10:41,954] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:10:41,963] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:10:41,970] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 18:10:54,714] {scheduler_job.py:155} INFO - Started process (PID=3662) to work on /airflow/dags/download_data.py
[2022-02-18 18:10:54,718] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:10:54,719] {logging_mixin.py:112} INFO - [2022-02-18 18:10:54,719] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:10:55,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:10:55,201] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:10:55,208] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:10:55,212] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 18:11:07,973] {scheduler_job.py:155} INFO - Started process (PID=3688) to work on /airflow/dags/download_data.py
[2022-02-18 18:11:07,983] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:11:07,985] {logging_mixin.py:112} INFO - [2022-02-18 18:11:07,985] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:11:08,420] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:11:08,487] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:11:08,494] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:11:08,499] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 18:11:21,225] {scheduler_job.py:155} INFO - Started process (PID=3714) to work on /airflow/dags/download_data.py
[2022-02-18 18:11:21,230] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:11:21,232] {logging_mixin.py:112} INFO - [2022-02-18 18:11:21,232] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:11:21,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:11:21,769] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:11:21,778] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:11:21,787] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 18:11:34,468] {scheduler_job.py:155} INFO - Started process (PID=3740) to work on /airflow/dags/download_data.py
[2022-02-18 18:11:34,477] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:11:34,480] {logging_mixin.py:112} INFO - [2022-02-18 18:11:34,480] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:11:34,957] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:11:35,012] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:11:35,019] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:11:35,025] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 18:11:47,775] {scheduler_job.py:155} INFO - Started process (PID=3766) to work on /airflow/dags/download_data.py
[2022-02-18 18:11:47,781] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:11:47,783] {logging_mixin.py:112} INFO - [2022-02-18 18:11:47,783] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:11:48,232] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:11:48,278] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:11:48,285] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:11:48,290] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 18:12:01,041] {scheduler_job.py:155} INFO - Started process (PID=3792) to work on /airflow/dags/download_data.py
[2022-02-18 18:12:01,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:12:01,048] {logging_mixin.py:112} INFO - [2022-02-18 18:12:01,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:12:01,499] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:12:01,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:12:01,561] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:12:01,565] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 18:12:14,292] {scheduler_job.py:155} INFO - Started process (PID=3818) to work on /airflow/dags/download_data.py
[2022-02-18 18:12:14,301] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:12:14,303] {logging_mixin.py:112} INFO - [2022-02-18 18:12:14,303] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:12:14,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:12:14,836] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:12:14,845] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:12:14,851] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 18:12:27,566] {scheduler_job.py:155} INFO - Started process (PID=3844) to work on /airflow/dags/download_data.py
[2022-02-18 18:12:27,573] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:12:27,577] {logging_mixin.py:112} INFO - [2022-02-18 18:12:27,576] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:12:28,017] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:12:28,066] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:12:28,075] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:12:28,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 18:12:40,808] {scheduler_job.py:155} INFO - Started process (PID=3870) to work on /airflow/dags/download_data.py
[2022-02-18 18:12:40,813] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:12:40,815] {logging_mixin.py:112} INFO - [2022-02-18 18:12:40,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:12:41,276] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:12:41,325] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:12:41,337] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:12:41,341] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 18:12:54,086] {scheduler_job.py:155} INFO - Started process (PID=3896) to work on /airflow/dags/download_data.py
[2022-02-18 18:12:54,090] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:12:54,092] {logging_mixin.py:112} INFO - [2022-02-18 18:12:54,092] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:12:54,538] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:12:54,586] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:12:54,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:12:54,603] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 18:13:07,344] {scheduler_job.py:155} INFO - Started process (PID=3922) to work on /airflow/dags/download_data.py
[2022-02-18 18:13:07,349] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:13:07,351] {logging_mixin.py:112} INFO - [2022-02-18 18:13:07,351] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:13:07,796] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:13:07,826] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:13:07,832] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:13:07,835] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 18:13:20,639] {scheduler_job.py:155} INFO - Started process (PID=3948) to work on /airflow/dags/download_data.py
[2022-02-18 18:13:20,645] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:13:20,647] {logging_mixin.py:112} INFO - [2022-02-18 18:13:20,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:13:21,092] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:13:21,142] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:13:21,150] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:13:21,157] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 18:13:33,908] {scheduler_job.py:155} INFO - Started process (PID=3974) to work on /airflow/dags/download_data.py
[2022-02-18 18:13:33,912] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:13:33,914] {logging_mixin.py:112} INFO - [2022-02-18 18:13:33,914] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:13:34,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:13:34,403] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:13:34,412] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:13:34,416] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 18:13:47,165] {scheduler_job.py:155} INFO - Started process (PID=4000) to work on /airflow/dags/download_data.py
[2022-02-18 18:13:47,169] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:13:47,170] {logging_mixin.py:112} INFO - [2022-02-18 18:13:47,170] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:13:47,606] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:13:47,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:13:47,669] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:13:47,675] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 18:14:00,459] {scheduler_job.py:155} INFO - Started process (PID=4026) to work on /airflow/dags/download_data.py
[2022-02-18 18:14:00,463] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:14:00,464] {logging_mixin.py:112} INFO - [2022-02-18 18:14:00,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:14:00,911] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:14:00,966] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:14:00,977] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:14:00,981] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 18:14:13,693] {scheduler_job.py:155} INFO - Started process (PID=4052) to work on /airflow/dags/download_data.py
[2022-02-18 18:14:13,703] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:14:13,706] {logging_mixin.py:112} INFO - [2022-02-18 18:14:13,705] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:14:14,146] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:14:14,197] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:14:14,210] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:14:14,216] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 18:14:26,943] {scheduler_job.py:155} INFO - Started process (PID=4078) to work on /airflow/dags/download_data.py
[2022-02-18 18:14:26,948] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:14:26,949] {logging_mixin.py:112} INFO - [2022-02-18 18:14:26,949] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:14:27,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:14:27,425] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:14:27,430] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:14:27,433] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.490 seconds
[2022-02-18 18:14:40,230] {scheduler_job.py:155} INFO - Started process (PID=4104) to work on /airflow/dags/download_data.py
[2022-02-18 18:14:40,234] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:14:40,235] {logging_mixin.py:112} INFO - [2022-02-18 18:14:40,235] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:14:40,716] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:14:40,771] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:14:40,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:14:40,782] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 18:14:53,545] {scheduler_job.py:155} INFO - Started process (PID=4130) to work on /airflow/dags/download_data.py
[2022-02-18 18:14:53,551] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:14:53,553] {logging_mixin.py:112} INFO - [2022-02-18 18:14:53,553] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:14:54,018] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:14:54,057] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:14:54,063] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:14:54,067] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 18:15:07,055] {scheduler_job.py:155} INFO - Started process (PID=4156) to work on /airflow/dags/download_data.py
[2022-02-18 18:15:07,062] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:15:07,064] {logging_mixin.py:112} INFO - [2022-02-18 18:15:07,064] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:15:07,528] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:15:07,577] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:15:07,592] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:15:07,608] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 18:15:21,537] {scheduler_job.py:155} INFO - Started process (PID=4182) to work on /airflow/dags/download_data.py
[2022-02-18 18:15:21,549] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:15:21,552] {logging_mixin.py:112} INFO - [2022-02-18 18:15:21,551] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:15:22,464] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:15:22,586] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:15:22,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:15:22,628] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.092 seconds
[2022-02-18 18:38:52,750] {scheduler_job.py:155} INFO - Started process (PID=4208) to work on /airflow/dags/download_data.py
[2022-02-18 18:38:52,761] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:38:52,763] {logging_mixin.py:112} INFO - [2022-02-18 18:38:52,763] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:38:53,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:38:53,321] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:38:53,329] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:38:53,335] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-18 18:39:05,013] {scheduler_job.py:155} INFO - Started process (PID=4233) to work on /airflow/dags/download_data.py
[2022-02-18 18:39:05,020] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:39:05,022] {logging_mixin.py:112} INFO - [2022-02-18 18:39:05,022] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:39:05,514] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:39:05,574] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:39:05,583] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:39:05,590] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 18:39:18,302] {scheduler_job.py:155} INFO - Started process (PID=4259) to work on /airflow/dags/download_data.py
[2022-02-18 18:39:18,307] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:39:18,309] {logging_mixin.py:112} INFO - [2022-02-18 18:39:18,309] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:39:19,380] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:39:19,432] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:39:19,444] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:39:19,448] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.146 seconds
[2022-02-18 18:39:32,233] {scheduler_job.py:155} INFO - Started process (PID=4285) to work on /airflow/dags/download_data.py
[2022-02-18 18:39:32,241] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:39:32,243] {logging_mixin.py:112} INFO - [2022-02-18 18:39:32,243] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:39:32,699] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:39:32,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:39:32,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:39:32,754] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 18:39:45,555] {scheduler_job.py:155} INFO - Started process (PID=4311) to work on /airflow/dags/download_data.py
[2022-02-18 18:39:45,565] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:39:45,567] {logging_mixin.py:112} INFO - [2022-02-18 18:39:45,567] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:39:46,013] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:39:46,049] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:39:46,056] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:39:46,059] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 18:39:58,854] {scheduler_job.py:155} INFO - Started process (PID=4337) to work on /airflow/dags/download_data.py
[2022-02-18 18:39:58,866] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:39:58,870] {logging_mixin.py:112} INFO - [2022-02-18 18:39:58,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:39:59,438] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:39:59,486] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:39:59,496] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:39:59,501] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.647 seconds
[2022-02-18 18:40:12,234] {scheduler_job.py:155} INFO - Started process (PID=4363) to work on /airflow/dags/download_data.py
[2022-02-18 18:40:12,244] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:40:12,247] {logging_mixin.py:112} INFO - [2022-02-18 18:40:12,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:40:12,759] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:40:12,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:40:12,814] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:40:12,819] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 18:40:25,473] {scheduler_job.py:155} INFO - Started process (PID=4389) to work on /airflow/dags/download_data.py
[2022-02-18 18:40:25,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:40:25,480] {logging_mixin.py:112} INFO - [2022-02-18 18:40:25,480] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:40:25,960] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:40:26,004] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:40:26,014] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:40:26,022] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 18:40:38,748] {scheduler_job.py:155} INFO - Started process (PID=4415) to work on /airflow/dags/download_data.py
[2022-02-18 18:40:38,760] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:40:38,764] {logging_mixin.py:112} INFO - [2022-02-18 18:40:38,763] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:40:39,364] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:40:39,412] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:40:39,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:40:39,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.680 seconds
[2022-02-18 18:40:52,022] {scheduler_job.py:155} INFO - Started process (PID=4441) to work on /airflow/dags/download_data.py
[2022-02-18 18:40:52,057] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:40:52,060] {logging_mixin.py:112} INFO - [2022-02-18 18:40:52,060] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:40:52,568] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:40:52,614] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:40:52,631] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:40:52,637] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-18 18:41:05,320] {scheduler_job.py:155} INFO - Started process (PID=4467) to work on /airflow/dags/download_data.py
[2022-02-18 18:41:05,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:41:05,334] {logging_mixin.py:112} INFO - [2022-02-18 18:41:05,334] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:41:05,841] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:41:05,899] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:41:05,910] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:41:05,922] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 18:41:18,593] {scheduler_job.py:155} INFO - Started process (PID=4493) to work on /airflow/dags/download_data.py
[2022-02-18 18:41:18,599] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:41:18,601] {logging_mixin.py:112} INFO - [2022-02-18 18:41:18,601] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:41:19,112] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:41:19,166] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:41:19,176] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:41:19,189] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 18:41:31,852] {scheduler_job.py:155} INFO - Started process (PID=4519) to work on /airflow/dags/download_data.py
[2022-02-18 18:41:31,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:41:31,863] {logging_mixin.py:112} INFO - [2022-02-18 18:41:31,862] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:41:32,327] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:41:32,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:41:32,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:41:32,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 18:41:45,129] {scheduler_job.py:155} INFO - Started process (PID=4545) to work on /airflow/dags/download_data.py
[2022-02-18 18:41:45,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:41:45,149] {logging_mixin.py:112} INFO - [2022-02-18 18:41:45,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:41:45,658] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:41:45,727] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:41:45,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:41:45,742] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-18 18:41:58,453] {scheduler_job.py:155} INFO - Started process (PID=4571) to work on /airflow/dags/download_data.py
[2022-02-18 18:41:58,465] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:41:58,470] {logging_mixin.py:112} INFO - [2022-02-18 18:41:58,470] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:41:58,990] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:41:59,035] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:41:59,043] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:41:59,049] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 18:42:11,744] {scheduler_job.py:155} INFO - Started process (PID=4597) to work on /airflow/dags/download_data.py
[2022-02-18 18:42:11,752] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:42:11,754] {logging_mixin.py:112} INFO - [2022-02-18 18:42:11,754] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:42:12,294] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:42:12,342] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:42:12,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:42:12,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-18 18:42:25,008] {scheduler_job.py:155} INFO - Started process (PID=4623) to work on /airflow/dags/download_data.py
[2022-02-18 18:42:25,013] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:42:25,015] {logging_mixin.py:112} INFO - [2022-02-18 18:42:25,015] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:42:25,505] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:42:25,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:42:25,568] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:42:25,573] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 18:42:38,289] {scheduler_job.py:155} INFO - Started process (PID=4649) to work on /airflow/dags/download_data.py
[2022-02-18 18:42:38,294] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:42:38,295] {logging_mixin.py:112} INFO - [2022-02-18 18:42:38,295] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:42:38,774] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:42:38,816] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:42:38,824] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:42:38,829] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 18:42:51,508] {scheduler_job.py:155} INFO - Started process (PID=4675) to work on /airflow/dags/download_data.py
[2022-02-18 18:42:51,513] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:42:51,515] {logging_mixin.py:112} INFO - [2022-02-18 18:42:51,515] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:42:51,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:42:52,021] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:42:52,027] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:42:52,031] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 18:43:04,815] {scheduler_job.py:155} INFO - Started process (PID=4701) to work on /airflow/dags/download_data.py
[2022-02-18 18:43:04,819] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:43:04,822] {logging_mixin.py:112} INFO - [2022-02-18 18:43:04,821] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:43:05,341] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:43:05,384] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:43:05,395] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:43:05,399] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 18:43:18,115] {scheduler_job.py:155} INFO - Started process (PID=4727) to work on /airflow/dags/download_data.py
[2022-02-18 18:43:18,123] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:43:18,125] {logging_mixin.py:112} INFO - [2022-02-18 18:43:18,125] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:43:18,662] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:43:18,714] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:43:18,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:43:18,730] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.615 seconds
[2022-02-18 18:43:31,450] {scheduler_job.py:155} INFO - Started process (PID=4753) to work on /airflow/dags/download_data.py
[2022-02-18 18:43:31,456] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:43:31,458] {logging_mixin.py:112} INFO - [2022-02-18 18:43:31,458] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:43:31,920] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:43:31,967] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:43:31,977] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:43:31,982] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 18:43:44,716] {scheduler_job.py:155} INFO - Started process (PID=4779) to work on /airflow/dags/download_data.py
[2022-02-18 18:43:44,721] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:43:44,723] {logging_mixin.py:112} INFO - [2022-02-18 18:43:44,723] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:43:45,192] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:43:45,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:43:45,259] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:43:45,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 18:43:58,027] {scheduler_job.py:155} INFO - Started process (PID=4805) to work on /airflow/dags/download_data.py
[2022-02-18 18:43:58,035] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:43:58,038] {logging_mixin.py:112} INFO - [2022-02-18 18:43:58,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:43:58,528] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:43:58,584] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:43:58,594] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:43:58,599] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 18:44:11,280] {scheduler_job.py:155} INFO - Started process (PID=4831) to work on /airflow/dags/download_data.py
[2022-02-18 18:44:11,288] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:44:11,289] {logging_mixin.py:112} INFO - [2022-02-18 18:44:11,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:44:11,760] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:44:11,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:44:11,958] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:44:11,962] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.682 seconds
[2022-02-18 18:44:24,524] {scheduler_job.py:155} INFO - Started process (PID=4857) to work on /airflow/dags/download_data.py
[2022-02-18 18:44:24,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:44:24,535] {logging_mixin.py:112} INFO - [2022-02-18 18:44:24,534] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:44:25,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:44:25,053] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:44:25,059] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:44:25,064] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 18:44:37,852] {scheduler_job.py:155} INFO - Started process (PID=4883) to work on /airflow/dags/download_data.py
[2022-02-18 18:44:37,859] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:44:37,862] {logging_mixin.py:112} INFO - [2022-02-18 18:44:37,861] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:44:38,314] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:44:38,354] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:44:38,359] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:44:38,363] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 18:44:51,067] {scheduler_job.py:155} INFO - Started process (PID=4909) to work on /airflow/dags/download_data.py
[2022-02-18 18:44:51,076] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:44:51,078] {logging_mixin.py:112} INFO - [2022-02-18 18:44:51,078] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:44:51,567] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:44:51,609] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:44:51,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:44:51,621] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 18:45:04,381] {scheduler_job.py:155} INFO - Started process (PID=4935) to work on /airflow/dags/download_data.py
[2022-02-18 18:45:04,395] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:45:04,399] {logging_mixin.py:112} INFO - [2022-02-18 18:45:04,399] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:45:04,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:45:05,003] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:45:05,015] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:45:05,023] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-18 18:45:17,669] {scheduler_job.py:155} INFO - Started process (PID=4961) to work on /airflow/dags/download_data.py
[2022-02-18 18:45:17,678] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:45:17,680] {logging_mixin.py:112} INFO - [2022-02-18 18:45:17,680] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:45:18,155] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:45:18,223] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:45:18,231] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:45:18,237] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 18:45:31,100] {scheduler_job.py:155} INFO - Started process (PID=4987) to work on /airflow/dags/download_data.py
[2022-02-18 18:45:31,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:45:31,135] {logging_mixin.py:112} INFO - [2022-02-18 18:45:31,134] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:45:32,862] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:45:32,943] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:45:32,960] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:45:32,972] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.872 seconds
[2022-02-18 18:45:45,405] {scheduler_job.py:155} INFO - Started process (PID=5013) to work on /airflow/dags/download_data.py
[2022-02-18 18:45:45,421] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:45:45,426] {logging_mixin.py:112} INFO - [2022-02-18 18:45:45,426] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:45:45,966] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:45:46,017] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:45:46,030] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:45:46,033] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-18 18:45:57,635] {scheduler_job.py:155} INFO - Started process (PID=5038) to work on /airflow/dags/download_data.py
[2022-02-18 18:45:57,641] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:45:57,642] {logging_mixin.py:112} INFO - [2022-02-18 18:45:57,642] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:45:58,119] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:45:58,168] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:45:58,177] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:45:58,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 18:46:11,037] {scheduler_job.py:155} INFO - Started process (PID=5064) to work on /airflow/dags/download_data.py
[2022-02-18 18:46:11,048] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:46:11,054] {logging_mixin.py:112} INFO - [2022-02-18 18:46:11,053] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:46:11,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:46:11,688] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:46:11,698] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:46:11,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.672 seconds
[2022-02-18 18:46:24,270] {scheduler_job.py:155} INFO - Started process (PID=5090) to work on /airflow/dags/download_data.py
[2022-02-18 18:46:24,274] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:46:24,278] {logging_mixin.py:112} INFO - [2022-02-18 18:46:24,277] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:46:24,795] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:46:24,851] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:46:24,866] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:46:24,874] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 18:46:37,604] {scheduler_job.py:155} INFO - Started process (PID=5116) to work on /airflow/dags/download_data.py
[2022-02-18 18:46:37,611] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:46:37,615] {logging_mixin.py:112} INFO - [2022-02-18 18:46:37,613] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:46:38,230] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:46:38,289] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:46:38,302] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:46:38,308] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.703 seconds
[2022-02-18 18:46:50,871] {scheduler_job.py:155} INFO - Started process (PID=5142) to work on /airflow/dags/download_data.py
[2022-02-18 18:46:50,885] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:46:50,888] {logging_mixin.py:112} INFO - [2022-02-18 18:46:50,887] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:46:51,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:46:51,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:46:51,453] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:46:51,460] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 18:47:04,201] {scheduler_job.py:155} INFO - Started process (PID=5168) to work on /airflow/dags/download_data.py
[2022-02-18 18:47:04,208] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:47:04,210] {logging_mixin.py:112} INFO - [2022-02-18 18:47:04,210] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:47:04,779] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:47:04,846] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:47:04,868] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:47:04,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.676 seconds
[2022-02-18 18:47:17,548] {scheduler_job.py:155} INFO - Started process (PID=5194) to work on /airflow/dags/download_data.py
[2022-02-18 18:47:17,559] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:47:17,562] {logging_mixin.py:112} INFO - [2022-02-18 18:47:17,562] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:47:18,189] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:47:18,247] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:47:18,257] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:47:18,264] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.716 seconds
[2022-02-18 18:47:30,789] {scheduler_job.py:155} INFO - Started process (PID=5220) to work on /airflow/dags/download_data.py
[2022-02-18 18:47:30,802] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:47:30,808] {logging_mixin.py:112} INFO - [2022-02-18 18:47:30,807] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:47:31,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:47:31,358] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:47:31,364] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:47:31,370] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 18:47:44,168] {scheduler_job.py:155} INFO - Started process (PID=5246) to work on /airflow/dags/download_data.py
[2022-02-18 18:47:44,180] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:47:44,183] {logging_mixin.py:112} INFO - [2022-02-18 18:47:44,182] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:47:44,743] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:47:44,792] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:47:44,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:47:44,805] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-18 18:47:57,394] {scheduler_job.py:155} INFO - Started process (PID=5272) to work on /airflow/dags/download_data.py
[2022-02-18 18:47:57,411] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:47:57,415] {logging_mixin.py:112} INFO - [2022-02-18 18:47:57,414] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:47:57,989] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:47:58,054] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:47:58,066] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:47:58,073] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-18 18:48:10,688] {scheduler_job.py:155} INFO - Started process (PID=5298) to work on /airflow/dags/download_data.py
[2022-02-18 18:48:10,702] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:48:10,707] {logging_mixin.py:112} INFO - [2022-02-18 18:48:10,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:48:11,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:48:11,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:48:11,517] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:48:11,522] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.833 seconds
[2022-02-18 18:48:23,944] {scheduler_job.py:155} INFO - Started process (PID=5324) to work on /airflow/dags/download_data.py
[2022-02-18 18:48:23,955] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:48:23,958] {logging_mixin.py:112} INFO - [2022-02-18 18:48:23,957] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:48:24,448] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:48:24,497] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:48:24,507] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:48:24,515] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 18:48:37,249] {scheduler_job.py:155} INFO - Started process (PID=5350) to work on /airflow/dags/download_data.py
[2022-02-18 18:48:37,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:48:37,256] {logging_mixin.py:112} INFO - [2022-02-18 18:48:37,255] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:48:37,786] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:48:37,835] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:48:37,847] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:48:37,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 18:48:50,667] {scheduler_job.py:155} INFO - Started process (PID=5376) to work on /airflow/dags/download_data.py
[2022-02-18 18:48:50,674] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:48:50,677] {logging_mixin.py:112} INFO - [2022-02-18 18:48:50,676] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:48:51,165] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:48:51,211] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:48:51,216] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:48:51,222] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 18:49:03,966] {scheduler_job.py:155} INFO - Started process (PID=5402) to work on /airflow/dags/download_data.py
[2022-02-18 18:49:03,972] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:49:03,974] {logging_mixin.py:112} INFO - [2022-02-18 18:49:03,973] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:49:04,477] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:49:04,533] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:49:04,544] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:49:04,552] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 18:49:17,250] {scheduler_job.py:155} INFO - Started process (PID=5428) to work on /airflow/dags/download_data.py
[2022-02-18 18:49:17,263] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:49:17,266] {logging_mixin.py:112} INFO - [2022-02-18 18:49:17,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:49:17,756] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:49:17,811] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:49:17,832] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:49:17,837] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 18:49:30,500] {scheduler_job.py:155} INFO - Started process (PID=5454) to work on /airflow/dags/download_data.py
[2022-02-18 18:49:30,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:49:30,513] {logging_mixin.py:112} INFO - [2022-02-18 18:49:30,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:49:31,097] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:49:31,147] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:49:31,159] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:49:31,164] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.664 seconds
[2022-02-18 18:49:43,814] {scheduler_job.py:155} INFO - Started process (PID=5480) to work on /airflow/dags/download_data.py
[2022-02-18 18:49:43,824] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:49:43,827] {logging_mixin.py:112} INFO - [2022-02-18 18:49:43,826] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:49:44,326] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:49:44,372] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:49:44,378] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:49:44,384] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 18:49:57,072] {scheduler_job.py:155} INFO - Started process (PID=5506) to work on /airflow/dags/download_data.py
[2022-02-18 18:49:57,080] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:49:57,099] {logging_mixin.py:112} INFO - [2022-02-18 18:49:57,098] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:49:57,640] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:49:57,697] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:49:57,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:49:57,753] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.681 seconds
[2022-02-18 18:50:10,364] {scheduler_job.py:155} INFO - Started process (PID=5532) to work on /airflow/dags/download_data.py
[2022-02-18 18:50:10,369] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:50:10,372] {logging_mixin.py:112} INFO - [2022-02-18 18:50:10,372] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:50:10,951] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:50:11,003] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:50:11,013] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:50:11,017] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.653 seconds
[2022-02-18 18:50:23,653] {scheduler_job.py:155} INFO - Started process (PID=5558) to work on /airflow/dags/download_data.py
[2022-02-18 18:50:23,666] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:50:23,678] {logging_mixin.py:112} INFO - [2022-02-18 18:50:23,678] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:50:24,258] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:50:24,317] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:50:24,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:50:24,340] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.688 seconds
[2022-02-18 18:50:36,938] {scheduler_job.py:155} INFO - Started process (PID=5584) to work on /airflow/dags/download_data.py
[2022-02-18 18:50:36,949] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:50:36,951] {logging_mixin.py:112} INFO - [2022-02-18 18:50:36,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:50:37,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:50:37,533] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:50:37,544] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:50:37,551] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-18 18:50:50,184] {scheduler_job.py:155} INFO - Started process (PID=5610) to work on /airflow/dags/download_data.py
[2022-02-18 18:50:50,191] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:50:50,193] {logging_mixin.py:112} INFO - [2022-02-18 18:50:50,193] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:50:50,718] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:50:50,767] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:50:50,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:50:50,785] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 18:51:03,449] {scheduler_job.py:155} INFO - Started process (PID=5636) to work on /airflow/dags/download_data.py
[2022-02-18 18:51:03,460] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:51:03,462] {logging_mixin.py:112} INFO - [2022-02-18 18:51:03,462] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:51:03,960] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:51:04,008] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:51:04,015] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:51:04,021] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 18:51:16,799] {scheduler_job.py:155} INFO - Started process (PID=5662) to work on /airflow/dags/download_data.py
[2022-02-18 18:51:16,803] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:51:16,806] {logging_mixin.py:112} INFO - [2022-02-18 18:51:16,805] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:51:17,275] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:51:17,332] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:51:17,340] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:51:17,347] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 18:51:30,026] {scheduler_job.py:155} INFO - Started process (PID=5688) to work on /airflow/dags/download_data.py
[2022-02-18 18:51:30,030] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:51:30,032] {logging_mixin.py:112} INFO - [2022-02-18 18:51:30,032] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:51:30,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:51:30,590] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:51:30,600] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:51:30,606] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 18:51:43,312] {scheduler_job.py:155} INFO - Started process (PID=5714) to work on /airflow/dags/download_data.py
[2022-02-18 18:51:43,318] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:51:43,320] {logging_mixin.py:112} INFO - [2022-02-18 18:51:43,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:51:43,837] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:51:43,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:51:43,899] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:51:43,904] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 18:51:56,555] {scheduler_job.py:155} INFO - Started process (PID=5740) to work on /airflow/dags/download_data.py
[2022-02-18 18:51:56,565] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:51:56,567] {logging_mixin.py:112} INFO - [2022-02-18 18:51:56,567] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:51:57,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:51:57,175] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:51:57,182] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:51:57,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.631 seconds
[2022-02-18 18:52:09,894] {scheduler_job.py:155} INFO - Started process (PID=5766) to work on /airflow/dags/download_data.py
[2022-02-18 18:52:09,905] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:52:09,907] {logging_mixin.py:112} INFO - [2022-02-18 18:52:09,907] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:52:10,606] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:52:10,648] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:52:10,660] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:52:10,669] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.775 seconds
[2022-02-18 18:52:23,138] {scheduler_job.py:155} INFO - Started process (PID=5792) to work on /airflow/dags/download_data.py
[2022-02-18 18:52:23,145] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:52:23,148] {logging_mixin.py:112} INFO - [2022-02-18 18:52:23,147] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:52:23,662] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:52:23,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:52:23,728] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:52:23,733] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 18:52:36,424] {scheduler_job.py:155} INFO - Started process (PID=5818) to work on /airflow/dags/download_data.py
[2022-02-18 18:52:36,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:52:36,446] {logging_mixin.py:112} INFO - [2022-02-18 18:52:36,446] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:52:36,978] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:52:37,025] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:52:37,033] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:52:37,044] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.620 seconds
[2022-02-18 18:52:49,705] {scheduler_job.py:155} INFO - Started process (PID=5844) to work on /airflow/dags/download_data.py
[2022-02-18 18:52:49,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:52:49,718] {logging_mixin.py:112} INFO - [2022-02-18 18:52:49,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:52:50,223] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:52:50,273] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:52:50,282] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:52:50,288] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 18:53:03,019] {scheduler_job.py:155} INFO - Started process (PID=5870) to work on /airflow/dags/download_data.py
[2022-02-18 18:53:03,029] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:53:03,032] {logging_mixin.py:112} INFO - [2022-02-18 18:53:03,032] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:53:03,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:53:03,583] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:53:03,590] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:53:03,595] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 18:53:16,312] {scheduler_job.py:155} INFO - Started process (PID=5896) to work on /airflow/dags/download_data.py
[2022-02-18 18:53:16,322] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:53:16,324] {logging_mixin.py:112} INFO - [2022-02-18 18:53:16,323] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:53:16,909] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:53:16,964] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:53:16,974] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:53:16,979] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-18 18:53:29,590] {scheduler_job.py:155} INFO - Started process (PID=5922) to work on /airflow/dags/download_data.py
[2022-02-18 18:53:29,594] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:53:29,597] {logging_mixin.py:112} INFO - [2022-02-18 18:53:29,597] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:53:30,066] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:53:30,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:53:30,119] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:53:30,124] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 18:53:42,910] {scheduler_job.py:155} INFO - Started process (PID=5948) to work on /airflow/dags/download_data.py
[2022-02-18 18:53:42,914] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:53:42,917] {logging_mixin.py:112} INFO - [2022-02-18 18:53:42,917] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:53:43,412] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:53:43,465] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:53:43,471] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:53:43,477] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 18:53:56,209] {scheduler_job.py:155} INFO - Started process (PID=5974) to work on /airflow/dags/download_data.py
[2022-02-18 18:53:56,214] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:53:56,217] {logging_mixin.py:112} INFO - [2022-02-18 18:53:56,216] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:53:56,756] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:53:56,804] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:53:56,810] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:53:56,816] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-18 18:54:09,524] {scheduler_job.py:155} INFO - Started process (PID=6000) to work on /airflow/dags/download_data.py
[2022-02-18 18:54:09,536] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:54:09,548] {logging_mixin.py:112} INFO - [2022-02-18 18:54:09,543] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:54:10,259] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:54:10,312] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:54:10,322] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:54:10,330] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.806 seconds
[2022-02-18 18:54:22,821] {scheduler_job.py:155} INFO - Started process (PID=6026) to work on /airflow/dags/download_data.py
[2022-02-18 18:54:22,844] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:54:22,849] {logging_mixin.py:112} INFO - [2022-02-18 18:54:22,849] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:54:23,612] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:54:23,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:54:23,699] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:54:23,706] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.885 seconds
[2022-02-18 18:54:36,092] {scheduler_job.py:155} INFO - Started process (PID=6052) to work on /airflow/dags/download_data.py
[2022-02-18 18:54:36,098] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:54:36,100] {logging_mixin.py:112} INFO - [2022-02-18 18:54:36,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:54:36,715] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:54:36,773] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:54:36,779] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:54:36,782] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.691 seconds
[2022-02-18 18:54:49,346] {scheduler_job.py:155} INFO - Started process (PID=6078) to work on /airflow/dags/download_data.py
[2022-02-18 18:54:49,361] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:54:49,365] {logging_mixin.py:112} INFO - [2022-02-18 18:54:49,364] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:54:49,852] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:54:49,913] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:54:49,928] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:54:49,937] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 18:55:02,615] {scheduler_job.py:155} INFO - Started process (PID=6104) to work on /airflow/dags/download_data.py
[2022-02-18 18:55:02,628] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:55:02,631] {logging_mixin.py:112} INFO - [2022-02-18 18:55:02,631] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:55:03,104] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:55:03,149] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:55:03,201] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:55:03,211] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-18 18:55:15,899] {scheduler_job.py:155} INFO - Started process (PID=6130) to work on /airflow/dags/download_data.py
[2022-02-18 18:55:15,910] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:55:15,913] {logging_mixin.py:112} INFO - [2022-02-18 18:55:15,912] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:55:16,415] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:55:16,468] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:55:16,478] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:55:16,485] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 18:55:29,127] {scheduler_job.py:155} INFO - Started process (PID=6156) to work on /airflow/dags/download_data.py
[2022-02-18 18:55:29,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:55:29,134] {logging_mixin.py:112} INFO - [2022-02-18 18:55:29,134] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:55:29,651] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:55:29,705] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:55:29,712] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:55:29,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 18:55:42,510] {scheduler_job.py:155} INFO - Started process (PID=6182) to work on /airflow/dags/download_data.py
[2022-02-18 18:55:42,518] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:55:42,521] {logging_mixin.py:112} INFO - [2022-02-18 18:55:42,521] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:55:43,279] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:55:43,334] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:55:43,347] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:55:43,352] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.842 seconds
[2022-02-18 18:55:55,776] {scheduler_job.py:155} INFO - Started process (PID=6208) to work on /airflow/dags/download_data.py
[2022-02-18 18:55:55,790] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:55:55,792] {logging_mixin.py:112} INFO - [2022-02-18 18:55:55,792] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:55:56,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:55:56,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:55:56,425] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:55:56,435] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.659 seconds
[2022-02-18 18:56:09,019] {scheduler_job.py:155} INFO - Started process (PID=6234) to work on /airflow/dags/download_data.py
[2022-02-18 18:56:09,032] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:56:09,034] {logging_mixin.py:112} INFO - [2022-02-18 18:56:09,034] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:56:09,609] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:56:09,669] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:56:09,683] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:56:09,687] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.668 seconds
[2022-02-18 18:56:22,351] {scheduler_job.py:155} INFO - Started process (PID=6260) to work on /airflow/dags/download_data.py
[2022-02-18 18:56:22,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:56:22,359] {logging_mixin.py:112} INFO - [2022-02-18 18:56:22,358] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:56:22,905] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:56:22,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:56:22,960] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:56:22,965] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-18 18:56:35,649] {scheduler_job.py:155} INFO - Started process (PID=6286) to work on /airflow/dags/download_data.py
[2022-02-18 18:56:35,658] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:56:35,660] {logging_mixin.py:112} INFO - [2022-02-18 18:56:35,660] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:56:36,180] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:56:36,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:56:36,248] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:56:36,254] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 18:56:48,927] {scheduler_job.py:155} INFO - Started process (PID=6312) to work on /airflow/dags/download_data.py
[2022-02-18 18:56:48,934] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:56:48,936] {logging_mixin.py:112} INFO - [2022-02-18 18:56:48,936] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:56:49,486] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:56:49,541] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:56:49,556] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:56:49,565] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-18 18:57:02,277] {scheduler_job.py:155} INFO - Started process (PID=6338) to work on /airflow/dags/download_data.py
[2022-02-18 18:57:02,286] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:57:02,288] {logging_mixin.py:112} INFO - [2022-02-18 18:57:02,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:57:02,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:57:02,897] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:57:02,903] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:57:02,906] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.631 seconds
[2022-02-18 18:57:15,592] {scheduler_job.py:155} INFO - Started process (PID=6364) to work on /airflow/dags/download_data.py
[2022-02-18 18:57:15,602] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:57:15,606] {logging_mixin.py:112} INFO - [2022-02-18 18:57:15,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:57:16,103] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:57:16,172] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:57:16,185] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:57:16,193] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-18 18:57:28,822] {scheduler_job.py:155} INFO - Started process (PID=6390) to work on /airflow/dags/download_data.py
[2022-02-18 18:57:28,827] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:57:28,828] {logging_mixin.py:112} INFO - [2022-02-18 18:57:28,828] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:57:29,301] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:57:29,354] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:57:29,367] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:57:29,372] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 18:57:42,128] {scheduler_job.py:155} INFO - Started process (PID=6416) to work on /airflow/dags/download_data.py
[2022-02-18 18:57:42,134] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:57:42,138] {logging_mixin.py:112} INFO - [2022-02-18 18:57:42,137] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:57:42,629] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:57:42,677] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:57:42,683] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:57:42,689] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 18:57:55,408] {scheduler_job.py:155} INFO - Started process (PID=6442) to work on /airflow/dags/download_data.py
[2022-02-18 18:57:55,416] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:57:55,418] {logging_mixin.py:112} INFO - [2022-02-18 18:57:55,417] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:57:55,868] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:57:55,909] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:57:55,916] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:57:55,920] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 18:58:08,705] {scheduler_job.py:155} INFO - Started process (PID=6468) to work on /airflow/dags/download_data.py
[2022-02-18 18:58:08,715] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:58:08,718] {logging_mixin.py:112} INFO - [2022-02-18 18:58:08,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:58:09,243] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:58:09,294] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:58:09,306] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:58:09,311] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 18:58:21,962] {scheduler_job.py:155} INFO - Started process (PID=6494) to work on /airflow/dags/download_data.py
[2022-02-18 18:58:21,968] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:58:21,970] {logging_mixin.py:112} INFO - [2022-02-18 18:58:21,970] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:58:22,424] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:58:22,475] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:58:22,481] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:58:22,485] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 18:58:35,216] {scheduler_job.py:155} INFO - Started process (PID=6520) to work on /airflow/dags/download_data.py
[2022-02-18 18:58:35,222] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:58:35,224] {logging_mixin.py:112} INFO - [2022-02-18 18:58:35,224] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:58:35,689] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:58:35,748] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:58:35,754] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:58:35,758] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 18:58:48,517] {scheduler_job.py:155} INFO - Started process (PID=6546) to work on /airflow/dags/download_data.py
[2022-02-18 18:58:48,525] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:58:48,527] {logging_mixin.py:112} INFO - [2022-02-18 18:58:48,527] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:58:48,971] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:58:49,021] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:58:49,028] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:58:49,033] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 18:59:01,828] {scheduler_job.py:155} INFO - Started process (PID=6572) to work on /airflow/dags/download_data.py
[2022-02-18 18:59:01,834] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:59:01,836] {logging_mixin.py:112} INFO - [2022-02-18 18:59:01,836] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:59:02,295] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:59:02,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:59:02,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:59:02,359] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 18:59:15,112] {scheduler_job.py:155} INFO - Started process (PID=6598) to work on /airflow/dags/download_data.py
[2022-02-18 18:59:15,122] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:59:15,124] {logging_mixin.py:112} INFO - [2022-02-18 18:59:15,124] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:59:15,584] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:59:15,633] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:59:15,639] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:59:15,644] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 18:59:28,378] {scheduler_job.py:155} INFO - Started process (PID=6624) to work on /airflow/dags/download_data.py
[2022-02-18 18:59:28,389] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:59:28,393] {logging_mixin.py:112} INFO - [2022-02-18 18:59:28,392] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:59:28,881] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:59:28,931] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:59:28,937] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:59:28,942] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 18:59:41,624] {scheduler_job.py:155} INFO - Started process (PID=6650) to work on /airflow/dags/download_data.py
[2022-02-18 18:59:41,632] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:59:41,634] {logging_mixin.py:112} INFO - [2022-02-18 18:59:41,633] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:59:42,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:59:42,321] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:59:42,332] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:59:42,338] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.714 seconds
[2022-02-18 18:59:54,905] {scheduler_job.py:155} INFO - Started process (PID=6676) to work on /airflow/dags/download_data.py
[2022-02-18 18:59:54,912] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 18:59:54,915] {logging_mixin.py:112} INFO - [2022-02-18 18:59:54,915] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 18:59:55,474] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 18:59:55,519] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 18:59:55,526] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 18:59:55,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-18 19:00:08,187] {scheduler_job.py:155} INFO - Started process (PID=6702) to work on /airflow/dags/download_data.py
[2022-02-18 19:00:08,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:00:08,194] {logging_mixin.py:112} INFO - [2022-02-18 19:00:08,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:00:08,647] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:00:08,697] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:00:08,707] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:00:08,712] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 19:21:18,382] {scheduler_job.py:155} INFO - Started process (PID=6728) to work on /airflow/dags/download_data.py
[2022-02-18 19:21:18,388] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:21:18,390] {logging_mixin.py:112} INFO - [2022-02-18 19:21:18,389] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:21:18,881] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:21:18,919] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:21:18,925] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:21:18,930] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 19:21:32,028] {scheduler_job.py:155} INFO - Started process (PID=6754) to work on /airflow/dags/download_data.py
[2022-02-18 19:21:32,039] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:21:32,052] {logging_mixin.py:112} INFO - [2022-02-18 19:21:32,052] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:21:33,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:21:33,376] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:21:33,385] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:21:33,389] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.362 seconds
[2022-02-18 19:21:46,900] {scheduler_job.py:155} INFO - Started process (PID=6780) to work on /airflow/dags/download_data.py
[2022-02-18 19:21:46,912] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:21:46,914] {logging_mixin.py:112} INFO - [2022-02-18 19:21:46,913] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:21:47,403] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:21:47,447] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:21:47,453] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:21:47,457] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 19:21:59,195] {scheduler_job.py:155} INFO - Started process (PID=6805) to work on /airflow/dags/download_data.py
[2022-02-18 19:21:59,205] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:21:59,207] {logging_mixin.py:112} INFO - [2022-02-18 19:21:59,207] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:21:59,670] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:21:59,719] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:21:59,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:21:59,728] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 19:22:12,487] {scheduler_job.py:155} INFO - Started process (PID=6831) to work on /airflow/dags/download_data.py
[2022-02-18 19:22:12,493] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:22:12,496] {logging_mixin.py:112} INFO - [2022-02-18 19:22:12,496] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:22:13,314] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:22:13,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:22:13,393] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:22:13,397] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.910 seconds
[2022-02-18 19:22:25,741] {scheduler_job.py:155} INFO - Started process (PID=6857) to work on /airflow/dags/download_data.py
[2022-02-18 19:22:25,753] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:22:25,756] {logging_mixin.py:112} INFO - [2022-02-18 19:22:25,756] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:22:26,357] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:22:26,403] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:22:26,413] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:22:26,419] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.678 seconds
[2022-02-18 19:22:39,099] {scheduler_job.py:155} INFO - Started process (PID=6883) to work on /airflow/dags/download_data.py
[2022-02-18 19:22:39,105] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:22:39,107] {logging_mixin.py:112} INFO - [2022-02-18 19:22:39,106] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:22:39,571] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:22:39,622] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:22:39,632] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:22:39,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 19:22:52,344] {scheduler_job.py:155} INFO - Started process (PID=6909) to work on /airflow/dags/download_data.py
[2022-02-18 19:22:52,374] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:22:52,376] {logging_mixin.py:112} INFO - [2022-02-18 19:22:52,376] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:22:52,818] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:22:52,870] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:22:52,877] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:22:52,883] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 19:23:05,615] {scheduler_job.py:155} INFO - Started process (PID=6935) to work on /airflow/dags/download_data.py
[2022-02-18 19:23:05,631] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:23:05,633] {logging_mixin.py:112} INFO - [2022-02-18 19:23:05,632] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:23:06,143] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:23:06,203] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:23:06,210] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:23:06,218] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 19:23:18,905] {scheduler_job.py:155} INFO - Started process (PID=6961) to work on /airflow/dags/download_data.py
[2022-02-18 19:23:18,917] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:23:18,921] {logging_mixin.py:112} INFO - [2022-02-18 19:23:18,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:23:19,394] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:23:19,447] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:23:19,458] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:23:19,464] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 19:23:32,184] {scheduler_job.py:155} INFO - Started process (PID=6987) to work on /airflow/dags/download_data.py
[2022-02-18 19:23:32,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:23:32,195] {logging_mixin.py:112} INFO - [2022-02-18 19:23:32,194] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:23:32,646] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:23:32,696] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:23:32,704] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:23:32,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 19:23:45,436] {scheduler_job.py:155} INFO - Started process (PID=7013) to work on /airflow/dags/download_data.py
[2022-02-18 19:23:45,443] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:23:45,445] {logging_mixin.py:112} INFO - [2022-02-18 19:23:45,445] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:23:45,941] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:23:45,989] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:23:45,998] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:23:46,004] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 19:23:58,986] {scheduler_job.py:155} INFO - Started process (PID=7039) to work on /airflow/dags/download_data.py
[2022-02-18 19:23:58,990] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:23:58,992] {logging_mixin.py:112} INFO - [2022-02-18 19:23:58,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:23:59,468] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:23:59,521] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:23:59,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:23:59,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 19:24:12,263] {scheduler_job.py:155} INFO - Started process (PID=7065) to work on /airflow/dags/download_data.py
[2022-02-18 19:24:12,271] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:24:12,273] {logging_mixin.py:112} INFO - [2022-02-18 19:24:12,273] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:24:12,711] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:24:12,759] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:24:12,768] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:24:12,774] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 19:24:25,508] {scheduler_job.py:155} INFO - Started process (PID=7091) to work on /airflow/dags/download_data.py
[2022-02-18 19:24:25,522] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:24:25,524] {logging_mixin.py:112} INFO - [2022-02-18 19:24:25,524] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:24:26,141] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:24:26,190] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:24:26,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:24:26,207] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.699 seconds
[2022-02-18 19:24:38,803] {scheduler_job.py:155} INFO - Started process (PID=7117) to work on /airflow/dags/download_data.py
[2022-02-18 19:24:38,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:24:38,825] {logging_mixin.py:112} INFO - [2022-02-18 19:24:38,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:24:39,323] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:24:39,379] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:24:39,387] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:24:39,394] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 19:24:52,044] {scheduler_job.py:155} INFO - Started process (PID=7143) to work on /airflow/dags/download_data.py
[2022-02-18 19:24:52,053] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:24:52,056] {logging_mixin.py:112} INFO - [2022-02-18 19:24:52,055] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:24:52,507] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:24:52,557] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:24:52,566] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:24:52,569] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 19:25:05,318] {scheduler_job.py:155} INFO - Started process (PID=7169) to work on /airflow/dags/download_data.py
[2022-02-18 19:25:05,327] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:25:05,330] {logging_mixin.py:112} INFO - [2022-02-18 19:25:05,329] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:25:05,793] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:25:05,838] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:25:05,848] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:25:05,856] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 19:25:18,537] {scheduler_job.py:155} INFO - Started process (PID=7195) to work on /airflow/dags/download_data.py
[2022-02-18 19:25:18,542] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:25:18,544] {logging_mixin.py:112} INFO - [2022-02-18 19:25:18,543] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:25:19,010] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:25:19,064] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:25:19,072] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:25:19,075] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 19:25:31,842] {scheduler_job.py:155} INFO - Started process (PID=7221) to work on /airflow/dags/download_data.py
[2022-02-18 19:25:31,846] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:25:31,849] {logging_mixin.py:112} INFO - [2022-02-18 19:25:31,849] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:25:32,820] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:25:32,907] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:25:32,922] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:25:32,935] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.093 seconds
[2022-02-18 19:25:46,075] {scheduler_job.py:155} INFO - Started process (PID=7247) to work on /airflow/dags/download_data.py
[2022-02-18 19:25:46,085] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:25:46,086] {logging_mixin.py:112} INFO - [2022-02-18 19:25:46,086] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:25:46,564] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:25:46,607] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:25:46,616] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:25:46,620] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 19:25:58,338] {scheduler_job.py:155} INFO - Started process (PID=7272) to work on /airflow/dags/download_data.py
[2022-02-18 19:25:58,346] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:25:58,350] {logging_mixin.py:112} INFO - [2022-02-18 19:25:58,350] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:25:58,886] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:25:58,935] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:25:58,941] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:25:58,946] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-18 19:26:11,642] {scheduler_job.py:155} INFO - Started process (PID=7298) to work on /airflow/dags/download_data.py
[2022-02-18 19:26:11,654] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:26:11,656] {logging_mixin.py:112} INFO - [2022-02-18 19:26:11,656] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:26:12,420] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:26:12,471] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:26:12,477] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:26:12,483] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.840 seconds
[2022-02-18 19:26:24,938] {scheduler_job.py:155} INFO - Started process (PID=7324) to work on /airflow/dags/download_data.py
[2022-02-18 19:26:24,944] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:26:24,946] {logging_mixin.py:112} INFO - [2022-02-18 19:26:24,946] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:26:25,388] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:26:25,445] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:26:25,457] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:26:25,464] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 19:26:38,167] {scheduler_job.py:155} INFO - Started process (PID=7350) to work on /airflow/dags/download_data.py
[2022-02-18 19:26:38,174] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:26:38,176] {logging_mixin.py:112} INFO - [2022-02-18 19:26:38,176] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:26:38,628] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:26:38,678] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:26:38,686] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:26:38,693] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 19:26:51,407] {scheduler_job.py:155} INFO - Started process (PID=7376) to work on /airflow/dags/download_data.py
[2022-02-18 19:26:51,418] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:26:51,421] {logging_mixin.py:112} INFO - [2022-02-18 19:26:51,420] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:26:51,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:26:51,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:26:51,930] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:26:51,936] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 19:27:04,710] {scheduler_job.py:155} INFO - Started process (PID=7402) to work on /airflow/dags/download_data.py
[2022-02-18 19:27:04,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:27:04,719] {logging_mixin.py:112} INFO - [2022-02-18 19:27:04,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:27:05,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:27:05,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:27:05,278] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:27:05,283] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-18 19:27:17,932] {scheduler_job.py:155} INFO - Started process (PID=7428) to work on /airflow/dags/download_data.py
[2022-02-18 19:27:17,941] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:27:17,943] {logging_mixin.py:112} INFO - [2022-02-18 19:27:17,943] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:27:18,419] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:27:18,475] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:27:18,483] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:27:18,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 19:27:31,240] {scheduler_job.py:155} INFO - Started process (PID=7454) to work on /airflow/dags/download_data.py
[2022-02-18 19:27:31,245] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:27:31,247] {logging_mixin.py:112} INFO - [2022-02-18 19:27:31,247] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:27:31,690] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:27:31,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:27:31,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:27:31,754] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 19:27:44,466] {scheduler_job.py:155} INFO - Started process (PID=7480) to work on /airflow/dags/download_data.py
[2022-02-18 19:27:44,472] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:27:44,473] {logging_mixin.py:112} INFO - [2022-02-18 19:27:44,473] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:27:44,939] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:27:44,989] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:27:45,006] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:27:45,010] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 19:27:57,740] {scheduler_job.py:155} INFO - Started process (PID=7506) to work on /airflow/dags/download_data.py
[2022-02-18 19:27:57,746] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:27:57,748] {logging_mixin.py:112} INFO - [2022-02-18 19:27:57,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:27:58,210] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:27:58,254] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:27:58,260] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:27:58,264] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 19:28:11,018] {scheduler_job.py:155} INFO - Started process (PID=7532) to work on /airflow/dags/download_data.py
[2022-02-18 19:28:11,022] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:28:11,025] {logging_mixin.py:112} INFO - [2022-02-18 19:28:11,024] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:28:11,487] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:28:11,537] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:28:11,545] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:28:11,549] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 19:28:24,281] {scheduler_job.py:155} INFO - Started process (PID=7558) to work on /airflow/dags/download_data.py
[2022-02-18 19:28:24,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:28:24,289] {logging_mixin.py:112} INFO - [2022-02-18 19:28:24,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:28:24,750] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:28:24,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:28:24,810] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:28:24,815] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 19:28:37,575] {scheduler_job.py:155} INFO - Started process (PID=7584) to work on /airflow/dags/download_data.py
[2022-02-18 19:28:37,585] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:28:37,588] {logging_mixin.py:112} INFO - [2022-02-18 19:28:37,587] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:28:38,041] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:28:38,094] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:28:38,101] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:28:38,106] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 19:28:50,842] {scheduler_job.py:155} INFO - Started process (PID=7610) to work on /airflow/dags/download_data.py
[2022-02-18 19:28:50,851] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:28:50,853] {logging_mixin.py:112} INFO - [2022-02-18 19:28:50,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:28:51,303] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:28:51,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:28:51,357] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:28:51,363] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 19:29:04,109] {scheduler_job.py:155} INFO - Started process (PID=7636) to work on /airflow/dags/download_data.py
[2022-02-18 19:29:04,121] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:29:04,123] {logging_mixin.py:112} INFO - [2022-02-18 19:29:04,123] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:29:04,565] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:29:04,606] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:29:04,614] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:29:04,620] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 19:29:17,340] {scheduler_job.py:155} INFO - Started process (PID=7662) to work on /airflow/dags/download_data.py
[2022-02-18 19:29:17,346] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:29:17,347] {logging_mixin.py:112} INFO - [2022-02-18 19:29:17,347] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:29:17,841] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:29:17,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:29:17,898] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:29:17,903] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 19:29:30,639] {scheduler_job.py:155} INFO - Started process (PID=7688) to work on /airflow/dags/download_data.py
[2022-02-18 19:29:30,645] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:29:30,647] {logging_mixin.py:112} INFO - [2022-02-18 19:29:30,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:29:31,077] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:29:31,126] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:29:31,134] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:29:31,139] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 19:29:43,874] {scheduler_job.py:155} INFO - Started process (PID=7714) to work on /airflow/dags/download_data.py
[2022-02-18 19:29:43,879] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:29:43,882] {logging_mixin.py:112} INFO - [2022-02-18 19:29:43,882] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:29:44,364] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:29:44,421] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:29:44,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:29:44,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 19:29:57,189] {scheduler_job.py:155} INFO - Started process (PID=7740) to work on /airflow/dags/download_data.py
[2022-02-18 19:29:57,194] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:29:57,197] {logging_mixin.py:112} INFO - [2022-02-18 19:29:57,197] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:29:57,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:29:57,765] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:29:57,773] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:29:57,779] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 19:30:10,483] {scheduler_job.py:155} INFO - Started process (PID=7766) to work on /airflow/dags/download_data.py
[2022-02-18 19:30:10,494] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:30:10,505] {logging_mixin.py:112} INFO - [2022-02-18 19:30:10,504] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:30:11,076] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:30:11,147] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:30:11,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:30:11,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-18 19:30:23,695] {scheduler_job.py:155} INFO - Started process (PID=7792) to work on /airflow/dags/download_data.py
[2022-02-18 19:30:23,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:30:23,701] {logging_mixin.py:112} INFO - [2022-02-18 19:30:23,701] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:30:24,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:30:24,292] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:30:24,304] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:30:24,309] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-18 19:30:36,994] {scheduler_job.py:155} INFO - Started process (PID=7818) to work on /airflow/dags/download_data.py
[2022-02-18 19:30:36,998] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:30:37,000] {logging_mixin.py:112} INFO - [2022-02-18 19:30:37,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:30:37,555] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:30:37,607] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:30:37,616] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:30:37,621] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-18 19:30:50,243] {scheduler_job.py:155} INFO - Started process (PID=7844) to work on /airflow/dags/download_data.py
[2022-02-18 19:30:50,248] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:30:50,249] {logging_mixin.py:112} INFO - [2022-02-18 19:30:50,249] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:30:50,711] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:30:50,768] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:30:50,775] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:30:50,781] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 19:31:03,522] {scheduler_job.py:155} INFO - Started process (PID=7870) to work on /airflow/dags/download_data.py
[2022-02-18 19:31:03,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:31:03,529] {logging_mixin.py:112} INFO - [2022-02-18 19:31:03,529] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:31:04,012] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:31:04,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:31:04,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:31:04,081] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 19:31:16,813] {scheduler_job.py:155} INFO - Started process (PID=7896) to work on /airflow/dags/download_data.py
[2022-02-18 19:31:16,820] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:31:16,822] {logging_mixin.py:112} INFO - [2022-02-18 19:31:16,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:31:17,263] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:31:17,315] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:31:17,325] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:31:17,332] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 19:31:30,113] {scheduler_job.py:155} INFO - Started process (PID=7922) to work on /airflow/dags/download_data.py
[2022-02-18 19:31:30,119] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:31:30,121] {logging_mixin.py:112} INFO - [2022-02-18 19:31:30,121] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:31:30,567] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:31:30,609] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:31:30,617] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:31:30,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 19:31:43,375] {scheduler_job.py:155} INFO - Started process (PID=7948) to work on /airflow/dags/download_data.py
[2022-02-18 19:31:43,383] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:31:43,386] {logging_mixin.py:112} INFO - [2022-02-18 19:31:43,385] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:31:43,805] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:31:43,858] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:31:43,865] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:31:43,868] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 19:31:56,583] {scheduler_job.py:155} INFO - Started process (PID=7974) to work on /airflow/dags/download_data.py
[2022-02-18 19:31:56,587] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:31:56,589] {logging_mixin.py:112} INFO - [2022-02-18 19:31:56,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:31:57,034] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:31:57,085] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:31:57,096] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:31:57,100] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 19:32:09,893] {scheduler_job.py:155} INFO - Started process (PID=8000) to work on /airflow/dags/download_data.py
[2022-02-18 19:32:09,901] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:32:09,904] {logging_mixin.py:112} INFO - [2022-02-18 19:32:09,903] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:32:10,346] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:32:10,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:32:10,411] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:32:10,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 19:32:23,176] {scheduler_job.py:155} INFO - Started process (PID=8026) to work on /airflow/dags/download_data.py
[2022-02-18 19:32:23,181] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:32:23,184] {logging_mixin.py:112} INFO - [2022-02-18 19:32:23,182] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:32:23,755] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:32:23,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:32:23,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:32:23,832] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.656 seconds
[2022-02-18 19:32:36,462] {scheduler_job.py:155} INFO - Started process (PID=8052) to work on /airflow/dags/download_data.py
[2022-02-18 19:32:36,467] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:32:36,469] {logging_mixin.py:112} INFO - [2022-02-18 19:32:36,469] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:32:37,020] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:32:37,075] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:32:37,082] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:32:37,089] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-18 19:32:49,694] {scheduler_job.py:155} INFO - Started process (PID=8078) to work on /airflow/dags/download_data.py
[2022-02-18 19:32:49,698] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:32:49,700] {logging_mixin.py:112} INFO - [2022-02-18 19:32:49,700] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:32:50,194] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:32:50,245] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:32:50,255] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:32:50,260] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 19:33:02,980] {scheduler_job.py:155} INFO - Started process (PID=8104) to work on /airflow/dags/download_data.py
[2022-02-18 19:33:02,992] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:33:02,994] {logging_mixin.py:112} INFO - [2022-02-18 19:33:02,993] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:33:03,450] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:33:03,499] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:33:03,506] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:33:03,512] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 19:33:16,222] {scheduler_job.py:155} INFO - Started process (PID=8130) to work on /airflow/dags/download_data.py
[2022-02-18 19:33:16,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:33:16,229] {logging_mixin.py:112} INFO - [2022-02-18 19:33:16,228] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:33:16,711] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:33:16,768] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:33:16,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:33:16,783] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 19:33:29,497] {scheduler_job.py:155} INFO - Started process (PID=8156) to work on /airflow/dags/download_data.py
[2022-02-18 19:33:29,501] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:33:29,502] {logging_mixin.py:112} INFO - [2022-02-18 19:33:29,502] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:33:29,964] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:33:30,004] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:33:30,014] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:33:30,019] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 19:33:42,829] {scheduler_job.py:155} INFO - Started process (PID=8182) to work on /airflow/dags/download_data.py
[2022-02-18 19:33:42,838] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:33:42,840] {logging_mixin.py:112} INFO - [2022-02-18 19:33:42,840] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:33:43,492] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:33:43,561] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:33:43,573] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:33:43,581] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.752 seconds
[2022-02-18 19:33:56,112] {scheduler_job.py:155} INFO - Started process (PID=8208) to work on /airflow/dags/download_data.py
[2022-02-18 19:33:56,123] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:33:56,127] {logging_mixin.py:112} INFO - [2022-02-18 19:33:56,127] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:33:56,647] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:33:56,680] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:33:56,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:33:56,689] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 19:34:09,436] {scheduler_job.py:155} INFO - Started process (PID=8234) to work on /airflow/dags/download_data.py
[2022-02-18 19:34:09,444] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:34:09,446] {logging_mixin.py:112} INFO - [2022-02-18 19:34:09,446] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:34:09,879] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:34:09,914] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:34:09,919] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:34:09,924] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-18 19:34:22,686] {scheduler_job.py:155} INFO - Started process (PID=8260) to work on /airflow/dags/download_data.py
[2022-02-18 19:34:22,692] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:34:22,694] {logging_mixin.py:112} INFO - [2022-02-18 19:34:22,694] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:34:23,163] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:34:23,203] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:34:23,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:34:23,216] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 19:34:35,967] {scheduler_job.py:155} INFO - Started process (PID=8286) to work on /airflow/dags/download_data.py
[2022-02-18 19:34:35,974] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:34:35,976] {logging_mixin.py:112} INFO - [2022-02-18 19:34:35,976] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:34:36,508] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:34:36,551] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:34:36,561] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:34:36,578] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 19:34:49,227] {scheduler_job.py:155} INFO - Started process (PID=8312) to work on /airflow/dags/download_data.py
[2022-02-18 19:34:49,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:34:49,237] {logging_mixin.py:112} INFO - [2022-02-18 19:34:49,237] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:34:49,757] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:34:49,805] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:34:49,813] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:34:49,820] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 19:35:02,549] {scheduler_job.py:155} INFO - Started process (PID=8338) to work on /airflow/dags/download_data.py
[2022-02-18 19:35:02,555] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:35:02,556] {logging_mixin.py:112} INFO - [2022-02-18 19:35:02,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:35:03,106] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:35:03,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:35:03,175] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:35:03,184] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-18 19:35:15,803] {scheduler_job.py:155} INFO - Started process (PID=8364) to work on /airflow/dags/download_data.py
[2022-02-18 19:35:15,814] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:35:15,816] {logging_mixin.py:112} INFO - [2022-02-18 19:35:15,815] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:35:16,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:35:16,458] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:35:16,468] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:35:16,475] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.673 seconds
[2022-02-18 19:35:29,078] {scheduler_job.py:155} INFO - Started process (PID=8390) to work on /airflow/dags/download_data.py
[2022-02-18 19:35:29,083] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:35:29,084] {logging_mixin.py:112} INFO - [2022-02-18 19:35:29,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:35:29,570] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:35:29,622] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:35:29,631] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:35:29,638] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 19:35:42,389] {scheduler_job.py:155} INFO - Started process (PID=8416) to work on /airflow/dags/download_data.py
[2022-02-18 19:35:42,399] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:35:42,402] {logging_mixin.py:112} INFO - [2022-02-18 19:35:42,401] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:35:43,229] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:35:43,285] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:35:43,295] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:35:43,302] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.914 seconds
[2022-02-18 19:35:55,629] {scheduler_job.py:155} INFO - Started process (PID=8442) to work on /airflow/dags/download_data.py
[2022-02-18 19:35:55,634] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:35:55,636] {logging_mixin.py:112} INFO - [2022-02-18 19:35:55,636] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:35:56,078] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:35:56,128] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:35:56,137] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:35:56,142] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 19:36:08,897] {scheduler_job.py:155} INFO - Started process (PID=8468) to work on /airflow/dags/download_data.py
[2022-02-18 19:36:08,904] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:36:08,906] {logging_mixin.py:112} INFO - [2022-02-18 19:36:08,906] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:36:09,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:36:09,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:36:09,392] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:36:09,398] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 19:36:22,161] {scheduler_job.py:155} INFO - Started process (PID=8494) to work on /airflow/dags/download_data.py
[2022-02-18 19:36:22,169] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:36:22,171] {logging_mixin.py:112} INFO - [2022-02-18 19:36:22,171] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:36:22,623] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:36:22,675] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:36:22,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:36:22,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 19:36:35,452] {scheduler_job.py:155} INFO - Started process (PID=8520) to work on /airflow/dags/download_data.py
[2022-02-18 19:36:35,456] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:36:35,457] {logging_mixin.py:112} INFO - [2022-02-18 19:36:35,457] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:36:35,908] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:36:35,956] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:36:35,966] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:36:35,972] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 19:36:48,672] {scheduler_job.py:155} INFO - Started process (PID=8546) to work on /airflow/dags/download_data.py
[2022-02-18 19:36:48,677] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:36:48,679] {logging_mixin.py:112} INFO - [2022-02-18 19:36:48,679] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:36:49,117] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:36:49,163] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:36:49,170] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:36:49,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 19:37:01,937] {scheduler_job.py:155} INFO - Started process (PID=8572) to work on /airflow/dags/download_data.py
[2022-02-18 19:37:01,943] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:37:01,946] {logging_mixin.py:112} INFO - [2022-02-18 19:37:01,944] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:37:02,381] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:37:02,426] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:37:02,432] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:37:02,440] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 19:37:15,193] {scheduler_job.py:155} INFO - Started process (PID=8598) to work on /airflow/dags/download_data.py
[2022-02-18 19:37:15,198] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:37:15,200] {logging_mixin.py:112} INFO - [2022-02-18 19:37:15,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:37:15,669] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:37:15,721] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:37:15,732] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:37:15,737] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 19:37:28,457] {scheduler_job.py:155} INFO - Started process (PID=8624) to work on /airflow/dags/download_data.py
[2022-02-18 19:37:28,468] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:37:28,470] {logging_mixin.py:112} INFO - [2022-02-18 19:37:28,470] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:37:28,938] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:37:28,991] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:37:29,001] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:37:29,008] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 19:37:41,732] {scheduler_job.py:155} INFO - Started process (PID=8650) to work on /airflow/dags/download_data.py
[2022-02-18 19:37:41,738] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:37:41,739] {logging_mixin.py:112} INFO - [2022-02-18 19:37:41,739] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:37:42,190] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:37:42,231] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:37:42,238] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:37:42,245] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 19:37:54,950] {scheduler_job.py:155} INFO - Started process (PID=8676) to work on /airflow/dags/download_data.py
[2022-02-18 19:37:54,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:37:54,956] {logging_mixin.py:112} INFO - [2022-02-18 19:37:54,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:37:55,444] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:37:55,499] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:37:55,510] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:37:55,516] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 19:38:08,276] {scheduler_job.py:155} INFO - Started process (PID=8702) to work on /airflow/dags/download_data.py
[2022-02-18 19:38:08,282] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:38:08,284] {logging_mixin.py:112} INFO - [2022-02-18 19:38:08,284] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:38:09,015] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:38:09,060] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:38:09,067] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:38:09,073] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.797 seconds
[2022-02-18 19:38:21,738] {scheduler_job.py:155} INFO - Started process (PID=8728) to work on /airflow/dags/download_data.py
[2022-02-18 19:38:21,748] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:38:21,750] {logging_mixin.py:112} INFO - [2022-02-18 19:38:21,750] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:38:22,166] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:38:22,217] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:38:22,224] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:38:22,231] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 19:38:35,672] {scheduler_job.py:155} INFO - Started process (PID=8754) to work on /airflow/dags/download_data.py
[2022-02-18 19:38:35,679] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:38:35,681] {logging_mixin.py:112} INFO - [2022-02-18 19:38:35,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:38:36,189] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:38:36,241] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:38:36,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:38:36,254] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 19:42:10,844] {scheduler_job.py:155} INFO - Started process (PID=8780) to work on /airflow/dags/download_data.py
[2022-02-18 19:42:10,851] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:42:10,852] {logging_mixin.py:112} INFO - [2022-02-18 19:42:10,852] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:42:11,334] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:42:11,373] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:42:11,381] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:42:11,386] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 19:42:24,122] {scheduler_job.py:155} INFO - Started process (PID=8806) to work on /airflow/dags/download_data.py
[2022-02-18 19:42:24,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:42:24,129] {logging_mixin.py:112} INFO - [2022-02-18 19:42:24,128] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:42:24,649] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:42:24,700] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:42:24,709] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:42:24,714] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 19:42:37,424] {scheduler_job.py:155} INFO - Started process (PID=8832) to work on /airflow/dags/download_data.py
[2022-02-18 19:42:37,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:42:37,431] {logging_mixin.py:112} INFO - [2022-02-18 19:42:37,431] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:42:37,903] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:42:37,966] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:42:37,976] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:42:37,983] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 19:42:50,694] {scheduler_job.py:155} INFO - Started process (PID=8858) to work on /airflow/dags/download_data.py
[2022-02-18 19:42:50,698] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:42:50,700] {logging_mixin.py:112} INFO - [2022-02-18 19:42:50,700] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:42:51,162] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:42:51,206] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:42:51,215] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:42:51,222] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 19:43:03,984] {scheduler_job.py:155} INFO - Started process (PID=8884) to work on /airflow/dags/download_data.py
[2022-02-18 19:43:03,991] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:43:03,993] {logging_mixin.py:112} INFO - [2022-02-18 19:43:03,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:43:04,548] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:43:04,604] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:43:04,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:43:04,618] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.634 seconds
[2022-02-18 19:43:17,270] {scheduler_job.py:155} INFO - Started process (PID=8910) to work on /airflow/dags/download_data.py
[2022-02-18 19:43:17,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:43:17,286] {logging_mixin.py:112} INFO - [2022-02-18 19:43:17,286] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:43:17,801] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:43:17,853] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:43:17,862] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:43:17,867] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-18 19:43:30,541] {scheduler_job.py:155} INFO - Started process (PID=8936) to work on /airflow/dags/download_data.py
[2022-02-18 19:43:30,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:43:30,557] {logging_mixin.py:112} INFO - [2022-02-18 19:43:30,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:43:31,060] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:43:31,113] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:43:31,123] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:43:31,128] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 19:43:43,798] {scheduler_job.py:155} INFO - Started process (PID=8962) to work on /airflow/dags/download_data.py
[2022-02-18 19:43:43,802] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:43:43,808] {logging_mixin.py:112} INFO - [2022-02-18 19:43:43,808] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:43:44,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:43:44,361] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:43:44,370] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:43:44,374] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 19:43:57,040] {scheduler_job.py:155} INFO - Started process (PID=8988) to work on /airflow/dags/download_data.py
[2022-02-18 19:43:57,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:43:57,048] {logging_mixin.py:112} INFO - [2022-02-18 19:43:57,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:43:57,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:43:57,631] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:43:57,640] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:43:57,645] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 19:44:10,281] {scheduler_job.py:155} INFO - Started process (PID=9014) to work on /airflow/dags/download_data.py
[2022-02-18 19:44:10,287] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:44:10,288] {logging_mixin.py:112} INFO - [2022-02-18 19:44:10,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:44:10,763] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:44:10,808] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:44:10,814] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:44:10,817] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 19:44:23,529] {scheduler_job.py:155} INFO - Started process (PID=9040) to work on /airflow/dags/download_data.py
[2022-02-18 19:44:23,534] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:44:23,536] {logging_mixin.py:112} INFO - [2022-02-18 19:44:23,536] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:44:23,994] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:44:24,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:44:24,050] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:44:24,055] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 19:44:36,765] {scheduler_job.py:155} INFO - Started process (PID=9066) to work on /airflow/dags/download_data.py
[2022-02-18 19:44:36,770] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:44:36,771] {logging_mixin.py:112} INFO - [2022-02-18 19:44:36,771] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:44:37,212] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:44:37,255] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:44:37,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:44:37,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 19:44:50,058] {scheduler_job.py:155} INFO - Started process (PID=9092) to work on /airflow/dags/download_data.py
[2022-02-18 19:44:50,065] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:44:50,068] {logging_mixin.py:112} INFO - [2022-02-18 19:44:50,068] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:44:50,568] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:44:50,623] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:44:50,633] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:44:50,639] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 19:45:03,358] {scheduler_job.py:155} INFO - Started process (PID=9118) to work on /airflow/dags/download_data.py
[2022-02-18 19:45:03,371] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:45:03,373] {logging_mixin.py:112} INFO - [2022-02-18 19:45:03,373] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:45:04,456] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:45:04,510] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:45:04,525] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:45:04,533] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.175 seconds
[2022-02-18 19:45:17,644] {scheduler_job.py:155} INFO - Started process (PID=9144) to work on /airflow/dags/download_data.py
[2022-02-18 19:45:17,662] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:45:17,667] {logging_mixin.py:112} INFO - [2022-02-18 19:45:17,666] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:45:18,152] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:45:18,216] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:45:18,224] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:45:18,228] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 19:45:29,942] {scheduler_job.py:155} INFO - Started process (PID=9169) to work on /airflow/dags/download_data.py
[2022-02-18 19:45:29,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:45:29,956] {logging_mixin.py:112} INFO - [2022-02-18 19:45:29,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:45:30,512] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:45:30,563] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:45:30,574] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:45:30,578] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.636 seconds
[2022-02-18 19:45:43,287] {scheduler_job.py:155} INFO - Started process (PID=9195) to work on /airflow/dags/download_data.py
[2022-02-18 19:45:43,297] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:45:43,301] {logging_mixin.py:112} INFO - [2022-02-18 19:45:43,301] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:45:43,812] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:45:43,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:45:43,858] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:45:43,866] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 19:45:56,586] {scheduler_job.py:155} INFO - Started process (PID=9221) to work on /airflow/dags/download_data.py
[2022-02-18 19:45:56,593] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:45:56,596] {logging_mixin.py:112} INFO - [2022-02-18 19:45:56,595] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:45:57,112] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:45:57,156] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:45:57,165] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:45:57,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.585 seconds
[2022-02-18 19:46:09,835] {scheduler_job.py:155} INFO - Started process (PID=9247) to work on /airflow/dags/download_data.py
[2022-02-18 19:46:09,840] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:46:09,842] {logging_mixin.py:112} INFO - [2022-02-18 19:46:09,842] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:46:10,314] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:46:10,355] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:46:10,361] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:46:10,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 19:46:23,166] {scheduler_job.py:155} INFO - Started process (PID=9273) to work on /airflow/dags/download_data.py
[2022-02-18 19:46:23,176] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:46:23,178] {logging_mixin.py:112} INFO - [2022-02-18 19:46:23,178] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:46:23,727] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:46:23,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:46:23,789] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:46:23,793] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.627 seconds
[2022-02-18 19:46:36,413] {scheduler_job.py:155} INFO - Started process (PID=9299) to work on /airflow/dags/download_data.py
[2022-02-18 19:46:36,425] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:46:36,427] {logging_mixin.py:112} INFO - [2022-02-18 19:46:36,427] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:46:36,875] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:46:36,927] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:46:36,938] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:46:36,943] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 19:46:49,732] {scheduler_job.py:155} INFO - Started process (PID=9325) to work on /airflow/dags/download_data.py
[2022-02-18 19:46:49,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:46:49,745] {logging_mixin.py:112} INFO - [2022-02-18 19:46:49,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:46:50,244] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:46:50,296] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:46:50,303] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:46:50,308] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 19:47:03,080] {scheduler_job.py:155} INFO - Started process (PID=9351) to work on /airflow/dags/download_data.py
[2022-02-18 19:47:03,092] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:47:03,095] {logging_mixin.py:112} INFO - [2022-02-18 19:47:03,094] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:47:03,629] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:47:03,679] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:47:03,690] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:47:03,699] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.618 seconds
[2022-02-18 19:47:16,341] {scheduler_job.py:155} INFO - Started process (PID=9377) to work on /airflow/dags/download_data.py
[2022-02-18 19:47:16,346] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:47:16,348] {logging_mixin.py:112} INFO - [2022-02-18 19:47:16,348] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:47:16,774] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:47:16,816] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:47:16,821] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:47:16,825] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-18 19:47:29,653] {scheduler_job.py:155} INFO - Started process (PID=9403) to work on /airflow/dags/download_data.py
[2022-02-18 19:47:29,662] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:47:29,666] {logging_mixin.py:112} INFO - [2022-02-18 19:47:29,665] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:47:30,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:47:30,298] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:47:30,311] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:47:30,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.665 seconds
[2022-02-18 19:47:42,902] {scheduler_job.py:155} INFO - Started process (PID=9429) to work on /airflow/dags/download_data.py
[2022-02-18 19:47:42,916] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:47:42,920] {logging_mixin.py:112} INFO - [2022-02-18 19:47:42,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:47:43,541] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:47:43,594] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:47:43,602] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:47:43,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.722 seconds
[2022-02-18 19:47:56,206] {scheduler_job.py:155} INFO - Started process (PID=9455) to work on /airflow/dags/download_data.py
[2022-02-18 19:47:56,218] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:47:56,220] {logging_mixin.py:112} INFO - [2022-02-18 19:47:56,219] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:47:56,684] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:47:56,727] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:47:56,732] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:47:56,737] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 19:48:09,426] {scheduler_job.py:155} INFO - Started process (PID=9481) to work on /airflow/dags/download_data.py
[2022-02-18 19:48:09,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:48:09,432] {logging_mixin.py:112} INFO - [2022-02-18 19:48:09,432] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:48:09,908] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:48:09,962] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:48:09,973] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:48:09,979] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 19:48:22,698] {scheduler_job.py:155} INFO - Started process (PID=9507) to work on /airflow/dags/download_data.py
[2022-02-18 19:48:22,709] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:48:22,711] {logging_mixin.py:112} INFO - [2022-02-18 19:48:22,710] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:48:23,186] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:48:23,230] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:48:23,239] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:48:23,245] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 19:48:35,941] {scheduler_job.py:155} INFO - Started process (PID=9533) to work on /airflow/dags/download_data.py
[2022-02-18 19:48:35,947] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:48:35,948] {logging_mixin.py:112} INFO - [2022-02-18 19:48:35,948] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:48:36,445] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:48:36,510] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:48:36,520] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:48:36,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 19:48:49,260] {scheduler_job.py:155} INFO - Started process (PID=9559) to work on /airflow/dags/download_data.py
[2022-02-18 19:48:49,273] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:48:49,275] {logging_mixin.py:112} INFO - [2022-02-18 19:48:49,275] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:48:49,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:48:49,786] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:48:49,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:48:49,798] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 19:49:02,521] {scheduler_job.py:155} INFO - Started process (PID=9585) to work on /airflow/dags/download_data.py
[2022-02-18 19:49:02,528] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:49:02,531] {logging_mixin.py:112} INFO - [2022-02-18 19:49:02,531] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:49:03,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:49:03,114] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:49:03,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:49:03,138] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-18 19:49:15,769] {scheduler_job.py:155} INFO - Started process (PID=9611) to work on /airflow/dags/download_data.py
[2022-02-18 19:49:15,784] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:49:15,786] {logging_mixin.py:112} INFO - [2022-02-18 19:49:15,786] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:49:16,264] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:49:16,319] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:49:16,330] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:49:16,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 19:49:29,049] {scheduler_job.py:155} INFO - Started process (PID=9637) to work on /airflow/dags/download_data.py
[2022-02-18 19:49:29,062] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:49:29,064] {logging_mixin.py:112} INFO - [2022-02-18 19:49:29,064] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:49:29,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:49:29,593] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:49:29,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:49:29,607] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 19:49:42,305] {scheduler_job.py:155} INFO - Started process (PID=9663) to work on /airflow/dags/download_data.py
[2022-02-18 19:49:42,317] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:49:42,319] {logging_mixin.py:112} INFO - [2022-02-18 19:49:42,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:49:42,763] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:49:42,806] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:49:42,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:49:42,821] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 19:49:55,654] {scheduler_job.py:155} INFO - Started process (PID=9689) to work on /airflow/dags/download_data.py
[2022-02-18 19:49:55,660] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:49:55,661] {logging_mixin.py:112} INFO - [2022-02-18 19:49:55,661] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:49:56,168] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:49:56,222] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:49:56,230] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:49:56,235] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 19:50:08,898] {scheduler_job.py:155} INFO - Started process (PID=9715) to work on /airflow/dags/download_data.py
[2022-02-18 19:50:08,903] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:50:08,905] {logging_mixin.py:112} INFO - [2022-02-18 19:50:08,905] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:50:09,370] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:50:09,416] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:50:09,422] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:50:09,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 19:50:22,186] {scheduler_job.py:155} INFO - Started process (PID=9741) to work on /airflow/dags/download_data.py
[2022-02-18 19:50:22,190] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:50:22,193] {logging_mixin.py:112} INFO - [2022-02-18 19:50:22,193] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:50:23,914] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:50:24,034] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:50:24,050] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:50:24,058] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.872 seconds
[2022-02-18 19:50:36,510] {scheduler_job.py:155} INFO - Started process (PID=9767) to work on /airflow/dags/download_data.py
[2022-02-18 19:50:36,524] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:50:36,526] {logging_mixin.py:112} INFO - [2022-02-18 19:50:36,526] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:50:37,086] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:50:37,142] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:50:37,148] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:50:37,154] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-18 19:50:48,792] {scheduler_job.py:155} INFO - Started process (PID=9792) to work on /airflow/dags/download_data.py
[2022-02-18 19:50:48,796] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:50:48,798] {logging_mixin.py:112} INFO - [2022-02-18 19:50:48,797] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:50:49,241] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:50:49,292] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:50:49,299] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:50:49,302] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 19:51:02,063] {scheduler_job.py:155} INFO - Started process (PID=9818) to work on /airflow/dags/download_data.py
[2022-02-18 19:51:02,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:51:02,069] {logging_mixin.py:112} INFO - [2022-02-18 19:51:02,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:51:02,561] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:51:02,611] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:51:02,619] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:51:02,625] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 19:51:15,315] {scheduler_job.py:155} INFO - Started process (PID=9844) to work on /airflow/dags/download_data.py
[2022-02-18 19:51:15,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:51:15,329] {logging_mixin.py:112} INFO - [2022-02-18 19:51:15,329] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:51:15,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:51:15,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:51:15,883] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:51:15,887] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 19:51:28,628] {scheduler_job.py:155} INFO - Started process (PID=9870) to work on /airflow/dags/download_data.py
[2022-02-18 19:51:28,634] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:51:28,635] {logging_mixin.py:112} INFO - [2022-02-18 19:51:28,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:51:29,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:51:29,235] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:51:29,244] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:51:29,252] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-18 19:51:41,862] {scheduler_job.py:155} INFO - Started process (PID=9896) to work on /airflow/dags/download_data.py
[2022-02-18 19:51:41,867] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:51:41,869] {logging_mixin.py:112} INFO - [2022-02-18 19:51:41,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:51:42,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:51:42,390] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:51:42,399] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:51:42,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 19:51:55,154] {scheduler_job.py:155} INFO - Started process (PID=9922) to work on /airflow/dags/download_data.py
[2022-02-18 19:51:55,166] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:51:55,169] {logging_mixin.py:112} INFO - [2022-02-18 19:51:55,168] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:51:55,663] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:51:55,718] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:51:55,726] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:51:55,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 19:52:08,479] {scheduler_job.py:155} INFO - Started process (PID=9948) to work on /airflow/dags/download_data.py
[2022-02-18 19:52:08,490] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:52:08,492] {logging_mixin.py:112} INFO - [2022-02-18 19:52:08,491] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:52:08,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:52:08,997] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:52:09,007] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:52:09,014] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 19:52:21,760] {scheduler_job.py:155} INFO - Started process (PID=9974) to work on /airflow/dags/download_data.py
[2022-02-18 19:52:21,771] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:52:21,773] {logging_mixin.py:112} INFO - [2022-02-18 19:52:21,773] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:52:22,225] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:52:22,276] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:52:22,283] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:52:22,287] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 19:52:35,005] {scheduler_job.py:155} INFO - Started process (PID=10000) to work on /airflow/dags/download_data.py
[2022-02-18 19:52:35,013] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:52:35,015] {logging_mixin.py:112} INFO - [2022-02-18 19:52:35,015] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:52:35,486] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:52:35,544] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:52:35,554] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:52:35,565] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 19:52:48,272] {scheduler_job.py:155} INFO - Started process (PID=10026) to work on /airflow/dags/download_data.py
[2022-02-18 19:52:48,280] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:52:48,282] {logging_mixin.py:112} INFO - [2022-02-18 19:52:48,282] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:52:48,766] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:52:48,815] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:52:48,826] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:52:48,829] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 19:53:01,599] {scheduler_job.py:155} INFO - Started process (PID=10052) to work on /airflow/dags/download_data.py
[2022-02-18 19:53:01,603] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:53:01,605] {logging_mixin.py:112} INFO - [2022-02-18 19:53:01,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:53:02,117] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:53:02,154] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:53:02,161] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:53:02,167] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 19:53:14,841] {scheduler_job.py:155} INFO - Started process (PID=10078) to work on /airflow/dags/download_data.py
[2022-02-18 19:53:14,846] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:53:14,847] {logging_mixin.py:112} INFO - [2022-02-18 19:53:14,847] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:53:15,303] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:53:15,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:53:15,349] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:53:15,355] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 19:53:28,129] {scheduler_job.py:155} INFO - Started process (PID=10104) to work on /airflow/dags/download_data.py
[2022-02-18 19:53:28,139] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:53:28,145] {logging_mixin.py:112} INFO - [2022-02-18 19:53:28,145] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:53:28,614] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:53:28,657] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:53:28,666] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:53:28,670] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 19:53:41,365] {scheduler_job.py:155} INFO - Started process (PID=10130) to work on /airflow/dags/download_data.py
[2022-02-18 19:53:41,370] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:53:41,372] {logging_mixin.py:112} INFO - [2022-02-18 19:53:41,371] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:53:41,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:53:41,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:53:41,888] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:53:41,894] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 19:53:54,665] {scheduler_job.py:155} INFO - Started process (PID=10156) to work on /airflow/dags/download_data.py
[2022-02-18 19:53:54,673] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:53:54,675] {logging_mixin.py:112} INFO - [2022-02-18 19:53:54,675] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:53:55,171] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:53:55,224] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:53:55,232] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:53:55,237] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 19:54:07,916] {scheduler_job.py:155} INFO - Started process (PID=10182) to work on /airflow/dags/download_data.py
[2022-02-18 19:54:07,920] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:54:07,922] {logging_mixin.py:112} INFO - [2022-02-18 19:54:07,922] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:54:08,462] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:54:08,512] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:54:08,530] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:54:08,541] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-18 19:54:21,208] {scheduler_job.py:155} INFO - Started process (PID=10208) to work on /airflow/dags/download_data.py
[2022-02-18 19:54:21,213] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:54:21,215] {logging_mixin.py:112} INFO - [2022-02-18 19:54:21,215] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:54:21,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:54:21,807] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:54:21,818] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:54:21,824] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-18 19:54:34,529] {scheduler_job.py:155} INFO - Started process (PID=10234) to work on /airflow/dags/download_data.py
[2022-02-18 19:54:34,542] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:54:34,547] {logging_mixin.py:112} INFO - [2022-02-18 19:54:34,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:54:35,116] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:54:35,181] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:54:35,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:54:35,200] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.671 seconds
[2022-02-18 19:54:47,801] {scheduler_job.py:155} INFO - Started process (PID=10260) to work on /airflow/dags/download_data.py
[2022-02-18 19:54:47,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:54:47,812] {logging_mixin.py:112} INFO - [2022-02-18 19:54:47,811] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:54:48,356] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:54:48,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:54:48,410] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:54:48,427] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-18 19:55:01,088] {scheduler_job.py:155} INFO - Started process (PID=10286) to work on /airflow/dags/download_data.py
[2022-02-18 19:55:01,097] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:55:01,101] {logging_mixin.py:112} INFO - [2022-02-18 19:55:01,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:55:01,559] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:55:01,611] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:55:01,619] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:55:01,623] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 19:55:14,328] {scheduler_job.py:155} INFO - Started process (PID=10312) to work on /airflow/dags/download_data.py
[2022-02-18 19:55:14,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:55:14,333] {logging_mixin.py:112} INFO - [2022-02-18 19:55:14,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:55:14,801] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:55:14,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:55:14,859] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:55:14,864] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 19:55:27,633] {scheduler_job.py:155} INFO - Started process (PID=10338) to work on /airflow/dags/download_data.py
[2022-02-18 19:55:27,640] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:55:27,642] {logging_mixin.py:112} INFO - [2022-02-18 19:55:27,642] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:55:28,192] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:55:28,258] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:55:28,265] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:55:28,271] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-18 19:55:40,883] {scheduler_job.py:155} INFO - Started process (PID=10364) to work on /airflow/dags/download_data.py
[2022-02-18 19:55:40,893] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:55:40,896] {logging_mixin.py:112} INFO - [2022-02-18 19:55:40,895] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:55:41,371] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:55:41,424] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:55:41,437] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:55:41,440] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 19:55:54,192] {scheduler_job.py:155} INFO - Started process (PID=10390) to work on /airflow/dags/download_data.py
[2022-02-18 19:55:54,200] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:55:54,203] {logging_mixin.py:112} INFO - [2022-02-18 19:55:54,203] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:55:54,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:55:54,713] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:55:54,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:55:54,729] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 19:56:07,435] {scheduler_job.py:155} INFO - Started process (PID=10416) to work on /airflow/dags/download_data.py
[2022-02-18 19:56:07,442] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:56:07,446] {logging_mixin.py:112} INFO - [2022-02-18 19:56:07,446] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:56:07,919] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:56:07,972] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:56:07,985] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:56:07,993] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 19:56:20,725] {scheduler_job.py:155} INFO - Started process (PID=10442) to work on /airflow/dags/download_data.py
[2022-02-18 19:56:20,729] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:56:20,731] {logging_mixin.py:112} INFO - [2022-02-18 19:56:20,730] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:56:21,244] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:56:21,306] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:56:21,320] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:56:21,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 19:56:33,977] {scheduler_job.py:155} INFO - Started process (PID=10468) to work on /airflow/dags/download_data.py
[2022-02-18 19:56:33,981] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:56:33,983] {logging_mixin.py:112} INFO - [2022-02-18 19:56:33,983] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:56:34,440] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:56:34,496] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:56:34,506] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:56:34,513] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 19:56:47,218] {scheduler_job.py:155} INFO - Started process (PID=10494) to work on /airflow/dags/download_data.py
[2022-02-18 19:56:47,228] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:56:47,231] {logging_mixin.py:112} INFO - [2022-02-18 19:56:47,231] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:56:47,676] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:56:47,721] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:56:47,729] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:56:47,734] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 19:57:00,495] {scheduler_job.py:155} INFO - Started process (PID=10520) to work on /airflow/dags/download_data.py
[2022-02-18 19:57:00,501] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:57:00,502] {logging_mixin.py:112} INFO - [2022-02-18 19:57:00,502] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:57:00,986] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:57:01,030] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:57:01,040] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:57:01,044] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 19:57:13,753] {scheduler_job.py:155} INFO - Started process (PID=10546) to work on /airflow/dags/download_data.py
[2022-02-18 19:57:13,761] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:57:13,765] {logging_mixin.py:112} INFO - [2022-02-18 19:57:13,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:57:14,215] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:57:14,269] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:57:14,280] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:57:14,287] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 19:57:27,056] {scheduler_job.py:155} INFO - Started process (PID=10572) to work on /airflow/dags/download_data.py
[2022-02-18 19:57:27,070] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:57:27,077] {logging_mixin.py:112} INFO - [2022-02-18 19:57:27,076] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:57:27,725] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:57:27,777] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:57:27,789] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:57:27,792] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.742 seconds
[2022-02-18 19:57:40,314] {scheduler_job.py:155} INFO - Started process (PID=10598) to work on /airflow/dags/download_data.py
[2022-02-18 19:57:40,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:57:40,325] {logging_mixin.py:112} INFO - [2022-02-18 19:57:40,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:57:40,772] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:57:40,818] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:57:40,828] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:57:40,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 19:57:53,578] {scheduler_job.py:155} INFO - Started process (PID=10624) to work on /airflow/dags/download_data.py
[2022-02-18 19:57:53,589] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:57:53,592] {logging_mixin.py:112} INFO - [2022-02-18 19:57:53,591] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:57:54,107] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:57:54,161] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:57:54,171] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:57:54,177] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 19:58:06,838] {scheduler_job.py:155} INFO - Started process (PID=10650) to work on /airflow/dags/download_data.py
[2022-02-18 19:58:06,846] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:58:06,848] {logging_mixin.py:112} INFO - [2022-02-18 19:58:06,848] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:58:07,300] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:58:07,351] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:58:07,358] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:58:07,365] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 19:58:20,120] {scheduler_job.py:155} INFO - Started process (PID=10676) to work on /airflow/dags/download_data.py
[2022-02-18 19:58:20,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:58:20,137] {logging_mixin.py:112} INFO - [2022-02-18 19:58:20,136] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:58:20,658] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:58:20,697] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:58:20,702] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:58:20,713] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 19:58:33,428] {scheduler_job.py:155} INFO - Started process (PID=10702) to work on /airflow/dags/download_data.py
[2022-02-18 19:58:33,433] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:58:33,435] {logging_mixin.py:112} INFO - [2022-02-18 19:58:33,435] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:58:33,964] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:58:34,011] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:58:34,019] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:58:34,026] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 19:58:46,687] {scheduler_job.py:155} INFO - Started process (PID=10728) to work on /airflow/dags/download_data.py
[2022-02-18 19:58:46,695] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:58:46,699] {logging_mixin.py:112} INFO - [2022-02-18 19:58:46,699] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:58:47,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:58:47,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:58:47,416] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:58:47,423] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.736 seconds
[2022-02-18 19:58:59,948] {scheduler_job.py:155} INFO - Started process (PID=10754) to work on /airflow/dags/download_data.py
[2022-02-18 19:58:59,954] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:58:59,956] {logging_mixin.py:112} INFO - [2022-02-18 19:58:59,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:59:00,441] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:59:00,477] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:59:00,483] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:59:00,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 19:59:13,209] {scheduler_job.py:155} INFO - Started process (PID=10780) to work on /airflow/dags/download_data.py
[2022-02-18 19:59:13,214] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:59:13,218] {logging_mixin.py:112} INFO - [2022-02-18 19:59:13,218] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:59:13,777] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:59:13,837] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:59:13,851] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:59:13,856] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.647 seconds
[2022-02-18 19:59:26,485] {scheduler_job.py:155} INFO - Started process (PID=10806) to work on /airflow/dags/download_data.py
[2022-02-18 19:59:26,493] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:59:26,496] {logging_mixin.py:112} INFO - [2022-02-18 19:59:26,495] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:59:26,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:59:26,999] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:59:27,013] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:59:27,018] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 19:59:39,739] {scheduler_job.py:155} INFO - Started process (PID=10832) to work on /airflow/dags/download_data.py
[2022-02-18 19:59:39,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:59:39,750] {logging_mixin.py:112} INFO - [2022-02-18 19:59:39,750] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:59:40,385] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:59:40,437] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:59:40,445] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:59:40,449] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.711 seconds
[2022-02-18 19:59:53,068] {scheduler_job.py:155} INFO - Started process (PID=10858) to work on /airflow/dags/download_data.py
[2022-02-18 19:59:53,075] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 19:59:53,078] {logging_mixin.py:112} INFO - [2022-02-18 19:59:53,077] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 19:59:53,552] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 19:59:53,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 19:59:53,606] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 19:59:53,610] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 20:00:06,302] {scheduler_job.py:155} INFO - Started process (PID=10884) to work on /airflow/dags/download_data.py
[2022-02-18 20:00:06,306] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:00:06,308] {logging_mixin.py:112} INFO - [2022-02-18 20:00:06,308] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:00:06,770] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:00:06,818] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:00:06,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:00:06,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 20:00:19,549] {scheduler_job.py:155} INFO - Started process (PID=10910) to work on /airflow/dags/download_data.py
[2022-02-18 20:00:19,553] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:00:19,555] {logging_mixin.py:112} INFO - [2022-02-18 20:00:19,554] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:00:20,004] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:00:20,057] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:00:20,065] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:00:20,070] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 20:00:32,832] {scheduler_job.py:155} INFO - Started process (PID=10936) to work on /airflow/dags/download_data.py
[2022-02-18 20:00:32,844] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:00:32,845] {logging_mixin.py:112} INFO - [2022-02-18 20:00:32,845] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:00:33,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:00:33,387] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:00:33,397] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:00:33,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 20:00:46,102] {scheduler_job.py:155} INFO - Started process (PID=10962) to work on /airflow/dags/download_data.py
[2022-02-18 20:00:46,115] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:00:46,123] {logging_mixin.py:112} INFO - [2022-02-18 20:00:46,122] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:00:46,620] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:00:46,674] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:00:46,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:00:46,692] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 20:00:59,382] {scheduler_job.py:155} INFO - Started process (PID=10988) to work on /airflow/dags/download_data.py
[2022-02-18 20:00:59,386] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:00:59,388] {logging_mixin.py:112} INFO - [2022-02-18 20:00:59,388] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:00:59,854] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:00:59,906] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:00:59,913] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:00:59,919] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 20:01:12,623] {scheduler_job.py:155} INFO - Started process (PID=11014) to work on /airflow/dags/download_data.py
[2022-02-18 20:01:12,629] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:01:12,633] {logging_mixin.py:112} INFO - [2022-02-18 20:01:12,632] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:01:13,103] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:01:13,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:01:13,168] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:01:13,172] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 20:01:25,871] {scheduler_job.py:155} INFO - Started process (PID=11040) to work on /airflow/dags/download_data.py
[2022-02-18 20:01:25,879] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:01:25,880] {logging_mixin.py:112} INFO - [2022-02-18 20:01:25,880] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:01:26,335] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:01:26,387] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:01:26,395] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:01:26,400] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 20:01:39,142] {scheduler_job.py:155} INFO - Started process (PID=11066) to work on /airflow/dags/download_data.py
[2022-02-18 20:01:39,146] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:01:39,148] {logging_mixin.py:112} INFO - [2022-02-18 20:01:39,148] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:01:39,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:01:39,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:01:39,663] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:01:39,668] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 20:01:52,407] {scheduler_job.py:155} INFO - Started process (PID=11092) to work on /airflow/dags/download_data.py
[2022-02-18 20:01:52,412] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:01:52,413] {logging_mixin.py:112} INFO - [2022-02-18 20:01:52,413] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:01:52,875] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:01:52,927] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:01:52,935] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:01:52,941] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 20:02:05,641] {scheduler_job.py:155} INFO - Started process (PID=11118) to work on /airflow/dags/download_data.py
[2022-02-18 20:02:05,649] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:02:05,652] {logging_mixin.py:112} INFO - [2022-02-18 20:02:05,651] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:02:06,117] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:02:06,166] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:02:06,175] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:02:06,182] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 20:02:18,921] {scheduler_job.py:155} INFO - Started process (PID=11144) to work on /airflow/dags/download_data.py
[2022-02-18 20:02:18,925] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:02:18,927] {logging_mixin.py:112} INFO - [2022-02-18 20:02:18,927] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:02:19,379] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:02:19,420] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:02:19,430] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:02:19,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 20:02:32,219] {scheduler_job.py:155} INFO - Started process (PID=11170) to work on /airflow/dags/download_data.py
[2022-02-18 20:02:32,224] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:02:32,226] {logging_mixin.py:112} INFO - [2022-02-18 20:02:32,226] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:02:32,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:02:32,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:02:32,796] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:02:32,805] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 20:02:45,447] {scheduler_job.py:155} INFO - Started process (PID=11196) to work on /airflow/dags/download_data.py
[2022-02-18 20:02:45,459] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:02:45,462] {logging_mixin.py:112} INFO - [2022-02-18 20:02:45,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:02:45,914] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:02:45,963] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:02:45,970] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:02:45,975] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 20:02:58,729] {scheduler_job.py:155} INFO - Started process (PID=11222) to work on /airflow/dags/download_data.py
[2022-02-18 20:02:58,735] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:02:58,737] {logging_mixin.py:112} INFO - [2022-02-18 20:02:58,737] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:02:59,221] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:02:59,262] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:02:59,268] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:02:59,271] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 20:03:11,990] {scheduler_job.py:155} INFO - Started process (PID=11248) to work on /airflow/dags/download_data.py
[2022-02-18 20:03:11,995] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:03:11,996] {logging_mixin.py:112} INFO - [2022-02-18 20:03:11,996] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:03:12,461] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:03:12,504] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:03:12,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:03:12,520] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 20:03:25,257] {scheduler_job.py:155} INFO - Started process (PID=11274) to work on /airflow/dags/download_data.py
[2022-02-18 20:03:25,263] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:03:25,265] {logging_mixin.py:112} INFO - [2022-02-18 20:03:25,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:03:25,745] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:03:25,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:03:25,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:03:25,815] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 20:03:38,533] {scheduler_job.py:155} INFO - Started process (PID=11300) to work on /airflow/dags/download_data.py
[2022-02-18 20:03:38,541] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:03:38,543] {logging_mixin.py:112} INFO - [2022-02-18 20:03:38,543] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:03:38,991] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:03:39,040] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:03:39,053] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:03:39,062] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 20:03:51,941] {scheduler_job.py:155} INFO - Started process (PID=11326) to work on /airflow/dags/download_data.py
[2022-02-18 20:03:51,949] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:03:51,951] {logging_mixin.py:112} INFO - [2022-02-18 20:03:51,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:03:52,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:03:52,551] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:03:52,560] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:03:52,566] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-18 20:04:05,262] {scheduler_job.py:155} INFO - Started process (PID=11352) to work on /airflow/dags/download_data.py
[2022-02-18 20:04:05,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:04:05,268] {logging_mixin.py:112} INFO - [2022-02-18 20:04:05,268] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:04:05,746] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:04:05,800] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:04:05,812] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:04:05,818] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 20:04:18,547] {scheduler_job.py:155} INFO - Started process (PID=11378) to work on /airflow/dags/download_data.py
[2022-02-18 20:04:18,553] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:04:18,554] {logging_mixin.py:112} INFO - [2022-02-18 20:04:18,554] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:04:19,016] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:04:19,075] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:04:19,081] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:04:19,085] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 20:04:31,834] {scheduler_job.py:155} INFO - Started process (PID=11404) to work on /airflow/dags/download_data.py
[2022-02-18 20:04:31,838] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:04:31,841] {logging_mixin.py:112} INFO - [2022-02-18 20:04:31,841] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:04:32,332] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:04:32,375] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:04:32,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:04:32,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 20:04:45,095] {scheduler_job.py:155} INFO - Started process (PID=11430) to work on /airflow/dags/download_data.py
[2022-02-18 20:04:45,105] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:04:45,107] {logging_mixin.py:112} INFO - [2022-02-18 20:04:45,107] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:04:45,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:04:45,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:04:45,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:04:45,820] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.724 seconds
[2022-02-18 20:04:58,364] {scheduler_job.py:155} INFO - Started process (PID=11456) to work on /airflow/dags/download_data.py
[2022-02-18 20:04:58,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:04:58,382] {logging_mixin.py:112} INFO - [2022-02-18 20:04:58,381] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:04:58,989] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:04:59,038] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:04:59,051] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:04:59,059] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.695 seconds
[2022-02-18 20:05:11,607] {scheduler_job.py:155} INFO - Started process (PID=11482) to work on /airflow/dags/download_data.py
[2022-02-18 20:05:11,611] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:05:11,613] {logging_mixin.py:112} INFO - [2022-02-18 20:05:11,613] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:05:12,067] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:05:12,107] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:05:12,115] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:05:12,120] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 20:05:24,915] {scheduler_job.py:155} INFO - Started process (PID=11508) to work on /airflow/dags/download_data.py
[2022-02-18 20:05:24,921] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:05:24,922] {logging_mixin.py:112} INFO - [2022-02-18 20:05:24,922] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:05:25,386] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:05:25,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:05:25,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:05:25,454] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 20:05:38,186] {scheduler_job.py:155} INFO - Started process (PID=11534) to work on /airflow/dags/download_data.py
[2022-02-18 20:05:38,196] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:05:38,198] {logging_mixin.py:112} INFO - [2022-02-18 20:05:38,198] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:05:38,761] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:05:38,822] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:05:38,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:05:38,830] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-18 20:05:51,469] {scheduler_job.py:155} INFO - Started process (PID=11560) to work on /airflow/dags/download_data.py
[2022-02-18 20:05:51,479] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:05:51,482] {logging_mixin.py:112} INFO - [2022-02-18 20:05:51,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:05:51,995] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:05:52,044] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:05:52,054] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:05:52,059] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 20:06:04,700] {scheduler_job.py:155} INFO - Started process (PID=11586) to work on /airflow/dags/download_data.py
[2022-02-18 20:06:04,708] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:06:04,710] {logging_mixin.py:112} INFO - [2022-02-18 20:06:04,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:06:05,174] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:06:05,236] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:06:05,251] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:06:05,259] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 20:06:18,042] {scheduler_job.py:155} INFO - Started process (PID=11612) to work on /airflow/dags/download_data.py
[2022-02-18 20:06:18,053] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:06:18,057] {logging_mixin.py:112} INFO - [2022-02-18 20:06:18,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:06:18,555] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:06:18,608] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:06:18,616] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:06:18,621] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 20:06:31,351] {scheduler_job.py:155} INFO - Started process (PID=11638) to work on /airflow/dags/download_data.py
[2022-02-18 20:06:31,372] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:06:31,374] {logging_mixin.py:112} INFO - [2022-02-18 20:06:31,373] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:06:31,933] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:06:31,992] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:06:32,002] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:06:32,007] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-18 20:06:44,612] {scheduler_job.py:155} INFO - Started process (PID=11664) to work on /airflow/dags/download_data.py
[2022-02-18 20:06:44,618] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:06:44,620] {logging_mixin.py:112} INFO - [2022-02-18 20:06:44,619] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:06:45,074] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:06:45,115] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:06:45,121] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:06:45,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 20:06:57,870] {scheduler_job.py:155} INFO - Started process (PID=11690) to work on /airflow/dags/download_data.py
[2022-02-18 20:06:57,875] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:06:57,877] {logging_mixin.py:112} INFO - [2022-02-18 20:06:57,877] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:06:58,356] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:06:58,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:06:58,415] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:06:58,421] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 20:07:11,193] {scheduler_job.py:155} INFO - Started process (PID=11716) to work on /airflow/dags/download_data.py
[2022-02-18 20:07:11,198] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:07:11,200] {logging_mixin.py:112} INFO - [2022-02-18 20:07:11,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:07:11,717] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:07:11,771] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:07:11,781] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:07:11,788] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 20:07:24,459] {scheduler_job.py:155} INFO - Started process (PID=11742) to work on /airflow/dags/download_data.py
[2022-02-18 20:07:24,467] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:07:24,469] {logging_mixin.py:112} INFO - [2022-02-18 20:07:24,469] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:07:24,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:07:25,020] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:07:25,030] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:07:25,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 20:07:37,720] {scheduler_job.py:155} INFO - Started process (PID=11768) to work on /airflow/dags/download_data.py
[2022-02-18 20:07:37,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:07:37,738] {logging_mixin.py:112} INFO - [2022-02-18 20:07:37,738] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:07:38,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:07:38,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:07:38,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:07:38,267] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 20:07:51,001] {scheduler_job.py:155} INFO - Started process (PID=11794) to work on /airflow/dags/download_data.py
[2022-02-18 20:07:51,011] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:07:51,012] {logging_mixin.py:112} INFO - [2022-02-18 20:07:51,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:07:51,500] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:07:51,564] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:07:51,573] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:07:51,585] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 20:08:04,254] {scheduler_job.py:155} INFO - Started process (PID=11820) to work on /airflow/dags/download_data.py
[2022-02-18 20:08:04,258] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:08:04,260] {logging_mixin.py:112} INFO - [2022-02-18 20:08:04,260] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:08:04,704] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:08:04,755] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:08:04,762] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:08:04,767] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 20:08:17,514] {scheduler_job.py:155} INFO - Started process (PID=11846) to work on /airflow/dags/download_data.py
[2022-02-18 20:08:17,523] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:08:17,525] {logging_mixin.py:112} INFO - [2022-02-18 20:08:17,525] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:08:18,003] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:08:18,050] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:08:18,058] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:08:18,061] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 20:08:30,814] {scheduler_job.py:155} INFO - Started process (PID=11872) to work on /airflow/dags/download_data.py
[2022-02-18 20:08:30,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:08:30,820] {logging_mixin.py:112} INFO - [2022-02-18 20:08:30,820] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:08:31,446] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:08:31,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:08:31,512] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:08:31,524] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.710 seconds
[2022-02-18 20:08:44,112] {scheduler_job.py:155} INFO - Started process (PID=11898) to work on /airflow/dags/download_data.py
[2022-02-18 20:08:44,119] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:08:44,121] {logging_mixin.py:112} INFO - [2022-02-18 20:08:44,121] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:08:44,681] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:08:44,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:08:44,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:08:44,756] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-18 20:08:57,399] {scheduler_job.py:155} INFO - Started process (PID=11924) to work on /airflow/dags/download_data.py
[2022-02-18 20:08:57,409] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:08:57,411] {logging_mixin.py:112} INFO - [2022-02-18 20:08:57,411] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:08:57,880] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:08:57,939] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:08:57,951] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:08:57,956] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 20:09:10,667] {scheduler_job.py:155} INFO - Started process (PID=11950) to work on /airflow/dags/download_data.py
[2022-02-18 20:09:10,673] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:09:10,677] {logging_mixin.py:112} INFO - [2022-02-18 20:09:10,677] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:09:11,208] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:09:11,276] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:09:11,285] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:09:11,294] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-18 20:09:23,929] {scheduler_job.py:155} INFO - Started process (PID=11976) to work on /airflow/dags/download_data.py
[2022-02-18 20:09:23,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:09:23,939] {logging_mixin.py:112} INFO - [2022-02-18 20:09:23,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:09:24,501] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:09:24,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:09:24,566] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:09:24,571] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.646 seconds
[2022-02-18 20:09:37,179] {scheduler_job.py:155} INFO - Started process (PID=12002) to work on /airflow/dags/download_data.py
[2022-02-18 20:09:37,192] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:09:37,193] {logging_mixin.py:112} INFO - [2022-02-18 20:09:37,193] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:09:37,652] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:09:37,704] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:09:37,713] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:09:37,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 20:09:50,506] {scheduler_job.py:155} INFO - Started process (PID=12028) to work on /airflow/dags/download_data.py
[2022-02-18 20:09:50,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:09:50,512] {logging_mixin.py:112} INFO - [2022-02-18 20:09:50,512] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:09:51,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:09:51,073] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:09:51,083] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:09:51,087] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 20:10:03,774] {scheduler_job.py:155} INFO - Started process (PID=12054) to work on /airflow/dags/download_data.py
[2022-02-18 20:10:03,781] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:10:03,785] {logging_mixin.py:112} INFO - [2022-02-18 20:10:03,784] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:10:04,292] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:10:04,352] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:10:04,363] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:10:04,368] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 20:10:17,073] {scheduler_job.py:155} INFO - Started process (PID=12080) to work on /airflow/dags/download_data.py
[2022-02-18 20:10:17,080] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:10:17,082] {logging_mixin.py:112} INFO - [2022-02-18 20:10:17,082] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:10:17,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:10:17,651] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:10:17,661] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:10:17,666] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 20:10:30,387] {scheduler_job.py:155} INFO - Started process (PID=12106) to work on /airflow/dags/download_data.py
[2022-02-18 20:10:30,401] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:10:30,403] {logging_mixin.py:112} INFO - [2022-02-18 20:10:30,403] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:10:31,046] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:10:31,130] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:10:31,139] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:10:31,145] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.758 seconds
[2022-02-18 20:10:43,642] {scheduler_job.py:155} INFO - Started process (PID=12132) to work on /airflow/dags/download_data.py
[2022-02-18 20:10:43,650] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:10:43,656] {logging_mixin.py:112} INFO - [2022-02-18 20:10:43,655] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:10:44,161] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:10:44,221] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:10:44,237] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:10:44,245] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 20:10:56,938] {scheduler_job.py:155} INFO - Started process (PID=12158) to work on /airflow/dags/download_data.py
[2022-02-18 20:10:56,947] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:10:56,949] {logging_mixin.py:112} INFO - [2022-02-18 20:10:56,949] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:10:57,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:10:57,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:10:57,458] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:10:57,465] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 20:11:10,159] {scheduler_job.py:155} INFO - Started process (PID=12184) to work on /airflow/dags/download_data.py
[2022-02-18 20:11:10,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:11:10,165] {logging_mixin.py:112} INFO - [2022-02-18 20:11:10,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:11:10,624] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:11:10,686] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:11:10,699] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:11:10,705] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 20:11:23,472] {scheduler_job.py:155} INFO - Started process (PID=12210) to work on /airflow/dags/download_data.py
[2022-02-18 20:11:23,479] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:11:23,481] {logging_mixin.py:112} INFO - [2022-02-18 20:11:23,480] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:11:23,933] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:11:23,982] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:11:23,992] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:11:23,998] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 20:11:36,732] {scheduler_job.py:155} INFO - Started process (PID=12236) to work on /airflow/dags/download_data.py
[2022-02-18 20:11:36,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:11:36,744] {logging_mixin.py:112} INFO - [2022-02-18 20:11:36,744] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:11:37,180] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:11:37,236] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:11:37,243] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:11:37,250] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 20:11:50,022] {scheduler_job.py:155} INFO - Started process (PID=12262) to work on /airflow/dags/download_data.py
[2022-02-18 20:11:50,030] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:11:50,032] {logging_mixin.py:112} INFO - [2022-02-18 20:11:50,032] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:11:50,472] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:11:50,522] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:11:50,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:11:50,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 20:12:03,276] {scheduler_job.py:155} INFO - Started process (PID=12288) to work on /airflow/dags/download_data.py
[2022-02-18 20:12:03,284] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:12:03,286] {logging_mixin.py:112} INFO - [2022-02-18 20:12:03,286] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:12:03,743] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:12:03,782] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:12:03,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:12:03,791] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 20:12:16,567] {scheduler_job.py:155} INFO - Started process (PID=12314) to work on /airflow/dags/download_data.py
[2022-02-18 20:12:16,571] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:12:16,573] {logging_mixin.py:112} INFO - [2022-02-18 20:12:16,573] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:12:17,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:12:17,082] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:12:17,089] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:12:17,095] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 20:12:29,839] {scheduler_job.py:155} INFO - Started process (PID=12340) to work on /airflow/dags/download_data.py
[2022-02-18 20:12:29,846] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:12:29,863] {logging_mixin.py:112} INFO - [2022-02-18 20:12:29,862] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:12:30,377] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:12:30,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:12:30,433] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:12:30,437] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 20:12:43,074] {scheduler_job.py:155} INFO - Started process (PID=12366) to work on /airflow/dags/download_data.py
[2022-02-18 20:12:43,083] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:12:43,086] {logging_mixin.py:112} INFO - [2022-02-18 20:12:43,086] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:12:43,568] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:12:43,626] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:12:43,639] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:12:43,646] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 20:12:56,404] {scheduler_job.py:155} INFO - Started process (PID=12392) to work on /airflow/dags/download_data.py
[2022-02-18 20:12:56,412] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:12:56,414] {logging_mixin.py:112} INFO - [2022-02-18 20:12:56,414] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:12:56,955] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:12:57,007] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:12:57,017] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:12:57,024] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.621 seconds
[2022-02-18 20:13:09,637] {scheduler_job.py:155} INFO - Started process (PID=12418) to work on /airflow/dags/download_data.py
[2022-02-18 20:13:09,645] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:13:09,647] {logging_mixin.py:112} INFO - [2022-02-18 20:13:09,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:13:10,154] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:13:10,191] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:13:10,196] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:13:10,200] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 20:13:22,934] {scheduler_job.py:155} INFO - Started process (PID=12444) to work on /airflow/dags/download_data.py
[2022-02-18 20:13:22,939] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:13:22,941] {logging_mixin.py:112} INFO - [2022-02-18 20:13:22,940] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:13:23,427] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:13:23,473] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:13:23,479] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:13:23,483] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 20:13:36,169] {scheduler_job.py:155} INFO - Started process (PID=12470) to work on /airflow/dags/download_data.py
[2022-02-18 20:13:36,174] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:13:36,176] {logging_mixin.py:112} INFO - [2022-02-18 20:13:36,176] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:13:36,648] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:13:36,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:13:36,715] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:13:36,723] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 20:13:49,465] {scheduler_job.py:155} INFO - Started process (PID=12496) to work on /airflow/dags/download_data.py
[2022-02-18 20:13:49,473] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:13:49,475] {logging_mixin.py:112} INFO - [2022-02-18 20:13:49,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:13:49,942] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:13:49,994] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:13:50,000] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:13:50,006] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 20:14:02,757] {scheduler_job.py:155} INFO - Started process (PID=12522) to work on /airflow/dags/download_data.py
[2022-02-18 20:14:02,761] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:14:02,764] {logging_mixin.py:112} INFO - [2022-02-18 20:14:02,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:14:03,241] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:14:03,299] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:14:03,309] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:14:03,315] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 20:14:16,035] {scheduler_job.py:155} INFO - Started process (PID=12548) to work on /airflow/dags/download_data.py
[2022-02-18 20:14:16,042] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:14:16,053] {logging_mixin.py:112} INFO - [2022-02-18 20:14:16,053] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:14:16,591] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:14:16,652] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:14:16,659] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:14:16,664] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-18 20:14:29,299] {scheduler_job.py:155} INFO - Started process (PID=12574) to work on /airflow/dags/download_data.py
[2022-02-18 20:14:29,306] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:14:29,310] {logging_mixin.py:112} INFO - [2022-02-18 20:14:29,310] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:14:29,880] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:14:29,948] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:14:29,957] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:14:29,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.665 seconds
[2022-02-18 20:14:42,552] {scheduler_job.py:155} INFO - Started process (PID=12600) to work on /airflow/dags/download_data.py
[2022-02-18 20:14:42,555] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:14:42,557] {logging_mixin.py:112} INFO - [2022-02-18 20:14:42,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:14:43,037] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:14:43,081] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:14:43,089] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:14:43,094] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 20:14:55,847] {scheduler_job.py:155} INFO - Started process (PID=12626) to work on /airflow/dags/download_data.py
[2022-02-18 20:14:55,852] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:14:55,855] {logging_mixin.py:112} INFO - [2022-02-18 20:14:55,855] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:14:56,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:14:56,429] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:14:56,439] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:14:56,445] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 20:15:09,177] {scheduler_job.py:155} INFO - Started process (PID=12652) to work on /airflow/dags/download_data.py
[2022-02-18 20:15:09,197] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:15:09,206] {logging_mixin.py:112} INFO - [2022-02-18 20:15:09,205] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:15:09,807] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:15:09,855] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:15:09,861] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:15:09,868] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.692 seconds
[2022-02-18 20:15:22,447] {scheduler_job.py:155} INFO - Started process (PID=12678) to work on /airflow/dags/download_data.py
[2022-02-18 20:15:22,455] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:15:22,458] {logging_mixin.py:112} INFO - [2022-02-18 20:15:22,458] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:15:23,055] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:15:23,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:15:23,107] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:15:23,111] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.665 seconds
[2022-02-18 20:15:35,706] {scheduler_job.py:155} INFO - Started process (PID=12704) to work on /airflow/dags/download_data.py
[2022-02-18 20:15:35,711] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:15:35,714] {logging_mixin.py:112} INFO - [2022-02-18 20:15:35,714] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:15:36,248] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:15:36,295] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:15:36,306] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:15:36,316] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 20:15:49,034] {scheduler_job.py:155} INFO - Started process (PID=12730) to work on /airflow/dags/download_data.py
[2022-02-18 20:15:49,042] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:15:49,045] {logging_mixin.py:112} INFO - [2022-02-18 20:15:49,045] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:15:49,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:15:49,687] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:15:49,698] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:15:49,704] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.670 seconds
[2022-02-18 20:16:02,261] {scheduler_job.py:155} INFO - Started process (PID=12756) to work on /airflow/dags/download_data.py
[2022-02-18 20:16:02,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:16:02,268] {logging_mixin.py:112} INFO - [2022-02-18 20:16:02,268] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:16:02,752] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:16:02,792] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:16:02,802] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:16:02,807] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 20:16:15,500] {scheduler_job.py:155} INFO - Started process (PID=12782) to work on /airflow/dags/download_data.py
[2022-02-18 20:16:15,505] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:16:15,507] {logging_mixin.py:112} INFO - [2022-02-18 20:16:15,507] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:16:16,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:16:16,053] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:16:16,060] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:16:16,065] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 20:16:28,850] {scheduler_job.py:155} INFO - Started process (PID=12808) to work on /airflow/dags/download_data.py
[2022-02-18 20:16:28,866] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:16:28,868] {logging_mixin.py:112} INFO - [2022-02-18 20:16:28,868] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:16:29,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:16:29,498] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:16:29,510] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:16:29,515] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.666 seconds
[2022-02-18 20:16:42,104] {scheduler_job.py:155} INFO - Started process (PID=12834) to work on /airflow/dags/download_data.py
[2022-02-18 20:16:42,115] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:16:42,121] {logging_mixin.py:112} INFO - [2022-02-18 20:16:42,121] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:16:42,660] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:16:42,726] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:16:42,744] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:16:42,749] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-18 20:16:55,413] {scheduler_job.py:155} INFO - Started process (PID=12860) to work on /airflow/dags/download_data.py
[2022-02-18 20:16:55,420] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:16:55,422] {logging_mixin.py:112} INFO - [2022-02-18 20:16:55,422] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:16:55,990] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:16:56,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:16:56,050] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:16:56,055] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-18 20:17:08,714] {scheduler_job.py:155} INFO - Started process (PID=12886) to work on /airflow/dags/download_data.py
[2022-02-18 20:17:08,720] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:17:08,722] {logging_mixin.py:112} INFO - [2022-02-18 20:17:08,722] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:17:09,293] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:17:09,351] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:17:09,360] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:17:09,367] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.654 seconds
[2022-02-18 20:17:22,018] {scheduler_job.py:155} INFO - Started process (PID=12912) to work on /airflow/dags/download_data.py
[2022-02-18 20:17:22,032] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:17:22,035] {logging_mixin.py:112} INFO - [2022-02-18 20:17:22,034] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:17:22,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:17:22,750] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:17:22,763] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:17:22,776] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.758 seconds
[2022-02-18 20:17:35,271] {scheduler_job.py:155} INFO - Started process (PID=12938) to work on /airflow/dags/download_data.py
[2022-02-18 20:17:35,277] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:17:35,280] {logging_mixin.py:112} INFO - [2022-02-18 20:17:35,280] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:17:35,815] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:17:35,859] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:17:35,867] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:17:35,871] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 20:17:48,598] {scheduler_job.py:155} INFO - Started process (PID=12964) to work on /airflow/dags/download_data.py
[2022-02-18 20:17:48,607] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:17:48,613] {logging_mixin.py:112} INFO - [2022-02-18 20:17:48,613] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:17:49,285] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:17:49,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:17:49,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:17:49,363] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.765 seconds
[2022-02-18 20:18:01,927] {scheduler_job.py:155} INFO - Started process (PID=12990) to work on /airflow/dags/download_data.py
[2022-02-18 20:18:01,936] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:18:01,939] {logging_mixin.py:112} INFO - [2022-02-18 20:18:01,938] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:18:02,525] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:18:02,592] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:18:02,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:18:02,609] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.682 seconds
[2022-02-18 20:18:15,195] {scheduler_job.py:155} INFO - Started process (PID=13016) to work on /airflow/dags/download_data.py
[2022-02-18 20:18:15,205] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:18:15,211] {logging_mixin.py:112} INFO - [2022-02-18 20:18:15,211] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:18:15,868] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:18:15,921] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:18:15,933] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:18:15,942] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.747 seconds
[2022-02-18 20:18:28,707] {scheduler_job.py:155} INFO - Started process (PID=13042) to work on /airflow/dags/download_data.py
[2022-02-18 20:18:28,713] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:18:28,715] {logging_mixin.py:112} INFO - [2022-02-18 20:18:28,715] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:18:29,263] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:18:29,314] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:18:29,323] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:18:29,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-18 20:18:41,975] {scheduler_job.py:155} INFO - Started process (PID=13068) to work on /airflow/dags/download_data.py
[2022-02-18 20:18:41,981] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:18:41,983] {logging_mixin.py:112} INFO - [2022-02-18 20:18:41,983] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:18:42,564] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:18:42,621] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:18:42,630] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:18:42,635] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.660 seconds
[2022-02-18 20:18:55,308] {scheduler_job.py:155} INFO - Started process (PID=13094) to work on /airflow/dags/download_data.py
[2022-02-18 20:18:55,313] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:18:55,316] {logging_mixin.py:112} INFO - [2022-02-18 20:18:55,316] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:18:56,026] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:18:56,082] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:18:56,095] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:18:56,103] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.795 seconds
[2022-02-18 20:19:08,589] {scheduler_job.py:155} INFO - Started process (PID=13120) to work on /airflow/dags/download_data.py
[2022-02-18 20:19:08,597] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:19:08,599] {logging_mixin.py:112} INFO - [2022-02-18 20:19:08,599] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:19:09,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:19:09,230] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:19:09,239] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:19:09,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-18 20:19:21,879] {scheduler_job.py:155} INFO - Started process (PID=13146) to work on /airflow/dags/download_data.py
[2022-02-18 20:19:21,886] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:19:21,889] {logging_mixin.py:112} INFO - [2022-02-18 20:19:21,888] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:19:22,447] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:19:22,484] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:19:22,496] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:19:22,502] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-18 20:19:35,191] {scheduler_job.py:155} INFO - Started process (PID=13172) to work on /airflow/dags/download_data.py
[2022-02-18 20:19:35,197] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:19:35,200] {logging_mixin.py:112} INFO - [2022-02-18 20:19:35,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:19:35,711] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:19:35,768] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:19:35,776] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:19:35,781] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 20:19:48,474] {scheduler_job.py:155} INFO - Started process (PID=13198) to work on /airflow/dags/download_data.py
[2022-02-18 20:19:48,479] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:19:48,481] {logging_mixin.py:112} INFO - [2022-02-18 20:19:48,481] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:19:49,167] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:19:49,232] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:19:49,240] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:19:49,244] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.771 seconds
[2022-02-18 20:20:01,808] {scheduler_job.py:155} INFO - Started process (PID=13224) to work on /airflow/dags/download_data.py
[2022-02-18 20:20:01,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:20:01,823] {logging_mixin.py:112} INFO - [2022-02-18 20:20:01,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:20:02,346] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:20:02,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:20:02,416] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:20:02,420] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-18 20:20:15,045] {scheduler_job.py:155} INFO - Started process (PID=13250) to work on /airflow/dags/download_data.py
[2022-02-18 20:20:15,061] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:20:15,065] {logging_mixin.py:112} INFO - [2022-02-18 20:20:15,065] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:20:15,705] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:20:15,769] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:20:15,781] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:20:15,786] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.741 seconds
[2022-02-18 20:20:28,373] {scheduler_job.py:155} INFO - Started process (PID=13276) to work on /airflow/dags/download_data.py
[2022-02-18 20:20:28,379] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:20:28,381] {logging_mixin.py:112} INFO - [2022-02-18 20:20:28,381] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:20:28,878] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:20:28,922] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:20:28,928] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:20:28,933] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 20:20:41,594] {scheduler_job.py:155} INFO - Started process (PID=13302) to work on /airflow/dags/download_data.py
[2022-02-18 20:20:41,599] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:20:41,601] {logging_mixin.py:112} INFO - [2022-02-18 20:20:41,601] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:20:42,053] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:20:42,120] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:20:42,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:20:42,137] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 20:20:54,907] {scheduler_job.py:155} INFO - Started process (PID=13328) to work on /airflow/dags/download_data.py
[2022-02-18 20:20:54,922] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:20:54,924] {logging_mixin.py:112} INFO - [2022-02-18 20:20:54,924] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:20:55,372] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:20:55,419] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:20:55,426] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:20:55,431] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 20:21:08,162] {scheduler_job.py:155} INFO - Started process (PID=13354) to work on /airflow/dags/download_data.py
[2022-02-18 20:21:08,168] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:21:08,172] {logging_mixin.py:112} INFO - [2022-02-18 20:21:08,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:21:08,631] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:21:08,675] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:21:08,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:21:08,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 20:21:21,461] {scheduler_job.py:155} INFO - Started process (PID=13380) to work on /airflow/dags/download_data.py
[2022-02-18 20:21:21,466] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:21:21,468] {logging_mixin.py:112} INFO - [2022-02-18 20:21:21,468] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:21:21,934] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:21:21,989] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:21:21,999] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:21:22,005] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 20:21:34,703] {scheduler_job.py:155} INFO - Started process (PID=13406) to work on /airflow/dags/download_data.py
[2022-02-18 20:21:34,707] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:21:34,709] {logging_mixin.py:112} INFO - [2022-02-18 20:21:34,709] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:21:35,159] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:21:35,208] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:21:35,213] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:21:35,217] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 20:21:47,953] {scheduler_job.py:155} INFO - Started process (PID=13432) to work on /airflow/dags/download_data.py
[2022-02-18 20:21:47,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:21:47,961] {logging_mixin.py:112} INFO - [2022-02-18 20:21:47,961] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:21:48,406] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:21:48,451] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:21:48,464] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:21:48,470] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 20:22:01,240] {scheduler_job.py:155} INFO - Started process (PID=13458) to work on /airflow/dags/download_data.py
[2022-02-18 20:22:01,245] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:22:01,247] {logging_mixin.py:112} INFO - [2022-02-18 20:22:01,246] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:22:01,698] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:22:01,745] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:22:01,751] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:22:01,754] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 20:22:14,504] {scheduler_job.py:155} INFO - Started process (PID=13484) to work on /airflow/dags/download_data.py
[2022-02-18 20:22:14,508] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:22:14,509] {logging_mixin.py:112} INFO - [2022-02-18 20:22:14,509] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:22:14,962] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:22:15,008] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:22:15,017] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:22:15,025] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 20:22:27,784] {scheduler_job.py:155} INFO - Started process (PID=13510) to work on /airflow/dags/download_data.py
[2022-02-18 20:22:27,789] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:22:27,791] {logging_mixin.py:112} INFO - [2022-02-18 20:22:27,790] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:22:28,267] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:22:28,312] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:22:28,320] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:22:28,323] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 20:22:41,027] {scheduler_job.py:155} INFO - Started process (PID=13536) to work on /airflow/dags/download_data.py
[2022-02-18 20:22:41,038] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:22:41,041] {logging_mixin.py:112} INFO - [2022-02-18 20:22:41,040] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:22:41,490] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:22:41,544] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:22:41,553] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:22:41,558] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 20:22:54,297] {scheduler_job.py:155} INFO - Started process (PID=13562) to work on /airflow/dags/download_data.py
[2022-02-18 20:22:54,310] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:22:54,313] {logging_mixin.py:112} INFO - [2022-02-18 20:22:54,313] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:22:54,755] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:22:54,811] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:22:54,821] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:22:54,828] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 20:23:07,580] {scheduler_job.py:155} INFO - Started process (PID=13588) to work on /airflow/dags/download_data.py
[2022-02-18 20:23:07,585] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:23:07,586] {logging_mixin.py:112} INFO - [2022-02-18 20:23:07,586] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:23:08,035] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:23:08,087] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:23:08,096] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:23:08,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 20:23:20,859] {scheduler_job.py:155} INFO - Started process (PID=13614) to work on /airflow/dags/download_data.py
[2022-02-18 20:23:20,867] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:23:20,870] {logging_mixin.py:112} INFO - [2022-02-18 20:23:20,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:23:21,314] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:23:21,356] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:23:21,366] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:23:21,372] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 20:23:34,103] {scheduler_job.py:155} INFO - Started process (PID=13640) to work on /airflow/dags/download_data.py
[2022-02-18 20:23:34,112] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:23:34,113] {logging_mixin.py:112} INFO - [2022-02-18 20:23:34,113] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:23:34,555] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:23:34,598] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:23:34,604] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:23:34,609] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 20:23:47,365] {scheduler_job.py:155} INFO - Started process (PID=13666) to work on /airflow/dags/download_data.py
[2022-02-18 20:23:47,371] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:23:47,373] {logging_mixin.py:112} INFO - [2022-02-18 20:23:47,372] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:23:47,839] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:23:47,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:23:47,902] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:23:47,907] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 20:24:00,671] {scheduler_job.py:155} INFO - Started process (PID=13692) to work on /airflow/dags/download_data.py
[2022-02-18 20:24:00,680] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:24:00,683] {logging_mixin.py:112} INFO - [2022-02-18 20:24:00,683] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:24:01,131] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:24:01,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:24:01,182] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:24:01,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 20:24:13,909] {scheduler_job.py:155} INFO - Started process (PID=13718) to work on /airflow/dags/download_data.py
[2022-02-18 20:24:13,914] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:24:13,916] {logging_mixin.py:112} INFO - [2022-02-18 20:24:13,915] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:24:14,390] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:24:14,444] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:24:14,456] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:24:14,459] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 20:24:27,179] {scheduler_job.py:155} INFO - Started process (PID=13744) to work on /airflow/dags/download_data.py
[2022-02-18 20:24:27,185] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:24:27,187] {logging_mixin.py:112} INFO - [2022-02-18 20:24:27,187] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:24:27,654] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:24:27,711] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:24:27,720] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:24:27,726] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 20:24:40,438] {scheduler_job.py:155} INFO - Started process (PID=13770) to work on /airflow/dags/download_data.py
[2022-02-18 20:24:40,446] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:24:40,449] {logging_mixin.py:112} INFO - [2022-02-18 20:24:40,448] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:24:40,896] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:24:40,951] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:24:40,959] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:24:40,962] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 20:24:53,701] {scheduler_job.py:155} INFO - Started process (PID=13796) to work on /airflow/dags/download_data.py
[2022-02-18 20:24:53,719] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:24:53,721] {logging_mixin.py:112} INFO - [2022-02-18 20:24:53,721] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:24:54,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:24:54,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:24:54,256] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:24:54,261] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 20:25:06,989] {scheduler_job.py:155} INFO - Started process (PID=13822) to work on /airflow/dags/download_data.py
[2022-02-18 20:25:06,994] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:25:06,995] {logging_mixin.py:112} INFO - [2022-02-18 20:25:06,995] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:25:07,452] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:25:07,500] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:25:07,505] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:25:07,509] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 20:25:20,259] {scheduler_job.py:155} INFO - Started process (PID=13848) to work on /airflow/dags/download_data.py
[2022-02-18 20:25:20,263] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:25:20,265] {logging_mixin.py:112} INFO - [2022-02-18 20:25:20,265] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:25:20,725] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:25:20,775] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:25:20,782] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:25:20,788] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 20:25:33,534] {scheduler_job.py:155} INFO - Started process (PID=13874) to work on /airflow/dags/download_data.py
[2022-02-18 20:25:33,539] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:25:33,542] {logging_mixin.py:112} INFO - [2022-02-18 20:25:33,541] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:25:33,987] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:25:34,042] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:25:34,050] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:25:34,056] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 20:25:46,781] {scheduler_job.py:155} INFO - Started process (PID=13900) to work on /airflow/dags/download_data.py
[2022-02-18 20:25:46,786] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:25:46,788] {logging_mixin.py:112} INFO - [2022-02-18 20:25:46,788] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:25:47,244] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:25:47,287] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:25:47,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:25:47,304] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 20:26:00,018] {scheduler_job.py:155} INFO - Started process (PID=13926) to work on /airflow/dags/download_data.py
[2022-02-18 20:26:00,024] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:26:00,025] {logging_mixin.py:112} INFO - [2022-02-18 20:26:00,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:26:00,510] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:26:00,547] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:26:00,556] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:26:00,560] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 20:26:13,272] {scheduler_job.py:155} INFO - Started process (PID=13952) to work on /airflow/dags/download_data.py
[2022-02-18 20:26:13,276] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:26:13,278] {logging_mixin.py:112} INFO - [2022-02-18 20:26:13,278] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:26:13,809] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:26:13,862] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:26:13,870] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:26:13,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 20:26:26,610] {scheduler_job.py:155} INFO - Started process (PID=13978) to work on /airflow/dags/download_data.py
[2022-02-18 20:26:26,615] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:26:26,617] {logging_mixin.py:112} INFO - [2022-02-18 20:26:26,617] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:26:27,146] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:26:27,200] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:26:27,207] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:26:27,212] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 20:26:39,870] {scheduler_job.py:155} INFO - Started process (PID=14004) to work on /airflow/dags/download_data.py
[2022-02-18 20:26:39,878] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:26:39,881] {logging_mixin.py:112} INFO - [2022-02-18 20:26:39,881] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:26:40,341] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:26:40,393] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:26:40,400] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:26:40,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 20:26:53,165] {scheduler_job.py:155} INFO - Started process (PID=14030) to work on /airflow/dags/download_data.py
[2022-02-18 20:26:53,170] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:26:53,172] {logging_mixin.py:112} INFO - [2022-02-18 20:26:53,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:26:53,768] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:26:53,834] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:26:53,841] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:26:53,850] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.685 seconds
[2022-02-18 20:27:06,430] {scheduler_job.py:155} INFO - Started process (PID=14056) to work on /airflow/dags/download_data.py
[2022-02-18 20:27:06,439] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:27:06,442] {logging_mixin.py:112} INFO - [2022-02-18 20:27:06,442] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:27:07,106] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:27:07,154] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:27:07,165] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:27:07,181] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.751 seconds
[2022-02-18 20:27:19,738] {scheduler_job.py:155} INFO - Started process (PID=14082) to work on /airflow/dags/download_data.py
[2022-02-18 20:27:19,749] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:27:19,752] {logging_mixin.py:112} INFO - [2022-02-18 20:27:19,751] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:27:20,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:27:20,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:27:20,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:27:20,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 20:27:33,045] {scheduler_job.py:155} INFO - Started process (PID=14108) to work on /airflow/dags/download_data.py
[2022-02-18 20:27:33,053] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:27:33,055] {logging_mixin.py:112} INFO - [2022-02-18 20:27:33,054] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:27:33,603] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:27:33,662] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:27:33,674] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:27:33,681] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-18 20:27:46,308] {scheduler_job.py:155} INFO - Started process (PID=14134) to work on /airflow/dags/download_data.py
[2022-02-18 20:27:46,315] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:27:46,317] {logging_mixin.py:112} INFO - [2022-02-18 20:27:46,317] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:27:46,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:27:46,846] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:27:46,858] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:27:46,863] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 20:27:59,557] {scheduler_job.py:155} INFO - Started process (PID=14160) to work on /airflow/dags/download_data.py
[2022-02-18 20:27:59,562] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:27:59,565] {logging_mixin.py:112} INFO - [2022-02-18 20:27:59,565] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:28:00,029] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:28:00,081] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:28:00,090] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:28:00,097] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 20:28:12,818] {scheduler_job.py:155} INFO - Started process (PID=14186) to work on /airflow/dags/download_data.py
[2022-02-18 20:28:12,825] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:28:12,827] {logging_mixin.py:112} INFO - [2022-02-18 20:28:12,827] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:28:13,268] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:28:13,328] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:28:13,335] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:28:13,340] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 20:28:26,076] {scheduler_job.py:155} INFO - Started process (PID=14212) to work on /airflow/dags/download_data.py
[2022-02-18 20:28:26,080] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:28:26,083] {logging_mixin.py:112} INFO - [2022-02-18 20:28:26,082] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:28:26,523] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:28:26,574] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:28:26,582] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:28:26,588] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 20:28:39,342] {scheduler_job.py:155} INFO - Started process (PID=14238) to work on /airflow/dags/download_data.py
[2022-02-18 20:28:39,347] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:28:39,349] {logging_mixin.py:112} INFO - [2022-02-18 20:28:39,349] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:28:39,857] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:28:39,904] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:28:39,912] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:28:39,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 20:28:52,712] {scheduler_job.py:155} INFO - Started process (PID=14264) to work on /airflow/dags/download_data.py
[2022-02-18 20:28:52,719] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:28:52,721] {logging_mixin.py:112} INFO - [2022-02-18 20:28:52,721] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:28:53,405] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:28:53,463] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:28:53,483] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:28:53,500] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.788 seconds
[2022-02-18 20:29:05,993] {scheduler_job.py:155} INFO - Started process (PID=14290) to work on /airflow/dags/download_data.py
[2022-02-18 20:29:06,005] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:29:06,013] {logging_mixin.py:112} INFO - [2022-02-18 20:29:06,013] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:29:06,581] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:29:06,627] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:29:06,636] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:29:06,640] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-18 20:29:19,271] {scheduler_job.py:155} INFO - Started process (PID=14316) to work on /airflow/dags/download_data.py
[2022-02-18 20:29:19,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:29:19,281] {logging_mixin.py:112} INFO - [2022-02-18 20:29:19,280] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:29:19,813] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:29:19,857] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:29:19,869] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:29:19,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 20:29:32,546] {scheduler_job.py:155} INFO - Started process (PID=14342) to work on /airflow/dags/download_data.py
[2022-02-18 20:29:32,552] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:29:32,557] {logging_mixin.py:112} INFO - [2022-02-18 20:29:32,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:29:33,060] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:29:33,124] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:29:33,134] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:29:33,141] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 20:29:45,796] {scheduler_job.py:155} INFO - Started process (PID=14368) to work on /airflow/dags/download_data.py
[2022-02-18 20:29:45,802] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:29:45,804] {logging_mixin.py:112} INFO - [2022-02-18 20:29:45,804] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:29:46,374] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:29:46,419] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:29:46,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:29:46,433] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.637 seconds
[2022-02-18 20:29:59,052] {scheduler_job.py:155} INFO - Started process (PID=14394) to work on /airflow/dags/download_data.py
[2022-02-18 20:29:59,058] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:29:59,063] {logging_mixin.py:112} INFO - [2022-02-18 20:29:59,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:29:59,594] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:29:59,649] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:29:59,660] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:29:59,665] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 20:30:12,282] {scheduler_job.py:155} INFO - Started process (PID=14420) to work on /airflow/dags/download_data.py
[2022-02-18 20:30:12,286] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:30:12,288] {logging_mixin.py:112} INFO - [2022-02-18 20:30:12,288] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:30:12,758] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:30:12,807] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:30:12,815] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:30:12,820] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 20:30:25,568] {scheduler_job.py:155} INFO - Started process (PID=14446) to work on /airflow/dags/download_data.py
[2022-02-18 20:30:25,574] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:30:25,576] {logging_mixin.py:112} INFO - [2022-02-18 20:30:25,575] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:30:26,039] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:30:26,088] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:30:26,095] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:30:26,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 20:30:38,830] {scheduler_job.py:155} INFO - Started process (PID=14472) to work on /airflow/dags/download_data.py
[2022-02-18 20:30:38,834] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:30:38,836] {logging_mixin.py:112} INFO - [2022-02-18 20:30:38,835] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:30:39,317] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:30:39,370] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:30:39,377] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:30:39,382] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 20:30:52,120] {scheduler_job.py:155} INFO - Started process (PID=14498) to work on /airflow/dags/download_data.py
[2022-02-18 20:30:52,129] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:30:52,132] {logging_mixin.py:112} INFO - [2022-02-18 20:30:52,131] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:30:52,681] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:30:52,734] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:30:52,744] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:30:52,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-18 20:31:05,390] {scheduler_job.py:155} INFO - Started process (PID=14524) to work on /airflow/dags/download_data.py
[2022-02-18 20:31:05,398] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:31:05,399] {logging_mixin.py:112} INFO - [2022-02-18 20:31:05,399] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:31:06,015] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:31:06,076] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:31:06,085] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:31:06,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.701 seconds
[2022-02-18 20:31:18,700] {scheduler_job.py:155} INFO - Started process (PID=14550) to work on /airflow/dags/download_data.py
[2022-02-18 20:31:18,713] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:31:18,716] {logging_mixin.py:112} INFO - [2022-02-18 20:31:18,715] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:31:19,177] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:31:19,229] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:31:19,239] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:31:19,243] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 20:31:31,962] {scheduler_job.py:155} INFO - Started process (PID=14576) to work on /airflow/dags/download_data.py
[2022-02-18 20:31:31,966] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:31:31,968] {logging_mixin.py:112} INFO - [2022-02-18 20:31:31,968] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:31:32,424] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:31:32,467] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:31:32,478] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:31:32,485] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 20:31:45,215] {scheduler_job.py:155} INFO - Started process (PID=14602) to work on /airflow/dags/download_data.py
[2022-02-18 20:31:45,221] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:31:45,222] {logging_mixin.py:112} INFO - [2022-02-18 20:31:45,222] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:31:45,683] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:31:45,737] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:31:45,744] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:31:45,748] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 20:31:58,478] {scheduler_job.py:155} INFO - Started process (PID=14628) to work on /airflow/dags/download_data.py
[2022-02-18 20:31:58,484] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:31:58,486] {logging_mixin.py:112} INFO - [2022-02-18 20:31:58,485] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:31:58,948] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:31:59,015] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:31:59,028] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:31:59,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 20:32:11,727] {scheduler_job.py:155} INFO - Started process (PID=14654) to work on /airflow/dags/download_data.py
[2022-02-18 20:32:11,737] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:32:11,739] {logging_mixin.py:112} INFO - [2022-02-18 20:32:11,738] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:32:12,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:32:12,243] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:32:12,255] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:32:12,260] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 20:32:24,976] {scheduler_job.py:155} INFO - Started process (PID=14680) to work on /airflow/dags/download_data.py
[2022-02-18 20:32:24,985] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:32:24,995] {logging_mixin.py:112} INFO - [2022-02-18 20:32:24,994] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:32:25,464] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:32:25,519] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:32:25,530] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:32:25,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 20:32:38,210] {scheduler_job.py:155} INFO - Started process (PID=14706) to work on /airflow/dags/download_data.py
[2022-02-18 20:32:38,219] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:32:38,221] {logging_mixin.py:112} INFO - [2022-02-18 20:32:38,221] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:32:38,678] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:32:38,720] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:32:38,726] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:32:38,731] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 20:32:51,503] {scheduler_job.py:155} INFO - Started process (PID=14732) to work on /airflow/dags/download_data.py
[2022-02-18 20:32:51,512] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:32:51,515] {logging_mixin.py:112} INFO - [2022-02-18 20:32:51,514] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:32:51,977] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:32:52,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:32:52,030] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:32:52,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 20:33:04,729] {scheduler_job.py:155} INFO - Started process (PID=14758) to work on /airflow/dags/download_data.py
[2022-02-18 20:33:04,734] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:33:04,737] {logging_mixin.py:112} INFO - [2022-02-18 20:33:04,737] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:33:05,210] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:33:05,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:33:05,273] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:33:05,280] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 20:33:18,019] {scheduler_job.py:155} INFO - Started process (PID=14784) to work on /airflow/dags/download_data.py
[2022-02-18 20:33:18,023] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:33:18,025] {logging_mixin.py:112} INFO - [2022-02-18 20:33:18,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:33:18,481] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:33:18,529] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:33:18,535] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:33:18,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 20:33:31,318] {scheduler_job.py:155} INFO - Started process (PID=14810) to work on /airflow/dags/download_data.py
[2022-02-18 20:33:31,325] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:33:31,327] {logging_mixin.py:112} INFO - [2022-02-18 20:33:31,327] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:33:31,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:33:31,840] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:33:31,851] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:33:31,855] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 20:33:44,550] {scheduler_job.py:155} INFO - Started process (PID=14836) to work on /airflow/dags/download_data.py
[2022-02-18 20:33:44,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:33:44,556] {logging_mixin.py:112} INFO - [2022-02-18 20:33:44,555] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:33:45,032] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:33:45,083] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:33:45,092] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:33:45,097] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 20:33:57,846] {scheduler_job.py:155} INFO - Started process (PID=14862) to work on /airflow/dags/download_data.py
[2022-02-18 20:33:57,857] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:33:57,859] {logging_mixin.py:112} INFO - [2022-02-18 20:33:57,859] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:33:58,321] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:33:58,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:33:58,393] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:33:58,402] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 20:34:11,129] {scheduler_job.py:155} INFO - Started process (PID=14888) to work on /airflow/dags/download_data.py
[2022-02-18 20:34:11,136] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:34:11,139] {logging_mixin.py:112} INFO - [2022-02-18 20:34:11,139] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:34:11,574] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:34:11,618] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:34:11,630] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:34:11,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 20:34:24,415] {scheduler_job.py:155} INFO - Started process (PID=14914) to work on /airflow/dags/download_data.py
[2022-02-18 20:34:24,423] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:34:24,425] {logging_mixin.py:112} INFO - [2022-02-18 20:34:24,424] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:34:24,863] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:34:24,919] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:34:24,929] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:34:24,936] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 20:34:38,120] {scheduler_job.py:155} INFO - Started process (PID=14940) to work on /airflow/dags/download_data.py
[2022-02-18 20:34:38,124] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:34:38,125] {logging_mixin.py:112} INFO - [2022-02-18 20:34:38,125] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:34:38,584] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:34:38,634] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:34:38,647] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:34:38,653] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 20:34:51,426] {scheduler_job.py:155} INFO - Started process (PID=14966) to work on /airflow/dags/download_data.py
[2022-02-18 20:34:51,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:34:51,432] {logging_mixin.py:112} INFO - [2022-02-18 20:34:51,432] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:34:51,995] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:34:52,045] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:34:52,056] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:34:52,061] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-18 20:35:04,671] {scheduler_job.py:155} INFO - Started process (PID=14992) to work on /airflow/dags/download_data.py
[2022-02-18 20:35:04,681] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:35:04,683] {logging_mixin.py:112} INFO - [2022-02-18 20:35:04,683] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:35:05,131] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:35:05,180] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:35:05,188] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:35:05,194] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 20:35:17,951] {scheduler_job.py:155} INFO - Started process (PID=15018) to work on /airflow/dags/download_data.py
[2022-02-18 20:35:17,962] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:35:17,963] {logging_mixin.py:112} INFO - [2022-02-18 20:35:17,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:35:18,440] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:35:18,493] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:35:18,503] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:35:18,508] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 20:35:31,243] {scheduler_job.py:155} INFO - Started process (PID=15044) to work on /airflow/dags/download_data.py
[2022-02-18 20:35:31,257] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:35:31,261] {logging_mixin.py:112} INFO - [2022-02-18 20:35:31,260] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:35:31,725] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:35:31,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:35:31,795] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:35:31,799] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 20:35:44,519] {scheduler_job.py:155} INFO - Started process (PID=15070) to work on /airflow/dags/download_data.py
[2022-02-18 20:35:44,526] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:35:44,529] {logging_mixin.py:112} INFO - [2022-02-18 20:35:44,529] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:35:45,003] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:35:45,056] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:35:45,066] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:35:45,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 20:35:57,775] {scheduler_job.py:155} INFO - Started process (PID=15096) to work on /airflow/dags/download_data.py
[2022-02-18 20:35:57,780] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:35:57,782] {logging_mixin.py:112} INFO - [2022-02-18 20:35:57,782] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:35:58,249] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:35:58,310] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:35:58,323] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:35:58,330] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 20:36:11,039] {scheduler_job.py:155} INFO - Started process (PID=15122) to work on /airflow/dags/download_data.py
[2022-02-18 20:36:11,052] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:36:11,055] {logging_mixin.py:112} INFO - [2022-02-18 20:36:11,054] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:36:11,614] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:36:11,672] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:36:11,682] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:36:11,690] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.651 seconds
[2022-02-18 20:36:24,411] {scheduler_job.py:155} INFO - Started process (PID=15148) to work on /airflow/dags/download_data.py
[2022-02-18 20:36:24,415] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:36:24,418] {logging_mixin.py:112} INFO - [2022-02-18 20:36:24,417] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:36:24,912] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:36:24,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:36:24,962] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:36:24,965] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 20:36:37,718] {scheduler_job.py:155} INFO - Started process (PID=15174) to work on /airflow/dags/download_data.py
[2022-02-18 20:36:37,725] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:36:37,726] {logging_mixin.py:112} INFO - [2022-02-18 20:36:37,726] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:36:38,280] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:36:38,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:36:38,325] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:36:38,327] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 20:36:51,054] {scheduler_job.py:155} INFO - Started process (PID=15200) to work on /airflow/dags/download_data.py
[2022-02-18 20:36:51,061] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:36:51,062] {logging_mixin.py:112} INFO - [2022-02-18 20:36:51,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:36:51,657] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:36:51,716] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:36:51,727] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:36:51,733] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-18 20:37:04,351] {scheduler_job.py:155} INFO - Started process (PID=15226) to work on /airflow/dags/download_data.py
[2022-02-18 20:37:04,364] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:37:04,372] {logging_mixin.py:112} INFO - [2022-02-18 20:37:04,372] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:37:04,953] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:37:04,998] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:37:05,007] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:37:05,012] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.661 seconds
[2022-02-18 20:37:17,749] {scheduler_job.py:155} INFO - Started process (PID=15252) to work on /airflow/dags/download_data.py
[2022-02-18 20:37:17,757] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:37:17,759] {logging_mixin.py:112} INFO - [2022-02-18 20:37:17,759] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:37:18,315] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:37:18,377] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:37:18,387] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:37:18,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-18 20:37:31,083] {scheduler_job.py:155} INFO - Started process (PID=15278) to work on /airflow/dags/download_data.py
[2022-02-18 20:37:31,093] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:37:31,096] {logging_mixin.py:112} INFO - [2022-02-18 20:37:31,096] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:37:31,650] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:37:31,732] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:37:31,743] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:37:31,749] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.667 seconds
[2022-02-18 20:37:44,324] {scheduler_job.py:155} INFO - Started process (PID=15304) to work on /airflow/dags/download_data.py
[2022-02-18 20:37:44,328] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:37:44,330] {logging_mixin.py:112} INFO - [2022-02-18 20:37:44,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:37:44,930] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:37:44,991] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:37:45,005] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:37:45,010] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.686 seconds
[2022-02-18 20:37:57,683] {scheduler_job.py:155} INFO - Started process (PID=15330) to work on /airflow/dags/download_data.py
[2022-02-18 20:37:57,691] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:37:57,694] {logging_mixin.py:112} INFO - [2022-02-18 20:37:57,693] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:37:58,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:37:58,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:37:58,417] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:37:58,422] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.738 seconds
[2022-02-18 20:38:11,011] {scheduler_job.py:155} INFO - Started process (PID=15356) to work on /airflow/dags/download_data.py
[2022-02-18 20:38:11,022] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:38:11,025] {logging_mixin.py:112} INFO - [2022-02-18 20:38:11,025] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:38:11,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:38:11,615] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:38:11,627] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:38:11,634] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.624 seconds
[2022-02-18 20:38:24,375] {scheduler_job.py:155} INFO - Started process (PID=15382) to work on /airflow/dags/download_data.py
[2022-02-18 20:38:24,384] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:38:24,387] {logging_mixin.py:112} INFO - [2022-02-18 20:38:24,386] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:38:24,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:38:25,013] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:38:25,018] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:38:25,022] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-18 20:38:37,694] {scheduler_job.py:155} INFO - Started process (PID=15408) to work on /airflow/dags/download_data.py
[2022-02-18 20:38:37,700] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:38:37,703] {logging_mixin.py:112} INFO - [2022-02-18 20:38:37,702] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:38:38,295] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:38:38,360] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:38:38,367] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:38:38,372] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.678 seconds
[2022-02-18 20:38:51,037] {scheduler_job.py:155} INFO - Started process (PID=15434) to work on /airflow/dags/download_data.py
[2022-02-18 20:38:51,042] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:38:51,044] {logging_mixin.py:112} INFO - [2022-02-18 20:38:51,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:38:51,621] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:38:51,681] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:38:51,688] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:38:51,692] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.655 seconds
[2022-02-18 20:39:04,318] {scheduler_job.py:155} INFO - Started process (PID=15460) to work on /airflow/dags/download_data.py
[2022-02-18 20:39:04,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:39:04,325] {logging_mixin.py:112} INFO - [2022-02-18 20:39:04,325] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:39:04,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:39:04,867] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:39:04,873] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:39:04,879] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 20:39:17,617] {scheduler_job.py:155} INFO - Started process (PID=15486) to work on /airflow/dags/download_data.py
[2022-02-18 20:39:17,621] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:39:17,623] {logging_mixin.py:112} INFO - [2022-02-18 20:39:17,622] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:39:18,122] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:39:18,181] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:39:18,194] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:39:18,199] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 20:39:30,947] {scheduler_job.py:155} INFO - Started process (PID=15512) to work on /airflow/dags/download_data.py
[2022-02-18 20:39:30,956] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:39:30,959] {logging_mixin.py:112} INFO - [2022-02-18 20:39:30,958] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:39:31,417] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:39:31,477] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:39:31,490] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:39:31,496] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 20:39:44,193] {scheduler_job.py:155} INFO - Started process (PID=15538) to work on /airflow/dags/download_data.py
[2022-02-18 20:39:44,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:39:44,201] {logging_mixin.py:112} INFO - [2022-02-18 20:39:44,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:39:44,709] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:39:44,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:39:44,760] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:39:44,765] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 20:39:57,516] {scheduler_job.py:155} INFO - Started process (PID=15564) to work on /airflow/dags/download_data.py
[2022-02-18 20:39:57,530] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:39:57,533] {logging_mixin.py:112} INFO - [2022-02-18 20:39:57,532] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:39:58,126] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:39:58,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:39:58,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:39:58,197] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.681 seconds
[2022-02-18 20:40:10,794] {scheduler_job.py:155} INFO - Started process (PID=15590) to work on /airflow/dags/download_data.py
[2022-02-18 20:40:10,800] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:40:10,802] {logging_mixin.py:112} INFO - [2022-02-18 20:40:10,801] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:40:11,281] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:40:11,346] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:40:11,354] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:40:11,359] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 20:40:24,140] {scheduler_job.py:155} INFO - Started process (PID=15616) to work on /airflow/dags/download_data.py
[2022-02-18 20:40:24,144] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:40:24,146] {logging_mixin.py:112} INFO - [2022-02-18 20:40:24,146] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:40:24,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:40:24,683] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:40:24,695] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:40:24,701] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 20:40:37,419] {scheduler_job.py:155} INFO - Started process (PID=15642) to work on /airflow/dags/download_data.py
[2022-02-18 20:40:37,426] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:40:37,429] {logging_mixin.py:112} INFO - [2022-02-18 20:40:37,428] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:40:37,904] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:40:37,954] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:40:37,963] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:40:37,970] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 20:40:50,771] {scheduler_job.py:155} INFO - Started process (PID=15668) to work on /airflow/dags/download_data.py
[2022-02-18 20:40:50,776] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:40:50,779] {logging_mixin.py:112} INFO - [2022-02-18 20:40:50,778] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:40:51,272] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:40:51,334] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:40:51,341] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:40:51,345] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.574 seconds
[2022-02-18 20:41:04,035] {scheduler_job.py:155} INFO - Started process (PID=15694) to work on /airflow/dags/download_data.py
[2022-02-18 20:41:04,039] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:41:04,041] {logging_mixin.py:112} INFO - [2022-02-18 20:41:04,040] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:41:04,521] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:41:04,586] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:41:04,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:41:04,602] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 20:41:17,327] {scheduler_job.py:155} INFO - Started process (PID=15720) to work on /airflow/dags/download_data.py
[2022-02-18 20:41:17,336] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:41:17,339] {logging_mixin.py:112} INFO - [2022-02-18 20:41:17,338] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:41:17,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:41:17,886] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:41:17,897] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:41:17,905] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 20:41:30,706] {scheduler_job.py:155} INFO - Started process (PID=15746) to work on /airflow/dags/download_data.py
[2022-02-18 20:41:30,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:41:30,718] {logging_mixin.py:112} INFO - [2022-02-18 20:41:30,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:41:31,164] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:41:31,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:41:31,229] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:41:31,235] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 20:41:45,449] {scheduler_job.py:155} INFO - Started process (PID=15772) to work on /airflow/dags/download_data.py
[2022-02-18 20:41:45,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:41:45,466] {logging_mixin.py:112} INFO - [2022-02-18 20:41:45,465] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:41:45,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:41:45,979] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:41:45,984] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:41:45,988] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 20:44:15,321] {scheduler_job.py:155} INFO - Started process (PID=15798) to work on /airflow/dags/download_data.py
[2022-02-18 20:44:15,338] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:44:15,341] {logging_mixin.py:112} INFO - [2022-02-18 20:44:15,341] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:44:16,106] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:44:16,167] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:44:16,181] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:44:16,190] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.870 seconds
[2022-02-18 20:44:28,644] {scheduler_job.py:155} INFO - Started process (PID=15824) to work on /airflow/dags/download_data.py
[2022-02-18 20:44:28,648] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:44:28,650] {logging_mixin.py:112} INFO - [2022-02-18 20:44:28,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:44:29,089] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:44:29,131] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:44:29,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:44:29,147] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 20:44:40,933] {scheduler_job.py:155} INFO - Started process (PID=15849) to work on /airflow/dags/download_data.py
[2022-02-18 20:44:40,940] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:44:40,941] {logging_mixin.py:112} INFO - [2022-02-18 20:44:40,941] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:44:41,415] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:44:41,480] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:44:41,491] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:44:41,498] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 20:44:55,033] {scheduler_job.py:155} INFO - Started process (PID=15875) to work on /airflow/dags/download_data.py
[2022-02-18 20:44:55,047] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:44:55,050] {logging_mixin.py:112} INFO - [2022-02-18 20:44:55,050] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:44:55,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:44:55,594] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:44:55,611] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:44:55,622] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 20:45:10,998] {scheduler_job.py:155} INFO - Started process (PID=15901) to work on /airflow/dags/download_data.py
[2022-02-18 20:45:11,009] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 20:45:11,012] {logging_mixin.py:112} INFO - [2022-02-18 20:45:11,011] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 20:45:11,606] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 20:45:11,684] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 20:45:11,700] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 20:45:11,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.711 seconds
[2022-02-18 21:12:14,530] {scheduler_job.py:155} INFO - Started process (PID=15926) to work on /airflow/dags/download_data.py
[2022-02-18 21:12:14,543] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:12:14,545] {logging_mixin.py:112} INFO - [2022-02-18 21:12:14,544] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:12:15,063] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:12:15,119] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:12:15,127] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:12:15,136] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 21:12:26,824] {scheduler_job.py:155} INFO - Started process (PID=15951) to work on /airflow/dags/download_data.py
[2022-02-18 21:12:26,832] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:12:26,835] {logging_mixin.py:112} INFO - [2022-02-18 21:12:26,834] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:12:27,305] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:12:27,367] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:12:27,377] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:12:27,387] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 21:12:40,144] {scheduler_job.py:155} INFO - Started process (PID=15977) to work on /airflow/dags/download_data.py
[2022-02-18 21:12:40,156] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:12:40,159] {logging_mixin.py:112} INFO - [2022-02-18 21:12:40,159] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:12:40,629] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:12:40,690] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:12:40,702] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:12:40,709] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 21:12:53,428] {scheduler_job.py:155} INFO - Started process (PID=16003) to work on /airflow/dags/download_data.py
[2022-02-18 21:12:53,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:12:53,436] {logging_mixin.py:112} INFO - [2022-02-18 21:12:53,436] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:12:53,922] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:12:53,988] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:12:54,007] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:12:54,013] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 21:13:06,740] {scheduler_job.py:155} INFO - Started process (PID=16029) to work on /airflow/dags/download_data.py
[2022-02-18 21:13:06,746] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:13:06,748] {logging_mixin.py:112} INFO - [2022-02-18 21:13:06,748] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:13:07,264] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:13:07,309] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:13:07,317] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:13:07,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 21:13:20,604] {scheduler_job.py:155} INFO - Started process (PID=16055) to work on /airflow/dags/download_data.py
[2022-02-18 21:13:20,613] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:13:20,614] {logging_mixin.py:112} INFO - [2022-02-18 21:13:20,614] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:13:21,065] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:13:21,124] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:13:21,130] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:13:21,135] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 21:13:33,885] {scheduler_job.py:155} INFO - Started process (PID=16081) to work on /airflow/dags/download_data.py
[2022-02-18 21:13:33,890] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:13:33,892] {logging_mixin.py:112} INFO - [2022-02-18 21:13:33,892] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:13:34,363] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:13:34,427] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:13:34,440] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:13:34,447] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 21:13:47,179] {scheduler_job.py:155} INFO - Started process (PID=16107) to work on /airflow/dags/download_data.py
[2022-02-18 21:13:47,203] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:13:47,213] {logging_mixin.py:112} INFO - [2022-02-18 21:13:47,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:13:47,799] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:13:47,878] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:13:47,910] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:13:47,934] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.755 seconds
[2022-02-18 21:14:00,512] {scheduler_job.py:155} INFO - Started process (PID=16133) to work on /airflow/dags/download_data.py
[2022-02-18 21:14:00,521] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:14:00,524] {logging_mixin.py:112} INFO - [2022-02-18 21:14:00,523] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:14:01,081] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:14:01,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:14:01,153] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:14:01,159] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.647 seconds
[2022-02-18 21:14:13,809] {scheduler_job.py:155} INFO - Started process (PID=16159) to work on /airflow/dags/download_data.py
[2022-02-18 21:14:13,821] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:14:13,823] {logging_mixin.py:112} INFO - [2022-02-18 21:14:13,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:14:14,346] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:14:14,407] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:14:14,420] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:14:14,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-18 21:14:27,120] {scheduler_job.py:155} INFO - Started process (PID=16185) to work on /airflow/dags/download_data.py
[2022-02-18 21:14:27,126] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:14:27,129] {logging_mixin.py:112} INFO - [2022-02-18 21:14:27,128] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:14:27,585] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:14:27,631] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:14:27,643] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:14:27,651] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 21:14:40,407] {scheduler_job.py:155} INFO - Started process (PID=16211) to work on /airflow/dags/download_data.py
[2022-02-18 21:14:40,414] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:14:40,415] {logging_mixin.py:112} INFO - [2022-02-18 21:14:40,415] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:14:40,959] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:14:41,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:14:41,029] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:14:41,037] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-18 21:14:53,723] {scheduler_job.py:155} INFO - Started process (PID=16237) to work on /airflow/dags/download_data.py
[2022-02-18 21:14:53,734] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:14:53,736] {logging_mixin.py:112} INFO - [2022-02-18 21:14:53,735] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:14:54,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:14:54,254] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:14:54,267] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:14:54,274] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 21:15:06,964] {scheduler_job.py:155} INFO - Started process (PID=16263) to work on /airflow/dags/download_data.py
[2022-02-18 21:15:06,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:15:06,972] {logging_mixin.py:112} INFO - [2022-02-18 21:15:06,971] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:15:07,441] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:15:07,502] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:15:07,516] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:15:07,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 21:15:20,290] {scheduler_job.py:155} INFO - Started process (PID=16289) to work on /airflow/dags/download_data.py
[2022-02-18 21:15:20,301] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:15:20,304] {logging_mixin.py:112} INFO - [2022-02-18 21:15:20,304] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:15:20,781] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:15:20,829] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:15:20,839] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:15:20,846] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 21:15:33,617] {scheduler_job.py:155} INFO - Started process (PID=16315) to work on /airflow/dags/download_data.py
[2022-02-18 21:15:33,627] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:15:33,630] {logging_mixin.py:112} INFO - [2022-02-18 21:15:33,629] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:15:34,206] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:15:34,251] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:15:34,261] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:15:34,265] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-18 21:15:46,880] {scheduler_job.py:155} INFO - Started process (PID=16341) to work on /airflow/dags/download_data.py
[2022-02-18 21:15:46,887] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:15:46,889] {logging_mixin.py:112} INFO - [2022-02-18 21:15:46,889] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:15:47,375] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:15:47,423] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:15:47,436] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:15:47,442] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 21:16:00,202] {scheduler_job.py:155} INFO - Started process (PID=16367) to work on /airflow/dags/download_data.py
[2022-02-18 21:16:00,210] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:16:00,211] {logging_mixin.py:112} INFO - [2022-02-18 21:16:00,211] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:16:00,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:16:00,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:16:00,744] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:16:00,748] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 21:16:13,483] {scheduler_job.py:155} INFO - Started process (PID=16393) to work on /airflow/dags/download_data.py
[2022-02-18 21:16:13,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:16:13,489] {logging_mixin.py:112} INFO - [2022-02-18 21:16:13,488] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:16:13,947] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:16:14,005] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:16:14,020] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:16:14,025] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 21:16:26,797] {scheduler_job.py:155} INFO - Started process (PID=16419) to work on /airflow/dags/download_data.py
[2022-02-18 21:16:26,803] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:16:26,805] {logging_mixin.py:112} INFO - [2022-02-18 21:16:26,804] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:16:27,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:16:27,326] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:16:27,341] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:16:27,347] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 21:16:40,081] {scheduler_job.py:155} INFO - Started process (PID=16445) to work on /airflow/dags/download_data.py
[2022-02-18 21:16:40,090] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:16:40,092] {logging_mixin.py:112} INFO - [2022-02-18 21:16:40,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:16:40,576] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:16:40,636] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:16:40,645] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:16:40,650] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 21:16:53,431] {scheduler_job.py:155} INFO - Started process (PID=16471) to work on /airflow/dags/download_data.py
[2022-02-18 21:16:53,442] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:16:53,446] {logging_mixin.py:112} INFO - [2022-02-18 21:16:53,446] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:16:53,910] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:16:53,970] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:16:53,980] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:16:53,985] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 21:17:06,742] {scheduler_job.py:155} INFO - Started process (PID=16497) to work on /airflow/dags/download_data.py
[2022-02-18 21:17:06,747] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:17:06,749] {logging_mixin.py:112} INFO - [2022-02-18 21:17:06,749] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:17:07,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:17:07,276] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:17:07,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:17:07,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 21:17:20,081] {scheduler_job.py:155} INFO - Started process (PID=16523) to work on /airflow/dags/download_data.py
[2022-02-18 21:17:20,088] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:17:20,091] {logging_mixin.py:112} INFO - [2022-02-18 21:17:20,090] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:17:20,566] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:17:20,619] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:17:20,628] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:17:20,637] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 21:17:33,400] {scheduler_job.py:155} INFO - Started process (PID=16549) to work on /airflow/dags/download_data.py
[2022-02-18 21:17:33,407] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:17:33,408] {logging_mixin.py:112} INFO - [2022-02-18 21:17:33,408] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:17:33,933] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:17:33,981] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:17:33,994] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:17:34,007] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.607 seconds
[2022-02-18 21:17:46,663] {scheduler_job.py:155} INFO - Started process (PID=16575) to work on /airflow/dags/download_data.py
[2022-02-18 21:17:46,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:17:46,671] {logging_mixin.py:112} INFO - [2022-02-18 21:17:46,671] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:17:47,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:17:47,224] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:17:47,230] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:17:47,235] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 21:17:59,929] {scheduler_job.py:155} INFO - Started process (PID=16601) to work on /airflow/dags/download_data.py
[2022-02-18 21:17:59,934] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:17:59,936] {logging_mixin.py:112} INFO - [2022-02-18 21:17:59,936] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:18:00,422] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:18:00,480] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:18:00,487] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:18:00,493] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 21:18:13,192] {scheduler_job.py:155} INFO - Started process (PID=16627) to work on /airflow/dags/download_data.py
[2022-02-18 21:18:13,198] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:18:13,200] {logging_mixin.py:112} INFO - [2022-02-18 21:18:13,200] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:18:13,661] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:18:13,717] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:18:13,728] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:18:13,733] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 21:18:26,498] {scheduler_job.py:155} INFO - Started process (PID=16653) to work on /airflow/dags/download_data.py
[2022-02-18 21:18:26,508] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:18:26,510] {logging_mixin.py:112} INFO - [2022-02-18 21:18:26,510] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:18:26,965] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:18:27,016] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:18:27,022] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:18:27,027] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 21:18:39,734] {scheduler_job.py:155} INFO - Started process (PID=16679) to work on /airflow/dags/download_data.py
[2022-02-18 21:18:39,739] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:18:39,741] {logging_mixin.py:112} INFO - [2022-02-18 21:18:39,741] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:18:40,251] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:18:40,299] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:18:40,307] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:18:40,312] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 21:18:53,097] {scheduler_job.py:155} INFO - Started process (PID=16705) to work on /airflow/dags/download_data.py
[2022-02-18 21:18:53,107] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:18:53,110] {logging_mixin.py:112} INFO - [2022-02-18 21:18:53,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:18:53,587] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:18:53,644] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:18:53,659] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:18:53,665] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 21:19:06,325] {scheduler_job.py:155} INFO - Started process (PID=16731) to work on /airflow/dags/download_data.py
[2022-02-18 21:19:06,330] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:19:06,332] {logging_mixin.py:112} INFO - [2022-02-18 21:19:06,331] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:19:06,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:19:06,863] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:19:06,869] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:19:06,872] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 21:19:19,656] {scheduler_job.py:155} INFO - Started process (PID=16757) to work on /airflow/dags/download_data.py
[2022-02-18 21:19:19,663] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:19:19,665] {logging_mixin.py:112} INFO - [2022-02-18 21:19:19,665] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:19:20,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:19:20,237] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:19:20,244] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:19:20,248] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 21:19:32,925] {scheduler_job.py:155} INFO - Started process (PID=16783) to work on /airflow/dags/download_data.py
[2022-02-18 21:19:32,931] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:19:32,933] {logging_mixin.py:112} INFO - [2022-02-18 21:19:32,933] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:19:33,471] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:19:33,518] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:19:33,525] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:19:33,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 21:19:46,251] {scheduler_job.py:155} INFO - Started process (PID=16809) to work on /airflow/dags/download_data.py
[2022-02-18 21:19:46,257] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:19:46,259] {logging_mixin.py:112} INFO - [2022-02-18 21:19:46,259] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:19:46,741] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:19:46,790] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:19:46,798] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:19:46,801] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 21:19:59,524] {scheduler_job.py:155} INFO - Started process (PID=16835) to work on /airflow/dags/download_data.py
[2022-02-18 21:19:59,535] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:19:59,538] {logging_mixin.py:112} INFO - [2022-02-18 21:19:59,537] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:19:59,978] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:20:00,027] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:20:00,035] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:20:00,039] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 21:20:12,798] {scheduler_job.py:155} INFO - Started process (PID=16861) to work on /airflow/dags/download_data.py
[2022-02-18 21:20:12,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:20:12,807] {logging_mixin.py:112} INFO - [2022-02-18 21:20:12,807] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:20:13,308] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:20:13,349] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:20:13,356] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:20:13,360] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 21:20:26,137] {scheduler_job.py:155} INFO - Started process (PID=16887) to work on /airflow/dags/download_data.py
[2022-02-18 21:20:26,146] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:20:26,149] {logging_mixin.py:112} INFO - [2022-02-18 21:20:26,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:20:26,621] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:20:26,675] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:20:26,682] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:20:26,686] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 21:20:39,422] {scheduler_job.py:155} INFO - Started process (PID=16913) to work on /airflow/dags/download_data.py
[2022-02-18 21:20:39,430] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:20:39,435] {logging_mixin.py:112} INFO - [2022-02-18 21:20:39,435] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:20:39,885] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:20:39,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:20:39,942] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:20:39,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 21:20:52,748] {scheduler_job.py:155} INFO - Started process (PID=16939) to work on /airflow/dags/download_data.py
[2022-02-18 21:20:52,754] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:20:52,757] {logging_mixin.py:112} INFO - [2022-02-18 21:20:52,756] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:20:53,211] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:20:53,264] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:20:53,276] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:20:53,283] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 21:21:06,016] {scheduler_job.py:155} INFO - Started process (PID=16965) to work on /airflow/dags/download_data.py
[2022-02-18 21:21:06,022] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:21:06,024] {logging_mixin.py:112} INFO - [2022-02-18 21:21:06,023] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:21:06,458] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:21:06,508] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:21:06,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:21:06,520] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 21:21:19,293] {scheduler_job.py:155} INFO - Started process (PID=16991) to work on /airflow/dags/download_data.py
[2022-02-18 21:21:19,298] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:21:19,299] {logging_mixin.py:112} INFO - [2022-02-18 21:21:19,299] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:21:19,739] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:21:19,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:21:19,798] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:21:19,802] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 21:21:32,601] {scheduler_job.py:155} INFO - Started process (PID=17017) to work on /airflow/dags/download_data.py
[2022-02-18 21:21:32,606] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:21:32,607] {logging_mixin.py:112} INFO - [2022-02-18 21:21:32,607] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:21:33,049] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:21:33,106] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:21:33,121] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:21:33,128] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 21:21:45,876] {scheduler_job.py:155} INFO - Started process (PID=17043) to work on /airflow/dags/download_data.py
[2022-02-18 21:21:45,882] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:21:45,884] {logging_mixin.py:112} INFO - [2022-02-18 21:21:45,883] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:21:46,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:21:46,348] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:21:46,355] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:21:46,361] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.485 seconds
[2022-02-18 21:21:59,184] {scheduler_job.py:155} INFO - Started process (PID=17069) to work on /airflow/dags/download_data.py
[2022-02-18 21:21:59,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:21:59,191] {logging_mixin.py:112} INFO - [2022-02-18 21:21:59,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:21:59,635] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:21:59,680] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:21:59,685] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:21:59,689] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 21:22:12,486] {scheduler_job.py:155} INFO - Started process (PID=17095) to work on /airflow/dags/download_data.py
[2022-02-18 21:22:12,490] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:22:12,492] {logging_mixin.py:112} INFO - [2022-02-18 21:22:12,492] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:22:12,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:22:12,973] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:22:12,980] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:22:12,984] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 21:22:25,774] {scheduler_job.py:155} INFO - Started process (PID=17121) to work on /airflow/dags/download_data.py
[2022-02-18 21:22:25,783] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:22:25,785] {logging_mixin.py:112} INFO - [2022-02-18 21:22:25,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:22:26,215] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:22:26,255] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:22:26,262] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:22:26,266] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 21:22:39,028] {scheduler_job.py:155} INFO - Started process (PID=17147) to work on /airflow/dags/download_data.py
[2022-02-18 21:22:39,032] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:22:39,034] {logging_mixin.py:112} INFO - [2022-02-18 21:22:39,033] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:22:39,473] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:22:39,523] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:22:39,531] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:22:39,536] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 21:22:52,347] {scheduler_job.py:155} INFO - Started process (PID=17173) to work on /airflow/dags/download_data.py
[2022-02-18 21:22:52,353] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:22:52,355] {logging_mixin.py:112} INFO - [2022-02-18 21:22:52,354] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:22:52,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:22:52,839] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:22:52,849] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:22:52,854] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 21:23:05,596] {scheduler_job.py:155} INFO - Started process (PID=17199) to work on /airflow/dags/download_data.py
[2022-02-18 21:23:05,601] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:23:05,603] {logging_mixin.py:112} INFO - [2022-02-18 21:23:05,603] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:23:06,039] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:23:06,087] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:23:06,095] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:23:06,102] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 21:23:18,901] {scheduler_job.py:155} INFO - Started process (PID=17225) to work on /airflow/dags/download_data.py
[2022-02-18 21:23:18,907] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:23:18,909] {logging_mixin.py:112} INFO - [2022-02-18 21:23:18,908] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:23:19,345] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:23:19,396] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:23:19,403] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:23:19,406] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 21:23:32,202] {scheduler_job.py:155} INFO - Started process (PID=17251) to work on /airflow/dags/download_data.py
[2022-02-18 21:23:32,207] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:23:32,210] {logging_mixin.py:112} INFO - [2022-02-18 21:23:32,209] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:23:32,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:23:32,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:23:32,712] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:23:32,716] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 21:23:45,454] {scheduler_job.py:155} INFO - Started process (PID=17277) to work on /airflow/dags/download_data.py
[2022-02-18 21:23:45,458] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:23:45,460] {logging_mixin.py:112} INFO - [2022-02-18 21:23:45,460] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:23:45,904] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:23:45,949] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:23:45,958] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:23:45,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 21:23:58,750] {scheduler_job.py:155} INFO - Started process (PID=17303) to work on /airflow/dags/download_data.py
[2022-02-18 21:23:58,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:23:58,765] {logging_mixin.py:112} INFO - [2022-02-18 21:23:58,765] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:23:59,213] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:23:59,264] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:23:59,271] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:23:59,275] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 21:24:11,989] {scheduler_job.py:155} INFO - Started process (PID=17329) to work on /airflow/dags/download_data.py
[2022-02-18 21:24:11,995] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:24:11,996] {logging_mixin.py:112} INFO - [2022-02-18 21:24:11,996] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:24:12,432] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:24:12,479] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:24:12,489] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:24:12,502] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 21:24:25,297] {scheduler_job.py:155} INFO - Started process (PID=17355) to work on /airflow/dags/download_data.py
[2022-02-18 21:24:25,307] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:24:25,309] {logging_mixin.py:112} INFO - [2022-02-18 21:24:25,309] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:24:25,735] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:24:25,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:24:25,795] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:24:25,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 21:24:38,620] {scheduler_job.py:155} INFO - Started process (PID=17381) to work on /airflow/dags/download_data.py
[2022-02-18 21:24:38,629] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:24:38,631] {logging_mixin.py:112} INFO - [2022-02-18 21:24:38,631] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:24:39,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:24:39,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:24:39,106] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:24:39,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 21:24:51,912] {scheduler_job.py:155} INFO - Started process (PID=17407) to work on /airflow/dags/download_data.py
[2022-02-18 21:24:51,919] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:24:51,922] {logging_mixin.py:112} INFO - [2022-02-18 21:24:51,921] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:24:52,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:24:52,401] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:24:52,407] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:24:52,413] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 21:25:05,192] {scheduler_job.py:155} INFO - Started process (PID=17433) to work on /airflow/dags/download_data.py
[2022-02-18 21:25:05,200] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:25:05,202] {logging_mixin.py:112} INFO - [2022-02-18 21:25:05,202] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:25:05,649] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:25:05,706] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:25:05,712] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:25:05,715] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 21:25:18,519] {scheduler_job.py:155} INFO - Started process (PID=17459) to work on /airflow/dags/download_data.py
[2022-02-18 21:25:18,529] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:25:18,530] {logging_mixin.py:112} INFO - [2022-02-18 21:25:18,530] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:25:18,977] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:25:19,018] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:25:19,028] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:25:19,033] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 21:25:31,786] {scheduler_job.py:155} INFO - Started process (PID=17485) to work on /airflow/dags/download_data.py
[2022-02-18 21:25:31,792] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:25:31,794] {logging_mixin.py:112} INFO - [2022-02-18 21:25:31,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:25:32,255] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:25:32,317] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:25:32,329] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:25:32,333] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 21:25:45,036] {scheduler_job.py:155} INFO - Started process (PID=17511) to work on /airflow/dags/download_data.py
[2022-02-18 21:25:45,042] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:25:45,044] {logging_mixin.py:112} INFO - [2022-02-18 21:25:45,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:25:45,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:25:45,525] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:25:45,531] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:25:45,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 21:25:58,355] {scheduler_job.py:155} INFO - Started process (PID=17537) to work on /airflow/dags/download_data.py
[2022-02-18 21:25:58,359] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:25:58,361] {logging_mixin.py:112} INFO - [2022-02-18 21:25:58,360] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:25:58,790] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:25:58,842] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:25:58,849] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:25:58,853] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 21:26:11,632] {scheduler_job.py:155} INFO - Started process (PID=17563) to work on /airflow/dags/download_data.py
[2022-02-18 21:26:11,637] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:26:11,638] {logging_mixin.py:112} INFO - [2022-02-18 21:26:11,638] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:26:12,083] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:26:12,129] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:26:12,136] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:26:12,141] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 21:26:24,926] {scheduler_job.py:155} INFO - Started process (PID=17589) to work on /airflow/dags/download_data.py
[2022-02-18 21:26:24,933] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:26:24,934] {logging_mixin.py:112} INFO - [2022-02-18 21:26:24,934] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:26:25,364] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:26:25,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:26:25,413] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:26:25,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 21:26:38,154] {scheduler_job.py:155} INFO - Started process (PID=17615) to work on /airflow/dags/download_data.py
[2022-02-18 21:26:38,159] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:26:38,161] {logging_mixin.py:112} INFO - [2022-02-18 21:26:38,161] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:26:38,597] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:26:38,650] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:26:38,658] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:26:38,663] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 21:26:51,453] {scheduler_job.py:155} INFO - Started process (PID=17641) to work on /airflow/dags/download_data.py
[2022-02-18 21:26:51,457] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:26:51,459] {logging_mixin.py:112} INFO - [2022-02-18 21:26:51,459] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:26:51,901] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:26:51,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:26:51,959] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:26:51,963] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 21:27:04,688] {scheduler_job.py:155} INFO - Started process (PID=17667) to work on /airflow/dags/download_data.py
[2022-02-18 21:27:04,693] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:27:04,695] {logging_mixin.py:112} INFO - [2022-02-18 21:27:04,695] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:27:05,154] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:27:05,201] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:27:05,210] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:27:05,215] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 21:27:18,012] {scheduler_job.py:155} INFO - Started process (PID=17693) to work on /airflow/dags/download_data.py
[2022-02-18 21:27:18,021] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:27:18,024] {logging_mixin.py:112} INFO - [2022-02-18 21:27:18,023] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:27:18,462] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:27:18,502] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:27:18,509] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:27:18,514] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 21:27:31,327] {scheduler_job.py:155} INFO - Started process (PID=17719) to work on /airflow/dags/download_data.py
[2022-02-18 21:27:31,332] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:27:31,334] {logging_mixin.py:112} INFO - [2022-02-18 21:27:31,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:27:31,794] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:27:31,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:27:31,861] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:27:31,867] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 21:27:44,604] {scheduler_job.py:155} INFO - Started process (PID=17745) to work on /airflow/dags/download_data.py
[2022-02-18 21:27:44,610] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:27:44,612] {logging_mixin.py:112} INFO - [2022-02-18 21:27:44,612] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:27:45,039] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:27:45,089] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:27:45,098] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:27:45,107] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 21:27:57,936] {scheduler_job.py:155} INFO - Started process (PID=17771) to work on /airflow/dags/download_data.py
[2022-02-18 21:27:57,945] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:27:57,947] {logging_mixin.py:112} INFO - [2022-02-18 21:27:57,947] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:27:58,377] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:27:58,434] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:27:58,447] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:27:58,453] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 21:28:11,218] {scheduler_job.py:155} INFO - Started process (PID=17797) to work on /airflow/dags/download_data.py
[2022-02-18 21:28:11,225] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:28:11,227] {logging_mixin.py:112} INFO - [2022-02-18 21:28:11,227] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:28:11,647] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:28:11,688] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:28:11,695] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:28:11,699] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.481 seconds
[2022-02-18 21:28:24,534] {scheduler_job.py:155} INFO - Started process (PID=17823) to work on /airflow/dags/download_data.py
[2022-02-18 21:28:24,541] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:28:24,543] {logging_mixin.py:112} INFO - [2022-02-18 21:28:24,543] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:28:24,984] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:28:25,029] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:28:25,039] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:28:25,044] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 21:28:37,829] {scheduler_job.py:155} INFO - Started process (PID=17849) to work on /airflow/dags/download_data.py
[2022-02-18 21:28:37,834] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:28:37,835] {logging_mixin.py:112} INFO - [2022-02-18 21:28:37,835] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:28:38,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:28:38,321] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:28:38,329] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:28:38,334] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 21:28:51,125] {scheduler_job.py:155} INFO - Started process (PID=17875) to work on /airflow/dags/download_data.py
[2022-02-18 21:28:51,133] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:28:51,135] {logging_mixin.py:112} INFO - [2022-02-18 21:28:51,135] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:28:51,586] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:28:51,638] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:28:51,652] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:28:51,658] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 21:29:04,367] {scheduler_job.py:155} INFO - Started process (PID=17901) to work on /airflow/dags/download_data.py
[2022-02-18 21:29:04,376] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:29:04,380] {logging_mixin.py:112} INFO - [2022-02-18 21:29:04,379] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:29:04,824] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:29:04,881] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:29:04,891] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:29:04,897] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 21:29:17,638] {scheduler_job.py:155} INFO - Started process (PID=17927) to work on /airflow/dags/download_data.py
[2022-02-18 21:29:17,642] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:29:17,644] {logging_mixin.py:112} INFO - [2022-02-18 21:29:17,643] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:29:18,132] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:29:18,188] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:29:18,195] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:29:18,200] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 21:29:30,949] {scheduler_job.py:155} INFO - Started process (PID=17953) to work on /airflow/dags/download_data.py
[2022-02-18 21:29:30,955] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:29:30,957] {logging_mixin.py:112} INFO - [2022-02-18 21:29:30,956] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:29:31,423] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:29:31,476] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:29:31,482] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:29:31,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 21:29:44,197] {scheduler_job.py:155} INFO - Started process (PID=17979) to work on /airflow/dags/download_data.py
[2022-02-18 21:29:44,203] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:29:44,205] {logging_mixin.py:112} INFO - [2022-02-18 21:29:44,205] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:29:44,647] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:29:44,693] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:29:44,700] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:29:44,705] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 21:29:57,500] {scheduler_job.py:155} INFO - Started process (PID=18005) to work on /airflow/dags/download_data.py
[2022-02-18 21:29:57,506] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:29:57,508] {logging_mixin.py:112} INFO - [2022-02-18 21:29:57,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:29:57,956] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:29:58,013] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:29:58,023] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:29:58,028] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 21:30:10,749] {scheduler_job.py:155} INFO - Started process (PID=18031) to work on /airflow/dags/download_data.py
[2022-02-18 21:30:10,754] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:30:10,755] {logging_mixin.py:112} INFO - [2022-02-18 21:30:10,755] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:30:11,182] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:30:11,232] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:30:11,240] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:30:11,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 21:30:24,063] {scheduler_job.py:155} INFO - Started process (PID=18057) to work on /airflow/dags/download_data.py
[2022-02-18 21:30:24,068] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:30:24,070] {logging_mixin.py:112} INFO - [2022-02-18 21:30:24,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:30:24,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:30:24,570] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:30:24,577] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:30:24,580] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 21:30:37,346] {scheduler_job.py:155} INFO - Started process (PID=18083) to work on /airflow/dags/download_data.py
[2022-02-18 21:30:37,351] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:30:37,359] {logging_mixin.py:112} INFO - [2022-02-18 21:30:37,353] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:30:37,808] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:30:37,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:30:37,859] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:30:37,863] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 21:30:50,654] {scheduler_job.py:155} INFO - Started process (PID=18109) to work on /airflow/dags/download_data.py
[2022-02-18 21:30:50,662] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:30:50,664] {logging_mixin.py:112} INFO - [2022-02-18 21:30:50,664] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:30:51,108] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:30:51,157] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:30:51,163] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:30:51,169] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 21:31:03,954] {scheduler_job.py:155} INFO - Started process (PID=18135) to work on /airflow/dags/download_data.py
[2022-02-18 21:31:03,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:31:03,932] {logging_mixin.py:112} INFO - [2022-02-18 21:31:03,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:31:04,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:31:04,439] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:31:04,446] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:31:04,450] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.496 seconds
[2022-02-18 21:31:17,244] {scheduler_job.py:155} INFO - Started process (PID=18161) to work on /airflow/dags/download_data.py
[2022-02-18 21:31:17,250] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:31:17,253] {logging_mixin.py:112} INFO - [2022-02-18 21:31:17,252] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:31:17,686] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:31:17,735] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:31:17,745] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:31:17,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 21:31:30,525] {scheduler_job.py:155} INFO - Started process (PID=18187) to work on /airflow/dags/download_data.py
[2022-02-18 21:31:30,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:31:30,534] {logging_mixin.py:112} INFO - [2022-02-18 21:31:30,534] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:31:30,987] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:31:31,033] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:31:31,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:31:31,052] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 21:31:43,826] {scheduler_job.py:155} INFO - Started process (PID=18213) to work on /airflow/dags/download_data.py
[2022-02-18 21:31:43,831] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:31:43,833] {logging_mixin.py:112} INFO - [2022-02-18 21:31:43,832] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:31:44,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:31:44,308] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:31:44,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:31:44,322] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 21:31:57,096] {scheduler_job.py:155} INFO - Started process (PID=18239) to work on /airflow/dags/download_data.py
[2022-02-18 21:31:57,100] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:31:57,103] {logging_mixin.py:112} INFO - [2022-02-18 21:31:57,102] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:31:57,542] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:31:57,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:31:57,595] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:31:57,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 21:32:10,388] {scheduler_job.py:155} INFO - Started process (PID=18265) to work on /airflow/dags/download_data.py
[2022-02-18 21:32:10,393] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:32:10,395] {logging_mixin.py:112} INFO - [2022-02-18 21:32:10,395] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:32:10,834] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:32:10,885] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:32:10,896] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:32:10,902] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 21:32:23,679] {scheduler_job.py:155} INFO - Started process (PID=18291) to work on /airflow/dags/download_data.py
[2022-02-18 21:32:23,686] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:32:23,688] {logging_mixin.py:112} INFO - [2022-02-18 21:32:23,687] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:32:24,109] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:32:24,151] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:32:24,159] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:32:24,163] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-18 21:32:36,965] {scheduler_job.py:155} INFO - Started process (PID=18317) to work on /airflow/dags/download_data.py
[2022-02-18 21:32:36,972] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:32:36,974] {logging_mixin.py:112} INFO - [2022-02-18 21:32:36,974] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:32:37,440] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:32:37,500] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:32:37,517] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:32:37,525] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 21:32:50,249] {scheduler_job.py:155} INFO - Started process (PID=18343) to work on /airflow/dags/download_data.py
[2022-02-18 21:32:50,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:32:50,255] {logging_mixin.py:112} INFO - [2022-02-18 21:32:50,255] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:32:50,692] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:32:50,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:32:50,750] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:32:50,754] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 21:33:03,571] {scheduler_job.py:155} INFO - Started process (PID=18369) to work on /airflow/dags/download_data.py
[2022-02-18 21:33:03,585] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:33:03,588] {logging_mixin.py:112} INFO - [2022-02-18 21:33:03,587] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:33:04,290] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:33:04,341] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:33:04,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:33:04,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.785 seconds
[2022-02-18 21:33:17,051] {scheduler_job.py:155} INFO - Started process (PID=18395) to work on /airflow/dags/download_data.py
[2022-02-18 21:33:17,057] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:33:17,059] {logging_mixin.py:112} INFO - [2022-02-18 21:33:17,059] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:33:17,519] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:33:17,562] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:33:17,570] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:33:17,573] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 21:33:30,338] {scheduler_job.py:155} INFO - Started process (PID=18421) to work on /airflow/dags/download_data.py
[2022-02-18 21:33:30,342] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:33:30,344] {logging_mixin.py:112} INFO - [2022-02-18 21:33:30,344] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:33:30,806] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:33:30,858] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:33:30,869] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:33:30,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 21:33:43,627] {scheduler_job.py:155} INFO - Started process (PID=18447) to work on /airflow/dags/download_data.py
[2022-02-18 21:33:43,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:33:43,635] {logging_mixin.py:112} INFO - [2022-02-18 21:33:43,634] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:33:44,086] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:33:44,138] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:33:44,144] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:33:44,149] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 21:33:56,906] {scheduler_job.py:155} INFO - Started process (PID=18473) to work on /airflow/dags/download_data.py
[2022-02-18 21:33:56,915] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:33:56,917] {logging_mixin.py:112} INFO - [2022-02-18 21:33:56,917] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:33:57,342] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:33:57,392] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:33:57,397] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:33:57,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 21:34:10,186] {scheduler_job.py:155} INFO - Started process (PID=18499) to work on /airflow/dags/download_data.py
[2022-02-18 21:34:10,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:34:10,201] {logging_mixin.py:112} INFO - [2022-02-18 21:34:10,201] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:34:10,630] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:34:10,680] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:34:10,690] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:34:10,694] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 21:34:23,488] {scheduler_job.py:155} INFO - Started process (PID=18525) to work on /airflow/dags/download_data.py
[2022-02-18 21:34:23,495] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:34:23,497] {logging_mixin.py:112} INFO - [2022-02-18 21:34:23,497] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:34:23,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:34:23,982] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:34:23,991] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:34:23,996] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 21:34:36,758] {scheduler_job.py:155} INFO - Started process (PID=18551) to work on /airflow/dags/download_data.py
[2022-02-18 21:34:36,766] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:34:36,768] {logging_mixin.py:112} INFO - [2022-02-18 21:34:36,768] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:34:37,238] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:34:37,281] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:34:37,289] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:34:37,294] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 21:34:50,060] {scheduler_job.py:155} INFO - Started process (PID=18577) to work on /airflow/dags/download_data.py
[2022-02-18 21:34:50,072] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:34:50,074] {logging_mixin.py:112} INFO - [2022-02-18 21:34:50,074] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:34:50,524] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:34:50,578] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:34:50,588] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:34:50,594] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 21:35:03,357] {scheduler_job.py:155} INFO - Started process (PID=18603) to work on /airflow/dags/download_data.py
[2022-02-18 21:35:03,366] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:35:03,369] {logging_mixin.py:112} INFO - [2022-02-18 21:35:03,368] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:35:03,824] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:35:03,869] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:35:03,878] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:35:03,883] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 21:35:16,607] {scheduler_job.py:155} INFO - Started process (PID=18629) to work on /airflow/dags/download_data.py
[2022-02-18 21:35:16,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:35:16,620] {logging_mixin.py:112} INFO - [2022-02-18 21:35:16,617] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:35:17,043] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:35:17,095] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:35:17,102] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:35:17,105] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.498 seconds
[2022-02-18 21:35:29,926] {scheduler_job.py:155} INFO - Started process (PID=18655) to work on /airflow/dags/download_data.py
[2022-02-18 21:35:29,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:35:29,932] {logging_mixin.py:112} INFO - [2022-02-18 21:35:29,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:35:30,369] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:35:30,421] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:35:30,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:35:30,435] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 21:35:43,207] {scheduler_job.py:155} INFO - Started process (PID=18681) to work on /airflow/dags/download_data.py
[2022-02-18 21:35:43,212] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:35:43,218] {logging_mixin.py:112} INFO - [2022-02-18 21:35:43,218] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:35:43,674] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:35:43,722] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:35:43,729] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:35:43,734] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 21:35:56,506] {scheduler_job.py:155} INFO - Started process (PID=18707) to work on /airflow/dags/download_data.py
[2022-02-18 21:35:56,512] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:35:56,513] {logging_mixin.py:112} INFO - [2022-02-18 21:35:56,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:35:56,949] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:35:56,999] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:35:57,010] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:35:57,017] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 21:36:09,807] {scheduler_job.py:155} INFO - Started process (PID=18733) to work on /airflow/dags/download_data.py
[2022-02-18 21:36:09,814] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:36:09,816] {logging_mixin.py:112} INFO - [2022-02-18 21:36:09,816] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:36:10,242] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:36:10,289] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:36:10,296] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:36:10,299] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 21:36:23,103] {scheduler_job.py:155} INFO - Started process (PID=18759) to work on /airflow/dags/download_data.py
[2022-02-18 21:36:23,107] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:36:23,109] {logging_mixin.py:112} INFO - [2022-02-18 21:36:23,109] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:36:23,553] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:36:23,603] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:36:23,611] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:36:23,616] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 21:36:36,348] {scheduler_job.py:155} INFO - Started process (PID=18785) to work on /airflow/dags/download_data.py
[2022-02-18 21:36:36,355] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:36:36,357] {logging_mixin.py:112} INFO - [2022-02-18 21:36:36,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:36:36,798] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:36:36,849] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:36:36,860] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:36:36,866] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 21:36:49,652] {scheduler_job.py:155} INFO - Started process (PID=18811) to work on /airflow/dags/download_data.py
[2022-02-18 21:36:49,658] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:36:49,659] {logging_mixin.py:112} INFO - [2022-02-18 21:36:49,659] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:36:50,100] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:36:50,150] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:36:50,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:36:50,168] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 21:37:02,958] {scheduler_job.py:155} INFO - Started process (PID=18837) to work on /airflow/dags/download_data.py
[2022-02-18 21:37:02,965] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:37:02,967] {logging_mixin.py:112} INFO - [2022-02-18 21:37:02,967] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:37:03,411] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:37:03,488] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:37:03,501] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:37:03,505] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 21:37:16,247] {scheduler_job.py:155} INFO - Started process (PID=18863) to work on /airflow/dags/download_data.py
[2022-02-18 21:37:16,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:37:16,255] {logging_mixin.py:112} INFO - [2022-02-18 21:37:16,255] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:37:16,704] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:37:16,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:37:16,757] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:37:16,762] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 21:37:29,569] {scheduler_job.py:155} INFO - Started process (PID=18889) to work on /airflow/dags/download_data.py
[2022-02-18 21:37:29,573] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:37:29,574] {logging_mixin.py:112} INFO - [2022-02-18 21:37:29,574] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:37:30,017] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:37:30,057] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:37:30,064] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:37:30,068] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 21:37:42,828] {scheduler_job.py:155} INFO - Started process (PID=18915) to work on /airflow/dags/download_data.py
[2022-02-18 21:37:42,839] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:37:42,841] {logging_mixin.py:112} INFO - [2022-02-18 21:37:42,840] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:37:43,269] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:37:43,336] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:37:43,343] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:37:43,348] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 21:37:56,124] {scheduler_job.py:155} INFO - Started process (PID=18941) to work on /airflow/dags/download_data.py
[2022-02-18 21:37:56,129] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:37:56,130] {logging_mixin.py:112} INFO - [2022-02-18 21:37:56,130] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:37:56,591] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:37:56,635] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:37:56,642] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:37:56,647] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 21:38:09,404] {scheduler_job.py:155} INFO - Started process (PID=18967) to work on /airflow/dags/download_data.py
[2022-02-18 21:38:09,412] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:38:09,415] {logging_mixin.py:112} INFO - [2022-02-18 21:38:09,415] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:38:09,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:38:09,885] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:38:09,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:38:09,898] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 21:38:22,724] {scheduler_job.py:155} INFO - Started process (PID=18993) to work on /airflow/dags/download_data.py
[2022-02-18 21:38:22,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:38:22,734] {logging_mixin.py:112} INFO - [2022-02-18 21:38:22,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:38:23,166] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:38:23,219] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:38:23,226] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:38:23,231] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 21:38:36,006] {scheduler_job.py:155} INFO - Started process (PID=19019) to work on /airflow/dags/download_data.py
[2022-02-18 21:38:36,015] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:38:36,017] {logging_mixin.py:112} INFO - [2022-02-18 21:38:36,017] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:38:36,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:38:36,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:38:36,510] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:38:36,514] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 21:38:49,321] {scheduler_job.py:155} INFO - Started process (PID=19045) to work on /airflow/dags/download_data.py
[2022-02-18 21:38:49,328] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:38:49,330] {logging_mixin.py:112} INFO - [2022-02-18 21:38:49,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:38:50,065] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:38:50,121] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:38:50,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:38:50,136] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.815 seconds
[2022-02-18 21:39:02,609] {scheduler_job.py:155} INFO - Started process (PID=19071) to work on /airflow/dags/download_data.py
[2022-02-18 21:39:02,615] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:39:02,616] {logging_mixin.py:112} INFO - [2022-02-18 21:39:02,616] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:39:03,191] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:39:03,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:39:03,263] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:39:03,273] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.664 seconds
[2022-02-18 21:39:16,398] {scheduler_job.py:155} INFO - Started process (PID=19097) to work on /airflow/dags/download_data.py
[2022-02-18 21:39:16,404] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:39:16,406] {logging_mixin.py:112} INFO - [2022-02-18 21:39:16,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:39:16,882] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:39:16,932] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:39:16,943] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:39:16,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 21:39:29,769] {scheduler_job.py:155} INFO - Started process (PID=19123) to work on /airflow/dags/download_data.py
[2022-02-18 21:39:29,779] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:39:29,782] {logging_mixin.py:112} INFO - [2022-02-18 21:39:29,782] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:39:30,403] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:39:30,455] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:39:30,464] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:39:30,471] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.703 seconds
[2022-02-18 21:39:43,216] {scheduler_job.py:155} INFO - Started process (PID=19149) to work on /airflow/dags/download_data.py
[2022-02-18 21:39:43,221] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:39:43,226] {logging_mixin.py:112} INFO - [2022-02-18 21:39:43,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:39:43,739] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:39:43,781] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:39:43,791] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:39:43,794] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 21:39:56,497] {scheduler_job.py:155} INFO - Started process (PID=19175) to work on /airflow/dags/download_data.py
[2022-02-18 21:39:56,504] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:39:56,506] {logging_mixin.py:112} INFO - [2022-02-18 21:39:56,506] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:39:56,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:39:57,019] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:39:57,028] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:39:57,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 21:40:09,728] {scheduler_job.py:155} INFO - Started process (PID=19201) to work on /airflow/dags/download_data.py
[2022-02-18 21:40:09,740] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:40:09,742] {logging_mixin.py:112} INFO - [2022-02-18 21:40:09,742] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:40:10,217] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:40:10,272] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:40:10,282] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:40:10,287] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 21:40:23,031] {scheduler_job.py:155} INFO - Started process (PID=19227) to work on /airflow/dags/download_data.py
[2022-02-18 21:40:23,038] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:40:23,041] {logging_mixin.py:112} INFO - [2022-02-18 21:40:23,040] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:40:23,502] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:40:23,591] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:40:23,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:40:23,607] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 21:40:36,287] {scheduler_job.py:155} INFO - Started process (PID=19253) to work on /airflow/dags/download_data.py
[2022-02-18 21:40:36,293] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:40:36,295] {logging_mixin.py:112} INFO - [2022-02-18 21:40:36,295] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:40:36,765] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:40:36,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:40:36,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:40:36,835] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 21:40:49,591] {scheduler_job.py:155} INFO - Started process (PID=19279) to work on /airflow/dags/download_data.py
[2022-02-18 21:40:49,602] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:40:49,604] {logging_mixin.py:112} INFO - [2022-02-18 21:40:49,603] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:40:50,039] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:40:50,083] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:40:50,093] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:40:50,101] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 21:41:02,854] {scheduler_job.py:155} INFO - Started process (PID=19305) to work on /airflow/dags/download_data.py
[2022-02-18 21:41:02,864] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:41:02,867] {logging_mixin.py:112} INFO - [2022-02-18 21:41:02,866] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:41:03,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:41:03,379] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:41:03,386] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:41:03,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 21:41:16,104] {scheduler_job.py:155} INFO - Started process (PID=19331) to work on /airflow/dags/download_data.py
[2022-02-18 21:41:16,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:41:16,115] {logging_mixin.py:112} INFO - [2022-02-18 21:41:16,115] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:41:16,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:41:16,629] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:41:16,637] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:41:16,642] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 21:41:29,365] {scheduler_job.py:155} INFO - Started process (PID=19357) to work on /airflow/dags/download_data.py
[2022-02-18 21:41:29,372] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:41:29,374] {logging_mixin.py:112} INFO - [2022-02-18 21:41:29,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:41:29,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:41:29,874] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:41:29,885] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:41:29,890] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 21:41:42,640] {scheduler_job.py:155} INFO - Started process (PID=19383) to work on /airflow/dags/download_data.py
[2022-02-18 21:41:42,646] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:41:42,648] {logging_mixin.py:112} INFO - [2022-02-18 21:41:42,648] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:41:43,138] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:41:43,190] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:41:43,199] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:41:43,204] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 21:41:55,931] {scheduler_job.py:155} INFO - Started process (PID=19409) to work on /airflow/dags/download_data.py
[2022-02-18 21:41:55,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:41:55,937] {logging_mixin.py:112} INFO - [2022-02-18 21:41:55,937] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:41:56,405] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:41:56,453] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:41:56,463] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:41:56,471] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 21:42:09,191] {scheduler_job.py:155} INFO - Started process (PID=19435) to work on /airflow/dags/download_data.py
[2022-02-18 21:42:09,196] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:42:09,198] {logging_mixin.py:112} INFO - [2022-02-18 21:42:09,197] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:42:09,641] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:42:09,692] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:42:09,700] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:42:09,705] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 21:42:22,448] {scheduler_job.py:155} INFO - Started process (PID=19461) to work on /airflow/dags/download_data.py
[2022-02-18 21:42:22,454] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:42:22,456] {logging_mixin.py:112} INFO - [2022-02-18 21:42:22,455] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:42:22,914] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:42:22,968] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:42:22,974] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:42:22,980] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 21:42:35,705] {scheduler_job.py:155} INFO - Started process (PID=19487) to work on /airflow/dags/download_data.py
[2022-02-18 21:42:35,716] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:42:35,718] {logging_mixin.py:112} INFO - [2022-02-18 21:42:35,717] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:42:36,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:42:36,237] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:42:36,247] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:42:36,255] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 21:42:48,988] {scheduler_job.py:155} INFO - Started process (PID=19513) to work on /airflow/dags/download_data.py
[2022-02-18 21:42:48,998] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:42:49,000] {logging_mixin.py:112} INFO - [2022-02-18 21:42:49,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:42:49,431] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:42:49,477] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:42:49,484] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:42:49,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 21:43:02,252] {scheduler_job.py:155} INFO - Started process (PID=19539) to work on /airflow/dags/download_data.py
[2022-02-18 21:43:02,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:43:02,266] {logging_mixin.py:112} INFO - [2022-02-18 21:43:02,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:43:02,738] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:43:02,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:43:02,814] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:43:02,823] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 21:43:15,495] {scheduler_job.py:155} INFO - Started process (PID=19565) to work on /airflow/dags/download_data.py
[2022-02-18 21:43:15,500] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:43:15,502] {logging_mixin.py:112} INFO - [2022-02-18 21:43:15,501] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:43:15,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:43:15,987] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:43:15,994] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:43:15,998] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.503 seconds
[2022-02-18 21:43:28,769] {scheduler_job.py:155} INFO - Started process (PID=19591) to work on /airflow/dags/download_data.py
[2022-02-18 21:43:28,782] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:43:28,783] {logging_mixin.py:112} INFO - [2022-02-18 21:43:28,783] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:43:29,227] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:43:29,284] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:43:29,289] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:43:29,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 21:43:42,021] {scheduler_job.py:155} INFO - Started process (PID=19617) to work on /airflow/dags/download_data.py
[2022-02-18 21:43:42,026] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:43:42,028] {logging_mixin.py:112} INFO - [2022-02-18 21:43:42,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:43:42,488] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:43:42,550] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:43:42,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:43:42,569] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 21:43:55,324] {scheduler_job.py:155} INFO - Started process (PID=19643) to work on /airflow/dags/download_data.py
[2022-02-18 21:43:55,329] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:43:55,331] {logging_mixin.py:112} INFO - [2022-02-18 21:43:55,330] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:43:55,769] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:43:55,820] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:43:55,831] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:43:55,834] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 21:44:08,552] {scheduler_job.py:155} INFO - Started process (PID=19669) to work on /airflow/dags/download_data.py
[2022-02-18 21:44:08,562] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:44:08,564] {logging_mixin.py:112} INFO - [2022-02-18 21:44:08,564] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:44:09,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:44:09,056] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:44:09,063] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:44:09,070] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 21:44:21,851] {scheduler_job.py:155} INFO - Started process (PID=19695) to work on /airflow/dags/download_data.py
[2022-02-18 21:44:21,855] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:44:21,857] {logging_mixin.py:112} INFO - [2022-02-18 21:44:21,857] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:44:22,397] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:44:22,449] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:44:22,458] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:44:22,464] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.614 seconds
[2022-02-18 21:44:35,089] {scheduler_job.py:155} INFO - Started process (PID=19721) to work on /airflow/dags/download_data.py
[2022-02-18 21:44:35,095] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:44:35,098] {logging_mixin.py:112} INFO - [2022-02-18 21:44:35,097] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:44:35,577] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:44:35,644] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:44:35,655] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:44:35,661] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 21:44:48,380] {scheduler_job.py:155} INFO - Started process (PID=19747) to work on /airflow/dags/download_data.py
[2022-02-18 21:44:48,385] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:44:48,389] {logging_mixin.py:112} INFO - [2022-02-18 21:44:48,388] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:44:48,876] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:44:48,915] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:44:48,921] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:44:48,924] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 21:45:01,633] {scheduler_job.py:155} INFO - Started process (PID=19773) to work on /airflow/dags/download_data.py
[2022-02-18 21:45:01,640] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:45:01,643] {logging_mixin.py:112} INFO - [2022-02-18 21:45:01,643] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:45:02,149] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:45:02,214] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:45:02,222] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:45:02,229] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 21:45:14,894] {scheduler_job.py:155} INFO - Started process (PID=19799) to work on /airflow/dags/download_data.py
[2022-02-18 21:45:14,900] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:45:14,902] {logging_mixin.py:112} INFO - [2022-02-18 21:45:14,902] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:45:15,371] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:45:15,422] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:45:15,429] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:45:15,434] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 21:45:28,194] {scheduler_job.py:155} INFO - Started process (PID=19825) to work on /airflow/dags/download_data.py
[2022-02-18 21:45:28,203] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:45:28,205] {logging_mixin.py:112} INFO - [2022-02-18 21:45:28,204] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:45:28,657] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:45:28,710] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:45:28,720] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:45:28,725] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 21:45:41,453] {scheduler_job.py:155} INFO - Started process (PID=19851) to work on /airflow/dags/download_data.py
[2022-02-18 21:45:41,459] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:45:41,462] {logging_mixin.py:112} INFO - [2022-02-18 21:45:41,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:45:41,929] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:45:41,978] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:45:41,987] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:45:41,991] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 21:45:54,724] {scheduler_job.py:155} INFO - Started process (PID=19877) to work on /airflow/dags/download_data.py
[2022-02-18 21:45:54,734] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:45:54,736] {logging_mixin.py:112} INFO - [2022-02-18 21:45:54,736] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:45:55,188] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:45:55,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:45:55,249] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:45:55,252] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 21:46:07,985] {scheduler_job.py:155} INFO - Started process (PID=19903) to work on /airflow/dags/download_data.py
[2022-02-18 21:46:07,989] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:46:07,993] {logging_mixin.py:112} INFO - [2022-02-18 21:46:07,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:46:08,467] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:46:08,518] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:46:08,525] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:46:08,528] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 21:46:21,286] {scheduler_job.py:155} INFO - Started process (PID=19929) to work on /airflow/dags/download_data.py
[2022-02-18 21:46:21,291] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:46:21,293] {logging_mixin.py:112} INFO - [2022-02-18 21:46:21,293] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:46:21,772] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:46:21,826] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:46:21,836] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:46:21,842] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 21:46:34,531] {scheduler_job.py:155} INFO - Started process (PID=19955) to work on /airflow/dags/download_data.py
[2022-02-18 21:46:34,537] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:46:34,539] {logging_mixin.py:112} INFO - [2022-02-18 21:46:34,539] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:46:35,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:46:35,098] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:46:35,105] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:46:35,116] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.587 seconds
[2022-02-18 21:46:47,849] {scheduler_job.py:155} INFO - Started process (PID=19981) to work on /airflow/dags/download_data.py
[2022-02-18 21:46:47,864] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:46:47,867] {logging_mixin.py:112} INFO - [2022-02-18 21:46:47,866] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:46:48,361] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:46:48,405] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:46:48,415] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:46:48,421] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 21:47:01,115] {scheduler_job.py:155} INFO - Started process (PID=20007) to work on /airflow/dags/download_data.py
[2022-02-18 21:47:01,122] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:47:01,124] {logging_mixin.py:112} INFO - [2022-02-18 21:47:01,124] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:47:01,659] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:47:01,702] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:47:01,711] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:47:01,719] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 21:47:14,397] {scheduler_job.py:155} INFO - Started process (PID=20033) to work on /airflow/dags/download_data.py
[2022-02-18 21:47:14,407] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:47:14,409] {logging_mixin.py:112} INFO - [2022-02-18 21:47:14,409] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:47:14,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:47:14,899] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:47:14,909] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:47:14,915] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 21:47:27,691] {scheduler_job.py:155} INFO - Started process (PID=20059) to work on /airflow/dags/download_data.py
[2022-02-18 21:47:27,697] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:47:27,699] {logging_mixin.py:112} INFO - [2022-02-18 21:47:27,699] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:47:28,144] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:47:28,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:47:28,204] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:47:28,210] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 21:47:40,923] {scheduler_job.py:155} INFO - Started process (PID=20085) to work on /airflow/dags/download_data.py
[2022-02-18 21:47:40,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:47:40,932] {logging_mixin.py:112} INFO - [2022-02-18 21:47:40,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:47:41,393] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:47:41,439] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:47:41,447] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:47:41,453] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 21:47:54,233] {scheduler_job.py:155} INFO - Started process (PID=20111) to work on /airflow/dags/download_data.py
[2022-02-18 21:47:54,238] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:47:54,240] {logging_mixin.py:112} INFO - [2022-02-18 21:47:54,239] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:47:54,698] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:47:54,749] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:47:54,754] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:47:54,758] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 21:48:07,459] {scheduler_job.py:155} INFO - Started process (PID=20137) to work on /airflow/dags/download_data.py
[2022-02-18 21:48:07,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:48:07,476] {logging_mixin.py:112} INFO - [2022-02-18 21:48:07,475] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:48:07,926] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:48:07,978] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:48:07,986] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:48:07,990] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 21:48:20,734] {scheduler_job.py:155} INFO - Started process (PID=20163) to work on /airflow/dags/download_data.py
[2022-02-18 21:48:20,744] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:48:20,747] {logging_mixin.py:112} INFO - [2022-02-18 21:48:20,746] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:48:21,181] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:48:21,234] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:48:21,244] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:48:21,248] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 21:48:34,007] {scheduler_job.py:155} INFO - Started process (PID=20189) to work on /airflow/dags/download_data.py
[2022-02-18 21:48:34,012] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:48:34,014] {logging_mixin.py:112} INFO - [2022-02-18 21:48:34,014] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:48:34,496] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:48:34,556] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:48:34,570] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:48:34,577] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 21:48:47,614] {scheduler_job.py:155} INFO - Started process (PID=20215) to work on /airflow/dags/download_data.py
[2022-02-18 21:48:47,624] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:48:47,626] {logging_mixin.py:112} INFO - [2022-02-18 21:48:47,625] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:48:48,065] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:48:48,120] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:48:48,128] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:48:48,133] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 21:49:00,891] {scheduler_job.py:155} INFO - Started process (PID=20241) to work on /airflow/dags/download_data.py
[2022-02-18 21:49:00,896] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:49:00,898] {logging_mixin.py:112} INFO - [2022-02-18 21:49:00,898] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:49:01,390] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:49:01,447] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:49:01,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:49:01,473] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 21:49:14,150] {scheduler_job.py:155} INFO - Started process (PID=20267) to work on /airflow/dags/download_data.py
[2022-02-18 21:49:14,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:49:14,165] {logging_mixin.py:112} INFO - [2022-02-18 21:49:14,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:49:14,642] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:49:14,691] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:49:14,699] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:49:14,704] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 21:49:27,448] {scheduler_job.py:155} INFO - Started process (PID=20293) to work on /airflow/dags/download_data.py
[2022-02-18 21:49:27,457] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:49:27,459] {logging_mixin.py:112} INFO - [2022-02-18 21:49:27,459] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:49:27,890] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:49:27,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:49:27,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:49:27,954] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 21:49:40,670] {scheduler_job.py:155} INFO - Started process (PID=20319) to work on /airflow/dags/download_data.py
[2022-02-18 21:49:40,681] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:49:40,684] {logging_mixin.py:112} INFO - [2022-02-18 21:49:40,683] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:49:41,278] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:49:41,352] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:49:41,370] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:49:41,393] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.723 seconds
[2022-02-18 21:49:53,953] {scheduler_job.py:155} INFO - Started process (PID=20345) to work on /airflow/dags/download_data.py
[2022-02-18 21:49:53,961] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:49:53,964] {logging_mixin.py:112} INFO - [2022-02-18 21:49:53,963] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:49:54,444] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:49:54,500] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:49:54,509] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:49:54,512] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 21:50:07,182] {scheduler_job.py:155} INFO - Started process (PID=20371) to work on /airflow/dags/download_data.py
[2022-02-18 21:50:07,186] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:50:07,189] {logging_mixin.py:112} INFO - [2022-02-18 21:50:07,188] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:50:07,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:50:07,683] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:50:07,689] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:50:07,693] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 21:50:20,438] {scheduler_job.py:155} INFO - Started process (PID=20397) to work on /airflow/dags/download_data.py
[2022-02-18 21:50:20,442] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:50:20,443] {logging_mixin.py:112} INFO - [2022-02-18 21:50:20,443] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:50:20,896] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:50:20,939] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:50:20,946] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:50:20,950] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 21:50:33,677] {scheduler_job.py:155} INFO - Started process (PID=20423) to work on /airflow/dags/download_data.py
[2022-02-18 21:50:33,683] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:50:33,686] {logging_mixin.py:112} INFO - [2022-02-18 21:50:33,686] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:50:34,168] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:50:34,226] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:50:34,236] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:50:34,242] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 21:50:46,961] {scheduler_job.py:155} INFO - Started process (PID=20449) to work on /airflow/dags/download_data.py
[2022-02-18 21:50:46,967] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:50:46,969] {logging_mixin.py:112} INFO - [2022-02-18 21:50:46,968] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:50:47,426] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:50:47,479] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:50:47,489] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:50:47,495] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 21:51:00,228] {scheduler_job.py:155} INFO - Started process (PID=20475) to work on /airflow/dags/download_data.py
[2022-02-18 21:51:00,242] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:51:00,245] {logging_mixin.py:112} INFO - [2022-02-18 21:51:00,245] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:51:00,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:51:00,742] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:51:00,754] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:51:00,759] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 21:51:13,472] {scheduler_job.py:155} INFO - Started process (PID=20501) to work on /airflow/dags/download_data.py
[2022-02-18 21:51:13,478] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:51:13,480] {logging_mixin.py:112} INFO - [2022-02-18 21:51:13,480] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:51:13,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:51:14,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:51:14,029] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:51:14,033] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 21:51:26,744] {scheduler_job.py:155} INFO - Started process (PID=20527) to work on /airflow/dags/download_data.py
[2022-02-18 21:51:26,748] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:51:26,750] {logging_mixin.py:112} INFO - [2022-02-18 21:51:26,749] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:51:27,189] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:51:27,245] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:51:27,255] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:51:27,259] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 21:51:39,985] {scheduler_job.py:155} INFO - Started process (PID=20553) to work on /airflow/dags/download_data.py
[2022-02-18 21:51:39,993] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:51:39,995] {logging_mixin.py:112} INFO - [2022-02-18 21:51:39,995] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:51:40,440] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:51:40,484] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:51:40,494] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:51:40,500] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 21:51:53,218] {scheduler_job.py:155} INFO - Started process (PID=20579) to work on /airflow/dags/download_data.py
[2022-02-18 21:51:53,222] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:51:53,224] {logging_mixin.py:112} INFO - [2022-02-18 21:51:53,223] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:51:53,688] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:51:53,737] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:51:53,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:51:53,755] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 21:52:06,493] {scheduler_job.py:155} INFO - Started process (PID=20605) to work on /airflow/dags/download_data.py
[2022-02-18 21:52:06,498] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:52:06,500] {logging_mixin.py:112} INFO - [2022-02-18 21:52:06,500] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:52:06,994] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:52:07,044] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:52:07,053] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:52:07,059] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 21:52:19,848] {scheduler_job.py:155} INFO - Started process (PID=20631) to work on /airflow/dags/download_data.py
[2022-02-18 21:52:19,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:52:19,871] {logging_mixin.py:112} INFO - [2022-02-18 21:52:19,871] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:52:20,336] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:52:20,389] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:52:20,401] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:52:20,407] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 21:52:33,170] {scheduler_job.py:155} INFO - Started process (PID=20657) to work on /airflow/dags/download_data.py
[2022-02-18 21:52:33,183] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:52:33,186] {logging_mixin.py:112} INFO - [2022-02-18 21:52:33,186] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:52:33,701] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:52:33,761] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:52:33,773] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:52:33,780] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 21:52:46,441] {scheduler_job.py:155} INFO - Started process (PID=20683) to work on /airflow/dags/download_data.py
[2022-02-18 21:52:46,446] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:52:46,448] {logging_mixin.py:112} INFO - [2022-02-18 21:52:46,447] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:52:46,921] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:52:46,985] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:52:46,993] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:52:46,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 21:52:59,790] {scheduler_job.py:155} INFO - Started process (PID=20709) to work on /airflow/dags/download_data.py
[2022-02-18 21:52:59,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:52:59,810] {logging_mixin.py:112} INFO - [2022-02-18 21:52:59,810] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:53:00,283] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:53:00,335] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:53:00,346] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:53:00,352] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 21:53:13,053] {scheduler_job.py:155} INFO - Started process (PID=20735) to work on /airflow/dags/download_data.py
[2022-02-18 21:53:13,062] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:53:13,065] {logging_mixin.py:112} INFO - [2022-02-18 21:53:13,064] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:53:13,634] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:53:13,682] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:53:13,691] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:53:13,695] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-18 21:53:26,326] {scheduler_job.py:155} INFO - Started process (PID=20761) to work on /airflow/dags/download_data.py
[2022-02-18 21:53:26,331] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:53:26,333] {logging_mixin.py:112} INFO - [2022-02-18 21:53:26,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:53:26,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:53:26,873] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:53:26,883] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:53:26,889] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 21:53:39,604] {scheduler_job.py:155} INFO - Started process (PID=20787) to work on /airflow/dags/download_data.py
[2022-02-18 21:53:39,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:53:39,618] {logging_mixin.py:112} INFO - [2022-02-18 21:53:39,617] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:53:40,168] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:53:40,214] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:53:40,223] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:53:40,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-18 21:53:52,942] {scheduler_job.py:155} INFO - Started process (PID=20813) to work on /airflow/dags/download_data.py
[2022-02-18 21:53:52,951] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:53:52,953] {logging_mixin.py:112} INFO - [2022-02-18 21:53:52,953] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:53:53,422] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:53:53,465] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:53:53,477] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:53:53,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 21:54:06,193] {scheduler_job.py:155} INFO - Started process (PID=20839) to work on /airflow/dags/download_data.py
[2022-02-18 21:54:06,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:54:06,201] {logging_mixin.py:112} INFO - [2022-02-18 21:54:06,201] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:54:06,689] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:54:06,751] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:54:06,764] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:54:06,771] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 21:54:19,502] {scheduler_job.py:155} INFO - Started process (PID=20865) to work on /airflow/dags/download_data.py
[2022-02-18 21:54:19,516] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:54:19,522] {logging_mixin.py:112} INFO - [2022-02-18 21:54:19,522] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:54:19,998] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:54:20,040] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:54:20,045] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:54:20,048] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 21:54:32,839] {scheduler_job.py:155} INFO - Started process (PID=20891) to work on /airflow/dags/download_data.py
[2022-02-18 21:54:32,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:54:32,850] {logging_mixin.py:112} INFO - [2022-02-18 21:54:32,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:54:33,403] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:54:33,461] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:54:33,471] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:54:33,477] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.638 seconds
[2022-02-18 21:54:46,130] {scheduler_job.py:155} INFO - Started process (PID=20917) to work on /airflow/dags/download_data.py
[2022-02-18 21:54:46,148] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:54:46,149] {logging_mixin.py:112} INFO - [2022-02-18 21:54:46,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:54:46,624] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:54:46,673] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:54:46,679] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:54:46,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 21:54:59,445] {scheduler_job.py:155} INFO - Started process (PID=20943) to work on /airflow/dags/download_data.py
[2022-02-18 21:54:59,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:54:59,454] {logging_mixin.py:112} INFO - [2022-02-18 21:54:59,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:54:59,931] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:54:59,984] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:54:59,993] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:54:59,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 21:55:12,740] {scheduler_job.py:155} INFO - Started process (PID=20969) to work on /airflow/dags/download_data.py
[2022-02-18 21:55:12,746] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:55:12,748] {logging_mixin.py:112} INFO - [2022-02-18 21:55:12,747] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:55:13,301] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:55:13,359] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:55:13,376] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:55:13,381] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 21:55:26,070] {scheduler_job.py:155} INFO - Started process (PID=20995) to work on /airflow/dags/download_data.py
[2022-02-18 21:55:26,078] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:55:26,080] {logging_mixin.py:112} INFO - [2022-02-18 21:55:26,080] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:55:26,534] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:55:26,573] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:55:26,580] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:55:26,584] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 21:55:39,361] {scheduler_job.py:155} INFO - Started process (PID=21021) to work on /airflow/dags/download_data.py
[2022-02-18 21:55:39,370] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:55:39,373] {logging_mixin.py:112} INFO - [2022-02-18 21:55:39,373] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:55:39,898] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:55:39,953] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:55:39,963] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:55:39,970] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-18 21:55:52,626] {scheduler_job.py:155} INFO - Started process (PID=21047) to work on /airflow/dags/download_data.py
[2022-02-18 21:55:52,630] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:55:52,635] {logging_mixin.py:112} INFO - [2022-02-18 21:55:52,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:55:53,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:55:53,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:55:53,186] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:55:53,191] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 21:56:05,925] {scheduler_job.py:155} INFO - Started process (PID=21073) to work on /airflow/dags/download_data.py
[2022-02-18 21:56:05,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:56:05,933] {logging_mixin.py:112} INFO - [2022-02-18 21:56:05,932] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:56:06,407] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:56:06,466] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:56:06,479] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:56:06,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 21:56:19,895] {scheduler_job.py:155} INFO - Started process (PID=21099) to work on /airflow/dags/download_data.py
[2022-02-18 21:56:19,899] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:56:19,902] {logging_mixin.py:112} INFO - [2022-02-18 21:56:19,902] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:56:20,374] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:56:20,435] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:56:20,444] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:56:20,451] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 21:56:33,241] {scheduler_job.py:155} INFO - Started process (PID=21125) to work on /airflow/dags/download_data.py
[2022-02-18 21:56:33,251] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:56:33,254] {logging_mixin.py:112} INFO - [2022-02-18 21:56:33,253] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:56:33,787] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:56:33,845] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:56:33,854] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:56:33,859] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-18 21:56:46,540] {scheduler_job.py:155} INFO - Started process (PID=21151) to work on /airflow/dags/download_data.py
[2022-02-18 21:56:46,544] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:56:46,547] {logging_mixin.py:112} INFO - [2022-02-18 21:56:46,546] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:56:47,002] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:56:47,057] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:56:47,063] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:56:47,067] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 21:56:59,837] {scheduler_job.py:155} INFO - Started process (PID=21177) to work on /airflow/dags/download_data.py
[2022-02-18 21:56:59,849] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:56:59,852] {logging_mixin.py:112} INFO - [2022-02-18 21:56:59,851] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:57:00,321] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:57:00,362] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:57:00,371] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:57:00,375] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 21:57:13,174] {scheduler_job.py:155} INFO - Started process (PID=21203) to work on /airflow/dags/download_data.py
[2022-02-18 21:57:13,179] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:57:13,181] {logging_mixin.py:112} INFO - [2022-02-18 21:57:13,181] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:57:13,643] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:57:13,692] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:57:13,700] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:57:13,707] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 21:57:26,481] {scheduler_job.py:155} INFO - Started process (PID=21229) to work on /airflow/dags/download_data.py
[2022-02-18 21:57:26,492] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:57:26,495] {logging_mixin.py:112} INFO - [2022-02-18 21:57:26,494] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:57:26,938] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:57:26,983] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:57:26,993] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:57:26,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 21:57:41,032] {scheduler_job.py:155} INFO - Started process (PID=21255) to work on /airflow/dags/download_data.py
[2022-02-18 21:57:41,040] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:57:41,042] {logging_mixin.py:112} INFO - [2022-02-18 21:57:41,042] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:57:41,496] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:57:41,555] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:57:41,566] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:57:41,572] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 21:57:59,778] {scheduler_job.py:155} INFO - Started process (PID=21281) to work on /airflow/dags/download_data.py
[2022-02-18 21:57:59,787] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:57:59,789] {logging_mixin.py:112} INFO - [2022-02-18 21:57:59,789] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:58:00,231] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:58:00,271] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:58:00,277] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:58:00,281] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 21:58:12,023] {scheduler_job.py:155} INFO - Started process (PID=21306) to work on /airflow/dags/download_data.py
[2022-02-18 21:58:12,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:58:12,029] {logging_mixin.py:112} INFO - [2022-02-18 21:58:12,029] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:58:12,464] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:58:12,512] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:58:12,519] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:58:12,522] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 21:58:26,644] {scheduler_job.py:155} INFO - Started process (PID=21332) to work on /airflow/dags/download_data.py
[2022-02-18 21:58:26,648] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:58:26,649] {logging_mixin.py:112} INFO - [2022-02-18 21:58:26,649] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:58:27,125] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:58:27,177] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:58:27,185] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:58:27,190] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 21:58:44,964] {scheduler_job.py:155} INFO - Started process (PID=21358) to work on /airflow/dags/download_data.py
[2022-02-18 21:58:45,016] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:58:45,037] {logging_mixin.py:112} INFO - [2022-02-18 21:58:45,032] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:58:47,572] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:58:47,653] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:58:47,666] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:58:47,673] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.710 seconds
[2022-02-18 21:58:59,274] {scheduler_job.py:155} INFO - Started process (PID=21384) to work on /airflow/dags/download_data.py
[2022-02-18 21:58:59,288] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:58:59,290] {logging_mixin.py:112} INFO - [2022-02-18 21:58:59,289] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:58:59,738] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:58:59,783] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:58:59,791] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:58:59,795] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 21:59:12,557] {scheduler_job.py:155} INFO - Started process (PID=21410) to work on /airflow/dags/download_data.py
[2022-02-18 21:59:12,562] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:59:12,564] {logging_mixin.py:112} INFO - [2022-02-18 21:59:12,564] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:59:13,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:59:13,085] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:59:13,097] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:59:13,111] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 21:59:27,030] {scheduler_job.py:155} INFO - Started process (PID=21436) to work on /airflow/dags/download_data.py
[2022-02-18 21:59:27,034] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:59:27,036] {logging_mixin.py:112} INFO - [2022-02-18 21:59:27,035] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:59:27,462] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:59:27,509] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:59:27,517] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:59:27,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 21:59:45,602] {scheduler_job.py:155} INFO - Started process (PID=21462) to work on /airflow/dags/download_data.py
[2022-02-18 21:59:45,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:59:45,616] {logging_mixin.py:112} INFO - [2022-02-18 21:59:45,616] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:59:46,081] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:59:46,137] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:59:46,144] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:59:46,149] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 21:59:52,744] {scheduler_job.py:155} INFO - Started process (PID=21487) to work on /airflow/dags/download_data.py
[2022-02-18 21:59:52,751] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 21:59:52,753] {logging_mixin.py:112} INFO - [2022-02-18 21:59:52,753] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 21:59:53,203] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 21:59:53,248] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 21:59:53,259] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 21:59:53,264] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 22:00:02,829] {scheduler_job.py:155} INFO - Started process (PID=21514) to work on /airflow/dags/download_data.py
[2022-02-18 22:00:02,833] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:00:02,835] {logging_mixin.py:112} INFO - [2022-02-18 22:00:02,835] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:00:03,279] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:00:03,324] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:00:03,336] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:00:03,340] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 22:00:16,895] {scheduler_job.py:155} INFO - Started process (PID=21541) to work on /airflow/dags/download_data.py
[2022-02-18 22:00:16,900] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:00:16,902] {logging_mixin.py:112} INFO - [2022-02-18 22:00:16,902] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:00:17,395] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:00:17,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:00:17,449] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:00:17,455] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 22:00:34,451] {scheduler_job.py:155} INFO - Started process (PID=21567) to work on /airflow/dags/download_data.py
[2022-02-18 22:00:34,568] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:00:34,595] {logging_mixin.py:112} INFO - [2022-02-18 22:00:34,594] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:00:57,674] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:00:57,755] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:00:57,769] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:00:57,780] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 23.333 seconds
[2022-02-18 22:01:09,142] {scheduler_job.py:155} INFO - Started process (PID=21593) to work on /airflow/dags/download_data.py
[2022-02-18 22:01:09,148] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:01:09,149] {logging_mixin.py:112} INFO - [2022-02-18 22:01:09,149] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:01:09,601] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:01:09,641] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:01:09,648] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:01:09,653] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 22:01:22,436] {scheduler_job.py:155} INFO - Started process (PID=21619) to work on /airflow/dags/download_data.py
[2022-02-18 22:01:22,440] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:01:22,441] {logging_mixin.py:112} INFO - [2022-02-18 22:01:22,441] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:01:22,885] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:01:22,936] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:01:22,946] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:01:22,950] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 22:01:36,993] {scheduler_job.py:155} INFO - Started process (PID=21645) to work on /airflow/dags/download_data.py
[2022-02-18 22:01:37,001] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:01:37,004] {logging_mixin.py:112} INFO - [2022-02-18 22:01:37,003] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:01:37,445] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:01:37,489] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:01:37,501] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:01:37,508] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 22:02:07,392] {scheduler_job.py:155} INFO - Started process (PID=21671) to work on /airflow/dags/download_data.py
[2022-02-18 22:02:07,399] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:02:07,405] {logging_mixin.py:112} INFO - [2022-02-18 22:02:07,405] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:02:07,886] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:02:07,945] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:02:07,960] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:02:07,967] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 22:02:19,724] {scheduler_job.py:155} INFO - Started process (PID=21696) to work on /airflow/dags/download_data.py
[2022-02-18 22:02:19,728] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:02:19,730] {logging_mixin.py:112} INFO - [2022-02-18 22:02:19,730] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:02:20,168] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:02:20,218] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:02:20,229] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:02:20,235] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 22:02:33,020] {scheduler_job.py:155} INFO - Started process (PID=21722) to work on /airflow/dags/download_data.py
[2022-02-18 22:02:33,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:02:33,029] {logging_mixin.py:112} INFO - [2022-02-18 22:02:33,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:02:33,463] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:02:34,986] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:02:35,000] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:02:35,007] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.987 seconds
[2022-02-18 22:02:50,776] {scheduler_job.py:155} INFO - Started process (PID=21748) to work on /airflow/dags/download_data.py
[2022-02-18 22:02:50,852] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:02:50,879] {logging_mixin.py:112} INFO - [2022-02-18 22:02:50,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:02:56,329] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:02:56,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:02:56,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:02:56,439] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 5.664 seconds
[2022-02-18 22:03:07,308] {scheduler_job.py:155} INFO - Started process (PID=21773) to work on /airflow/dags/download_data.py
[2022-02-18 22:03:07,314] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:03:07,316] {logging_mixin.py:112} INFO - [2022-02-18 22:03:07,316] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:03:07,739] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:03:07,802] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:03:07,812] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:03:07,818] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 22:03:19,545] {scheduler_job.py:155} INFO - Started process (PID=21798) to work on /airflow/dags/download_data.py
[2022-02-18 22:03:19,549] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:03:19,551] {logging_mixin.py:112} INFO - [2022-02-18 22:03:19,550] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:03:19,998] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:03:20,045] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:03:20,054] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:03:20,061] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 22:03:34,031] {scheduler_job.py:155} INFO - Started process (PID=21824) to work on /airflow/dags/download_data.py
[2022-02-18 22:03:34,035] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:03:34,037] {logging_mixin.py:112} INFO - [2022-02-18 22:03:34,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:03:34,468] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:03:34,520] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:03:34,528] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:03:34,532] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.501 seconds
[2022-02-18 22:03:52,753] {scheduler_job.py:155} INFO - Started process (PID=21850) to work on /airflow/dags/download_data.py
[2022-02-18 22:03:52,777] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:03:52,779] {logging_mixin.py:112} INFO - [2022-02-18 22:03:52,779] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:03:53,266] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:03:53,323] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:03:53,335] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:03:53,341] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 22:04:06,034] {scheduler_job.py:155} INFO - Started process (PID=21876) to work on /airflow/dags/download_data.py
[2022-02-18 22:04:06,041] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:04:06,043] {logging_mixin.py:112} INFO - [2022-02-18 22:04:06,043] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:04:06,554] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:04:06,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:04:06,628] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:04:06,634] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 22:04:18,312] {scheduler_job.py:155} INFO - Started process (PID=21901) to work on /airflow/dags/download_data.py
[2022-02-18 22:04:18,316] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:04:18,317] {logging_mixin.py:112} INFO - [2022-02-18 22:04:18,317] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:04:18,753] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:04:18,799] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:04:18,806] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:04:18,810] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.499 seconds
[2022-02-18 22:04:32,037] {scheduler_job.py:155} INFO - Started process (PID=21927) to work on /airflow/dags/download_data.py
[2022-02-18 22:04:32,041] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:04:32,042] {logging_mixin.py:112} INFO - [2022-02-18 22:04:32,042] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:04:32,581] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:04:32,635] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:04:32,641] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:04:32,645] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 22:04:48,273] {scheduler_job.py:155} INFO - Started process (PID=21953) to work on /airflow/dags/download_data.py
[2022-02-18 22:04:48,279] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:04:48,281] {logging_mixin.py:112} INFO - [2022-02-18 22:04:48,281] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:04:48,730] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:04:48,771] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:04:48,777] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:04:48,782] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 22:05:00,444] {scheduler_job.py:155} INFO - Started process (PID=21979) to work on /airflow/dags/download_data.py
[2022-02-18 22:05:00,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:05:00,453] {logging_mixin.py:112} INFO - [2022-02-18 22:05:00,452] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:05:00,887] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:05:00,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:05:00,949] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:05:00,956] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 22:05:13,735] {scheduler_job.py:155} INFO - Started process (PID=22005) to work on /airflow/dags/download_data.py
[2022-02-18 22:05:13,741] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:05:13,745] {logging_mixin.py:112} INFO - [2022-02-18 22:05:13,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:05:14,350] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:05:14,416] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:05:14,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:05:14,431] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.696 seconds
[2022-02-18 22:05:29,355] {scheduler_job.py:155} INFO - Started process (PID=22031) to work on /airflow/dags/download_data.py
[2022-02-18 22:05:29,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:05:29,557] {logging_mixin.py:112} INFO - [2022-02-18 22:05:29,553] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:05:38,058] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:05:38,171] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:05:38,189] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:05:38,202] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 8.849 seconds
[2022-02-18 22:05:49,140] {scheduler_job.py:155} INFO - Started process (PID=22057) to work on /airflow/dags/download_data.py
[2022-02-18 22:05:49,150] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:05:49,153] {logging_mixin.py:112} INFO - [2022-02-18 22:05:49,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:05:49,682] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:05:49,741] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:05:49,749] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:05:49,755] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-18 22:06:01,408] {scheduler_job.py:155} INFO - Started process (PID=22082) to work on /airflow/dags/download_data.py
[2022-02-18 22:06:01,413] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:06:01,414] {logging_mixin.py:112} INFO - [2022-02-18 22:06:01,414] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:06:01,881] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:06:01,929] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:06:01,936] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:06:01,940] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 22:06:15,977] {scheduler_job.py:155} INFO - Started process (PID=22108) to work on /airflow/dags/download_data.py
[2022-02-18 22:06:15,983] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:06:15,985] {logging_mixin.py:112} INFO - [2022-02-18 22:06:15,984] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:06:16,476] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:06:16,521] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:06:16,529] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:06:16,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 22:06:34,182] {scheduler_job.py:155} INFO - Started process (PID=22134) to work on /airflow/dags/download_data.py
[2022-02-18 22:06:34,188] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:06:34,190] {logging_mixin.py:112} INFO - [2022-02-18 22:06:34,190] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:06:34,683] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:06:34,722] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:06:34,731] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:06:34,739] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 22:06:47,664] {scheduler_job.py:155} INFO - Started process (PID=22160) to work on /airflow/dags/download_data.py
[2022-02-18 22:06:47,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:06:47,671] {logging_mixin.py:112} INFO - [2022-02-18 22:06:47,670] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:06:48,127] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:06:48,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:06:48,169] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:06:48,172] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 22:06:59,969] {scheduler_job.py:155} INFO - Started process (PID=22185) to work on /airflow/dags/download_data.py
[2022-02-18 22:06:59,974] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:06:59,976] {logging_mixin.py:112} INFO - [2022-02-18 22:06:59,976] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:07:00,414] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:07:00,472] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:07:00,484] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:07:00,489] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 22:07:14,108] {scheduler_job.py:155} INFO - Started process (PID=22211) to work on /airflow/dags/download_data.py
[2022-02-18 22:07:14,116] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:07:14,119] {logging_mixin.py:112} INFO - [2022-02-18 22:07:14,119] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:07:14,570] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:07:14,631] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:07:14,641] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:07:14,648] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 22:07:32,598] {scheduler_job.py:155} INFO - Started process (PID=22237) to work on /airflow/dags/download_data.py
[2022-02-18 22:07:32,603] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:07:32,608] {logging_mixin.py:112} INFO - [2022-02-18 22:07:32,608] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:07:33,068] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:07:33,129] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:07:33,143] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:07:33,151] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 22:07:44,857] {scheduler_job.py:155} INFO - Started process (PID=22262) to work on /airflow/dags/download_data.py
[2022-02-18 22:07:44,861] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:07:44,863] {logging_mixin.py:112} INFO - [2022-02-18 22:07:44,863] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:07:45,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:07:45,414] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:07:45,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:07:45,432] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 22:07:58,709] {scheduler_job.py:155} INFO - Started process (PID=22288) to work on /airflow/dags/download_data.py
[2022-02-18 22:07:58,723] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:07:58,727] {logging_mixin.py:112} INFO - [2022-02-18 22:07:58,727] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:07:59,223] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:07:59,300] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:07:59,311] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:07:59,318] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-18 22:08:23,181] {scheduler_job.py:155} INFO - Started process (PID=22314) to work on /airflow/dags/download_data.py
[2022-02-18 22:08:23,301] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:08:23,353] {logging_mixin.py:112} INFO - [2022-02-18 22:08:23,333] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:08:26,833] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:08:26,913] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:08:26,925] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:08:26,932] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 3.754 seconds
[2022-02-18 22:08:38,506] {scheduler_job.py:155} INFO - Started process (PID=22340) to work on /airflow/dags/download_data.py
[2022-02-18 22:08:38,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:08:38,513] {logging_mixin.py:112} INFO - [2022-02-18 22:08:38,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:08:38,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:08:39,037] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:08:39,049] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:08:39,053] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 22:08:52,675] {scheduler_job.py:155} INFO - Started process (PID=22366) to work on /airflow/dags/download_data.py
[2022-02-18 22:08:52,680] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:08:52,681] {logging_mixin.py:112} INFO - [2022-02-18 22:08:52,681] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:08:53,372] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:08:53,420] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:08:53,431] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:08:53,436] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.761 seconds
[2022-02-18 22:09:06,737] {scheduler_job.py:155} INFO - Started process (PID=22392) to work on /airflow/dags/download_data.py
[2022-02-18 22:09:06,741] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:09:06,743] {logging_mixin.py:112} INFO - [2022-02-18 22:09:06,743] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:09:07,183] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:09:07,236] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:09:07,244] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:09:07,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 22:09:25,867] {scheduler_job.py:155} INFO - Started process (PID=22418) to work on /airflow/dags/download_data.py
[2022-02-18 22:09:25,874] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:09:25,876] {logging_mixin.py:112} INFO - [2022-02-18 22:09:25,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:09:26,525] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:09:26,584] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:09:26,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:09:26,609] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.742 seconds
[2022-02-18 22:09:36,084] {scheduler_job.py:155} INFO - Started process (PID=22444) to work on /airflow/dags/download_data.py
[2022-02-18 22:09:36,090] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:09:36,092] {logging_mixin.py:112} INFO - [2022-02-18 22:09:36,091] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:09:36,565] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:09:36,613] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:09:36,622] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:09:36,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 22:09:49,351] {scheduler_job.py:155} INFO - Started process (PID=22470) to work on /airflow/dags/download_data.py
[2022-02-18 22:09:49,366] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:09:49,368] {logging_mixin.py:112} INFO - [2022-02-18 22:09:49,367] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:09:49,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:09:49,880] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:09:49,890] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:09:49,895] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 22:10:04,012] {scheduler_job.py:155} INFO - Started process (PID=22496) to work on /airflow/dags/download_data.py
[2022-02-18 22:10:04,016] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:10:04,018] {logging_mixin.py:112} INFO - [2022-02-18 22:10:04,018] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:10:04,470] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:10:04,522] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:10:04,529] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:10:04,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 22:10:22,330] {scheduler_job.py:155} INFO - Started process (PID=22522) to work on /airflow/dags/download_data.py
[2022-02-18 22:10:22,335] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:10:22,337] {logging_mixin.py:112} INFO - [2022-02-18 22:10:22,337] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:10:22,802] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:10:22,862] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:10:22,872] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:10:22,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 22:10:35,616] {scheduler_job.py:155} INFO - Started process (PID=22548) to work on /airflow/dags/download_data.py
[2022-02-18 22:10:35,621] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:10:35,623] {logging_mixin.py:112} INFO - [2022-02-18 22:10:35,623] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:10:36,058] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:10:36,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:10:36,121] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:10:36,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 22:10:47,875] {scheduler_job.py:155} INFO - Started process (PID=22573) to work on /airflow/dags/download_data.py
[2022-02-18 22:10:47,879] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:10:47,880] {logging_mixin.py:112} INFO - [2022-02-18 22:10:47,880] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:10:48,312] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:10:48,355] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:10:48,362] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:10:48,367] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.492 seconds
[2022-02-18 22:11:02,131] {scheduler_job.py:155} INFO - Started process (PID=22599) to work on /airflow/dags/download_data.py
[2022-02-18 22:11:02,138] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:11:02,142] {logging_mixin.py:112} INFO - [2022-02-18 22:11:02,142] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:11:02,625] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:11:04,068] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:11:04,212] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:11:04,260] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.129 seconds
[2022-02-18 22:11:16,868] {scheduler_job.py:155} INFO - Started process (PID=22625) to work on /airflow/dags/download_data.py
[2022-02-18 22:11:16,874] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:11:16,876] {logging_mixin.py:112} INFO - [2022-02-18 22:11:16,876] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:11:17,392] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:11:17,452] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:11:17,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:11:17,465] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.597 seconds
[2022-02-18 22:11:24,035] {scheduler_job.py:155} INFO - Started process (PID=22651) to work on /airflow/dags/download_data.py
[2022-02-18 22:11:24,040] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:11:24,041] {logging_mixin.py:112} INFO - [2022-02-18 22:11:24,041] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:11:24,562] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:11:24,630] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:11:24,641] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:11:24,647] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 22:11:31,179] {scheduler_job.py:155} INFO - Started process (PID=22678) to work on /airflow/dags/download_data.py
[2022-02-18 22:11:31,185] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:11:31,188] {logging_mixin.py:112} INFO - [2022-02-18 22:11:31,188] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:11:31,685] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:11:31,736] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:11:31,746] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:11:31,752] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 22:11:38,368] {scheduler_job.py:155} INFO - Started process (PID=22705) to work on /airflow/dags/download_data.py
[2022-02-18 22:11:38,379] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:11:38,382] {logging_mixin.py:112} INFO - [2022-02-18 22:11:38,381] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:11:38,856] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:11:38,907] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:11:38,915] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:11:38,919] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 22:12:03,119] {scheduler_job.py:155} INFO - Started process (PID=22732) to work on /airflow/dags/download_data.py
[2022-02-18 22:12:03,130] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:12:03,133] {logging_mixin.py:112} INFO - [2022-02-18 22:12:03,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:12:03,603] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:12:03,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:12:03,671] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:12:03,676] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 22:12:22,007] {scheduler_job.py:155} INFO - Started process (PID=22759) to work on /airflow/dags/download_data.py
[2022-02-18 22:12:22,034] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:12:22,040] {logging_mixin.py:112} INFO - [2022-02-18 22:12:22,039] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:12:22,913] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:12:22,982] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:12:23,014] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:12:23,020] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.015 seconds
[2022-02-18 22:12:29,330] {scheduler_job.py:155} INFO - Started process (PID=22785) to work on /airflow/dags/download_data.py
[2022-02-18 22:12:29,342] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:12:29,344] {logging_mixin.py:112} INFO - [2022-02-18 22:12:29,344] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:12:29,784] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:12:29,829] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:12:29,838] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:12:29,845] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 22:12:41,475] {scheduler_job.py:155} INFO - Started process (PID=22812) to work on /airflow/dags/download_data.py
[2022-02-18 22:12:41,488] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:12:41,490] {logging_mixin.py:112} INFO - [2022-02-18 22:12:41,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:12:41,944] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:12:41,990] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:12:41,998] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:12:42,003] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 22:12:55,942] {scheduler_job.py:155} INFO - Started process (PID=22839) to work on /airflow/dags/download_data.py
[2022-02-18 22:12:55,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:12:55,955] {logging_mixin.py:112} INFO - [2022-02-18 22:12:55,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:12:56,430] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:12:56,482] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:12:56,489] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:12:56,494] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 22:13:13,025] {scheduler_job.py:155} INFO - Started process (PID=22865) to work on /airflow/dags/download_data.py
[2022-02-18 22:13:13,095] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:13:13,118] {logging_mixin.py:112} INFO - [2022-02-18 22:13:13,117] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:13:16,491] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:13:16,567] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:13:16,584] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:13:16,594] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 3.572 seconds
[2022-02-18 22:13:22,235] {scheduler_job.py:155} INFO - Started process (PID=22891) to work on /airflow/dags/download_data.py
[2022-02-18 22:13:22,239] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:13:22,242] {logging_mixin.py:112} INFO - [2022-02-18 22:13:22,242] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:13:22,686] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:13:22,739] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:13:22,747] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:13:22,750] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 22:13:29,396] {scheduler_job.py:155} INFO - Started process (PID=22918) to work on /airflow/dags/download_data.py
[2022-02-18 22:13:29,402] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:13:29,405] {logging_mixin.py:112} INFO - [2022-02-18 22:13:29,404] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:13:29,851] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:13:29,899] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:13:29,907] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:13:29,912] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 22:13:36,576] {scheduler_job.py:155} INFO - Started process (PID=22945) to work on /airflow/dags/download_data.py
[2022-02-18 22:13:36,586] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:13:36,588] {logging_mixin.py:112} INFO - [2022-02-18 22:13:36,588] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:13:37,062] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:13:37,114] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:13:37,122] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:13:37,126] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 22:13:43,751] {scheduler_job.py:155} INFO - Started process (PID=22972) to work on /airflow/dags/download_data.py
[2022-02-18 22:13:43,760] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:13:43,761] {logging_mixin.py:112} INFO - [2022-02-18 22:13:43,761] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:13:44,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:13:44,261] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:13:44,271] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:13:44,275] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 22:13:55,953] {scheduler_job.py:155} INFO - Started process (PID=22999) to work on /airflow/dags/download_data.py
[2022-02-18 22:13:55,957] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:13:55,958] {logging_mixin.py:112} INFO - [2022-02-18 22:13:55,958] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:13:56,396] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:13:56,439] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:13:56,445] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:13:56,450] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 22:14:16,503] {scheduler_job.py:155} INFO - Started process (PID=23026) to work on /airflow/dags/download_data.py
[2022-02-18 22:14:16,514] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:14:16,516] {logging_mixin.py:112} INFO - [2022-02-18 22:14:16,516] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:14:16,982] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:14:17,041] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:14:17,054] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:14:17,062] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 22:14:29,829] {scheduler_job.py:155} INFO - Started process (PID=23052) to work on /airflow/dags/download_data.py
[2022-02-18 22:14:29,836] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:14:29,838] {logging_mixin.py:112} INFO - [2022-02-18 22:14:29,838] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:14:30,294] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:14:30,342] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:14:30,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:14:30,355] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 22:14:42,110] {scheduler_job.py:155} INFO - Started process (PID=23077) to work on /airflow/dags/download_data.py
[2022-02-18 22:14:42,117] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:14:42,119] {logging_mixin.py:112} INFO - [2022-02-18 22:14:42,119] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:14:42,563] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:14:42,611] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:14:42,619] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:14:42,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 22:14:56,830] {scheduler_job.py:155} INFO - Started process (PID=23103) to work on /airflow/dags/download_data.py
[2022-02-18 22:14:56,990] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:14:57,016] {logging_mixin.py:112} INFO - [2022-02-18 22:14:57,012] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:15:05,927] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:15:06,037] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:15:06,058] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:15:06,076] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 9.248 seconds
[2022-02-18 22:15:16,940] {scheduler_job.py:155} INFO - Started process (PID=23129) to work on /airflow/dags/download_data.py
[2022-02-18 22:15:16,946] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:15:16,948] {logging_mixin.py:112} INFO - [2022-02-18 22:15:16,948] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:15:17,389] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:15:17,435] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:15:17,444] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:15:17,450] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 22:15:30,228] {scheduler_job.py:155} INFO - Started process (PID=23155) to work on /airflow/dags/download_data.py
[2022-02-18 22:15:30,234] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:15:30,237] {logging_mixin.py:112} INFO - [2022-02-18 22:15:30,236] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:15:30,665] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:15:30,705] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:15:30,714] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:15:30,719] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 22:15:44,827] {scheduler_job.py:155} INFO - Started process (PID=23181) to work on /airflow/dags/download_data.py
[2022-02-18 22:15:44,835] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:15:44,838] {logging_mixin.py:112} INFO - [2022-02-18 22:15:44,837] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:15:45,286] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:15:45,338] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:15:45,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:15:45,355] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 22:16:03,151] {scheduler_job.py:155} INFO - Started process (PID=23207) to work on /airflow/dags/download_data.py
[2022-02-18 22:16:03,156] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:16:03,158] {logging_mixin.py:112} INFO - [2022-02-18 22:16:03,158] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:16:03,591] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:16:03,627] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:16:03,634] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:16:03,639] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.488 seconds
[2022-02-18 22:16:16,453] {scheduler_job.py:155} INFO - Started process (PID=23233) to work on /airflow/dags/download_data.py
[2022-02-18 22:16:16,468] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:16:16,469] {logging_mixin.py:112} INFO - [2022-02-18 22:16:16,469] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:16:16,907] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:16:16,962] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:16:16,973] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:16:16,980] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.526 seconds
[2022-02-18 22:16:28,737] {scheduler_job.py:155} INFO - Started process (PID=23258) to work on /airflow/dags/download_data.py
[2022-02-18 22:16:28,745] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:16:28,746] {logging_mixin.py:112} INFO - [2022-02-18 22:16:28,746] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:16:29,182] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:16:29,232] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:16:29,242] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:16:29,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 22:16:42,731] {scheduler_job.py:155} INFO - Started process (PID=23284) to work on /airflow/dags/download_data.py
[2022-02-18 22:16:42,739] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:16:42,741] {logging_mixin.py:112} INFO - [2022-02-18 22:16:42,741] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:16:44,081] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:16:45,028] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:16:45,120] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:16:45,164] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 2.432 seconds
[2022-02-18 22:17:02,370] {scheduler_job.py:155} INFO - Started process (PID=23310) to work on /airflow/dags/download_data.py
[2022-02-18 22:17:02,381] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:17:02,384] {logging_mixin.py:112} INFO - [2022-02-18 22:17:02,383] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:17:02,843] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:17:02,901] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:17:02,912] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:17:02,916] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 22:17:14,664] {scheduler_job.py:155} INFO - Started process (PID=23335) to work on /airflow/dags/download_data.py
[2022-02-18 22:17:14,672] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:17:14,674] {logging_mixin.py:112} INFO - [2022-02-18 22:17:14,673] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:17:15,111] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:17:15,156] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:17:15,162] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:17:15,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 22:17:29,349] {scheduler_job.py:155} INFO - Started process (PID=23361) to work on /airflow/dags/download_data.py
[2022-02-18 22:17:29,353] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:17:29,355] {logging_mixin.py:112} INFO - [2022-02-18 22:17:29,355] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:17:29,791] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:17:29,846] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:17:29,854] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:17:29,859] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 22:17:48,092] {scheduler_job.py:155} INFO - Started process (PID=23387) to work on /airflow/dags/download_data.py
[2022-02-18 22:17:48,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:17:48,101] {logging_mixin.py:112} INFO - [2022-02-18 22:17:48,101] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:17:48,730] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:17:48,789] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:17:48,799] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:17:48,808] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.716 seconds
[2022-02-18 22:18:01,466] {scheduler_job.py:155} INFO - Started process (PID=23413) to work on /airflow/dags/download_data.py
[2022-02-18 22:18:01,470] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:18:01,473] {logging_mixin.py:112} INFO - [2022-02-18 22:18:01,473] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:18:01,927] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:18:01,974] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:18:01,980] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:18:01,985] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 22:18:13,706] {scheduler_job.py:155} INFO - Started process (PID=23438) to work on /airflow/dags/download_data.py
[2022-02-18 22:18:13,711] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:18:13,713] {logging_mixin.py:112} INFO - [2022-02-18 22:18:13,712] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:18:14,157] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:18:14,208] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:18:14,219] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:18:14,225] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 22:18:28,270] {scheduler_job.py:155} INFO - Started process (PID=23464) to work on /airflow/dags/download_data.py
[2022-02-18 22:18:28,275] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:18:28,277] {logging_mixin.py:112} INFO - [2022-02-18 22:18:28,276] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:18:28,723] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:18:28,773] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:18:28,780] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:18:28,785] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 22:18:44,294] {scheduler_job.py:155} INFO - Started process (PID=23490) to work on /airflow/dags/download_data.py
[2022-02-18 22:18:44,304] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:18:44,307] {logging_mixin.py:112} INFO - [2022-02-18 22:18:44,307] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:18:44,819] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:18:44,879] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:18:44,891] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:18:44,901] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 22:18:56,609] {scheduler_job.py:155} INFO - Started process (PID=23516) to work on /airflow/dags/download_data.py
[2022-02-18 22:18:56,614] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:18:56,616] {logging_mixin.py:112} INFO - [2022-02-18 22:18:56,615] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:18:57,054] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:18:57,098] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:18:57,109] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:18:57,116] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 22:19:09,923] {scheduler_job.py:155} INFO - Started process (PID=23542) to work on /airflow/dags/download_data.py
[2022-02-18 22:19:09,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:19:09,930] {logging_mixin.py:112} INFO - [2022-02-18 22:19:09,930] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:19:10,368] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:19:10,413] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:19:10,420] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:19:10,426] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 22:19:24,149] {scheduler_job.py:155} INFO - Started process (PID=23568) to work on /airflow/dags/download_data.py
[2022-02-18 22:19:24,154] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:19:24,156] {logging_mixin.py:112} INFO - [2022-02-18 22:19:24,156] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:19:24,609] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:19:25,270] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:19:25,403] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:19:25,448] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.299 seconds
[2022-02-18 22:20:22,878] {scheduler_job.py:155} INFO - Started process (PID=23594) to work on /airflow/dags/download_data.py
[2022-02-18 22:20:22,886] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:20:22,888] {logging_mixin.py:112} INFO - [2022-02-18 22:20:22,888] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:20:23,435] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:20:23,469] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:20:23,479] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:20:23,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 22:20:36,183] {scheduler_job.py:155} INFO - Started process (PID=23620) to work on /airflow/dags/download_data.py
[2022-02-18 22:20:36,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:20:36,191] {logging_mixin.py:112} INFO - [2022-02-18 22:20:36,190] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:20:36,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:20:36,674] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:20:36,679] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:20:36,683] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.500 seconds
[2022-02-18 22:20:50,887] {scheduler_job.py:155} INFO - Started process (PID=23646) to work on /airflow/dags/download_data.py
[2022-02-18 22:20:50,893] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:20:50,895] {logging_mixin.py:112} INFO - [2022-02-18 22:20:50,895] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:20:51,378] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:20:51,440] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:20:51,454] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:20:51,465] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 22:21:08,944] {scheduler_job.py:155} INFO - Started process (PID=23672) to work on /airflow/dags/download_data.py
[2022-02-18 22:21:08,971] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:21:08,981] {logging_mixin.py:112} INFO - [2022-02-18 22:21:08,980] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:21:09,910] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:21:09,988] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:21:09,997] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:21:10,005] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.061 seconds
[2022-02-18 22:21:16,453] {scheduler_job.py:155} INFO - Started process (PID=23698) to work on /airflow/dags/download_data.py
[2022-02-18 22:21:16,461] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:21:16,464] {logging_mixin.py:112} INFO - [2022-02-18 22:21:16,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:21:16,928] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:21:16,985] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:21:16,994] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:21:17,003] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 22:21:23,596] {scheduler_job.py:155} INFO - Started process (PID=23725) to work on /airflow/dags/download_data.py
[2022-02-18 22:21:23,603] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:21:23,608] {logging_mixin.py:112} INFO - [2022-02-18 22:21:23,607] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:21:24,101] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:21:24,161] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:21:24,174] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:21:24,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 22:21:30,727] {scheduler_job.py:155} INFO - Started process (PID=23752) to work on /airflow/dags/download_data.py
[2022-02-18 22:21:30,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:21:30,734] {logging_mixin.py:112} INFO - [2022-02-18 22:21:30,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:21:31,195] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:21:31,260] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:21:31,272] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:21:31,277] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 22:21:37,863] {scheduler_job.py:155} INFO - Started process (PID=23779) to work on /airflow/dags/download_data.py
[2022-02-18 22:21:37,867] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:21:37,871] {logging_mixin.py:112} INFO - [2022-02-18 22:21:37,871] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:21:38,333] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:21:38,388] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:21:38,398] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:21:38,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 22:21:51,273] {scheduler_job.py:155} INFO - Started process (PID=23806) to work on /airflow/dags/download_data.py
[2022-02-18 22:21:51,279] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:21:51,281] {logging_mixin.py:112} INFO - [2022-02-18 22:21:51,280] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:21:51,722] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:21:51,765] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:21:51,771] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:21:51,775] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 22:22:08,699] {scheduler_job.py:155} INFO - Started process (PID=23832) to work on /airflow/dags/download_data.py
[2022-02-18 22:22:08,703] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:22:08,705] {logging_mixin.py:112} INFO - [2022-02-18 22:22:08,705] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:22:09,139] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:22:09,189] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:22:09,198] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:22:09,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 22:22:22,043] {scheduler_job.py:155} INFO - Started process (PID=23858) to work on /airflow/dags/download_data.py
[2022-02-18 22:22:22,050] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:22:22,052] {logging_mixin.py:112} INFO - [2022-02-18 22:22:22,051] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:22:22,524] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:22:22,585] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:22:22,600] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:22:22,605] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 22:22:35,338] {scheduler_job.py:155} INFO - Started process (PID=23884) to work on /airflow/dags/download_data.py
[2022-02-18 22:22:35,345] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:22:35,346] {logging_mixin.py:112} INFO - [2022-02-18 22:22:35,346] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:22:35,766] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:22:35,811] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:22:35,820] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:22:35,824] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.486 seconds
[2022-02-18 22:22:48,589] {scheduler_job.py:155} INFO - Started process (PID=23910) to work on /airflow/dags/download_data.py
[2022-02-18 22:22:48,594] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:22:48,596] {logging_mixin.py:112} INFO - [2022-02-18 22:22:48,595] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:22:49,058] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:22:49,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:22:49,125] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:22:49,131] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 22:23:01,963] {scheduler_job.py:155} INFO - Started process (PID=23936) to work on /airflow/dags/download_data.py
[2022-02-18 22:23:01,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:23:01,972] {logging_mixin.py:112} INFO - [2022-02-18 22:23:01,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:23:02,413] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:23:02,467] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:23:02,478] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:23:02,481] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 22:23:15,244] {scheduler_job.py:155} INFO - Started process (PID=23962) to work on /airflow/dags/download_data.py
[2022-02-18 22:23:15,256] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:23:15,258] {logging_mixin.py:112} INFO - [2022-02-18 22:23:15,258] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:23:15,714] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:23:15,770] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:23:15,781] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:23:15,789] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 22:23:28,559] {scheduler_job.py:155} INFO - Started process (PID=23988) to work on /airflow/dags/download_data.py
[2022-02-18 22:23:28,564] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:23:28,566] {logging_mixin.py:112} INFO - [2022-02-18 22:23:28,566] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:23:29,003] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:23:29,052] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:23:29,062] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:23:29,069] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 22:23:41,865] {scheduler_job.py:155} INFO - Started process (PID=24014) to work on /airflow/dags/download_data.py
[2022-02-18 22:23:41,869] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:23:41,870] {logging_mixin.py:112} INFO - [2022-02-18 22:23:41,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:23:42,306] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:23:42,347] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:23:42,354] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:23:42,358] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 22:23:55,177] {scheduler_job.py:155} INFO - Started process (PID=24040) to work on /airflow/dags/download_data.py
[2022-02-18 22:23:55,182] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:23:55,183] {logging_mixin.py:112} INFO - [2022-02-18 22:23:55,183] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:23:55,636] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:23:55,683] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:23:55,690] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:23:55,695] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 22:24:08,489] {scheduler_job.py:155} INFO - Started process (PID=24066) to work on /airflow/dags/download_data.py
[2022-02-18 22:24:08,496] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:24:08,498] {logging_mixin.py:112} INFO - [2022-02-18 22:24:08,498] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:24:08,925] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:24:08,967] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:24:08,978] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:24:08,983] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.493 seconds
[2022-02-18 22:24:21,744] {scheduler_job.py:155} INFO - Started process (PID=24092) to work on /airflow/dags/download_data.py
[2022-02-18 22:24:21,751] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:24:21,755] {logging_mixin.py:112} INFO - [2022-02-18 22:24:21,754] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:24:22,201] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:24:22,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:24:22,276] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:24:22,282] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 22:24:35,095] {scheduler_job.py:155} INFO - Started process (PID=24118) to work on /airflow/dags/download_data.py
[2022-02-18 22:24:35,099] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:24:35,101] {logging_mixin.py:112} INFO - [2022-02-18 22:24:35,100] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:24:35,547] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:24:35,590] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:24:35,597] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:24:35,601] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 22:24:49,298] {scheduler_job.py:155} INFO - Started process (PID=24144) to work on /airflow/dags/download_data.py
[2022-02-18 22:24:49,315] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:24:49,318] {logging_mixin.py:112} INFO - [2022-02-18 22:24:49,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:24:50,132] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:24:50,186] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:24:50,192] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:24:50,207] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.910 seconds
[2022-02-18 22:25:02,578] {scheduler_job.py:155} INFO - Started process (PID=24170) to work on /airflow/dags/download_data.py
[2022-02-18 22:25:02,586] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:25:02,588] {logging_mixin.py:112} INFO - [2022-02-18 22:25:02,587] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:25:03,205] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:25:03,273] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:25:03,284] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:25:03,288] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.710 seconds
[2022-02-18 22:25:15,860] {scheduler_job.py:155} INFO - Started process (PID=24196) to work on /airflow/dags/download_data.py
[2022-02-18 22:25:15,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:25:15,873] {logging_mixin.py:112} INFO - [2022-02-18 22:25:15,873] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:25:16,373] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:25:16,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:25:16,424] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:25:16,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-18 22:25:29,166] {scheduler_job.py:155} INFO - Started process (PID=24222) to work on /airflow/dags/download_data.py
[2022-02-18 22:25:29,175] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:25:29,178] {logging_mixin.py:112} INFO - [2022-02-18 22:25:29,177] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:25:29,632] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:25:29,683] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:25:29,694] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:25:29,701] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 22:25:42,441] {scheduler_job.py:155} INFO - Started process (PID=24248) to work on /airflow/dags/download_data.py
[2022-02-18 22:25:42,482] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:25:42,484] {logging_mixin.py:112} INFO - [2022-02-18 22:25:42,484] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:25:43,216] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:25:43,262] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:25:43,272] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:25:43,276] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.835 seconds
[2022-02-18 22:25:55,680] {scheduler_job.py:155} INFO - Started process (PID=24274) to work on /airflow/dags/download_data.py
[2022-02-18 22:25:55,684] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:25:55,686] {logging_mixin.py:112} INFO - [2022-02-18 22:25:55,686] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:25:56,145] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:25:56,201] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:25:56,207] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:25:56,213] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 22:26:08,953] {scheduler_job.py:155} INFO - Started process (PID=24300) to work on /airflow/dags/download_data.py
[2022-02-18 22:26:08,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:26:08,959] {logging_mixin.py:112} INFO - [2022-02-18 22:26:08,959] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:26:09,404] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:26:09,457] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:26:09,467] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:26:09,473] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 22:26:22,170] {scheduler_job.py:155} INFO - Started process (PID=24326) to work on /airflow/dags/download_data.py
[2022-02-18 22:26:22,181] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:26:22,184] {logging_mixin.py:112} INFO - [2022-02-18 22:26:22,184] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:26:22,676] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:26:22,733] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:26:22,743] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:26:22,749] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 22:26:35,461] {scheduler_job.py:155} INFO - Started process (PID=24352) to work on /airflow/dags/download_data.py
[2022-02-18 22:26:35,471] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:26:35,473] {logging_mixin.py:112} INFO - [2022-02-18 22:26:35,473] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:26:35,954] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:26:36,008] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:26:36,020] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:26:36,026] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 22:26:48,731] {scheduler_job.py:155} INFO - Started process (PID=24378) to work on /airflow/dags/download_data.py
[2022-02-18 22:26:48,740] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:26:48,742] {logging_mixin.py:112} INFO - [2022-02-18 22:26:48,742] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:26:49,216] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:26:49,275] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:26:49,286] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:26:49,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 22:27:02,029] {scheduler_job.py:155} INFO - Started process (PID=24404) to work on /airflow/dags/download_data.py
[2022-02-18 22:27:02,033] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:27:02,035] {logging_mixin.py:112} INFO - [2022-02-18 22:27:02,035] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:27:02,541] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:27:02,587] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:27:02,601] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:27:02,611] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 22:27:15,318] {scheduler_job.py:155} INFO - Started process (PID=24430) to work on /airflow/dags/download_data.py
[2022-02-18 22:27:15,336] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:27:15,340] {logging_mixin.py:112} INFO - [2022-02-18 22:27:15,340] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:27:15,957] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:27:16,016] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:27:16,027] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:27:16,034] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.716 seconds
[2022-02-18 22:27:28,619] {scheduler_job.py:155} INFO - Started process (PID=24456) to work on /airflow/dags/download_data.py
[2022-02-18 22:27:28,626] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:27:28,628] {logging_mixin.py:112} INFO - [2022-02-18 22:27:28,628] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:27:29,080] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:27:29,132] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:27:29,140] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:27:29,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 22:27:41,908] {scheduler_job.py:155} INFO - Started process (PID=24482) to work on /airflow/dags/download_data.py
[2022-02-18 22:27:41,916] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:27:41,918] {logging_mixin.py:112} INFO - [2022-02-18 22:27:41,918] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:27:42,367] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:27:42,426] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:27:42,432] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:27:42,438] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 22:27:55,166] {scheduler_job.py:155} INFO - Started process (PID=24508) to work on /airflow/dags/download_data.py
[2022-02-18 22:27:55,171] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:27:55,172] {logging_mixin.py:112} INFO - [2022-02-18 22:27:55,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:27:55,613] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:27:55,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:27:55,669] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:27:55,674] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 22:28:08,493] {scheduler_job.py:155} INFO - Started process (PID=24534) to work on /airflow/dags/download_data.py
[2022-02-18 22:28:08,501] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:28:08,502] {logging_mixin.py:112} INFO - [2022-02-18 22:28:08,502] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:28:08,943] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:28:08,991] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:28:08,998] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:28:09,005] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.512 seconds
[2022-02-18 22:28:21,711] {scheduler_job.py:155} INFO - Started process (PID=24560) to work on /airflow/dags/download_data.py
[2022-02-18 22:28:21,715] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:28:21,717] {logging_mixin.py:112} INFO - [2022-02-18 22:28:21,717] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:28:22,191] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:28:22,243] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:28:22,256] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:28:22,261] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 22:28:35,076] {scheduler_job.py:155} INFO - Started process (PID=24586) to work on /airflow/dags/download_data.py
[2022-02-18 22:28:35,082] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:28:35,084] {logging_mixin.py:112} INFO - [2022-02-18 22:28:35,084] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:28:35,538] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:28:35,592] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:28:35,600] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:28:35,607] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 22:28:48,285] {scheduler_job.py:155} INFO - Started process (PID=24612) to work on /airflow/dags/download_data.py
[2022-02-18 22:28:48,291] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:28:48,293] {logging_mixin.py:112} INFO - [2022-02-18 22:28:48,293] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:28:48,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:28:48,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:28:48,838] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:28:48,848] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 22:29:01,608] {scheduler_job.py:155} INFO - Started process (PID=24638) to work on /airflow/dags/download_data.py
[2022-02-18 22:29:01,615] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:29:01,617] {logging_mixin.py:112} INFO - [2022-02-18 22:29:01,617] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:29:02,153] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:29:02,223] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:29:02,239] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:29:02,248] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 22:29:14,855] {scheduler_job.py:155} INFO - Started process (PID=24664) to work on /airflow/dags/download_data.py
[2022-02-18 22:29:14,867] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:29:14,870] {logging_mixin.py:112} INFO - [2022-02-18 22:29:14,869] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:29:15,498] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:29:15,567] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:29:15,585] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:29:15,637] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.783 seconds
[2022-02-18 22:29:28,285] {scheduler_job.py:155} INFO - Started process (PID=24690) to work on /airflow/dags/download_data.py
[2022-02-18 22:29:28,299] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:29:28,302] {logging_mixin.py:112} INFO - [2022-02-18 22:29:28,302] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:29:28,903] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:29:28,951] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:29:28,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:29:28,972] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.687 seconds
[2022-02-18 22:29:41,640] {scheduler_job.py:155} INFO - Started process (PID=24716) to work on /airflow/dags/download_data.py
[2022-02-18 22:29:41,646] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:29:41,648] {logging_mixin.py:112} INFO - [2022-02-18 22:29:41,648] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:29:42,332] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:29:42,412] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:29:42,425] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:29:42,432] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.792 seconds
[2022-02-18 22:29:54,887] {scheduler_job.py:155} INFO - Started process (PID=24742) to work on /airflow/dags/download_data.py
[2022-02-18 22:29:54,893] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:29:54,895] {logging_mixin.py:112} INFO - [2022-02-18 22:29:54,895] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:29:55,547] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:29:55,623] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:29:55,639] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:29:55,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.756 seconds
[2022-02-18 22:30:08,238] {scheduler_job.py:155} INFO - Started process (PID=24768) to work on /airflow/dags/download_data.py
[2022-02-18 22:30:08,245] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:30:08,247] {logging_mixin.py:112} INFO - [2022-02-18 22:30:08,247] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:30:08,742] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:30:08,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:30:08,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:30:08,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 22:30:21,505] {scheduler_job.py:155} INFO - Started process (PID=24794) to work on /airflow/dags/download_data.py
[2022-02-18 22:30:21,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:30:21,515] {logging_mixin.py:112} INFO - [2022-02-18 22:30:21,514] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:30:22,015] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:30:22,079] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:30:22,089] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:30:22,103] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 22:30:34,796] {scheduler_job.py:155} INFO - Started process (PID=24820) to work on /airflow/dags/download_data.py
[2022-02-18 22:30:34,803] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:30:34,806] {logging_mixin.py:112} INFO - [2022-02-18 22:30:34,805] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:30:35,510] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:30:35,633] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:30:35,644] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:30:35,652] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.856 seconds
[2022-02-18 22:30:48,021] {scheduler_job.py:155} INFO - Started process (PID=24846) to work on /airflow/dags/download_data.py
[2022-02-18 22:30:48,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:30:48,029] {logging_mixin.py:112} INFO - [2022-02-18 22:30:48,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:30:48,528] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:30:48,568] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:30:48,579] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:30:48,584] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 22:31:01,414] {scheduler_job.py:155} INFO - Started process (PID=24872) to work on /airflow/dags/download_data.py
[2022-02-18 22:31:01,419] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:31:01,421] {logging_mixin.py:112} INFO - [2022-02-18 22:31:01,421] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:31:02,057] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:31:02,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:31:02,136] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:31:02,149] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.735 seconds
[2022-02-18 22:31:14,616] {scheduler_job.py:155} INFO - Started process (PID=24898) to work on /airflow/dags/download_data.py
[2022-02-18 22:31:14,633] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:31:14,636] {logging_mixin.py:112} INFO - [2022-02-18 22:31:14,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:31:15,147] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:31:15,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:31:15,210] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:31:15,216] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 22:31:27,957] {scheduler_job.py:155} INFO - Started process (PID=24924) to work on /airflow/dags/download_data.py
[2022-02-18 22:31:27,970] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:31:27,972] {logging_mixin.py:112} INFO - [2022-02-18 22:31:27,972] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:31:28,501] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:31:28,563] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:31:28,572] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:31:28,579] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-18 22:31:41,308] {scheduler_job.py:155} INFO - Started process (PID=24950) to work on /airflow/dags/download_data.py
[2022-02-18 22:31:41,313] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:31:41,314] {logging_mixin.py:112} INFO - [2022-02-18 22:31:41,314] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:31:41,809] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:31:41,861] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:31:41,871] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:31:41,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-18 22:31:54,582] {scheduler_job.py:155} INFO - Started process (PID=24976) to work on /airflow/dags/download_data.py
[2022-02-18 22:31:54,586] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:31:54,589] {logging_mixin.py:112} INFO - [2022-02-18 22:31:54,589] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:31:55,051] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:31:55,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:31:55,106] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:31:55,112] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 22:32:07,843] {scheduler_job.py:155} INFO - Started process (PID=25002) to work on /airflow/dags/download_data.py
[2022-02-18 22:32:07,848] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:32:07,850] {logging_mixin.py:112} INFO - [2022-02-18 22:32:07,850] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:32:08,325] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:32:08,382] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:32:08,388] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:32:08,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 22:32:21,129] {scheduler_job.py:155} INFO - Started process (PID=25028) to work on /airflow/dags/download_data.py
[2022-02-18 22:32:21,142] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:32:21,143] {logging_mixin.py:112} INFO - [2022-02-18 22:32:21,143] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:32:21,613] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:32:21,676] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:32:21,689] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:32:21,695] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 22:32:34,463] {scheduler_job.py:155} INFO - Started process (PID=25054) to work on /airflow/dags/download_data.py
[2022-02-18 22:32:34,472] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:32:34,474] {logging_mixin.py:112} INFO - [2022-02-18 22:32:34,474] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:32:34,919] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:32:34,969] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:32:34,977] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:32:34,988] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 22:32:47,720] {scheduler_job.py:155} INFO - Started process (PID=25080) to work on /airflow/dags/download_data.py
[2022-02-18 22:32:47,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:32:47,735] {logging_mixin.py:112} INFO - [2022-02-18 22:32:47,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:32:48,639] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:32:48,799] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:32:48,813] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:32:48,831] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.111 seconds
[2022-02-18 22:33:02,026] {scheduler_job.py:155} INFO - Started process (PID=25106) to work on /airflow/dags/download_data.py
[2022-02-18 22:33:02,032] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:33:02,034] {logging_mixin.py:112} INFO - [2022-02-18 22:33:02,034] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:33:02,703] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:33:02,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:33:02,800] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:33:02,814] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.788 seconds
[2022-02-18 22:33:14,406] {scheduler_job.py:155} INFO - Started process (PID=25131) to work on /airflow/dags/download_data.py
[2022-02-18 22:33:14,413] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:33:14,415] {logging_mixin.py:112} INFO - [2022-02-18 22:33:14,415] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:33:14,926] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:33:14,983] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:33:14,996] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:33:15,010] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 22:33:27,734] {scheduler_job.py:155} INFO - Started process (PID=25157) to work on /airflow/dags/download_data.py
[2022-02-18 22:33:27,742] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:33:27,744] {logging_mixin.py:112} INFO - [2022-02-18 22:33:27,744] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:33:28,310] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:33:28,373] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:33:28,387] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:33:28,390] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-18 22:33:41,336] {scheduler_job.py:155} INFO - Started process (PID=25183) to work on /airflow/dags/download_data.py
[2022-02-18 22:33:41,341] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:33:41,343] {logging_mixin.py:112} INFO - [2022-02-18 22:33:41,343] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:33:41,854] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:33:41,917] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:33:41,925] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:33:41,933] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 22:33:54,566] {scheduler_job.py:155} INFO - Started process (PID=25209) to work on /airflow/dags/download_data.py
[2022-02-18 22:33:54,583] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:33:54,587] {logging_mixin.py:112} INFO - [2022-02-18 22:33:54,586] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:33:55,095] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:33:55,143] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:33:55,153] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:33:55,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 22:34:07,868] {scheduler_job.py:155} INFO - Started process (PID=25235) to work on /airflow/dags/download_data.py
[2022-02-18 22:34:07,879] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:34:07,881] {logging_mixin.py:112} INFO - [2022-02-18 22:34:07,880] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:34:08,405] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:34:08,464] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:34:08,471] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:34:08,477] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-18 22:34:21,121] {scheduler_job.py:155} INFO - Started process (PID=25261) to work on /airflow/dags/download_data.py
[2022-02-18 22:34:21,132] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:34:21,134] {logging_mixin.py:112} INFO - [2022-02-18 22:34:21,134] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:34:21,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:34:21,875] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:34:21,884] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:34:21,890] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.769 seconds
[2022-02-18 22:34:34,459] {scheduler_job.py:155} INFO - Started process (PID=25287) to work on /airflow/dags/download_data.py
[2022-02-18 22:34:34,465] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:34:34,468] {logging_mixin.py:112} INFO - [2022-02-18 22:34:34,468] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:34:35,246] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:34:35,316] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:34:35,325] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:34:35,329] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.870 seconds
[2022-02-18 22:34:47,727] {scheduler_job.py:155} INFO - Started process (PID=25313) to work on /airflow/dags/download_data.py
[2022-02-18 22:34:47,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:34:47,733] {logging_mixin.py:112} INFO - [2022-02-18 22:34:47,733] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:34:48,329] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:34:48,383] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:34:48,395] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:34:48,402] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.675 seconds
[2022-02-18 22:35:01,018] {scheduler_job.py:155} INFO - Started process (PID=25339) to work on /airflow/dags/download_data.py
[2022-02-18 22:35:01,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:35:01,029] {logging_mixin.py:112} INFO - [2022-02-18 22:35:01,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:35:01,607] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:35:01,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:35:01,665] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:35:01,669] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.651 seconds
[2022-02-18 22:35:14,289] {scheduler_job.py:155} INFO - Started process (PID=25365) to work on /airflow/dags/download_data.py
[2022-02-18 22:35:14,298] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:35:14,300] {logging_mixin.py:112} INFO - [2022-02-18 22:35:14,299] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:35:14,857] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:35:14,926] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:35:14,936] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:35:14,944] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.656 seconds
[2022-02-18 22:35:27,608] {scheduler_job.py:155} INFO - Started process (PID=25391) to work on /airflow/dags/download_data.py
[2022-02-18 22:35:27,628] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:35:27,631] {logging_mixin.py:112} INFO - [2022-02-18 22:35:27,630] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:35:28,148] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:35:28,205] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:35:28,213] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:35:28,219] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.612 seconds
[2022-02-18 22:35:40,942] {scheduler_job.py:155} INFO - Started process (PID=25417) to work on /airflow/dags/download_data.py
[2022-02-18 22:35:40,952] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:35:40,954] {logging_mixin.py:112} INFO - [2022-02-18 22:35:40,953] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:35:41,414] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:35:41,465] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:35:41,472] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:35:41,479] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 22:35:54,164] {scheduler_job.py:155} INFO - Started process (PID=25443) to work on /airflow/dags/download_data.py
[2022-02-18 22:35:54,171] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:35:54,174] {logging_mixin.py:112} INFO - [2022-02-18 22:35:54,174] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:35:54,653] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:35:54,708] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:35:54,719] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:35:54,724] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 22:36:07,480] {scheduler_job.py:155} INFO - Started process (PID=25469) to work on /airflow/dags/download_data.py
[2022-02-18 22:36:07,488] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:36:07,490] {logging_mixin.py:112} INFO - [2022-02-18 22:36:07,490] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:36:07,937] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:36:07,981] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:36:07,990] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:36:07,993] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 22:36:20,723] {scheduler_job.py:155} INFO - Started process (PID=25495) to work on /airflow/dags/download_data.py
[2022-02-18 22:36:20,728] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:36:20,736] {logging_mixin.py:112} INFO - [2022-02-18 22:36:20,736] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:36:21,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:36:21,298] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:36:21,308] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:36:21,315] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 22:36:33,972] {scheduler_job.py:155} INFO - Started process (PID=25521) to work on /airflow/dags/download_data.py
[2022-02-18 22:36:33,981] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:36:33,983] {logging_mixin.py:112} INFO - [2022-02-18 22:36:33,983] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:36:34,454] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:36:34,505] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:36:34,512] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:36:34,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 22:36:47,214] {scheduler_job.py:155} INFO - Started process (PID=25547) to work on /airflow/dags/download_data.py
[2022-02-18 22:36:47,229] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:36:47,233] {logging_mixin.py:112} INFO - [2022-02-18 22:36:47,232] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:36:47,766] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:36:47,817] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:36:47,827] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:36:47,833] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-18 22:37:00,501] {scheduler_job.py:155} INFO - Started process (PID=25573) to work on /airflow/dags/download_data.py
[2022-02-18 22:37:00,506] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:37:00,508] {logging_mixin.py:112} INFO - [2022-02-18 22:37:00,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:37:01,028] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:37:01,084] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:37:01,098] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:37:01,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 22:37:13,801] {scheduler_job.py:155} INFO - Started process (PID=25599) to work on /airflow/dags/download_data.py
[2022-02-18 22:37:13,809] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:37:13,810] {logging_mixin.py:112} INFO - [2022-02-18 22:37:13,810] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:37:14,325] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:37:14,387] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:37:14,396] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:37:14,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 22:37:27,052] {scheduler_job.py:155} INFO - Started process (PID=25625) to work on /airflow/dags/download_data.py
[2022-02-18 22:37:27,059] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:37:27,062] {logging_mixin.py:112} INFO - [2022-02-18 22:37:27,062] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:37:27,567] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:37:27,616] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:37:27,626] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:37:27,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 22:37:40,343] {scheduler_job.py:155} INFO - Started process (PID=25651) to work on /airflow/dags/download_data.py
[2022-02-18 22:37:40,357] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:37:40,359] {logging_mixin.py:112} INFO - [2022-02-18 22:37:40,359] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:37:41,036] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:37:41,085] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:37:41,093] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:37:41,098] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.755 seconds
[2022-02-18 22:37:53,591] {scheduler_job.py:155} INFO - Started process (PID=25677) to work on /airflow/dags/download_data.py
[2022-02-18 22:37:53,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:37:53,608] {logging_mixin.py:112} INFO - [2022-02-18 22:37:53,608] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:37:54,071] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:37:54,122] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:37:54,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:37:54,135] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.544 seconds
[2022-02-18 22:38:06,880] {scheduler_job.py:155} INFO - Started process (PID=25703) to work on /airflow/dags/download_data.py
[2022-02-18 22:38:06,886] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:38:06,887] {logging_mixin.py:112} INFO - [2022-02-18 22:38:06,887] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:38:07,497] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:38:07,564] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:38:07,573] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:38:07,580] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.701 seconds
[2022-02-18 22:38:20,103] {scheduler_job.py:155} INFO - Started process (PID=25729) to work on /airflow/dags/download_data.py
[2022-02-18 22:38:20,109] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:38:20,111] {logging_mixin.py:112} INFO - [2022-02-18 22:38:20,111] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:38:20,608] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:38:20,655] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:38:20,662] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:38:20,668] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 22:38:33,380] {scheduler_job.py:155} INFO - Started process (PID=25755) to work on /airflow/dags/download_data.py
[2022-02-18 22:38:33,385] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:38:33,386] {logging_mixin.py:112} INFO - [2022-02-18 22:38:33,386] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:38:33,851] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:38:33,903] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:38:33,914] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:38:33,922] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 22:38:46,647] {scheduler_job.py:155} INFO - Started process (PID=25781) to work on /airflow/dags/download_data.py
[2022-02-18 22:38:46,656] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:38:46,658] {logging_mixin.py:112} INFO - [2022-02-18 22:38:46,658] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:38:47,189] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:38:47,251] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:38:47,264] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:38:47,270] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-18 22:38:59,920] {scheduler_job.py:155} INFO - Started process (PID=25807) to work on /airflow/dags/download_data.py
[2022-02-18 22:38:59,928] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:38:59,930] {logging_mixin.py:112} INFO - [2022-02-18 22:38:59,930] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:39:00,396] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:39:00,449] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:39:00,459] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:39:00,463] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 22:39:13,195] {scheduler_job.py:155} INFO - Started process (PID=25833) to work on /airflow/dags/download_data.py
[2022-02-18 22:39:13,199] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:39:13,204] {logging_mixin.py:112} INFO - [2022-02-18 22:39:13,203] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:39:13,706] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:39:13,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:39:13,772] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:39:13,751] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 22:39:26,435] {scheduler_job.py:155} INFO - Started process (PID=25859) to work on /airflow/dags/download_data.py
[2022-02-18 22:39:26,439] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:39:26,441] {logging_mixin.py:112} INFO - [2022-02-18 22:39:26,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:39:26,886] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:39:26,937] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:39:26,944] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:39:26,950] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.515 seconds
[2022-02-18 22:39:39,714] {scheduler_job.py:155} INFO - Started process (PID=25885) to work on /airflow/dags/download_data.py
[2022-02-18 22:39:39,722] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:39:39,725] {logging_mixin.py:112} INFO - [2022-02-18 22:39:39,725] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:39:40,375] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:39:40,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:39:40,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:39:40,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.714 seconds
[2022-02-18 22:39:52,926] {scheduler_job.py:155} INFO - Started process (PID=25911) to work on /airflow/dags/download_data.py
[2022-02-18 22:39:52,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:39:52,932] {logging_mixin.py:112} INFO - [2022-02-18 22:39:52,932] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:39:53,417] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:39:53,466] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:39:53,475] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:39:53,480] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 22:40:06,204] {scheduler_job.py:155} INFO - Started process (PID=25937) to work on /airflow/dags/download_data.py
[2022-02-18 22:40:06,212] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:40:06,214] {logging_mixin.py:112} INFO - [2022-02-18 22:40:06,213] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:40:06,671] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:40:06,726] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:40:06,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:40:06,740] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 22:40:19,477] {scheduler_job.py:155} INFO - Started process (PID=25963) to work on /airflow/dags/download_data.py
[2022-02-18 22:40:19,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:40:19,489] {logging_mixin.py:112} INFO - [2022-02-18 22:40:19,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:40:19,966] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:40:20,023] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:40:20,031] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:40:20,040] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 22:40:32,713] {scheduler_job.py:155} INFO - Started process (PID=25989) to work on /airflow/dags/download_data.py
[2022-02-18 22:40:32,721] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:40:32,724] {logging_mixin.py:112} INFO - [2022-02-18 22:40:32,723] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:40:33,200] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:40:33,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:40:33,260] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:40:33,265] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 22:40:46,002] {scheduler_job.py:155} INFO - Started process (PID=26015) to work on /airflow/dags/download_data.py
[2022-02-18 22:40:46,011] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:40:46,014] {logging_mixin.py:112} INFO - [2022-02-18 22:40:46,014] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:40:46,522] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:40:46,579] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:40:46,591] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:40:46,595] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 22:40:59,268] {scheduler_job.py:155} INFO - Started process (PID=26041) to work on /airflow/dags/download_data.py
[2022-02-18 22:40:59,279] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:40:59,281] {logging_mixin.py:112} INFO - [2022-02-18 22:40:59,280] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:40:59,771] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:40:59,832] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:40:59,844] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:40:59,850] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 22:41:12,534] {scheduler_job.py:155} INFO - Started process (PID=26067) to work on /airflow/dags/download_data.py
[2022-02-18 22:41:12,541] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:41:12,545] {logging_mixin.py:112} INFO - [2022-02-18 22:41:12,544] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:41:13,029] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:41:13,078] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:41:13,088] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:41:13,094] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 22:41:25,791] {scheduler_job.py:155} INFO - Started process (PID=26093) to work on /airflow/dags/download_data.py
[2022-02-18 22:41:25,795] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:41:25,797] {logging_mixin.py:112} INFO - [2022-02-18 22:41:25,797] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:41:26,278] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:41:26,327] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:41:26,336] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:41:26,342] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.551 seconds
[2022-02-18 22:41:39,057] {scheduler_job.py:155} INFO - Started process (PID=26119) to work on /airflow/dags/download_data.py
[2022-02-18 22:41:39,069] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:41:39,072] {logging_mixin.py:112} INFO - [2022-02-18 22:41:39,071] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:41:39,522] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:41:39,572] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:41:39,580] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:41:39,584] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 22:41:52,351] {scheduler_job.py:155} INFO - Started process (PID=26145) to work on /airflow/dags/download_data.py
[2022-02-18 22:41:52,363] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:41:52,365] {logging_mixin.py:112} INFO - [2022-02-18 22:41:52,365] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:41:52,813] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:41:52,866] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:41:52,873] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:41:52,878] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 22:42:05,635] {scheduler_job.py:155} INFO - Started process (PID=26171) to work on /airflow/dags/download_data.py
[2022-02-18 22:42:05,660] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:42:05,661] {logging_mixin.py:112} INFO - [2022-02-18 22:42:05,661] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:42:06,377] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:42:06,435] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:42:06,448] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:42:06,454] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.819 seconds
[2022-02-18 22:42:18,967] {scheduler_job.py:155} INFO - Started process (PID=26197) to work on /airflow/dags/download_data.py
[2022-02-18 22:42:18,971] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:42:18,974] {logging_mixin.py:112} INFO - [2022-02-18 22:42:18,973] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:42:19,502] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:42:19,557] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:42:19,568] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:42:19,575] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 22:42:32,247] {scheduler_job.py:155} INFO - Started process (PID=26223) to work on /airflow/dags/download_data.py
[2022-02-18 22:42:32,253] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:42:32,254] {logging_mixin.py:112} INFO - [2022-02-18 22:42:32,254] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:42:32,817] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:42:32,863] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:42:32,870] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:42:32,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-18 22:42:45,529] {scheduler_job.py:155} INFO - Started process (PID=26249) to work on /airflow/dags/download_data.py
[2022-02-18 22:42:45,540] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:42:45,542] {logging_mixin.py:112} INFO - [2022-02-18 22:42:45,542] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:42:46,013] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:42:46,072] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:42:46,081] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:42:46,088] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 22:42:58,812] {scheduler_job.py:155} INFO - Started process (PID=26275) to work on /airflow/dags/download_data.py
[2022-02-18 22:42:58,824] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:42:58,826] {logging_mixin.py:112} INFO - [2022-02-18 22:42:58,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:42:59,307] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:42:59,359] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:42:59,366] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:42:59,371] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.559 seconds
[2022-02-18 22:43:12,063] {scheduler_job.py:155} INFO - Started process (PID=26301) to work on /airflow/dags/download_data.py
[2022-02-18 22:43:12,067] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:43:12,069] {logging_mixin.py:112} INFO - [2022-02-18 22:43:12,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:43:12,510] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:43:12,552] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:43:12,563] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:43:12,568] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 22:43:25,354] {scheduler_job.py:155} INFO - Started process (PID=26327) to work on /airflow/dags/download_data.py
[2022-02-18 22:43:25,363] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:43:25,366] {logging_mixin.py:112} INFO - [2022-02-18 22:43:25,365] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:43:25,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:43:25,884] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:43:25,895] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:43:25,903] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 22:43:38,642] {scheduler_job.py:155} INFO - Started process (PID=26353) to work on /airflow/dags/download_data.py
[2022-02-18 22:43:38,650] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:43:38,652] {logging_mixin.py:112} INFO - [2022-02-18 22:43:38,652] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:43:39,124] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:43:39,176] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:43:39,185] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:43:39,189] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 22:43:51,867] {scheduler_job.py:155} INFO - Started process (PID=26379) to work on /airflow/dags/download_data.py
[2022-02-18 22:43:51,873] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:43:51,875] {logging_mixin.py:112} INFO - [2022-02-18 22:43:51,875] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:43:52,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:43:52,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:43:52,393] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:43:52,399] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 22:44:05,127] {scheduler_job.py:155} INFO - Started process (PID=26405) to work on /airflow/dags/download_data.py
[2022-02-18 22:44:05,137] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:44:05,142] {logging_mixin.py:112} INFO - [2022-02-18 22:44:05,142] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:44:05,632] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:44:05,684] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:44:05,694] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:44:05,702] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 22:44:18,392] {scheduler_job.py:155} INFO - Started process (PID=26431) to work on /airflow/dags/download_data.py
[2022-02-18 22:44:18,397] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:44:18,399] {logging_mixin.py:112} INFO - [2022-02-18 22:44:18,398] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:44:18,898] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:44:18,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:44:18,971] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:44:18,976] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 22:44:31,682] {scheduler_job.py:155} INFO - Started process (PID=26457) to work on /airflow/dags/download_data.py
[2022-02-18 22:44:31,687] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:44:31,689] {logging_mixin.py:112} INFO - [2022-02-18 22:44:31,688] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:44:32,150] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:44:32,182] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:44:32,188] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:44:32,191] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 22:44:44,924] {scheduler_job.py:155} INFO - Started process (PID=26483) to work on /airflow/dags/download_data.py
[2022-02-18 22:44:44,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:44:44,940] {logging_mixin.py:112} INFO - [2022-02-18 22:44:44,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:44:45,409] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:44:45,465] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:44:45,482] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:44:45,487] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 22:44:58,215] {scheduler_job.py:155} INFO - Started process (PID=26509) to work on /airflow/dags/download_data.py
[2022-02-18 22:44:58,225] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:44:58,228] {logging_mixin.py:112} INFO - [2022-02-18 22:44:58,228] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:44:58,693] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:44:58,740] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:44:58,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:44:58,752] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 22:45:11,598] {scheduler_job.py:155} INFO - Started process (PID=26535) to work on /airflow/dags/download_data.py
[2022-02-18 22:45:11,604] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:45:11,605] {logging_mixin.py:112} INFO - [2022-02-18 22:45:11,605] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:45:12,070] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:45:12,119] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:45:12,127] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:45:12,132] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 22:45:24,882] {scheduler_job.py:155} INFO - Started process (PID=26561) to work on /airflow/dags/download_data.py
[2022-02-18 22:45:24,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:45:24,890] {logging_mixin.py:112} INFO - [2022-02-18 22:45:24,890] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:45:25,344] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:45:25,394] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:45:25,401] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:45:25,406] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 22:45:38,155] {scheduler_job.py:155} INFO - Started process (PID=26587) to work on /airflow/dags/download_data.py
[2022-02-18 22:45:38,159] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:45:38,161] {logging_mixin.py:112} INFO - [2022-02-18 22:45:38,161] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:45:38,622] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:45:38,672] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:45:38,678] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:45:38,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 22:45:51,403] {scheduler_job.py:155} INFO - Started process (PID=26613) to work on /airflow/dags/download_data.py
[2022-02-18 22:45:51,413] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:45:51,415] {logging_mixin.py:112} INFO - [2022-02-18 22:45:51,415] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:45:51,864] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:45:51,911] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:45:51,917] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:45:51,924] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 22:46:04,688] {scheduler_job.py:155} INFO - Started process (PID=26639) to work on /airflow/dags/download_data.py
[2022-02-18 22:46:04,695] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:46:04,697] {logging_mixin.py:112} INFO - [2022-02-18 22:46:04,697] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:46:05,150] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:46:05,203] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:46:05,213] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:46:05,220] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 22:46:17,939] {scheduler_job.py:155} INFO - Started process (PID=26665) to work on /airflow/dags/download_data.py
[2022-02-18 22:46:17,944] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:46:17,946] {logging_mixin.py:112} INFO - [2022-02-18 22:46:17,946] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:46:18,470] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:46:18,524] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:46:18,534] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:46:18,539] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.600 seconds
[2022-02-18 22:46:31,340] {scheduler_job.py:155} INFO - Started process (PID=26691) to work on /airflow/dags/download_data.py
[2022-02-18 22:46:31,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:46:31,357] {logging_mixin.py:112} INFO - [2022-02-18 22:46:31,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:46:31,821] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:46:31,876] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:46:31,883] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:46:31,888] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 22:46:44,575] {scheduler_job.py:155} INFO - Started process (PID=26717) to work on /airflow/dags/download_data.py
[2022-02-18 22:46:44,591] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:46:44,592] {logging_mixin.py:112} INFO - [2022-02-18 22:46:44,592] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:46:45,157] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:46:45,202] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:46:45,216] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:46:45,224] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.649 seconds
[2022-02-18 22:46:57,886] {scheduler_job.py:155} INFO - Started process (PID=26743) to work on /airflow/dags/download_data.py
[2022-02-18 22:46:57,892] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:46:57,893] {logging_mixin.py:112} INFO - [2022-02-18 22:46:57,893] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:46:58,354] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:46:58,402] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:46:58,413] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:46:58,420] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 22:47:11,128] {scheduler_job.py:155} INFO - Started process (PID=26769) to work on /airflow/dags/download_data.py
[2022-02-18 22:47:11,138] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:47:11,140] {logging_mixin.py:112} INFO - [2022-02-18 22:47:11,140] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:47:11,627] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:47:11,684] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:47:11,696] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:47:11,701] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 22:47:24,435] {scheduler_job.py:155} INFO - Started process (PID=26795) to work on /airflow/dags/download_data.py
[2022-02-18 22:47:24,441] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:47:24,442] {logging_mixin.py:112} INFO - [2022-02-18 22:47:24,442] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:47:24,938] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:47:24,988] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:47:24,997] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:47:25,003] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 22:47:37,676] {scheduler_job.py:155} INFO - Started process (PID=26821) to work on /airflow/dags/download_data.py
[2022-02-18 22:47:37,684] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:47:37,686] {logging_mixin.py:112} INFO - [2022-02-18 22:47:37,686] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:47:38,145] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:47:38,190] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:47:38,197] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:47:38,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 22:47:50,948] {scheduler_job.py:155} INFO - Started process (PID=26847) to work on /airflow/dags/download_data.py
[2022-02-18 22:47:50,953] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:47:50,955] {logging_mixin.py:112} INFO - [2022-02-18 22:47:50,955] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:47:51,417] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:47:51,464] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:47:51,477] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:47:51,484] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 22:48:04,237] {scheduler_job.py:155} INFO - Started process (PID=26873) to work on /airflow/dags/download_data.py
[2022-02-18 22:48:04,248] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:48:04,250] {logging_mixin.py:112} INFO - [2022-02-18 22:48:04,250] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:48:04,692] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:48:04,736] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:48:04,743] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:48:04,747] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 22:48:17,481] {scheduler_job.py:155} INFO - Started process (PID=26899) to work on /airflow/dags/download_data.py
[2022-02-18 22:48:17,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:48:17,489] {logging_mixin.py:112} INFO - [2022-02-18 22:48:17,489] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:48:17,972] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:48:18,021] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:48:18,031] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:48:18,036] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 22:48:30,749] {scheduler_job.py:155} INFO - Started process (PID=26925) to work on /airflow/dags/download_data.py
[2022-02-18 22:48:30,754] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:48:30,755] {logging_mixin.py:112} INFO - [2022-02-18 22:48:30,755] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:48:31,240] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:48:31,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:48:31,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:48:31,340] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 22:48:44,016] {scheduler_job.py:155} INFO - Started process (PID=26951) to work on /airflow/dags/download_data.py
[2022-02-18 22:48:44,027] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:48:44,030] {logging_mixin.py:112} INFO - [2022-02-18 22:48:44,030] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:48:44,685] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:48:44,753] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:48:44,764] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:48:44,769] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.752 seconds
[2022-02-18 22:48:57,341] {scheduler_job.py:155} INFO - Started process (PID=26977) to work on /airflow/dags/download_data.py
[2022-02-18 22:48:57,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:48:57,349] {logging_mixin.py:112} INFO - [2022-02-18 22:48:57,349] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:48:57,812] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:48:57,866] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:48:57,877] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:48:57,880] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 22:49:11,609] {scheduler_job.py:155} INFO - Started process (PID=27003) to work on /airflow/dags/download_data.py
[2022-02-18 22:49:11,619] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:49:11,623] {logging_mixin.py:112} INFO - [2022-02-18 22:49:11,622] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:49:12,137] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:49:12,194] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:49:12,200] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:49:12,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 22:49:24,906] {scheduler_job.py:155} INFO - Started process (PID=27029) to work on /airflow/dags/download_data.py
[2022-02-18 22:49:24,913] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:49:24,918] {logging_mixin.py:112} INFO - [2022-02-18 22:49:24,918] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:49:25,438] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:49:25,503] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:49:25,518] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:49:25,523] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-18 22:49:38,199] {scheduler_job.py:155} INFO - Started process (PID=27055) to work on /airflow/dags/download_data.py
[2022-02-18 22:49:38,204] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:49:38,208] {logging_mixin.py:112} INFO - [2022-02-18 22:49:38,207] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:49:38,702] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:49:38,782] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:49:38,788] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:49:38,793] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.594 seconds
[2022-02-18 22:49:51,447] {scheduler_job.py:155} INFO - Started process (PID=27081) to work on /airflow/dags/download_data.py
[2022-02-18 22:49:51,454] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:49:51,459] {logging_mixin.py:112} INFO - [2022-02-18 22:49:51,458] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:49:51,997] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:49:52,055] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:49:52,066] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:49:52,071] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.625 seconds
[2022-02-18 22:50:04,725] {scheduler_job.py:155} INFO - Started process (PID=27107) to work on /airflow/dags/download_data.py
[2022-02-18 22:50:04,731] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:50:04,732] {logging_mixin.py:112} INFO - [2022-02-18 22:50:04,732] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:50:05,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:50:05,269] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:50:05,279] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:50:05,285] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 22:50:17,966] {scheduler_job.py:155} INFO - Started process (PID=27133) to work on /airflow/dags/download_data.py
[2022-02-18 22:50:17,983] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:50:17,987] {logging_mixin.py:112} INFO - [2022-02-18 22:50:17,986] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:50:18,569] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:50:18,630] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:50:18,638] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:50:18,643] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.677 seconds
[2022-02-18 22:50:31,260] {scheduler_job.py:155} INFO - Started process (PID=27159) to work on /airflow/dags/download_data.py
[2022-02-18 22:50:31,266] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:50:31,270] {logging_mixin.py:112} INFO - [2022-02-18 22:50:31,270] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:50:31,742] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:50:31,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:50:31,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:50:31,799] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 22:50:44,512] {scheduler_job.py:155} INFO - Started process (PID=27185) to work on /airflow/dags/download_data.py
[2022-02-18 22:50:44,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:50:44,530] {logging_mixin.py:112} INFO - [2022-02-18 22:50:44,529] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:50:45,017] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:50:45,067] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:50:45,073] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:50:45,077] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 22:50:57,859] {scheduler_job.py:155} INFO - Started process (PID=27211) to work on /airflow/dags/download_data.py
[2022-02-18 22:50:57,865] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:50:57,870] {logging_mixin.py:112} INFO - [2022-02-18 22:50:57,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:50:58,357] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:50:58,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:50:58,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:50:58,425] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 22:51:11,131] {scheduler_job.py:155} INFO - Started process (PID=27237) to work on /airflow/dags/download_data.py
[2022-02-18 22:51:11,135] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:51:11,137] {logging_mixin.py:112} INFO - [2022-02-18 22:51:11,137] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:51:11,609] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:51:11,674] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:51:11,684] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:51:11,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 22:51:24,406] {scheduler_job.py:155} INFO - Started process (PID=27263) to work on /airflow/dags/download_data.py
[2022-02-18 22:51:24,420] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:51:24,422] {logging_mixin.py:112} INFO - [2022-02-18 22:51:24,422] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:51:24,933] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:51:24,978] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:51:24,988] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:51:24,992] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 22:51:37,689] {scheduler_job.py:155} INFO - Started process (PID=27289) to work on /airflow/dags/download_data.py
[2022-02-18 22:51:37,694] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:51:37,697] {logging_mixin.py:112} INFO - [2022-02-18 22:51:37,696] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:51:38,149] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:51:38,195] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:51:38,204] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:51:38,209] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 22:51:50,932] {scheduler_job.py:155} INFO - Started process (PID=27315) to work on /airflow/dags/download_data.py
[2022-02-18 22:51:50,938] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:51:50,940] {logging_mixin.py:112} INFO - [2022-02-18 22:51:50,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:51:51,463] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:51:51,514] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:51:51,522] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:51:51,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 22:52:04,264] {scheduler_job.py:155} INFO - Started process (PID=27341) to work on /airflow/dags/download_data.py
[2022-02-18 22:52:04,275] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:52:04,276] {logging_mixin.py:112} INFO - [2022-02-18 22:52:04,276] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:52:04,741] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:52:04,788] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:52:04,794] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:52:04,801] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 22:52:17,557] {scheduler_job.py:155} INFO - Started process (PID=27367) to work on /airflow/dags/download_data.py
[2022-02-18 22:52:17,579] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:52:17,583] {logging_mixin.py:112} INFO - [2022-02-18 22:52:17,582] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:52:18,132] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:52:18,187] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:52:18,199] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:52:18,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-18 22:52:30,920] {scheduler_job.py:155} INFO - Started process (PID=27393) to work on /airflow/dags/download_data.py
[2022-02-18 22:52:30,926] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:52:30,929] {logging_mixin.py:112} INFO - [2022-02-18 22:52:30,928] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:52:31,403] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:52:31,454] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:52:31,461] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:52:31,466] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 22:52:44,174] {scheduler_job.py:155} INFO - Started process (PID=27419) to work on /airflow/dags/download_data.py
[2022-02-18 22:52:44,182] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:52:44,184] {logging_mixin.py:112} INFO - [2022-02-18 22:52:44,184] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:52:44,741] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:52:44,787] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:52:44,795] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:52:44,804] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.630 seconds
[2022-02-18 22:52:57,472] {scheduler_job.py:155} INFO - Started process (PID=27445) to work on /airflow/dags/download_data.py
[2022-02-18 22:52:57,479] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:52:57,481] {logging_mixin.py:112} INFO - [2022-02-18 22:52:57,481] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:52:58,388] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:52:58,496] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:52:58,513] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:52:58,521] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.049 seconds
[2022-02-18 22:53:11,792] {scheduler_job.py:155} INFO - Started process (PID=27471) to work on /airflow/dags/download_data.py
[2022-02-18 22:53:11,805] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:53:11,808] {logging_mixin.py:112} INFO - [2022-02-18 22:53:11,808] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:53:12,271] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:53:12,317] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:53:12,323] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:53:12,330] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 22:53:24,022] {scheduler_job.py:155} INFO - Started process (PID=27496) to work on /airflow/dags/download_data.py
[2022-02-18 22:53:24,029] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:53:24,031] {logging_mixin.py:112} INFO - [2022-02-18 22:53:24,031] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:53:24,531] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:53:24,586] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:53:24,596] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:53:24,600] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 22:53:37,322] {scheduler_job.py:155} INFO - Started process (PID=27522) to work on /airflow/dags/download_data.py
[2022-02-18 22:53:37,337] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:53:37,341] {logging_mixin.py:112} INFO - [2022-02-18 22:53:37,340] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:53:37,833] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:53:37,874] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:53:37,883] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:53:37,890] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 22:53:50,546] {scheduler_job.py:155} INFO - Started process (PID=27548) to work on /airflow/dags/download_data.py
[2022-02-18 22:53:50,553] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:53:50,556] {logging_mixin.py:112} INFO - [2022-02-18 22:53:50,555] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:53:51,050] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:53:51,104] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:53:51,115] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:53:51,123] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 22:54:03,849] {scheduler_job.py:155} INFO - Started process (PID=27574) to work on /airflow/dags/download_data.py
[2022-02-18 22:54:03,859] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:54:03,862] {logging_mixin.py:112} INFO - [2022-02-18 22:54:03,861] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:54:04,359] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:54:04,409] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:54:04,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:54:04,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 22:54:17,080] {scheduler_job.py:155} INFO - Started process (PID=27600) to work on /airflow/dags/download_data.py
[2022-02-18 22:54:17,086] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:54:17,088] {logging_mixin.py:112} INFO - [2022-02-18 22:54:17,088] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:54:17,598] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:54:17,656] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:54:17,666] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:54:17,672] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 22:54:30,368] {scheduler_job.py:155} INFO - Started process (PID=27626) to work on /airflow/dags/download_data.py
[2022-02-18 22:54:30,373] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:54:30,374] {logging_mixin.py:112} INFO - [2022-02-18 22:54:30,374] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:54:30,838] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:54:30,877] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:54:30,886] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:54:30,891] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.523 seconds
[2022-02-18 22:54:43,638] {scheduler_job.py:155} INFO - Started process (PID=27652) to work on /airflow/dags/download_data.py
[2022-02-18 22:54:43,644] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:54:43,646] {logging_mixin.py:112} INFO - [2022-02-18 22:54:43,645] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:54:44,438] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:54:44,511] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:54:44,525] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:54:44,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.897 seconds
[2022-02-18 22:54:56,897] {scheduler_job.py:155} INFO - Started process (PID=27678) to work on /airflow/dags/download_data.py
[2022-02-18 22:54:56,903] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:54:56,904] {logging_mixin.py:112} INFO - [2022-02-18 22:54:56,904] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:54:57,401] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:54:57,442] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:54:57,450] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:54:57,454] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.558 seconds
[2022-02-18 22:55:10,193] {scheduler_job.py:155} INFO - Started process (PID=27704) to work on /airflow/dags/download_data.py
[2022-02-18 22:55:10,201] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:55:10,204] {logging_mixin.py:112} INFO - [2022-02-18 22:55:10,204] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:55:10,666] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:55:10,731] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:55:10,743] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:55:10,748] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 22:55:23,453] {scheduler_job.py:155} INFO - Started process (PID=27730) to work on /airflow/dags/download_data.py
[2022-02-18 22:55:23,462] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:55:23,465] {logging_mixin.py:112} INFO - [2022-02-18 22:55:23,464] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:55:23,993] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:55:24,062] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:55:24,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:55:24,079] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.627 seconds
[2022-02-18 22:55:36,767] {scheduler_job.py:155} INFO - Started process (PID=27756) to work on /airflow/dags/download_data.py
[2022-02-18 22:55:36,778] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:55:36,780] {logging_mixin.py:112} INFO - [2022-02-18 22:55:36,780] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:55:37,224] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:55:37,263] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:55:37,268] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:55:37,272] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 22:55:50,038] {scheduler_job.py:155} INFO - Started process (PID=27782) to work on /airflow/dags/download_data.py
[2022-02-18 22:55:50,047] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:55:50,051] {logging_mixin.py:112} INFO - [2022-02-18 22:55:50,050] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:55:50,522] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:55:50,572] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:55:50,582] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:55:50,587] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 22:56:03,338] {scheduler_job.py:155} INFO - Started process (PID=27808) to work on /airflow/dags/download_data.py
[2022-02-18 22:56:03,343] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:56:03,345] {logging_mixin.py:112} INFO - [2022-02-18 22:56:03,345] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:56:03,877] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:56:03,922] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:56:03,931] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:56:03,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 22:56:16,590] {scheduler_job.py:155} INFO - Started process (PID=27834) to work on /airflow/dags/download_data.py
[2022-02-18 22:56:16,596] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:56:16,598] {logging_mixin.py:112} INFO - [2022-02-18 22:56:16,598] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:56:17,179] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:56:17,240] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:56:17,248] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:56:17,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.662 seconds
[2022-02-18 22:56:29,916] {scheduler_job.py:155} INFO - Started process (PID=27860) to work on /airflow/dags/download_data.py
[2022-02-18 22:56:29,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:56:29,939] {logging_mixin.py:112} INFO - [2022-02-18 22:56:29,939] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:56:30,504] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:56:30,552] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:56:30,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:56:30,566] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.651 seconds
[2022-02-18 22:56:43,165] {scheduler_job.py:155} INFO - Started process (PID=27886) to work on /airflow/dags/download_data.py
[2022-02-18 22:56:43,173] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:56:43,176] {logging_mixin.py:112} INFO - [2022-02-18 22:56:43,176] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:56:43,812] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:56:43,883] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:56:43,893] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:56:43,898] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.733 seconds
[2022-02-18 22:56:56,454] {scheduler_job.py:155} INFO - Started process (PID=27912) to work on /airflow/dags/download_data.py
[2022-02-18 22:56:56,467] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:56:56,470] {logging_mixin.py:112} INFO - [2022-02-18 22:56:56,469] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:56:56,955] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:56:56,999] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:56:57,005] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:56:57,009] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 22:57:09,757] {scheduler_job.py:155} INFO - Started process (PID=27938) to work on /airflow/dags/download_data.py
[2022-02-18 22:57:09,768] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:57:09,770] {logging_mixin.py:112} INFO - [2022-02-18 22:57:09,770] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:57:10,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:57:10,302] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:57:10,315] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:57:10,323] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 22:57:23,050] {scheduler_job.py:155} INFO - Started process (PID=27964) to work on /airflow/dags/download_data.py
[2022-02-18 22:57:23,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:57:23,058] {logging_mixin.py:112} INFO - [2022-02-18 22:57:23,057] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:57:23,682] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:57:23,727] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:57:23,735] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:57:23,738] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.689 seconds
[2022-02-18 22:57:36,388] {scheduler_job.py:155} INFO - Started process (PID=27990) to work on /airflow/dags/download_data.py
[2022-02-18 22:57:36,395] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:57:36,397] {logging_mixin.py:112} INFO - [2022-02-18 22:57:36,397] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:57:36,849] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:57:36,901] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:57:36,911] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:57:36,918] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 22:57:49,624] {scheduler_job.py:155} INFO - Started process (PID=28016) to work on /airflow/dags/download_data.py
[2022-02-18 22:57:49,630] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:57:49,633] {logging_mixin.py:112} INFO - [2022-02-18 22:57:49,632] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:57:50,117] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:57:50,171] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:57:50,178] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:57:50,186] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 22:58:02,903] {scheduler_job.py:155} INFO - Started process (PID=28042) to work on /airflow/dags/download_data.py
[2022-02-18 22:58:02,925] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:58:02,930] {logging_mixin.py:112} INFO - [2022-02-18 22:58:02,929] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:58:03,486] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:58:03,542] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:58:03,555] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:58:03,562] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.660 seconds
[2022-02-18 22:58:16,176] {scheduler_job.py:155} INFO - Started process (PID=28068) to work on /airflow/dags/download_data.py
[2022-02-18 22:58:16,187] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:58:16,190] {logging_mixin.py:112} INFO - [2022-02-18 22:58:16,189] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:58:16,675] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:58:16,718] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:58:16,725] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:58:16,731] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 22:58:29,462] {scheduler_job.py:155} INFO - Started process (PID=28094) to work on /airflow/dags/download_data.py
[2022-02-18 22:58:29,469] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:58:29,472] {logging_mixin.py:112} INFO - [2022-02-18 22:58:29,471] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:58:30,006] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:58:30,055] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:58:30,065] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:58:30,070] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 22:58:42,709] {scheduler_job.py:155} INFO - Started process (PID=28120) to work on /airflow/dags/download_data.py
[2022-02-18 22:58:42,714] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:58:42,719] {logging_mixin.py:112} INFO - [2022-02-18 22:58:42,718] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:58:43,228] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:58:43,288] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:58:43,300] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:58:43,310] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.602 seconds
[2022-02-18 22:58:56,029] {scheduler_job.py:155} INFO - Started process (PID=28146) to work on /airflow/dags/download_data.py
[2022-02-18 22:58:56,036] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:58:56,037] {logging_mixin.py:112} INFO - [2022-02-18 22:58:56,037] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:58:56,593] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:58:56,642] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:58:56,650] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:58:56,657] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.628 seconds
[2022-02-18 22:59:09,314] {scheduler_job.py:155} INFO - Started process (PID=28172) to work on /airflow/dags/download_data.py
[2022-02-18 22:59:09,319] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:59:09,322] {logging_mixin.py:112} INFO - [2022-02-18 22:59:09,321] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:59:09,909] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:59:09,976] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:59:09,986] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:59:09,991] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.678 seconds
[2022-02-18 22:59:22,579] {scheduler_job.py:155} INFO - Started process (PID=28198) to work on /airflow/dags/download_data.py
[2022-02-18 22:59:22,588] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:59:22,590] {logging_mixin.py:112} INFO - [2022-02-18 22:59:22,590] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:59:23,080] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:59:23,140] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:59:23,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:59:23,166] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.586 seconds
[2022-02-18 22:59:35,851] {scheduler_job.py:155} INFO - Started process (PID=28224) to work on /airflow/dags/download_data.py
[2022-02-18 22:59:35,858] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:59:35,867] {logging_mixin.py:112} INFO - [2022-02-18 22:59:35,866] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:59:36,356] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:59:36,412] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:59:36,422] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:59:36,427] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.576 seconds
[2022-02-18 22:59:49,195] {scheduler_job.py:155} INFO - Started process (PID=28250) to work on /airflow/dags/download_data.py
[2022-02-18 22:59:49,200] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 22:59:49,201] {logging_mixin.py:112} INFO - [2022-02-18 22:59:49,201] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 22:59:49,691] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 22:59:49,739] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 22:59:49,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 22:59:49,754] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 23:00:02,485] {scheduler_job.py:155} INFO - Started process (PID=28276) to work on /airflow/dags/download_data.py
[2022-02-18 23:00:02,489] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:00:02,491] {logging_mixin.py:112} INFO - [2022-02-18 23:00:02,491] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:00:02,953] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:00:02,999] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:00:03,006] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:00:03,012] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 23:00:15,752] {scheduler_job.py:155} INFO - Started process (PID=28302) to work on /airflow/dags/download_data.py
[2022-02-18 23:00:15,762] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:00:15,766] {logging_mixin.py:112} INFO - [2022-02-18 23:00:15,764] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:00:16,260] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:00:16,320] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:00:16,329] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:00:16,333] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.581 seconds
[2022-02-18 23:00:29,012] {scheduler_job.py:155} INFO - Started process (PID=28328) to work on /airflow/dags/download_data.py
[2022-02-18 23:00:29,017] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:00:29,018] {logging_mixin.py:112} INFO - [2022-02-18 23:00:29,018] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:00:29,490] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:00:29,548] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:00:29,555] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:00:29,559] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.547 seconds
[2022-02-18 23:00:42,307] {scheduler_job.py:155} INFO - Started process (PID=28354) to work on /airflow/dags/download_data.py
[2022-02-18 23:00:42,315] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:00:42,318] {logging_mixin.py:112} INFO - [2022-02-18 23:00:42,318] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:00:42,747] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:00:42,803] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:00:42,811] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:00:42,817] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 23:00:55,563] {scheduler_job.py:155} INFO - Started process (PID=28380) to work on /airflow/dags/download_data.py
[2022-02-18 23:00:55,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:00:55,583] {logging_mixin.py:112} INFO - [2022-02-18 23:00:55,583] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:00:56,078] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:00:56,139] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:00:56,147] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:00:56,153] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 23:01:08,828] {scheduler_job.py:155} INFO - Started process (PID=28406) to work on /airflow/dags/download_data.py
[2022-02-18 23:01:08,832] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:01:08,834] {logging_mixin.py:112} INFO - [2022-02-18 23:01:08,834] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:01:09,300] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:01:09,351] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:01:09,362] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:01:09,369] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 23:01:22,094] {scheduler_job.py:155} INFO - Started process (PID=28432) to work on /airflow/dags/download_data.py
[2022-02-18 23:01:22,103] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:01:22,106] {logging_mixin.py:112} INFO - [2022-02-18 23:01:22,105] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:01:22,600] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:01:22,665] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:01:22,678] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:01:22,683] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 23:01:35,378] {scheduler_job.py:155} INFO - Started process (PID=28458) to work on /airflow/dags/download_data.py
[2022-02-18 23:01:35,387] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:01:35,390] {logging_mixin.py:112} INFO - [2022-02-18 23:01:35,389] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:01:35,840] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:01:35,880] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:01:35,886] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:01:35,889] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.511 seconds
[2022-02-18 23:01:48,604] {scheduler_job.py:155} INFO - Started process (PID=28484) to work on /airflow/dags/download_data.py
[2022-02-18 23:01:48,610] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:01:48,612] {logging_mixin.py:112} INFO - [2022-02-18 23:01:48,612] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:01:49,066] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:01:49,107] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:01:49,118] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:01:49,125] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 23:02:01,894] {scheduler_job.py:155} INFO - Started process (PID=28510) to work on /airflow/dags/download_data.py
[2022-02-18 23:02:01,899] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:02:01,900] {logging_mixin.py:112} INFO - [2022-02-18 23:02:01,900] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:02:02,358] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:02:02,409] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:02:02,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:02:02,423] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 23:02:15,197] {scheduler_job.py:155} INFO - Started process (PID=28536) to work on /airflow/dags/download_data.py
[2022-02-18 23:02:15,204] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:02:15,205] {logging_mixin.py:112} INFO - [2022-02-18 23:02:15,205] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:02:15,699] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:02:15,748] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:02:15,756] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:02:15,760] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.563 seconds
[2022-02-18 23:02:28,476] {scheduler_job.py:155} INFO - Started process (PID=28562) to work on /airflow/dags/download_data.py
[2022-02-18 23:02:28,480] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:02:28,482] {logging_mixin.py:112} INFO - [2022-02-18 23:02:28,482] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:02:28,932] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:02:28,984] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:02:28,993] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:02:28,997] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 23:02:41,760] {scheduler_job.py:155} INFO - Started process (PID=28588) to work on /airflow/dags/download_data.py
[2022-02-18 23:02:41,765] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:02:41,766] {logging_mixin.py:112} INFO - [2022-02-18 23:02:41,766] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:02:42,219] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:02:42,271] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:02:42,283] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:02:42,288] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 23:02:55,025] {scheduler_job.py:155} INFO - Started process (PID=28614) to work on /airflow/dags/download_data.py
[2022-02-18 23:02:55,041] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:02:55,044] {logging_mixin.py:112} INFO - [2022-02-18 23:02:55,043] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:02:55,564] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:02:55,612] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:02:55,625] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:02:55,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.604 seconds
[2022-02-18 23:03:08,314] {scheduler_job.py:155} INFO - Started process (PID=28640) to work on /airflow/dags/download_data.py
[2022-02-18 23:03:08,329] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:03:08,332] {logging_mixin.py:112} INFO - [2022-02-18 23:03:08,332] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:03:08,825] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:03:08,876] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:03:08,920] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:03:08,928] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-18 23:03:21,575] {scheduler_job.py:155} INFO - Started process (PID=28666) to work on /airflow/dags/download_data.py
[2022-02-18 23:03:21,579] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:03:21,581] {logging_mixin.py:112} INFO - [2022-02-18 23:03:21,581] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:03:22,102] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:03:22,174] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:03:22,180] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:03:22,184] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.609 seconds
[2022-02-18 23:03:34,851] {scheduler_job.py:155} INFO - Started process (PID=28692) to work on /airflow/dags/download_data.py
[2022-02-18 23:03:34,855] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:03:34,857] {logging_mixin.py:112} INFO - [2022-02-18 23:03:34,856] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:03:35,351] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:03:35,407] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:03:35,413] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:03:35,417] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 23:03:48,127] {scheduler_job.py:155} INFO - Started process (PID=28718) to work on /airflow/dags/download_data.py
[2022-02-18 23:03:48,136] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:03:48,138] {logging_mixin.py:112} INFO - [2022-02-18 23:03:48,137] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:03:48,649] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:03:48,715] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:03:48,726] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:03:48,732] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 23:04:01,378] {scheduler_job.py:155} INFO - Started process (PID=28744) to work on /airflow/dags/download_data.py
[2022-02-18 23:04:01,387] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:04:01,391] {logging_mixin.py:112} INFO - [2022-02-18 23:04:01,391] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:04:01,904] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:04:01,970] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:04:01,981] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:04:01,986] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.608 seconds
[2022-02-18 23:04:14,636] {scheduler_job.py:155} INFO - Started process (PID=28770) to work on /airflow/dags/download_data.py
[2022-02-18 23:04:14,641] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:04:14,643] {logging_mixin.py:112} INFO - [2022-02-18 23:04:14,643] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:04:15,300] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:04:15,341] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:04:15,350] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:04:15,357] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.721 seconds
[2022-02-18 23:04:27,928] {scheduler_job.py:155} INFO - Started process (PID=28796) to work on /airflow/dags/download_data.py
[2022-02-18 23:04:27,932] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:04:27,935] {logging_mixin.py:112} INFO - [2022-02-18 23:04:27,935] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:04:28,437] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:04:28,494] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:04:28,506] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:04:28,511] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 23:04:41,228] {scheduler_job.py:155} INFO - Started process (PID=28822) to work on /airflow/dags/download_data.py
[2022-02-18 23:04:41,236] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:04:41,238] {logging_mixin.py:112} INFO - [2022-02-18 23:04:41,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:04:41,724] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:04:41,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:04:41,810] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:04:41,816] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.588 seconds
[2022-02-18 23:04:54,470] {scheduler_job.py:155} INFO - Started process (PID=28848) to work on /airflow/dags/download_data.py
[2022-02-18 23:04:54,485] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:04:54,487] {logging_mixin.py:112} INFO - [2022-02-18 23:04:54,487] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:04:55,084] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:04:55,173] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:04:55,183] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:04:55,187] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.717 seconds
[2022-02-18 23:05:07,723] {scheduler_job.py:155} INFO - Started process (PID=28874) to work on /airflow/dags/download_data.py
[2022-02-18 23:05:07,732] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:05:07,734] {logging_mixin.py:112} INFO - [2022-02-18 23:05:07,734] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:05:08,262] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:05:08,319] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:05:08,330] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:05:08,334] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 23:05:20,995] {scheduler_job.py:155} INFO - Started process (PID=28900) to work on /airflow/dags/download_data.py
[2022-02-18 23:05:21,007] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:05:21,010] {logging_mixin.py:112} INFO - [2022-02-18 23:05:21,010] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:05:21,785] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:05:21,902] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:05:21,908] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:05:21,913] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.918 seconds
[2022-02-18 23:05:34,256] {scheduler_job.py:155} INFO - Started process (PID=28926) to work on /airflow/dags/download_data.py
[2022-02-18 23:05:34,264] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:05:34,267] {logging_mixin.py:112} INFO - [2022-02-18 23:05:34,266] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:05:34,722] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:05:34,769] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:05:34,779] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:05:34,786] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 23:05:47,530] {scheduler_job.py:155} INFO - Started process (PID=28952) to work on /airflow/dags/download_data.py
[2022-02-18 23:05:47,535] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:05:47,536] {logging_mixin.py:112} INFO - [2022-02-18 23:05:47,536] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:05:48,025] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:05:48,073] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:05:48,084] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:05:48,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.561 seconds
[2022-02-18 23:06:00,818] {scheduler_job.py:155} INFO - Started process (PID=28978) to work on /airflow/dags/download_data.py
[2022-02-18 23:06:00,827] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:06:00,830] {logging_mixin.py:112} INFO - [2022-02-18 23:06:00,830] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:06:01,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:06:01,517] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:06:01,525] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:06:01,532] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.714 seconds
[2022-02-18 23:06:14,104] {scheduler_job.py:155} INFO - Started process (PID=29004) to work on /airflow/dags/download_data.py
[2022-02-18 23:06:14,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:06:14,115] {logging_mixin.py:112} INFO - [2022-02-18 23:06:14,114] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:06:14,634] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:06:14,685] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:06:14,694] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:06:14,699] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 23:06:27,407] {scheduler_job.py:155} INFO - Started process (PID=29030) to work on /airflow/dags/download_data.py
[2022-02-18 23:06:27,415] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:06:27,417] {logging_mixin.py:112} INFO - [2022-02-18 23:06:27,417] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:06:28,030] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:06:28,079] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:06:28,089] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:06:28,095] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.689 seconds
[2022-02-18 23:06:40,681] {scheduler_job.py:155} INFO - Started process (PID=29056) to work on /airflow/dags/download_data.py
[2022-02-18 23:06:40,696] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:06:40,699] {logging_mixin.py:112} INFO - [2022-02-18 23:06:40,699] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:06:41,236] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:06:41,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:06:41,308] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:06:41,312] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.631 seconds
[2022-02-18 23:06:53,949] {scheduler_job.py:155} INFO - Started process (PID=29082) to work on /airflow/dags/download_data.py
[2022-02-18 23:06:53,963] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:06:53,966] {logging_mixin.py:112} INFO - [2022-02-18 23:06:53,966] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:06:54,449] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:06:54,497] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:06:54,510] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:06:54,519] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.570 seconds
[2022-02-18 23:07:07,232] {scheduler_job.py:155} INFO - Started process (PID=29108) to work on /airflow/dags/download_data.py
[2022-02-18 23:07:07,237] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:07:07,241] {logging_mixin.py:112} INFO - [2022-02-18 23:07:07,241] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:07:07,789] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:07:07,845] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:07:07,859] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:07:07,865] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-18 23:07:20,541] {scheduler_job.py:155} INFO - Started process (PID=29134) to work on /airflow/dags/download_data.py
[2022-02-18 23:07:20,546] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:07:20,548] {logging_mixin.py:112} INFO - [2022-02-18 23:07:20,547] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:07:21,127] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:07:21,201] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:07:21,213] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:07:21,217] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.676 seconds
[2022-02-18 23:07:33,826] {scheduler_job.py:155} INFO - Started process (PID=29160) to work on /airflow/dags/download_data.py
[2022-02-18 23:07:33,832] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:07:33,833] {logging_mixin.py:112} INFO - [2022-02-18 23:07:33,833] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:07:34,374] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:07:34,425] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:07:34,436] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:07:34,443] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.617 seconds
[2022-02-18 23:07:47,121] {scheduler_job.py:155} INFO - Started process (PID=29186) to work on /airflow/dags/download_data.py
[2022-02-18 23:07:47,130] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:07:47,134] {logging_mixin.py:112} INFO - [2022-02-18 23:07:47,134] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:07:47,828] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:07:47,918] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:07:47,927] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:07:47,932] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.811 seconds
[2022-02-18 23:08:00,400] {scheduler_job.py:155} INFO - Started process (PID=29212) to work on /airflow/dags/download_data.py
[2022-02-18 23:08:00,406] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:08:00,407] {logging_mixin.py:112} INFO - [2022-02-18 23:08:00,407] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:08:00,914] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:08:00,972] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:08:00,985] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:08:00,999] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 23:08:13,648] {scheduler_job.py:155} INFO - Started process (PID=29238) to work on /airflow/dags/download_data.py
[2022-02-18 23:08:13,663] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:08:13,667] {logging_mixin.py:112} INFO - [2022-02-18 23:08:13,666] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:08:14,439] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:08:14,501] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:08:14,509] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:08:14,515] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.867 seconds
[2022-02-18 23:08:26,998] {scheduler_job.py:155} INFO - Started process (PID=29264) to work on /airflow/dags/download_data.py
[2022-02-18 23:08:27,009] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:08:27,011] {logging_mixin.py:112} INFO - [2022-02-18 23:08:27,011] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:08:27,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:08:27,564] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:08:27,576] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:08:27,582] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 23:08:40,267] {scheduler_job.py:155} INFO - Started process (PID=29290) to work on /airflow/dags/download_data.py
[2022-02-18 23:08:40,278] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:08:40,281] {logging_mixin.py:112} INFO - [2022-02-18 23:08:40,281] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:08:40,766] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:08:40,822] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:08:40,834] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:08:40,839] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 23:08:53,544] {scheduler_job.py:155} INFO - Started process (PID=29316) to work on /airflow/dags/download_data.py
[2022-02-18 23:08:53,549] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:08:53,550] {logging_mixin.py:112} INFO - [2022-02-18 23:08:53,550] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:08:54,064] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:08:54,121] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:08:54,133] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:08:54,139] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.595 seconds
[2022-02-18 23:09:06,823] {scheduler_job.py:155} INFO - Started process (PID=29342) to work on /airflow/dags/download_data.py
[2022-02-18 23:09:06,829] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:09:06,831] {logging_mixin.py:112} INFO - [2022-02-18 23:09:06,831] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:09:07,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:09:07,399] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:09:07,405] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:09:07,413] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 23:09:20,153] {scheduler_job.py:155} INFO - Started process (PID=29368) to work on /airflow/dags/download_data.py
[2022-02-18 23:09:20,159] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:09:20,162] {logging_mixin.py:112} INFO - [2022-02-18 23:09:20,162] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:09:20,713] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:09:20,778] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:09:20,789] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:09:20,796] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.643 seconds
[2022-02-18 23:09:33,431] {scheduler_job.py:155} INFO - Started process (PID=29394) to work on /airflow/dags/download_data.py
[2022-02-18 23:09:33,435] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:09:33,437] {logging_mixin.py:112} INFO - [2022-02-18 23:09:33,437] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:09:33,980] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:09:34,025] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:09:34,034] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:09:34,040] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 23:09:46,696] {scheduler_job.py:155} INFO - Started process (PID=29420) to work on /airflow/dags/download_data.py
[2022-02-18 23:09:46,706] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:09:46,709] {logging_mixin.py:112} INFO - [2022-02-18 23:09:46,708] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:09:47,190] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:09:47,236] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:09:47,245] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:09:47,251] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 23:09:59,977] {scheduler_job.py:155} INFO - Started process (PID=29446) to work on /airflow/dags/download_data.py
[2022-02-18 23:09:59,989] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:09:59,997] {logging_mixin.py:112} INFO - [2022-02-18 23:09:59,997] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:10:00,552] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:10:00,645] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:10:00,661] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:10:00,670] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.693 seconds
[2022-02-18 23:10:13,234] {scheduler_job.py:155} INFO - Started process (PID=29472) to work on /airflow/dags/download_data.py
[2022-02-18 23:10:13,245] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:10:13,248] {logging_mixin.py:112} INFO - [2022-02-18 23:10:13,248] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:10:13,790] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:10:13,864] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:10:13,878] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:10:13,886] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.652 seconds
[2022-02-18 23:10:26,532] {scheduler_job.py:155} INFO - Started process (PID=29498) to work on /airflow/dags/download_data.py
[2022-02-18 23:10:26,537] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:10:26,539] {logging_mixin.py:112} INFO - [2022-02-18 23:10:26,539] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:10:26,998] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:10:27,045] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:10:27,052] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:10:27,057] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 23:10:39,798] {scheduler_job.py:155} INFO - Started process (PID=29524) to work on /airflow/dags/download_data.py
[2022-02-18 23:10:39,802] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:10:39,805] {logging_mixin.py:112} INFO - [2022-02-18 23:10:39,804] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:10:40,276] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:10:40,326] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:10:40,334] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:10:40,339] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 23:10:53,143] {scheduler_job.py:155} INFO - Started process (PID=29550) to work on /airflow/dags/download_data.py
[2022-02-18 23:10:53,150] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:10:53,154] {logging_mixin.py:112} INFO - [2022-02-18 23:10:53,153] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:10:53,634] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:10:53,678] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:10:53,683] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:10:53,688] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 23:11:06,409] {scheduler_job.py:155} INFO - Started process (PID=29576) to work on /airflow/dags/download_data.py
[2022-02-18 23:11:06,415] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:11:06,417] {logging_mixin.py:112} INFO - [2022-02-18 23:11:06,416] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:11:06,895] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:11:06,937] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:11:06,945] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:11:06,948] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 23:11:19,651] {scheduler_job.py:155} INFO - Started process (PID=29602) to work on /airflow/dags/download_data.py
[2022-02-18 23:11:19,658] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:11:19,660] {logging_mixin.py:112} INFO - [2022-02-18 23:11:19,660] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:11:20,171] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:11:20,226] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:11:20,240] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:11:20,243] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 23:11:32,926] {scheduler_job.py:155} INFO - Started process (PID=29628) to work on /airflow/dags/download_data.py
[2022-02-18 23:11:32,930] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:11:32,931] {logging_mixin.py:112} INFO - [2022-02-18 23:11:32,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:11:33,400] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:11:33,453] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:11:33,462] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:11:33,467] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 23:11:46,164] {scheduler_job.py:155} INFO - Started process (PID=29654) to work on /airflow/dags/download_data.py
[2022-02-18 23:11:46,180] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:11:46,188] {logging_mixin.py:112} INFO - [2022-02-18 23:11:46,188] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:11:46,715] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:11:46,765] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:11:46,778] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:11:46,783] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.620 seconds
[2022-02-18 23:11:59,409] {scheduler_job.py:155} INFO - Started process (PID=29680) to work on /airflow/dags/download_data.py
[2022-02-18 23:11:59,415] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:11:59,416] {logging_mixin.py:112} INFO - [2022-02-18 23:11:59,416] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:11:59,880] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:11:59,947] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:11:59,958] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:11:59,962] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 23:12:12,651] {scheduler_job.py:155} INFO - Started process (PID=29706) to work on /airflow/dags/download_data.py
[2022-02-18 23:12:12,665] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:12:12,668] {logging_mixin.py:112} INFO - [2022-02-18 23:12:12,668] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:12:13,202] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:12:13,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:12:13,273] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:12:13,277] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.626 seconds
[2022-02-18 23:12:26,028] {scheduler_job.py:155} INFO - Started process (PID=29732) to work on /airflow/dags/download_data.py
[2022-02-18 23:12:26,040] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:12:26,043] {logging_mixin.py:112} INFO - [2022-02-18 23:12:26,042] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:12:26,532] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:12:26,574] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:12:26,585] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:12:26,591] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 23:12:39,289] {scheduler_job.py:155} INFO - Started process (PID=29758) to work on /airflow/dags/download_data.py
[2022-02-18 23:12:39,296] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:12:39,298] {logging_mixin.py:112} INFO - [2022-02-18 23:12:39,298] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:12:39,786] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:12:39,833] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:12:39,839] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:12:39,844] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 23:12:52,560] {scheduler_job.py:155} INFO - Started process (PID=29784) to work on /airflow/dags/download_data.py
[2022-02-18 23:12:52,570] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:12:52,573] {logging_mixin.py:112} INFO - [2022-02-18 23:12:52,573] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:12:53,081] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:12:53,139] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:12:53,152] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:12:53,165] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.605 seconds
[2022-02-18 23:13:05,829] {scheduler_job.py:155} INFO - Started process (PID=29810) to work on /airflow/dags/download_data.py
[2022-02-18 23:13:05,833] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:13:05,835] {logging_mixin.py:112} INFO - [2022-02-18 23:13:05,835] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:13:06,395] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:13:06,470] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:13:06,480] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:13:06,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.657 seconds
[2022-02-18 23:13:19,050] {scheduler_job.py:155} INFO - Started process (PID=29836) to work on /airflow/dags/download_data.py
[2022-02-18 23:13:19,061] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:13:19,069] {logging_mixin.py:112} INFO - [2022-02-18 23:13:19,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:13:19,540] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:13:19,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:13:19,616] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:13:19,627] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.578 seconds
[2022-02-18 23:13:32,372] {scheduler_job.py:155} INFO - Started process (PID=29862) to work on /airflow/dags/download_data.py
[2022-02-18 23:13:32,380] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:13:32,383] {logging_mixin.py:112} INFO - [2022-02-18 23:13:32,382] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:13:33,007] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:13:33,056] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:13:33,065] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:13:33,070] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.699 seconds
[2022-02-18 23:13:45,600] {scheduler_job.py:155} INFO - Started process (PID=29888) to work on /airflow/dags/download_data.py
[2022-02-18 23:13:45,605] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:13:45,609] {logging_mixin.py:112} INFO - [2022-02-18 23:13:45,609] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:13:46,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:13:46,183] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:13:46,195] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:13:46,203] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 23:13:58,921] {scheduler_job.py:155} INFO - Started process (PID=29914) to work on /airflow/dags/download_data.py
[2022-02-18 23:13:58,935] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:13:58,938] {logging_mixin.py:112} INFO - [2022-02-18 23:13:58,938] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:13:59,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:13:59,540] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:13:59,550] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:13:59,556] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.635 seconds
[2022-02-18 23:14:12,169] {scheduler_job.py:155} INFO - Started process (PID=29940) to work on /airflow/dags/download_data.py
[2022-02-18 23:14:12,174] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:14:12,176] {logging_mixin.py:112} INFO - [2022-02-18 23:14:12,175] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:14:12,693] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:14:12,742] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:14:12,752] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:14:12,758] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 23:14:25,448] {scheduler_job.py:155} INFO - Started process (PID=29966) to work on /airflow/dags/download_data.py
[2022-02-18 23:14:25,455] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:14:25,461] {logging_mixin.py:112} INFO - [2022-02-18 23:14:25,461] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:14:26,014] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:14:26,079] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:14:26,087] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:14:26,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.643 seconds
[2022-02-18 23:14:38,737] {scheduler_job.py:155} INFO - Started process (PID=29992) to work on /airflow/dags/download_data.py
[2022-02-18 23:14:38,743] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:14:38,745] {logging_mixin.py:112} INFO - [2022-02-18 23:14:38,745] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:14:39,224] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:14:39,273] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:14:39,283] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:14:39,290] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.553 seconds
[2022-02-18 23:14:51,991] {scheduler_job.py:155} INFO - Started process (PID=30018) to work on /airflow/dags/download_data.py
[2022-02-18 23:14:52,002] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:14:52,004] {logging_mixin.py:112} INFO - [2022-02-18 23:14:52,004] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:14:52,547] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:14:52,604] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:14:52,615] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:14:52,620] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-18 23:15:05,316] {scheduler_job.py:155} INFO - Started process (PID=30044) to work on /airflow/dags/download_data.py
[2022-02-18 23:15:05,323] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:15:05,327] {logging_mixin.py:112} INFO - [2022-02-18 23:15:05,326] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:15:05,823] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:15:05,882] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:15:05,900] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:15:05,907] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 23:15:18,549] {scheduler_job.py:155} INFO - Started process (PID=30070) to work on /airflow/dags/download_data.py
[2022-02-18 23:15:18,553] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:15:18,555] {logging_mixin.py:112} INFO - [2022-02-18 23:15:18,555] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:15:19,081] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:15:19,147] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:15:19,160] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:15:19,168] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.619 seconds
[2022-02-18 23:15:31,834] {scheduler_job.py:155} INFO - Started process (PID=30096) to work on /airflow/dags/download_data.py
[2022-02-18 23:15:31,841] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:15:31,843] {logging_mixin.py:112} INFO - [2022-02-18 23:15:31,843] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:15:32,357] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:15:32,408] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:15:32,416] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:15:32,423] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.589 seconds
[2022-02-18 23:15:45,065] {scheduler_job.py:155} INFO - Started process (PID=30122) to work on /airflow/dags/download_data.py
[2022-02-18 23:15:45,074] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:15:45,077] {logging_mixin.py:112} INFO - [2022-02-18 23:15:45,077] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:15:45,620] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:15:45,698] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:15:45,710] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:15:45,717] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.652 seconds
[2022-02-18 23:15:58,339] {scheduler_job.py:155} INFO - Started process (PID=30148) to work on /airflow/dags/download_data.py
[2022-02-18 23:15:58,344] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:15:58,345] {logging_mixin.py:112} INFO - [2022-02-18 23:15:58,345] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:15:58,855] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:15:58,910] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:15:58,917] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:15:58,922] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 23:16:11,616] {scheduler_job.py:155} INFO - Started process (PID=30174) to work on /airflow/dags/download_data.py
[2022-02-18 23:16:11,596] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:16:11,598] {logging_mixin.py:112} INFO - [2022-02-18 23:16:11,598] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:16:12,160] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:16:12,214] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:16:12,228] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:16:12,238] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-18 23:16:24,863] {scheduler_job.py:155} INFO - Started process (PID=30200) to work on /airflow/dags/download_data.py
[2022-02-18 23:16:24,871] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:16:24,872] {logging_mixin.py:112} INFO - [2022-02-18 23:16:24,872] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:16:25,359] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:16:25,423] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:16:25,432] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:16:25,444] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 23:16:38,131] {scheduler_job.py:155} INFO - Started process (PID=30226) to work on /airflow/dags/download_data.py
[2022-02-18 23:16:38,138] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:16:38,140] {logging_mixin.py:112} INFO - [2022-02-18 23:16:38,140] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:16:38,599] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:16:38,648] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:16:38,656] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:16:38,661] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 23:16:51,391] {scheduler_job.py:155} INFO - Started process (PID=30252) to work on /airflow/dags/download_data.py
[2022-02-18 23:16:51,396] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:16:51,398] {logging_mixin.py:112} INFO - [2022-02-18 23:16:51,398] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:16:52,075] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:16:52,123] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:16:52,131] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:16:52,136] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.745 seconds
[2022-02-18 23:17:04,678] {scheduler_job.py:155} INFO - Started process (PID=30278) to work on /airflow/dags/download_data.py
[2022-02-18 23:17:04,687] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:17:04,691] {logging_mixin.py:112} INFO - [2022-02-18 23:17:04,690] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:17:05,221] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:17:05,283] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:17:05,291] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:17:05,297] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.620 seconds
[2022-02-18 23:17:17,947] {scheduler_job.py:155} INFO - Started process (PID=30304) to work on /airflow/dags/download_data.py
[2022-02-18 23:17:17,958] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:17:17,960] {logging_mixin.py:112} INFO - [2022-02-18 23:17:17,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:17:18,450] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:17:18,506] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:17:18,514] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:17:18,520] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 23:17:31,251] {scheduler_job.py:155} INFO - Started process (PID=30330) to work on /airflow/dags/download_data.py
[2022-02-18 23:17:31,259] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:17:31,261] {logging_mixin.py:112} INFO - [2022-02-18 23:17:31,261] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:17:31,779] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:17:31,828] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:17:31,836] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:17:31,843] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 23:17:44,535] {scheduler_job.py:155} INFO - Started process (PID=30356) to work on /airflow/dags/download_data.py
[2022-02-18 23:17:44,542] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:17:44,545] {logging_mixin.py:112} INFO - [2022-02-18 23:17:44,545] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:17:45,059] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:17:45,118] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:17:45,127] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:17:45,134] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.601 seconds
[2022-02-18 23:17:57,813] {scheduler_job.py:155} INFO - Started process (PID=30382) to work on /airflow/dags/download_data.py
[2022-02-18 23:17:57,823] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:17:57,825] {logging_mixin.py:112} INFO - [2022-02-18 23:17:57,825] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:17:58,388] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:17:58,443] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:17:58,454] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:17:58,458] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-18 23:18:11,093] {scheduler_job.py:155} INFO - Started process (PID=30408) to work on /airflow/dags/download_data.py
[2022-02-18 23:18:11,103] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:18:11,106] {logging_mixin.py:112} INFO - [2022-02-18 23:18:11,105] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:18:11,580] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:18:11,633] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:18:11,639] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:18:11,648] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 23:18:24,412] {scheduler_job.py:155} INFO - Started process (PID=30434) to work on /airflow/dags/download_data.py
[2022-02-18 23:18:24,428] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:18:24,432] {logging_mixin.py:112} INFO - [2022-02-18 23:18:24,431] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:18:25,719] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:18:25,794] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:18:25,810] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:18:25,817] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 1.404 seconds
[2022-02-18 23:18:38,721] {scheduler_job.py:155} INFO - Started process (PID=30460) to work on /airflow/dags/download_data.py
[2022-02-18 23:18:38,728] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:18:38,731] {logging_mixin.py:112} INFO - [2022-02-18 23:18:38,731] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:18:39,250] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:18:39,299] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:18:39,305] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:18:39,312] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.591 seconds
[2022-02-18 23:18:50,961] {scheduler_job.py:155} INFO - Started process (PID=30485) to work on /airflow/dags/download_data.py
[2022-02-18 23:18:50,966] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:18:50,967] {logging_mixin.py:112} INFO - [2022-02-18 23:18:50,967] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:18:51,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:18:51,569] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:18:51,581] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:18:51,587] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.627 seconds
[2022-02-18 23:19:04,253] {scheduler_job.py:155} INFO - Started process (PID=30511) to work on /airflow/dags/download_data.py
[2022-02-18 23:19:04,262] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:19:04,264] {logging_mixin.py:112} INFO - [2022-02-18 23:19:04,264] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:19:04,720] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:19:04,762] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:19:04,775] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:19:04,780] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 23:19:17,487] {scheduler_job.py:155} INFO - Started process (PID=30537) to work on /airflow/dags/download_data.py
[2022-02-18 23:19:17,492] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:19:17,495] {logging_mixin.py:112} INFO - [2022-02-18 23:19:17,494] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:19:17,998] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:19:18,062] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:19:18,071] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:19:18,079] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 23:19:30,774] {scheduler_job.py:155} INFO - Started process (PID=30563) to work on /airflow/dags/download_data.py
[2022-02-18 23:19:30,779] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:19:30,782] {logging_mixin.py:112} INFO - [2022-02-18 23:19:30,781] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:19:31,283] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:19:31,333] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:19:31,342] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:19:31,346] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 23:19:44,034] {scheduler_job.py:155} INFO - Started process (PID=30589) to work on /airflow/dags/download_data.py
[2022-02-18 23:19:44,046] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:19:44,055] {logging_mixin.py:112} INFO - [2022-02-18 23:19:44,055] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:19:44,580] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:19:44,622] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:19:44,632] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:19:44,636] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.603 seconds
[2022-02-18 23:19:57,312] {scheduler_job.py:155} INFO - Started process (PID=30615) to work on /airflow/dags/download_data.py
[2022-02-18 23:19:57,317] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:19:57,319] {logging_mixin.py:112} INFO - [2022-02-18 23:19:57,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:19:57,821] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:19:57,868] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:19:57,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:19:57,879] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.567 seconds
[2022-02-18 23:20:10,590] {scheduler_job.py:155} INFO - Started process (PID=30641) to work on /airflow/dags/download_data.py
[2022-02-18 23:20:10,599] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:20:10,601] {logging_mixin.py:112} INFO - [2022-02-18 23:20:10,601] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:20:11,099] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:20:11,143] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:20:11,154] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:20:11,159] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-18 23:20:23,865] {scheduler_job.py:155} INFO - Started process (PID=30667) to work on /airflow/dags/download_data.py
[2022-02-18 23:20:23,876] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:20:23,877] {logging_mixin.py:112} INFO - [2022-02-18 23:20:23,877] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:20:24,340] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:20:24,390] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:20:24,398] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:20:24,404] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 23:20:37,183] {scheduler_job.py:155} INFO - Started process (PID=30693) to work on /airflow/dags/download_data.py
[2022-02-18 23:20:37,189] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:20:37,191] {logging_mixin.py:112} INFO - [2022-02-18 23:20:37,191] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:20:37,692] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:20:37,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:20:37,771] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:20:37,778] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 23:20:50,403] {scheduler_job.py:155} INFO - Started process (PID=30719) to work on /airflow/dags/download_data.py
[2022-02-18 23:20:50,410] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:20:50,412] {logging_mixin.py:112} INFO - [2022-02-18 23:20:50,412] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:20:50,929] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:20:50,995] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:20:51,005] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:20:51,014] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 23:21:03,692] {scheduler_job.py:155} INFO - Started process (PID=30745) to work on /airflow/dags/download_data.py
[2022-02-18 23:21:03,697] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:21:03,699] {logging_mixin.py:112} INFO - [2022-02-18 23:21:03,699] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:21:04,203] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:21:04,250] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:21:04,258] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:21:04,264] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.572 seconds
[2022-02-18 23:21:16,953] {scheduler_job.py:155} INFO - Started process (PID=30771) to work on /airflow/dags/download_data.py
[2022-02-18 23:21:16,963] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:21:16,966] {logging_mixin.py:112} INFO - [2022-02-18 23:21:16,966] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:21:17,490] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:21:17,553] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:21:17,562] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:21:17,568] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.616 seconds
[2022-02-18 23:21:30,212] {scheduler_job.py:155} INFO - Started process (PID=30797) to work on /airflow/dags/download_data.py
[2022-02-18 23:21:30,216] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:21:30,218] {logging_mixin.py:112} INFO - [2022-02-18 23:21:30,217] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:21:30,707] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:21:30,755] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:21:30,766] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:21:30,777] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 23:21:43,473] {scheduler_job.py:155} INFO - Started process (PID=30823) to work on /airflow/dags/download_data.py
[2022-02-18 23:21:43,477] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:21:43,479] {logging_mixin.py:112} INFO - [2022-02-18 23:21:43,479] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:21:43,984] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:21:44,043] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:21:44,070] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:21:44,083] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 23:21:56,766] {scheduler_job.py:155} INFO - Started process (PID=30849) to work on /airflow/dags/download_data.py
[2022-02-18 23:21:56,771] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:21:56,772] {logging_mixin.py:112} INFO - [2022-02-18 23:21:56,772] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:21:57,275] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:21:57,344] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:21:57,351] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:21:57,356] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.590 seconds
[2022-02-18 23:22:10,086] {scheduler_job.py:155} INFO - Started process (PID=30875) to work on /airflow/dags/download_data.py
[2022-02-18 23:22:10,093] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:22:10,104] {logging_mixin.py:112} INFO - [2022-02-18 23:22:10,103] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:22:10,741] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:22:10,797] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:22:10,809] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:22:10,814] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.728 seconds
[2022-02-18 23:22:23,361] {scheduler_job.py:155} INFO - Started process (PID=30901) to work on /airflow/dags/download_data.py
[2022-02-18 23:22:23,366] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:22:23,368] {logging_mixin.py:112} INFO - [2022-02-18 23:22:23,368] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:22:24,001] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:22:24,045] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:22:24,053] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:22:24,057] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.696 seconds
[2022-02-18 23:22:36,662] {scheduler_job.py:155} INFO - Started process (PID=30927) to work on /airflow/dags/download_data.py
[2022-02-18 23:22:36,666] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:22:36,668] {logging_mixin.py:112} INFO - [2022-02-18 23:22:36,667] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:22:37,151] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:22:37,210] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:22:37,222] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:22:37,227] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 23:22:49,990] {scheduler_job.py:155} INFO - Started process (PID=30953) to work on /airflow/dags/download_data.py
[2022-02-18 23:22:49,998] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:22:50,000] {logging_mixin.py:112} INFO - [2022-02-18 23:22:50,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:22:50,455] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:22:50,511] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:22:50,524] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:22:50,530] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.541 seconds
[2022-02-18 23:23:03,273] {scheduler_job.py:155} INFO - Started process (PID=30979) to work on /airflow/dags/download_data.py
[2022-02-18 23:23:03,276] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:23:03,278] {logging_mixin.py:112} INFO - [2022-02-18 23:23:03,278] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:23:03,727] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:23:03,773] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:23:03,784] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:23:03,789] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 23:23:16,509] {scheduler_job.py:155} INFO - Started process (PID=31005) to work on /airflow/dags/download_data.py
[2022-02-18 23:23:16,513] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:23:16,515] {logging_mixin.py:112} INFO - [2022-02-18 23:23:16,515] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:23:16,977] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:23:17,034] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:23:17,041] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:23:17,047] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 23:23:29,807] {scheduler_job.py:155} INFO - Started process (PID=31031) to work on /airflow/dags/download_data.py
[2022-02-18 23:23:29,818] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:23:29,822] {logging_mixin.py:112} INFO - [2022-02-18 23:23:29,822] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:23:30,477] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:23:30,531] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:23:30,543] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:23:30,548] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.740 seconds
[2022-02-18 23:23:43,060] {scheduler_job.py:155} INFO - Started process (PID=31057) to work on /airflow/dags/download_data.py
[2022-02-18 23:23:43,064] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:23:43,070] {logging_mixin.py:112} INFO - [2022-02-18 23:23:43,069] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:23:43,523] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:23:43,574] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:23:43,581] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:23:43,587] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 23:23:56,333] {scheduler_job.py:155} INFO - Started process (PID=31083) to work on /airflow/dags/download_data.py
[2022-02-18 23:23:56,338] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:23:56,340] {logging_mixin.py:112} INFO - [2022-02-18 23:23:56,340] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:23:56,794] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:23:56,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:23:56,854] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:23:56,860] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.527 seconds
[2022-02-18 23:24:09,647] {scheduler_job.py:155} INFO - Started process (PID=31109) to work on /airflow/dags/download_data.py
[2022-02-18 23:24:09,653] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:24:09,655] {logging_mixin.py:112} INFO - [2022-02-18 23:24:09,654] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:24:10,110] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:24:10,164] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:24:10,173] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:24:10,178] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.531 seconds
[2022-02-18 23:24:22,877] {scheduler_job.py:155} INFO - Started process (PID=31135) to work on /airflow/dags/download_data.py
[2022-02-18 23:24:22,882] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:24:22,884] {logging_mixin.py:112} INFO - [2022-02-18 23:24:22,884] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:24:23,375] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:24:23,438] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:24:23,445] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:24:23,456] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.579 seconds
[2022-02-18 23:24:36,175] {scheduler_job.py:155} INFO - Started process (PID=31161) to work on /airflow/dags/download_data.py
[2022-02-18 23:24:36,180] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:24:36,182] {logging_mixin.py:112} INFO - [2022-02-18 23:24:36,182] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:24:36,630] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:24:36,682] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:24:36,693] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:24:36,699] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 23:24:49,437] {scheduler_job.py:155} INFO - Started process (PID=31187) to work on /airflow/dags/download_data.py
[2022-02-18 23:24:49,442] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:24:49,444] {logging_mixin.py:112} INFO - [2022-02-18 23:24:49,444] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:24:49,998] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:24:50,057] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:24:50,063] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:24:50,068] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.631 seconds
[2022-02-18 23:25:02,780] {scheduler_job.py:155} INFO - Started process (PID=31213) to work on /airflow/dags/download_data.py
[2022-02-18 23:25:02,785] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:25:02,787] {logging_mixin.py:112} INFO - [2022-02-18 23:25:02,787] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:25:03,341] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:25:03,410] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:25:03,418] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:25:03,422] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.642 seconds
[2022-02-18 23:25:16,044] {scheduler_job.py:155} INFO - Started process (PID=31239) to work on /airflow/dags/download_data.py
[2022-02-18 23:25:16,055] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:25:16,059] {logging_mixin.py:112} INFO - [2022-02-18 23:25:16,058] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:25:16,645] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:25:16,714] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:25:16,727] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:25:16,738] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.694 seconds
[2022-02-18 23:25:29,367] {scheduler_job.py:155} INFO - Started process (PID=31265) to work on /airflow/dags/download_data.py
[2022-02-18 23:25:29,375] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:25:29,377] {logging_mixin.py:112} INFO - [2022-02-18 23:25:29,377] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:25:29,833] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:25:29,893] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:25:29,903] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:25:29,910] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.543 seconds
[2022-02-18 23:25:42,622] {scheduler_job.py:155} INFO - Started process (PID=31291) to work on /airflow/dags/download_data.py
[2022-02-18 23:25:42,632] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:25:42,635] {logging_mixin.py:112} INFO - [2022-02-18 23:25:42,635] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:25:43,080] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:25:43,131] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:25:43,142] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:25:43,146] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 23:25:55,901] {scheduler_job.py:155} INFO - Started process (PID=31317) to work on /airflow/dags/download_data.py
[2022-02-18 23:25:55,906] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:25:55,909] {logging_mixin.py:112} INFO - [2022-02-18 23:25:55,908] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:25:56,380] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:25:56,421] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:25:56,428] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:25:56,431] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 23:26:09,231] {scheduler_job.py:155} INFO - Started process (PID=31343) to work on /airflow/dags/download_data.py
[2022-02-18 23:26:09,241] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:26:09,243] {logging_mixin.py:112} INFO - [2022-02-18 23:26:09,243] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:26:09,813] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:26:09,891] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:26:09,906] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:26:09,919] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.688 seconds
[2022-02-18 23:26:22,590] {scheduler_job.py:155} INFO - Started process (PID=31369) to work on /airflow/dags/download_data.py
[2022-02-18 23:26:22,600] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:26:22,603] {logging_mixin.py:112} INFO - [2022-02-18 23:26:22,602] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:26:23,080] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:26:23,143] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:26:23,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:26:23,162] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 23:26:35,847] {scheduler_job.py:155} INFO - Started process (PID=31395) to work on /airflow/dags/download_data.py
[2022-02-18 23:26:35,851] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:26:35,853] {logging_mixin.py:112} INFO - [2022-02-18 23:26:35,853] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:26:36,316] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:26:36,370] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:26:36,380] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:26:36,386] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 23:26:49,116] {scheduler_job.py:155} INFO - Started process (PID=31421) to work on /airflow/dags/download_data.py
[2022-02-18 23:26:49,122] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:26:49,124] {logging_mixin.py:112} INFO - [2022-02-18 23:26:49,124] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:26:49,608] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:26:49,660] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:26:49,678] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:26:49,691] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.575 seconds
[2022-02-18 23:27:02,408] {scheduler_job.py:155} INFO - Started process (PID=31447) to work on /airflow/dags/download_data.py
[2022-02-18 23:27:02,414] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:27:02,415] {logging_mixin.py:112} INFO - [2022-02-18 23:27:02,415] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:27:03,082] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:27:03,143] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:27:03,158] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:27:03,171] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.763 seconds
[2022-02-18 23:27:15,713] {scheduler_job.py:155} INFO - Started process (PID=31473) to work on /airflow/dags/download_data.py
[2022-02-18 23:27:15,720] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:27:15,722] {logging_mixin.py:112} INFO - [2022-02-18 23:27:15,722] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:27:16,235] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:27:16,310] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:27:16,318] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:27:16,324] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.611 seconds
[2022-02-18 23:27:29,008] {scheduler_job.py:155} INFO - Started process (PID=31499) to work on /airflow/dags/download_data.py
[2022-02-18 23:27:29,018] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:27:29,020] {logging_mixin.py:112} INFO - [2022-02-18 23:27:29,020] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:27:29,867] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:27:29,935] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:27:29,946] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:27:29,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.943 seconds
[2022-02-18 23:27:42,256] {scheduler_job.py:155} INFO - Started process (PID=31525) to work on /airflow/dags/download_data.py
[2022-02-18 23:27:42,260] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:27:42,261] {logging_mixin.py:112} INFO - [2022-02-18 23:27:42,261] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:27:42,728] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:27:42,779] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:27:42,787] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:27:42,791] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.535 seconds
[2022-02-18 23:27:55,571] {scheduler_job.py:155} INFO - Started process (PID=31551) to work on /airflow/dags/download_data.py
[2022-02-18 23:27:55,578] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:27:55,581] {logging_mixin.py:112} INFO - [2022-02-18 23:27:55,580] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:27:56,144] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:27:56,200] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:27:56,211] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:27:56,216] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.645 seconds
[2022-02-18 23:28:08,823] {scheduler_job.py:155} INFO - Started process (PID=31577) to work on /airflow/dags/download_data.py
[2022-02-18 23:28:08,828] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:28:08,829] {logging_mixin.py:112} INFO - [2022-02-18 23:28:08,829] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:28:09,298] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:28:09,354] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:28:09,365] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:28:09,372] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 23:28:22,082] {scheduler_job.py:155} INFO - Started process (PID=31603) to work on /airflow/dags/download_data.py
[2022-02-18 23:28:22,092] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:28:22,094] {logging_mixin.py:112} INFO - [2022-02-18 23:28:22,094] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:28:22,682] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:28:22,738] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:28:22,748] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:28:22,753] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.671 seconds
[2022-02-18 23:28:35,380] {scheduler_job.py:155} INFO - Started process (PID=31629) to work on /airflow/dags/download_data.py
[2022-02-18 23:28:35,390] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:28:35,395] {logging_mixin.py:112} INFO - [2022-02-18 23:28:35,394] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:28:35,866] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:28:35,918] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:28:35,924] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:28:35,928] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 23:28:48,638] {scheduler_job.py:155} INFO - Started process (PID=31655) to work on /airflow/dags/download_data.py
[2022-02-18 23:28:48,644] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:28:48,647] {logging_mixin.py:112} INFO - [2022-02-18 23:28:48,647] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:28:49,123] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:28:49,166] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:28:49,174] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:28:49,180] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 23:29:01,910] {scheduler_job.py:155} INFO - Started process (PID=31681) to work on /airflow/dags/download_data.py
[2022-02-18 23:29:01,921] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:29:01,923] {logging_mixin.py:112} INFO - [2022-02-18 23:29:01,922] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:29:02,535] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:29:02,573] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:29:02,584] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:29:02,589] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.679 seconds
[2022-02-18 23:29:15,212] {scheduler_job.py:155} INFO - Started process (PID=31707) to work on /airflow/dags/download_data.py
[2022-02-18 23:29:15,218] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:29:15,220] {logging_mixin.py:112} INFO - [2022-02-18 23:29:15,220] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:29:15,762] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:29:15,819] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:29:15,829] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:29:15,834] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.622 seconds
[2022-02-18 23:29:28,548] {scheduler_job.py:155} INFO - Started process (PID=31733) to work on /airflow/dags/download_data.py
[2022-02-18 23:29:28,554] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:29:28,556] {logging_mixin.py:112} INFO - [2022-02-18 23:29:28,556] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:29:29,051] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:29:29,111] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:29:29,125] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:29:29,132] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 23:29:41,884] {scheduler_job.py:155} INFO - Started process (PID=31759) to work on /airflow/dags/download_data.py
[2022-02-18 23:29:41,889] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:29:41,891] {logging_mixin.py:112} INFO - [2022-02-18 23:29:41,891] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:29:42,413] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:29:42,466] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:29:42,479] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:29:42,482] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.599 seconds
[2022-02-18 23:29:55,172] {scheduler_job.py:155} INFO - Started process (PID=31785) to work on /airflow/dags/download_data.py
[2022-02-18 23:29:55,178] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:29:55,186] {logging_mixin.py:112} INFO - [2022-02-18 23:29:55,186] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:29:55,726] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:29:55,778] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:29:55,792] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:29:55,800] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.629 seconds
[2022-02-18 23:30:08,449] {scheduler_job.py:155} INFO - Started process (PID=31811) to work on /airflow/dags/download_data.py
[2022-02-18 23:30:08,454] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:30:08,456] {logging_mixin.py:112} INFO - [2022-02-18 23:30:08,456] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:30:08,915] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:30:08,959] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:30:08,967] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:30:08,971] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 23:30:21,698] {scheduler_job.py:155} INFO - Started process (PID=31837) to work on /airflow/dags/download_data.py
[2022-02-18 23:30:21,705] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:30:21,706] {logging_mixin.py:112} INFO - [2022-02-18 23:30:21,706] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:30:22,177] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:30:22,236] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:30:22,244] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:30:22,250] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 23:30:34,992] {scheduler_job.py:155} INFO - Started process (PID=31863) to work on /airflow/dags/download_data.py
[2022-02-18 23:30:34,998] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:30:35,000] {logging_mixin.py:112} INFO - [2022-02-18 23:30:35,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:30:35,438] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:30:35,484] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:30:35,494] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:30:35,501] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 23:30:48,279] {scheduler_job.py:155} INFO - Started process (PID=31889) to work on /airflow/dags/download_data.py
[2022-02-18 23:30:48,289] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:30:48,291] {logging_mixin.py:112} INFO - [2022-02-18 23:30:48,291] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:30:48,748] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:30:48,801] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:30:48,809] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:30:48,814] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 23:31:01,556] {scheduler_job.py:155} INFO - Started process (PID=31915) to work on /airflow/dags/download_data.py
[2022-02-18 23:31:01,564] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:31:01,567] {logging_mixin.py:112} INFO - [2022-02-18 23:31:01,567] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:31:02,041] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:31:02,080] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:31:02,091] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:31:02,096] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 23:31:14,824] {scheduler_job.py:155} INFO - Started process (PID=31941) to work on /airflow/dags/download_data.py
[2022-02-18 23:31:14,829] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:31:14,831] {logging_mixin.py:112} INFO - [2022-02-18 23:31:14,831] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:31:15,311] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:31:15,367] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:31:15,376] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:31:15,384] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 23:31:28,108] {scheduler_job.py:155} INFO - Started process (PID=31967) to work on /airflow/dags/download_data.py
[2022-02-18 23:31:28,113] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:31:28,115] {logging_mixin.py:112} INFO - [2022-02-18 23:31:28,114] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:31:28,573] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:31:28,619] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:31:28,625] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:31:28,629] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 23:31:41,363] {scheduler_job.py:155} INFO - Started process (PID=31993) to work on /airflow/dags/download_data.py
[2022-02-18 23:31:41,369] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:31:41,372] {logging_mixin.py:112} INFO - [2022-02-18 23:31:41,371] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:31:41,811] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:31:41,863] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:31:41,871] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:31:41,877] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.514 seconds
[2022-02-18 23:31:54,644] {scheduler_job.py:155} INFO - Started process (PID=32019) to work on /airflow/dags/download_data.py
[2022-02-18 23:31:54,650] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:31:54,652] {logging_mixin.py:112} INFO - [2022-02-18 23:31:54,652] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:31:55,097] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:31:55,148] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:31:55,155] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:31:55,160] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 23:32:07,898] {scheduler_job.py:155} INFO - Started process (PID=32045) to work on /airflow/dags/download_data.py
[2022-02-18 23:32:07,909] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:32:07,912] {logging_mixin.py:112} INFO - [2022-02-18 23:32:07,911] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:32:08,381] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:32:08,432] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:32:08,438] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:32:08,444] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 23:32:21,158] {scheduler_job.py:155} INFO - Started process (PID=32071) to work on /airflow/dags/download_data.py
[2022-02-18 23:32:21,163] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:32:21,166] {logging_mixin.py:112} INFO - [2022-02-18 23:32:21,165] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:32:21,637] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:32:21,681] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:32:21,690] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:32:21,698] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.540 seconds
[2022-02-18 23:32:34,447] {scheduler_job.py:155} INFO - Started process (PID=32097) to work on /airflow/dags/download_data.py
[2022-02-18 23:32:34,451] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:32:34,453] {logging_mixin.py:112} INFO - [2022-02-18 23:32:34,453] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:32:34,904] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:32:34,966] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:32:34,976] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:32:34,980] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 23:32:47,708] {scheduler_job.py:155} INFO - Started process (PID=32123) to work on /airflow/dags/download_data.py
[2022-02-18 23:32:47,718] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:32:47,720] {logging_mixin.py:112} INFO - [2022-02-18 23:32:47,720] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:32:48,209] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:32:48,243] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:32:48,249] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:32:48,253] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 23:33:00,990] {scheduler_job.py:155} INFO - Started process (PID=32149) to work on /airflow/dags/download_data.py
[2022-02-18 23:33:01,001] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:33:01,012] {logging_mixin.py:112} INFO - [2022-02-18 23:33:01,004] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:33:01,494] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:33:01,548] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:33:01,558] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:33:01,562] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.573 seconds
[2022-02-18 23:33:14,204] {scheduler_job.py:155} INFO - Started process (PID=32175) to work on /airflow/dags/download_data.py
[2022-02-18 23:33:14,211] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:33:14,212] {logging_mixin.py:112} INFO - [2022-02-18 23:33:14,212] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:33:14,685] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:33:14,750] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:33:14,767] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:33:14,773] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-18 23:33:27,500] {scheduler_job.py:155} INFO - Started process (PID=32201) to work on /airflow/dags/download_data.py
[2022-02-18 23:33:27,505] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:33:27,509] {logging_mixin.py:112} INFO - [2022-02-18 23:33:27,508] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:33:27,969] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:33:28,016] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:33:28,022] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:33:28,027] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 23:33:40,718] {scheduler_job.py:155} INFO - Started process (PID=32227) to work on /airflow/dags/download_data.py
[2022-02-18 23:33:40,724] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:33:40,727] {logging_mixin.py:112} INFO - [2022-02-18 23:33:40,727] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:33:41,198] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:33:41,247] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:33:41,257] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:33:41,263] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.545 seconds
[2022-02-18 23:33:54,016] {scheduler_job.py:155} INFO - Started process (PID=32253) to work on /airflow/dags/download_data.py
[2022-02-18 23:33:54,025] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:33:54,027] {logging_mixin.py:112} INFO - [2022-02-18 23:33:54,027] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:33:54,472] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:33:54,522] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:33:54,529] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:33:54,535] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 23:34:07,256] {scheduler_job.py:155} INFO - Started process (PID=32279) to work on /airflow/dags/download_data.py
[2022-02-18 23:34:07,262] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:34:07,264] {logging_mixin.py:112} INFO - [2022-02-18 23:34:07,263] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:34:07,710] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:34:07,752] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:34:07,758] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:34:07,762] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 23:34:20,539] {scheduler_job.py:155} INFO - Started process (PID=32305) to work on /airflow/dags/download_data.py
[2022-02-18 23:34:20,553] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:34:20,557] {logging_mixin.py:112} INFO - [2022-02-18 23:34:20,557] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:34:21,032] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:34:21,075] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:34:21,087] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:34:21,091] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.552 seconds
[2022-02-18 23:34:33,821] {scheduler_job.py:155} INFO - Started process (PID=32331) to work on /airflow/dags/download_data.py
[2022-02-18 23:34:33,825] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:34:33,828] {logging_mixin.py:112} INFO - [2022-02-18 23:34:33,828] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:34:34,291] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:34:34,332] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:34:34,338] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:34:34,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 23:34:47,069] {scheduler_job.py:155} INFO - Started process (PID=32357) to work on /airflow/dags/download_data.py
[2022-02-18 23:34:47,075] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:34:47,077] {logging_mixin.py:112} INFO - [2022-02-18 23:34:47,077] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:34:47,551] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:34:47,614] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:34:47,626] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:34:47,633] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 23:35:00,335] {scheduler_job.py:155} INFO - Started process (PID=32383) to work on /airflow/dags/download_data.py
[2022-02-18 23:35:00,340] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:35:00,342] {logging_mixin.py:112} INFO - [2022-02-18 23:35:00,342] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:35:00,794] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:35:00,848] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:35:00,859] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:35:00,863] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 23:35:13,572] {scheduler_job.py:155} INFO - Started process (PID=32409) to work on /airflow/dags/download_data.py
[2022-02-18 23:35:13,585] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:35:13,587] {logging_mixin.py:112} INFO - [2022-02-18 23:35:13,587] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:35:14,098] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:35:14,146] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:35:14,156] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:35:14,163] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.592 seconds
[2022-02-18 23:35:26,883] {scheduler_job.py:155} INFO - Started process (PID=32435) to work on /airflow/dags/download_data.py
[2022-02-18 23:35:26,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:35:26,889] {logging_mixin.py:112} INFO - [2022-02-18 23:35:26,889] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:35:27,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:35:27,392] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:35:27,400] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:35:27,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 23:35:40,179] {scheduler_job.py:155} INFO - Started process (PID=32461) to work on /airflow/dags/download_data.py
[2022-02-18 23:35:40,183] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:35:40,185] {logging_mixin.py:112} INFO - [2022-02-18 23:35:40,185] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:35:40,599] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:35:40,653] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:35:40,663] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:35:40,670] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.491 seconds
[2022-02-18 23:35:53,430] {scheduler_job.py:155} INFO - Started process (PID=32487) to work on /airflow/dags/download_data.py
[2022-02-18 23:35:53,437] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:35:53,440] {logging_mixin.py:112} INFO - [2022-02-18 23:35:53,440] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:35:53,888] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:35:53,938] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:35:53,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:35:53,955] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 23:36:06,707] {scheduler_job.py:155} INFO - Started process (PID=32513) to work on /airflow/dags/download_data.py
[2022-02-18 23:36:06,711] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:36:06,713] {logging_mixin.py:112} INFO - [2022-02-18 23:36:06,713] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:36:07,173] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:36:07,225] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:36:07,237] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:36:07,245] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 23:36:19,980] {scheduler_job.py:155} INFO - Started process (PID=32539) to work on /airflow/dags/download_data.py
[2022-02-18 23:36:19,987] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:36:19,989] {logging_mixin.py:112} INFO - [2022-02-18 23:36:19,988] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:36:20,469] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:36:20,517] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:36:20,527] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:36:20,534] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 23:36:33,235] {scheduler_job.py:155} INFO - Started process (PID=32565) to work on /airflow/dags/download_data.py
[2022-02-18 23:36:33,239] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:36:33,241] {logging_mixin.py:112} INFO - [2022-02-18 23:36:33,241] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:36:33,711] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:36:33,766] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:36:33,778] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:36:33,784] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.550 seconds
[2022-02-18 23:36:46,522] {scheduler_job.py:155} INFO - Started process (PID=32591) to work on /airflow/dags/download_data.py
[2022-02-18 23:36:46,532] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:36:46,534] {logging_mixin.py:112} INFO - [2022-02-18 23:36:46,534] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:36:47,023] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:36:47,065] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:36:47,074] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:36:47,079] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 23:36:59,810] {scheduler_job.py:155} INFO - Started process (PID=32617) to work on /airflow/dags/download_data.py
[2022-02-18 23:36:59,821] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:36:59,827] {logging_mixin.py:112} INFO - [2022-02-18 23:36:59,826] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:37:00,282] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:37:00,332] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:37:00,338] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:37:00,343] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 23:37:13,021] {scheduler_job.py:155} INFO - Started process (PID=32643) to work on /airflow/dags/download_data.py
[2022-02-18 23:37:13,026] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:37:13,028] {logging_mixin.py:112} INFO - [2022-02-18 23:37:13,028] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:37:13,542] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:37:13,590] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:37:13,599] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:37:13,604] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.583 seconds
[2022-02-18 23:37:26,650] {scheduler_job.py:155} INFO - Started process (PID=32669) to work on /airflow/dags/download_data.py
[2022-02-18 23:37:26,669] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:37:26,673] {logging_mixin.py:112} INFO - [2022-02-18 23:37:26,672] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:37:27,170] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:37:27,229] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:37:27,241] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:37:27,246] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.596 seconds
[2022-02-18 23:37:39,883] {scheduler_job.py:155} INFO - Started process (PID=32695) to work on /airflow/dags/download_data.py
[2022-02-18 23:37:39,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:37:39,889] {logging_mixin.py:112} INFO - [2022-02-18 23:37:39,889] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:37:40,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:37:40,365] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:37:40,376] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:37:40,384] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.502 seconds
[2022-02-18 23:37:53,125] {scheduler_job.py:155} INFO - Started process (PID=32721) to work on /airflow/dags/download_data.py
[2022-02-18 23:37:53,131] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:37:53,132] {logging_mixin.py:112} INFO - [2022-02-18 23:37:53,132] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:37:53,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:37:53,600] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:37:53,606] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:37:53,610] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.484 seconds
[2022-02-18 23:38:06,402] {scheduler_job.py:155} INFO - Started process (PID=32747) to work on /airflow/dags/download_data.py
[2022-02-18 23:38:06,408] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:38:06,410] {logging_mixin.py:112} INFO - [2022-02-18 23:38:06,410] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:38:06,872] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:38:06,921] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:38:06,932] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:38:06,938] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 23:38:19,645] {scheduler_job.py:155} INFO - Started process (PID=32773) to work on /airflow/dags/download_data.py
[2022-02-18 23:38:19,650] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:38:19,652] {logging_mixin.py:112} INFO - [2022-02-18 23:38:19,652] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:38:20,207] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:38:20,275] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:38:20,288] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:38:20,293] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.648 seconds
[2022-02-18 23:38:32,915] {scheduler_job.py:155} INFO - Started process (PID=32799) to work on /airflow/dags/download_data.py
[2022-02-18 23:38:32,919] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:38:32,921] {logging_mixin.py:112} INFO - [2022-02-18 23:38:32,920] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:38:33,379] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:38:33,431] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:38:33,438] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:38:33,444] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 23:38:46,155] {scheduler_job.py:155} INFO - Started process (PID=32825) to work on /airflow/dags/download_data.py
[2022-02-18 23:38:46,169] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:38:46,173] {logging_mixin.py:112} INFO - [2022-02-18 23:38:46,172] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:38:46,672] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:38:46,720] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:38:46,730] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:38:46,735] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.580 seconds
[2022-02-18 23:38:59,440] {scheduler_job.py:155} INFO - Started process (PID=32851) to work on /airflow/dags/download_data.py
[2022-02-18 23:38:59,445] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:38:59,447] {logging_mixin.py:112} INFO - [2022-02-18 23:38:59,446] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:38:59,930] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:38:59,978] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:38:59,990] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:38:59,997] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.557 seconds
[2022-02-18 23:39:12,718] {scheduler_job.py:155} INFO - Started process (PID=32877) to work on /airflow/dags/download_data.py
[2022-02-18 23:39:12,728] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:39:12,730] {logging_mixin.py:112} INFO - [2022-02-18 23:39:12,730] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:39:13,171] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:39:13,208] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:39:13,218] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:39:13,223] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.506 seconds
[2022-02-18 23:39:26,036] {scheduler_job.py:155} INFO - Started process (PID=32903) to work on /airflow/dags/download_data.py
[2022-02-18 23:39:26,042] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:39:26,044] {logging_mixin.py:112} INFO - [2022-02-18 23:39:26,044] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:39:26,506] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:39:26,543] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:39:26,549] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:39:26,552] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 23:39:39,329] {scheduler_job.py:155} INFO - Started process (PID=32929) to work on /airflow/dags/download_data.py
[2022-02-18 23:39:39,334] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:39:39,336] {logging_mixin.py:112} INFO - [2022-02-18 23:39:39,336] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:39:39,820] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:39:39,871] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:39:39,880] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:39:39,889] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.560 seconds
[2022-02-18 23:39:52,605] {scheduler_job.py:155} INFO - Started process (PID=32955) to work on /airflow/dags/download_data.py
[2022-02-18 23:39:52,613] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:39:52,616] {logging_mixin.py:112} INFO - [2022-02-18 23:39:52,615] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:39:53,056] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:39:53,100] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:39:53,106] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:39:53,110] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.505 seconds
[2022-02-18 23:40:05,891] {scheduler_job.py:155} INFO - Started process (PID=32981) to work on /airflow/dags/download_data.py
[2022-02-18 23:40:05,897] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:40:05,899] {logging_mixin.py:112} INFO - [2022-02-18 23:40:05,898] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:40:06,353] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:40:06,396] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:40:06,404] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:40:06,408] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.518 seconds
[2022-02-18 23:40:19,124] {scheduler_job.py:155} INFO - Started process (PID=33007) to work on /airflow/dags/download_data.py
[2022-02-18 23:40:19,129] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:40:19,131] {logging_mixin.py:112} INFO - [2022-02-18 23:40:19,131] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:40:19,596] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:40:19,661] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:40:19,671] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:40:19,678] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 23:40:32,427] {scheduler_job.py:155} INFO - Started process (PID=33033) to work on /airflow/dags/download_data.py
[2022-02-18 23:40:32,431] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:40:32,433] {logging_mixin.py:112} INFO - [2022-02-18 23:40:32,433] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:40:32,886] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:40:32,936] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:40:32,961] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:40:32,966] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 23:40:45,647] {scheduler_job.py:155} INFO - Started process (PID=33059) to work on /airflow/dags/download_data.py
[2022-02-18 23:40:45,661] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:40:45,663] {logging_mixin.py:112} INFO - [2022-02-18 23:40:45,662] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:40:46,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:40:46,198] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:40:46,206] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:40:46,214] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 23:40:58,979] {scheduler_job.py:155} INFO - Started process (PID=33085) to work on /airflow/dags/download_data.py
[2022-02-18 23:40:58,983] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:40:58,984] {logging_mixin.py:112} INFO - [2022-02-18 23:40:58,984] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:40:59,448] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:40:59,499] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:40:59,506] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:40:59,511] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 23:41:12,211] {scheduler_job.py:155} INFO - Started process (PID=33111) to work on /airflow/dags/download_data.py
[2022-02-18 23:41:12,219] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:41:12,221] {logging_mixin.py:112} INFO - [2022-02-18 23:41:12,221] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:41:12,664] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:41:12,709] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:41:12,716] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:41:12,722] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 23:41:25,518] {scheduler_job.py:155} INFO - Started process (PID=33137) to work on /airflow/dags/download_data.py
[2022-02-18 23:41:25,527] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:41:25,531] {logging_mixin.py:112} INFO - [2022-02-18 23:41:25,530] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:41:26,000] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:41:26,059] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:41:26,067] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:41:26,072] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 23:41:38,788] {scheduler_job.py:155} INFO - Started process (PID=33163) to work on /airflow/dags/download_data.py
[2022-02-18 23:41:38,796] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:41:38,799] {logging_mixin.py:112} INFO - [2022-02-18 23:41:38,798] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:41:39,243] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:41:39,295] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:41:39,305] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:41:39,314] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.525 seconds
[2022-02-18 23:41:52,052] {scheduler_job.py:155} INFO - Started process (PID=33189) to work on /airflow/dags/download_data.py
[2022-02-18 23:41:52,059] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:41:52,061] {logging_mixin.py:112} INFO - [2022-02-18 23:41:52,061] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:41:52,520] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:41:52,565] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:41:52,576] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:41:52,583] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 23:42:05,345] {scheduler_job.py:155} INFO - Started process (PID=33215) to work on /airflow/dags/download_data.py
[2022-02-18 23:42:05,354] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:42:05,357] {logging_mixin.py:112} INFO - [2022-02-18 23:42:05,357] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:42:05,815] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:42:05,867] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:42:05,875] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:42:05,882] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 23:42:18,649] {scheduler_job.py:155} INFO - Started process (PID=33241) to work on /airflow/dags/download_data.py
[2022-02-18 23:42:18,655] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:42:18,657] {logging_mixin.py:112} INFO - [2022-02-18 23:42:18,657] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:42:19,139] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:42:19,202] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:42:19,214] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:42:19,219] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.571 seconds
[2022-02-18 23:42:31,946] {scheduler_job.py:155} INFO - Started process (PID=33267) to work on /airflow/dags/download_data.py
[2022-02-18 23:42:31,950] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:42:31,951] {logging_mixin.py:112} INFO - [2022-02-18 23:42:31,951] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:42:32,397] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:42:32,449] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:42:32,460] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:42:32,465] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 23:42:45,194] {scheduler_job.py:155} INFO - Started process (PID=33293) to work on /airflow/dags/download_data.py
[2022-02-18 23:42:45,201] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:42:45,202] {logging_mixin.py:112} INFO - [2022-02-18 23:42:45,202] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:42:45,687] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:42:45,736] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:42:45,750] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:42:45,759] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.565 seconds
[2022-02-18 23:42:58,497] {scheduler_job.py:155} INFO - Started process (PID=33319) to work on /airflow/dags/download_data.py
[2022-02-18 23:42:58,505] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:42:58,507] {logging_mixin.py:112} INFO - [2022-02-18 23:42:58,507] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:42:58,948] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:42:58,988] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:42:58,996] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:42:59,001] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 23:43:11,743] {scheduler_job.py:155} INFO - Started process (PID=33345) to work on /airflow/dags/download_data.py
[2022-02-18 23:43:11,748] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:43:11,751] {logging_mixin.py:112} INFO - [2022-02-18 23:43:11,751] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:43:12,196] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:43:12,244] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:43:12,250] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:43:12,253] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 23:43:25,031] {scheduler_job.py:155} INFO - Started process (PID=33371) to work on /airflow/dags/download_data.py
[2022-02-18 23:43:25,045] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:43:25,048] {logging_mixin.py:112} INFO - [2022-02-18 23:43:25,048] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:43:25,695] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:43:25,769] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:43:25,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:43:25,799] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.768 seconds
[2022-02-18 23:43:38,390] {scheduler_job.py:155} INFO - Started process (PID=33397) to work on /airflow/dags/download_data.py
[2022-02-18 23:43:38,395] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:43:38,397] {logging_mixin.py:112} INFO - [2022-02-18 23:43:38,397] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:43:38,874] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:43:38,924] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:43:38,933] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:43:38,938] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.548 seconds
[2022-02-18 23:43:51,639] {scheduler_job.py:155} INFO - Started process (PID=33423) to work on /airflow/dags/download_data.py
[2022-02-18 23:43:51,647] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:43:51,651] {logging_mixin.py:112} INFO - [2022-02-18 23:43:51,650] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:43:52,193] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:43:52,270] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:43:52,279] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:43:52,285] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.646 seconds
[2022-02-18 23:44:04,924] {scheduler_job.py:155} INFO - Started process (PID=33449) to work on /airflow/dags/download_data.py
[2022-02-18 23:44:04,929] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:44:04,931] {logging_mixin.py:112} INFO - [2022-02-18 23:44:04,931] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:44:05,421] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:44:05,471] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:44:05,482] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:44:05,486] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 23:44:18,166] {scheduler_job.py:155} INFO - Started process (PID=33475) to work on /airflow/dags/download_data.py
[2022-02-18 23:44:18,175] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:44:18,178] {logging_mixin.py:112} INFO - [2022-02-18 23:44:18,178] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:44:18,647] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:44:18,703] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:44:18,716] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:44:18,722] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 23:44:31,447] {scheduler_job.py:155} INFO - Started process (PID=33501) to work on /airflow/dags/download_data.py
[2022-02-18 23:44:31,455] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:44:31,457] {logging_mixin.py:112} INFO - [2022-02-18 23:44:31,457] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:44:31,905] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:44:31,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:44:31,963] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:44:31,967] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 23:44:44,696] {scheduler_job.py:155} INFO - Started process (PID=33527) to work on /airflow/dags/download_data.py
[2022-02-18 23:44:44,701] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:44:44,703] {logging_mixin.py:112} INFO - [2022-02-18 23:44:44,703] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:44:45,204] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:44:45,258] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:44:45,268] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:44:45,272] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.577 seconds
[2022-02-18 23:44:57,990] {scheduler_job.py:155} INFO - Started process (PID=33553) to work on /airflow/dags/download_data.py
[2022-02-18 23:44:57,994] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:44:57,995] {logging_mixin.py:112} INFO - [2022-02-18 23:44:57,995] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:44:58,463] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:44:58,510] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:44:58,518] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:44:58,523] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.534 seconds
[2022-02-18 23:45:11,266] {scheduler_job.py:155} INFO - Started process (PID=33579) to work on /airflow/dags/download_data.py
[2022-02-18 23:45:11,271] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:45:11,274] {logging_mixin.py:112} INFO - [2022-02-18 23:45:11,274] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:45:11,745] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:45:11,795] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:45:11,807] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:45:11,815] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 23:45:24,544] {scheduler_job.py:155} INFO - Started process (PID=33605) to work on /airflow/dags/download_data.py
[2022-02-18 23:45:24,552] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:45:24,554] {logging_mixin.py:112} INFO - [2022-02-18 23:45:24,554] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:45:25,133] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:45:25,190] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:45:25,201] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:45:25,205] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.661 seconds
[2022-02-18 23:45:37,872] {scheduler_job.py:155} INFO - Started process (PID=33631) to work on /airflow/dags/download_data.py
[2022-02-18 23:45:37,880] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:45:37,882] {logging_mixin.py:112} INFO - [2022-02-18 23:45:37,882] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:45:38,323] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:45:38,385] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:45:38,395] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:45:38,401] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 23:45:51,121] {scheduler_job.py:155} INFO - Started process (PID=33657) to work on /airflow/dags/download_data.py
[2022-02-18 23:45:51,127] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:45:51,129] {logging_mixin.py:112} INFO - [2022-02-18 23:45:51,129] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:45:51,616] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:45:51,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:45:51,677] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:45:51,684] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.562 seconds
[2022-02-18 23:46:04,384] {scheduler_job.py:155} INFO - Started process (PID=33683) to work on /airflow/dags/download_data.py
[2022-02-18 23:46:04,388] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:46:04,390] {logging_mixin.py:112} INFO - [2022-02-18 23:46:04,389] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:46:04,846] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:46:04,887] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:46:04,897] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:46:04,903] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.519 seconds
[2022-02-18 23:46:17,654] {scheduler_job.py:155} INFO - Started process (PID=33709) to work on /airflow/dags/download_data.py
[2022-02-18 23:46:17,667] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:46:17,670] {logging_mixin.py:112} INFO - [2022-02-18 23:46:17,670] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:46:18,166] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:46:18,229] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:46:18,242] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:46:18,247] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 23:46:30,950] {scheduler_job.py:155} INFO - Started process (PID=33735) to work on /airflow/dags/download_data.py
[2022-02-18 23:46:30,959] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:46:30,961] {logging_mixin.py:112} INFO - [2022-02-18 23:46:30,960] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:46:31,410] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:46:31,455] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:46:31,478] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:46:31,483] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 23:46:44,221] {scheduler_job.py:155} INFO - Started process (PID=33761) to work on /airflow/dags/download_data.py
[2022-02-18 23:46:44,227] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:46:44,228] {logging_mixin.py:112} INFO - [2022-02-18 23:46:44,228] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:46:44,698] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:46:44,760] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:46:44,771] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:46:44,776] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.555 seconds
[2022-02-18 23:46:57,502] {scheduler_job.py:155} INFO - Started process (PID=33787) to work on /airflow/dags/download_data.py
[2022-02-18 23:46:57,509] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:46:57,513] {logging_mixin.py:112} INFO - [2022-02-18 23:46:57,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:46:58,080] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:46:58,127] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:46:58,139] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:46:58,149] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.646 seconds
[2022-02-18 23:47:10,805] {scheduler_job.py:155} INFO - Started process (PID=33813) to work on /airflow/dags/download_data.py
[2022-02-18 23:47:10,815] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:47:10,818] {logging_mixin.py:112} INFO - [2022-02-18 23:47:10,818] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:47:11,338] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:47:11,401] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:47:11,412] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:47:11,418] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.613 seconds
[2022-02-18 23:47:24,066] {scheduler_job.py:155} INFO - Started process (PID=33839) to work on /airflow/dags/download_data.py
[2022-02-18 23:47:24,071] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:47:24,073] {logging_mixin.py:112} INFO - [2022-02-18 23:47:24,073] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:47:24,537] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:47:24,597] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:47:24,607] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:47:24,615] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 23:47:37,338] {scheduler_job.py:155} INFO - Started process (PID=33865) to work on /airflow/dags/download_data.py
[2022-02-18 23:47:37,348] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:47:37,350] {logging_mixin.py:112} INFO - [2022-02-18 23:47:37,349] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:47:37,810] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:47:37,852] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:47:37,864] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:47:37,869] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.530 seconds
[2022-02-18 23:47:50,633] {scheduler_job.py:155} INFO - Started process (PID=33891) to work on /airflow/dags/download_data.py
[2022-02-18 23:47:50,639] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:47:50,642] {logging_mixin.py:112} INFO - [2022-02-18 23:47:50,641] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:47:51,147] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:47:51,207] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:47:51,219] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:47:51,226] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.593 seconds
[2022-02-18 23:48:04,147] {scheduler_job.py:155} INFO - Started process (PID=33917) to work on /airflow/dags/download_data.py
[2022-02-18 23:48:04,152] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:48:04,154] {logging_mixin.py:112} INFO - [2022-02-18 23:48:04,154] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:48:04,680] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:48:04,733] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:48:04,741] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:48:04,744] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 23:48:17,408] {scheduler_job.py:155} INFO - Started process (PID=33943) to work on /airflow/dags/download_data.py
[2022-02-18 23:48:17,414] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:48:17,416] {logging_mixin.py:112} INFO - [2022-02-18 23:48:17,415] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:48:17,891] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:48:17,957] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:48:17,968] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:48:17,974] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 23:48:30,687] {scheduler_job.py:155} INFO - Started process (PID=33969) to work on /airflow/dags/download_data.py
[2022-02-18 23:48:30,692] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:48:30,693] {logging_mixin.py:112} INFO - [2022-02-18 23:48:30,693] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:48:31,203] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:48:31,254] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:48:31,280] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:48:31,292] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.606 seconds
[2022-02-18 23:48:43,938] {scheduler_job.py:155} INFO - Started process (PID=33995) to work on /airflow/dags/download_data.py
[2022-02-18 23:48:43,942] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:48:43,944] {logging_mixin.py:112} INFO - [2022-02-18 23:48:43,944] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:48:44,418] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:48:44,477] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:48:44,487] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:48:44,491] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 23:48:57,227] {scheduler_job.py:155} INFO - Started process (PID=34021) to work on /airflow/dags/download_data.py
[2022-02-18 23:48:57,235] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:48:57,238] {logging_mixin.py:112} INFO - [2022-02-18 23:48:57,238] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:48:57,708] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:48:57,753] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:48:57,759] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:48:57,765] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.538 seconds
[2022-02-18 23:49:10,482] {scheduler_job.py:155} INFO - Started process (PID=34047) to work on /airflow/dags/download_data.py
[2022-02-18 23:49:10,487] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:49:10,488] {logging_mixin.py:112} INFO - [2022-02-18 23:49:10,488] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:49:10,948] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:49:11,003] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:49:11,011] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:49:11,015] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.533 seconds
[2022-02-18 23:49:23,773] {scheduler_job.py:155} INFO - Started process (PID=34073) to work on /airflow/dags/download_data.py
[2022-02-18 23:49:23,781] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:49:23,786] {logging_mixin.py:112} INFO - [2022-02-18 23:49:23,785] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:49:24,339] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:49:24,380] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:49:24,388] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:49:24,396] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.623 seconds
[2022-02-18 23:49:37,066] {scheduler_job.py:155} INFO - Started process (PID=34099) to work on /airflow/dags/download_data.py
[2022-02-18 23:49:37,073] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:49:37,076] {logging_mixin.py:112} INFO - [2022-02-18 23:49:37,075] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:49:37,544] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:49:37,602] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:49:37,616] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:49:37,622] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.556 seconds
[2022-02-18 23:49:50,332] {scheduler_job.py:155} INFO - Started process (PID=34125) to work on /airflow/dags/download_data.py
[2022-02-18 23:49:50,343] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:49:50,346] {logging_mixin.py:112} INFO - [2022-02-18 23:49:50,345] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:49:50,822] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:49:50,868] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:49:50,874] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:49:50,878] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.546 seconds
[2022-02-18 23:50:03,610] {scheduler_job.py:155} INFO - Started process (PID=34151) to work on /airflow/dags/download_data.py
[2022-02-18 23:50:03,615] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:50:03,617] {logging_mixin.py:112} INFO - [2022-02-18 23:50:03,616] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:50:04,072] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:50:04,123] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:50:04,129] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:50:04,132] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.522 seconds
[2022-02-18 23:50:16,863] {scheduler_job.py:155} INFO - Started process (PID=34177) to work on /airflow/dags/download_data.py
[2022-02-18 23:50:16,868] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:50:16,870] {logging_mixin.py:112} INFO - [2022-02-18 23:50:16,870] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:50:17,355] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:50:17,413] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:50:17,423] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:50:17,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.564 seconds
[2022-02-18 23:50:30,150] {scheduler_job.py:155} INFO - Started process (PID=34203) to work on /airflow/dags/download_data.py
[2022-02-18 23:50:30,158] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:50:30,161] {logging_mixin.py:112} INFO - [2022-02-18 23:50:30,160] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:50:30,641] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:50:30,684] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:50:30,693] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:50:30,699] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 23:50:43,458] {scheduler_job.py:155} INFO - Started process (PID=34229) to work on /airflow/dags/download_data.py
[2022-02-18 23:50:43,463] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:50:43,465] {logging_mixin.py:112} INFO - [2022-02-18 23:50:43,465] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:50:43,989] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:50:44,031] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:50:44,037] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:50:44,040] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.582 seconds
[2022-02-18 23:50:56,769] {scheduler_job.py:155} INFO - Started process (PID=34255) to work on /airflow/dags/download_data.py
[2022-02-18 23:50:56,776] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:50:56,779] {logging_mixin.py:112} INFO - [2022-02-18 23:50:56,779] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:50:57,328] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:50:57,386] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:50:57,397] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:50:57,403] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.634 seconds
[2022-02-18 23:51:10,059] {scheduler_job.py:155} INFO - Started process (PID=34281) to work on /airflow/dags/download_data.py
[2022-02-18 23:51:10,066] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:51:10,069] {logging_mixin.py:112} INFO - [2022-02-18 23:51:10,068] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:51:10,511] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:51:10,562] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:51:10,569] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:51:10,575] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.516 seconds
[2022-02-18 23:51:23,353] {scheduler_job.py:155} INFO - Started process (PID=34307) to work on /airflow/dags/download_data.py
[2022-02-18 23:51:23,361] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:51:23,363] {logging_mixin.py:112} INFO - [2022-02-18 23:51:23,363] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:51:23,917] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:51:23,981] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:51:23,988] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:51:23,993] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.641 seconds
[2022-02-18 23:51:36,651] {scheduler_job.py:155} INFO - Started process (PID=34333) to work on /airflow/dags/download_data.py
[2022-02-18 23:51:36,660] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:51:36,662] {logging_mixin.py:112} INFO - [2022-02-18 23:51:36,662] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:51:37,122] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:51:37,160] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:51:37,170] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:51:37,175] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 23:51:49,881] {scheduler_job.py:155} INFO - Started process (PID=34359) to work on /airflow/dags/download_data.py
[2022-02-18 23:51:49,888] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:51:49,890] {logging_mixin.py:112} INFO - [2022-02-18 23:51:49,890] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:51:50,341] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:51:50,389] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:51:50,397] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:51:50,402] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.521 seconds
[2022-02-18 23:52:03,136] {scheduler_job.py:155} INFO - Started process (PID=34385) to work on /airflow/dags/download_data.py
[2022-02-18 23:52:03,147] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:52:03,151] {logging_mixin.py:112} INFO - [2022-02-18 23:52:03,150] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:52:03,610] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:52:03,663] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:52:03,676] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:52:03,685] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.549 seconds
[2022-02-18 23:52:16,412] {scheduler_job.py:155} INFO - Started process (PID=34411) to work on /airflow/dags/download_data.py
[2022-02-18 23:52:16,418] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:52:16,420] {logging_mixin.py:112} INFO - [2022-02-18 23:52:16,419] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:52:16,981] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:52:17,027] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:52:17,037] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:52:17,044] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.632 seconds
[2022-02-18 23:52:29,726] {scheduler_job.py:155} INFO - Started process (PID=34437) to work on /airflow/dags/download_data.py
[2022-02-18 23:52:29,733] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:52:29,736] {logging_mixin.py:112} INFO - [2022-02-18 23:52:29,735] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:52:30,512] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:52:30,585] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:52:30,602] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:52:30,615] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.890 seconds
[2022-02-18 23:52:42,993] {scheduler_job.py:155} INFO - Started process (PID=34463) to work on /airflow/dags/download_data.py
[2022-02-18 23:52:42,999] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:52:43,001] {logging_mixin.py:112} INFO - [2022-02-18 23:52:43,000] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:52:43,538] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:52:43,588] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:52:43,598] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:52:43,603] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 23:52:56,305] {scheduler_job.py:155} INFO - Started process (PID=34489) to work on /airflow/dags/download_data.py
[2022-02-18 23:52:56,317] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:52:56,320] {logging_mixin.py:112} INFO - [2022-02-18 23:52:56,319] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:52:56,836] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:52:56,900] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:52:56,910] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:52:56,914] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.610 seconds
[2022-02-18 23:53:09,714] {scheduler_job.py:155} INFO - Started process (PID=34515) to work on /airflow/dags/download_data.py
[2022-02-18 23:53:09,724] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:53:09,726] {logging_mixin.py:112} INFO - [2022-02-18 23:53:09,726] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:53:10,215] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:53:10,293] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:53:10,305] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:53:10,311] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.598 seconds
[2022-02-18 23:53:22,979] {scheduler_job.py:155} INFO - Started process (PID=34541) to work on /airflow/dags/download_data.py
[2022-02-18 23:53:22,986] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:53:22,992] {logging_mixin.py:112} INFO - [2022-02-18 23:53:22,992] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:53:23,544] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:53:23,607] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:53:23,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:53:23,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.644 seconds
[2022-02-18 23:53:36,264] {scheduler_job.py:155} INFO - Started process (PID=34567) to work on /airflow/dags/download_data.py
[2022-02-18 23:53:36,271] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:53:36,273] {logging_mixin.py:112} INFO - [2022-02-18 23:53:36,273] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:53:36,714] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:53:36,765] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:53:36,772] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:53:36,777] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.513 seconds
[2022-02-18 23:53:49,501] {scheduler_job.py:155} INFO - Started process (PID=34593) to work on /airflow/dags/download_data.py
[2022-02-18 23:53:49,511] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:53:49,513] {logging_mixin.py:112} INFO - [2022-02-18 23:53:49,513] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:53:49,958] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:53:50,000] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:53:50,007] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:53:50,011] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.509 seconds
[2022-02-18 23:54:02,753] {scheduler_job.py:155} INFO - Started process (PID=34619) to work on /airflow/dags/download_data.py
[2022-02-18 23:54:02,763] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:54:02,767] {logging_mixin.py:112} INFO - [2022-02-18 23:54:02,766] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:54:03,252] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:54:03,303] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:54:03,313] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:54:03,321] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.568 seconds
[2022-02-18 23:54:16,008] {scheduler_job.py:155} INFO - Started process (PID=34645) to work on /airflow/dags/download_data.py
[2022-02-18 23:54:16,014] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:54:16,016] {logging_mixin.py:112} INFO - [2022-02-18 23:54:16,016] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:54:16,494] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:54:16,546] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:54:16,556] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:54:16,563] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.554 seconds
[2022-02-18 23:54:29,274] {scheduler_job.py:155} INFO - Started process (PID=34671) to work on /airflow/dags/download_data.py
[2022-02-18 23:54:29,279] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:54:29,281] {logging_mixin.py:112} INFO - [2022-02-18 23:54:29,281] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:54:29,727] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:54:29,780] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:54:29,786] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:54:29,791] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 23:54:42,513] {scheduler_job.py:155} INFO - Started process (PID=34697) to work on /airflow/dags/download_data.py
[2022-02-18 23:54:42,517] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:54:42,519] {logging_mixin.py:112} INFO - [2022-02-18 23:54:42,519] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:54:42,966] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:54:43,020] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:54:43,029] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:54:43,033] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 23:54:55,805] {scheduler_job.py:155} INFO - Started process (PID=34723) to work on /airflow/dags/download_data.py
[2022-02-18 23:54:55,811] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:54:55,813] {logging_mixin.py:112} INFO - [2022-02-18 23:54:55,813] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:54:56,316] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:54:56,372] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:54:56,382] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:54:56,389] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.584 seconds
[2022-02-18 23:55:09,052] {scheduler_job.py:155} INFO - Started process (PID=34749) to work on /airflow/dags/download_data.py
[2022-02-18 23:55:09,057] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:55:09,059] {logging_mixin.py:112} INFO - [2022-02-18 23:55:09,058] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:55:09,484] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:55:09,533] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:55:09,542] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:55:09,548] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.497 seconds
[2022-02-18 23:55:22,335] {scheduler_job.py:155} INFO - Started process (PID=34775) to work on /airflow/dags/download_data.py
[2022-02-18 23:55:22,341] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:55:22,343] {logging_mixin.py:112} INFO - [2022-02-18 23:55:22,343] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:55:22,822] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:55:22,883] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:55:22,896] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:55:22,901] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 23:55:35,604] {scheduler_job.py:155} INFO - Started process (PID=34801) to work on /airflow/dags/download_data.py
[2022-02-18 23:55:35,617] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:55:35,620] {logging_mixin.py:112} INFO - [2022-02-18 23:55:35,620] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:55:36,067] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:55:36,114] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:55:36,125] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:55:36,132] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 23:55:48,887] {scheduler_job.py:155} INFO - Started process (PID=34827) to work on /airflow/dags/download_data.py
[2022-02-18 23:55:48,891] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:55:48,892] {logging_mixin.py:112} INFO - [2022-02-18 23:55:48,892] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:55:49,336] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:55:49,381] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:55:49,387] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:55:49,394] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 23:56:02,148] {scheduler_job.py:155} INFO - Started process (PID=34853) to work on /airflow/dags/download_data.py
[2022-02-18 23:56:02,159] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:56:02,162] {logging_mixin.py:112} INFO - [2022-02-18 23:56:02,162] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:56:02,615] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:56:02,667] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:56:02,674] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:56:02,680] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.532 seconds
[2022-02-18 23:56:15,396] {scheduler_job.py:155} INFO - Started process (PID=34879) to work on /airflow/dags/download_data.py
[2022-02-18 23:56:15,408] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:56:15,410] {logging_mixin.py:112} INFO - [2022-02-18 23:56:15,410] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:56:15,873] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:56:15,916] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:56:15,922] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:56:15,925] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.529 seconds
[2022-02-18 23:56:28,657] {scheduler_job.py:155} INFO - Started process (PID=34905) to work on /airflow/dags/download_data.py
[2022-02-18 23:56:28,661] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:56:28,663] {logging_mixin.py:112} INFO - [2022-02-18 23:56:28,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:56:29,112] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:56:29,154] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:56:29,161] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:56:29,164] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.508 seconds
[2022-02-18 23:56:41,888] {scheduler_job.py:155} INFO - Started process (PID=34931) to work on /airflow/dags/download_data.py
[2022-02-18 23:56:41,897] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:56:41,899] {logging_mixin.py:112} INFO - [2022-02-18 23:56:41,898] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:56:42,356] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:56:42,413] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:56:42,420] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:56:42,424] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
[2022-02-18 23:56:55,183] {scheduler_job.py:155} INFO - Started process (PID=34957) to work on /airflow/dags/download_data.py
[2022-02-18 23:56:55,195] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:56:55,198] {logging_mixin.py:112} INFO - [2022-02-18 23:56:55,197] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:56:55,649] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:56:55,709] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:56:55,720] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:56:55,725] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.542 seconds
[2022-02-18 23:57:08,427] {scheduler_job.py:155} INFO - Started process (PID=34983) to work on /airflow/dags/download_data.py
[2022-02-18 23:57:08,432] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:57:08,435] {logging_mixin.py:112} INFO - [2022-02-18 23:57:08,434] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:57:08,886] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:57:08,939] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:57:08,948] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:57:08,951] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.524 seconds
[2022-02-18 23:57:21,712] {scheduler_job.py:155} INFO - Started process (PID=35009) to work on /airflow/dags/download_data.py
[2022-02-18 23:57:21,718] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:57:21,720] {logging_mixin.py:112} INFO - [2022-02-18 23:57:21,720] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:57:22,217] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:57:22,265] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:57:22,272] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:57:22,281] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.569 seconds
[2022-02-18 23:57:34,999] {scheduler_job.py:155} INFO - Started process (PID=35035) to work on /airflow/dags/download_data.py
[2022-02-18 23:57:35,003] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:57:35,004] {logging_mixin.py:112} INFO - [2022-02-18 23:57:35,004] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:57:35,459] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:57:35,510] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:57:35,515] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:57:35,518] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.520 seconds
[2022-02-18 23:57:48,254] {scheduler_job.py:155} INFO - Started process (PID=35061) to work on /airflow/dags/download_data.py
[2022-02-18 23:57:48,258] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:57:48,260] {logging_mixin.py:112} INFO - [2022-02-18 23:57:48,260] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:57:48,710] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:57:48,752] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:57:48,757] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:57:48,761] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.507 seconds
[2022-02-18 23:58:01,521] {scheduler_job.py:155} INFO - Started process (PID=35087) to work on /airflow/dags/download_data.py
[2022-02-18 23:58:01,526] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:58:01,528] {logging_mixin.py:112} INFO - [2022-02-18 23:58:01,528] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:58:01,967] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:58:02,014] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:58:02,025] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:58:02,031] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 23:58:14,780] {scheduler_job.py:155} INFO - Started process (PID=35113) to work on /airflow/dags/download_data.py
[2022-02-18 23:58:14,791] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:58:14,793] {logging_mixin.py:112} INFO - [2022-02-18 23:58:14,793] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:58:15,256] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:58:15,301] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:58:15,309] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:58:15,315] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.536 seconds
[2022-02-18 23:58:28,085] {scheduler_job.py:155} INFO - Started process (PID=35139) to work on /airflow/dags/download_data.py
[2022-02-18 23:58:28,092] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:58:28,093] {logging_mixin.py:112} INFO - [2022-02-18 23:58:28,093] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:58:28,558] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:58:28,608] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:58:28,618] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:58:28,624] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.539 seconds
[2022-02-18 23:58:41,348] {scheduler_job.py:155} INFO - Started process (PID=35165) to work on /airflow/dags/download_data.py
[2022-02-18 23:58:41,360] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:58:41,362] {logging_mixin.py:112} INFO - [2022-02-18 23:58:41,361] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:58:41,807] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:58:41,861] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:58:41,870] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:58:41,875] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.528 seconds
[2022-02-18 23:58:54,655] {scheduler_job.py:155} INFO - Started process (PID=35191) to work on /airflow/dags/download_data.py
[2022-02-18 23:58:54,661] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:58:54,663] {logging_mixin.py:112} INFO - [2022-02-18 23:58:54,663] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:58:55,115] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:58:55,150] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:58:55,155] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:58:55,158] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.504 seconds
[2022-02-18 23:59:07,917] {scheduler_job.py:155} INFO - Started process (PID=35217) to work on /airflow/dags/download_data.py
[2022-02-18 23:59:07,922] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:59:07,924] {logging_mixin.py:112} INFO - [2022-02-18 23:59:07,924] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:59:08,366] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:59:08,418] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:59:08,424] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:59:08,428] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.510 seconds
[2022-02-18 23:59:21,175] {scheduler_job.py:155} INFO - Started process (PID=35243) to work on /airflow/dags/download_data.py
[2022-02-18 23:59:21,180] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:59:21,182] {logging_mixin.py:112} INFO - [2022-02-18 23:59:21,182] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:59:21,660] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:59:21,724] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:59:21,736] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:59:21,741] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.566 seconds
[2022-02-18 23:59:34,457] {scheduler_job.py:155} INFO - Started process (PID=35269) to work on /airflow/dags/download_data.py
[2022-02-18 23:59:34,461] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:59:34,463] {logging_mixin.py:112} INFO - [2022-02-18 23:59:34,463] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:59:34,910] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:59:34,961] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:59:34,969] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:59:34,974] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.517 seconds
[2022-02-18 23:59:47,682] {scheduler_job.py:155} INFO - Started process (PID=35295) to work on /airflow/dags/download_data.py
[2022-02-18 23:59:47,690] {scheduler_job.py:1572} INFO - Processing file /airflow/dags/download_data.py for tasks to queue
[2022-02-18 23:59:47,692] {logging_mixin.py:112} INFO - [2022-02-18 23:59:47,691] {dagbag.py:417} INFO - Filling up the DagBag from /airflow/dags/download_data.py
[2022-02-18 23:59:48,160] {scheduler_job.py:1584} INFO - DAG(s) dict_keys(['0_download_data']) retrieved from /airflow/dags/download_data.py
[2022-02-18 23:59:48,209] {scheduler_job.py:1288} INFO - Processing 0_download_data
[2022-02-18 23:59:48,215] {scheduler_job.py:459} INFO - Skipping SLA check for <DAG: 0_download_data> because no tasks in DAG have SLAs
[2022-02-18 23:59:48,219] {scheduler_job.py:163} INFO - Processing /airflow/dags/download_data.py took 0.537 seconds
